{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils.GraphConvolution import GCN_Encoder_s, GCN_Classifier_s, Decoder_s\n",
    "from utils.GraphConvolution import GraphConvolution, GCN_Encoder3\n",
    "import argparse\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "import torch\n",
    "import ipdb\n",
    "from scipy.io import loadmat\n",
    "import utils\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    weight_decay = 5e-4\n",
    "    epochs = 300\n",
    "    learning_rate = 0.01\n",
    "    learning_rate_W = 0.01\n",
    "    dropout = 0.5\n",
    "    dropout_W = 0.5\n",
    "    gamma = 1\n",
    "    no_cuda = False\n",
    "    train_ratio=0.6\n",
    "    test_ratio=0.1\n",
    "    n_classes = 2\n",
    "    seed = 12345\n",
    "    torch.manual_seed(seed)\n",
    "    dataset = \"cora\"\n",
    "    # dataset = \"haberman\"\n",
    "    order = 4\n",
    "    n_features = 0\n",
    "    w_val_size = 10\n",
    "    imbalance_ratio = None\n",
    "    n_hidden = 64\n",
    "    setting = None\n",
    "    im_class_num = 3\n",
    "    setting = \"upsampling\"\n",
    "    opt_new_G = False\n",
    "    up_scale = 1\n",
    "    im_ratio = 0.5\n",
    "args = Args()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset specific variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_loader import data_loader_diabetes, data_loader_haberman, data_loader_cora\n",
    "\n",
    "cora_adj_mtx, cora_labels_df, cora_features_df, \\\n",
    "        cora_train_idx, cora_val_idx, cora_test_idx, cora_n_features = data_loader_cora(args)\n",
    "        \n",
    "diabetes_adj_mtx, diabetes_labels_df, diabetes_features_df, \\\n",
    "        diabetes_train_idx, diabetes_val_idx, diabetes_test_idx, diabetes_n_features = data_loader_diabetes(args)\n",
    "\n",
    "haberman_adj_mtx, haberman_labels_df, haberman_features_df, \\\n",
    "        haberman_train_idx, haberman_val_idx, haberman_test_idx, haberman_n_features = data_loader_haberman(args)\n",
    "\n",
    "if args.dataset == \"diabetes\":\n",
    "    adj_mtx = diabetes_adj_mtx\n",
    "    n_hidden = [64, 64, 64]\n",
    "    n_features = diabetes_n_features\n",
    "    features = diabetes_features_df\n",
    "    labels = diabetes_labels_df\n",
    "    # train_X = diabetes_train_X_df\n",
    "    # train_Y = diabetes_train_Y_df\n",
    "    # val_X = diabetes_val_X_df\n",
    "    # val_Y = diabetes_val_Y_df\n",
    "    # test_X = diabetes_test_X_df\n",
    "    # test_Y = diabetes_test_Y_df\n",
    "    train_idx = diabetes_train_idx\n",
    "    val_idx = diabetes_val_idx\n",
    "    test_idx = diabetes_test_idx\n",
    "elif args.dataset == \"cora\":\n",
    "    adj_mtx = cora_adj_mtx\n",
    "    n_hidden = [64, 64, 64]\n",
    "    n_features = cora_n_features\n",
    "    features = cora_features_df\n",
    "    labels = cora_labels_df\n",
    "    # train_X = diabetes_train_X_df\n",
    "    # train_Y = diabetes_train_Y_df\n",
    "    # val_X = diabetes_val_X_df\n",
    "    # val_Y = diabetes_val_Y_df\n",
    "    # test_X = diabetes_test_X_df\n",
    "    # test_Y = diabetes_test_Y_df\n",
    "    train_idx = cora_train_idx\n",
    "    val_idx = cora_val_idx\n",
    "    test_idx = cora_test_idx\n",
    "elif args.dataset == \"haberman\":\n",
    "    adj_mtx = haberman_adj_mtx\n",
    "    n_hidden = [64]\n",
    "    n_features = haberman_n_features\n",
    "    features = haberman_features_df\n",
    "    labels = haberman_labels_df\n",
    "    # train_X = haberman_train_X_df\n",
    "    # train_Y = haberman_train_Y_df\n",
    "    # val_X = haberman_val_X_df\n",
    "    # val_Y = haberman_val_Y_df\n",
    "    # test_X = haberman_test_X_df\n",
    "    # test_Y = haberman_test_Y_df\n",
    "    train_idx = haberman_train_idx\n",
    "    val_idx = haberman_val_idx\n",
    "    test_idx = haberman_test_idx\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(train_Y, columns=['labels']).labels.unique()\n",
    "# .groupby('Team')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert len(pd.DataFrame(val_Y, columns=['labels']).labels.unique()) == len(pd.DataFrame(train_Y, columns=['labels']).labels.unique()) == len(pd.DataFrame(test_Y, columns=['labels']).labels.unique()), \\\n",
    "#     \"There are some classes missing in one the 3 partitiones of the dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if False else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe to Tensor transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = torch.from_numpy(np.concatenate((train_X, val_X, test_X), axis=0)).to(device)\n",
    "# labels = torch.from_numpy(np.int64(np.concatenate((train_Y, val_Y, test_Y), axis=0))).to(device)\n",
    "train_idx = torch.from_numpy(np.array(train_idx, dtype = np.int64)).to(device)\n",
    "val_idx = torch.from_numpy(np.array(val_idx, dtype = np.int64)).to(device)\n",
    "test_idx = torch.from_numpy(np.array(test_idx, dtype = np.int64)).to(device)\n",
    "features = torch.from_numpy(np.array(features, dtype = np.float64)).to(device)\n",
    "labels = torch.from_numpy(np.array(labels, dtype = np.int64)).to(device)\n",
    "try:\n",
    "    adj_mtx = torch.from_numpy(np.array(adj_mtx, dtype = np.float64)).to(device)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.GraphConvolution import GCN_Encoder3, GCN_Classifier\n",
    "import time\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from utils.evaluation import accuracy, print_class_acc\n",
    "\n",
    "# encoder = GCN_Encoder3(nfeat=n_features,\n",
    "#         nhid=n_hidden,\n",
    "#         nembed=n_hidden[-1],\n",
    "#         dropout=args.dropout,\n",
    "#         nclass=args.n_classes,\n",
    "#         order=1)\n",
    "# classifier = GCN_Classifier(nembed=n_hidden[-1], \n",
    "#         nhid=n_hidden[-1], \n",
    "#         nclass=int(labels.max().item()) + 1, \n",
    "#         dropout=args.dropout, device=device)\n",
    "encoder = GCN_Encoder_s(nfeat = n_features, nhid = n_hidden[-1], nembed = n_hidden[-1], dropout = args.dropout)\n",
    "classifier = GCN_Classifier_s(nembed = n_hidden[-1], nhid = n_hidden[-1], nclass = int(labels.max().item()) + 1, dropout = args.dropout, device = device)\n",
    "optimizer_en = optim.Adam(encoder.parameters(),\n",
    "                       lr = args.learning_rate, weight_decay = args.weight_decay)\n",
    "optimizer_cls = optim.Adam(classifier.parameters(),\n",
    "                       lr = args.learning_rate, weight_decay = args.weight_decay)\n",
    "encoder.train()\n",
    "classifier.train()\n",
    "def train(epoch):\n",
    "        t = time.time()\n",
    "        optimizer_en.zero_grad()\n",
    "        optimizer_cls.zero_grad()\n",
    "        embed = encoder(features, adj_mtx)\n",
    "        output = classifier(embed, adj_mtx)\n",
    "        out = output[train_idx]\n",
    "        gt = labels[train_idx].reshape(-1)\n",
    "        if args.setting == 'reweight':\n",
    "                weight = \"STH\"\n",
    "                loss_train = F.cross_entropy(out, gt, weight = weight)\n",
    "        else:\n",
    "                loss_train = F.cross_entropy(out, gt)\n",
    "        acc_train = accuracy(out, gt)\n",
    "        loss_train.backward()\n",
    "        optimizer_en.step()\n",
    "        optimizer_cls.step()\n",
    "        gt_v = labels[test_idx].reshape(-1)\n",
    "        out_v = output[test_idx]\n",
    "        loss_val = F.cross_entropy(out_v, gt_v)\n",
    "        acc_val = accuracy(out_v, gt_v)\n",
    "        print_class_acc(out_v, gt_v)\n",
    "        print('Epoch: {:05d}'.format(epoch+ 1),\n",
    "          'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "          'acc_train: {:.4f}'.format(acc_train.item()),\n",
    "          'loss_val: {:.4f}'.format(loss_val.item()),\n",
    "          'acc_val: {:.4f}'.format(acc_val.item()),\n",
    "          'time: {:.4f}s'.format(time.time() - t))\n",
    "        \n",
    "        return acc_train.item(), acc_val.item(), loss_train.item(), loss_val.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid current auc-roc score: 0.518340, current macro_F score: 0.067606\n",
      "Epoch: 00001 loss_train: 1.8975 acc_train: 0.3079 loss_val: 1.8539 acc_val: 0.3100 time: 0.2419s\n",
      "valid current auc-roc score: 0.523352, current macro_F score: 0.067606\n",
      "Epoch: 00002 loss_train: 1.8939 acc_train: 0.3079 loss_val: 1.8613 acc_val: 0.3100 time: 0.5563s\n",
      "valid current auc-roc score: 0.501910, current macro_F score: 0.067606\n",
      "Epoch: 00003 loss_train: 1.8901 acc_train: 0.3079 loss_val: 1.8492 acc_val: 0.3100 time: 0.3589s\n",
      "valid current auc-roc score: 0.522767, current macro_F score: 0.067606\n",
      "Epoch: 00004 loss_train: 1.8882 acc_train: 0.3079 loss_val: 1.8420 acc_val: 0.3100 time: 0.3039s\n",
      "valid current auc-roc score: 0.510954, current macro_F score: 0.067606\n",
      "Epoch: 00005 loss_train: 1.8783 acc_train: 0.3079 loss_val: 1.8385 acc_val: 0.3100 time: 0.2365s\n",
      "valid current auc-roc score: 0.512946, current macro_F score: 0.067606\n",
      "Epoch: 00006 loss_train: 1.8797 acc_train: 0.3079 loss_val: 1.8456 acc_val: 0.3100 time: 0.2353s\n",
      "valid current auc-roc score: 0.521679, current macro_F score: 0.067606\n",
      "Epoch: 00007 loss_train: 1.8755 acc_train: 0.3079 loss_val: 1.8393 acc_val: 0.3100 time: 0.2709s\n",
      "valid current auc-roc score: 0.510057, current macro_F score: 0.067606\n",
      "Epoch: 00008 loss_train: 1.8701 acc_train: 0.3079 loss_val: 1.8310 acc_val: 0.3100 time: 0.3030s\n",
      "valid current auc-roc score: 0.489986, current macro_F score: 0.067606\n",
      "Epoch: 00009 loss_train: 1.8807 acc_train: 0.3079 loss_val: 1.8505 acc_val: 0.3100 time: 0.2202s\n",
      "valid current auc-roc score: 0.519927, current macro_F score: 0.067606\n",
      "Epoch: 00010 loss_train: 1.8639 acc_train: 0.3079 loss_val: 1.8289 acc_val: 0.3100 time: 0.4297s\n",
      "valid current auc-roc score: 0.510834, current macro_F score: 0.067606\n",
      "Epoch: 00011 loss_train: 1.8581 acc_train: 0.3079 loss_val: 1.8401 acc_val: 0.3100 time: 0.2427s\n",
      "valid current auc-roc score: 0.514547, current macro_F score: 0.067606\n",
      "Epoch: 00012 loss_train: 1.8584 acc_train: 0.3079 loss_val: 1.8372 acc_val: 0.3100 time: 0.3195s\n",
      "valid current auc-roc score: 0.518609, current macro_F score: 0.067606\n",
      "Epoch: 00013 loss_train: 1.8559 acc_train: 0.3079 loss_val: 1.8283 acc_val: 0.3100 time: 0.2322s\n",
      "valid current auc-roc score: 0.505245, current macro_F score: 0.067606\n",
      "Epoch: 00014 loss_train: 1.8567 acc_train: 0.3079 loss_val: 1.8393 acc_val: 0.3100 time: 0.1907s\n",
      "valid current auc-roc score: 0.525608, current macro_F score: 0.068376\n",
      "Epoch: 00015 loss_train: 1.8451 acc_train: 0.3060 loss_val: 1.8256 acc_val: 0.3100 time: 0.2071s\n",
      "valid current auc-roc score: 0.533640, current macro_F score: 0.068966\n",
      "Epoch: 00016 loss_train: 1.8219 acc_train: 0.3079 loss_val: 1.8043 acc_val: 0.3100 time: 0.1584s\n",
      "valid current auc-roc score: 0.537639, current macro_F score: 0.101172\n",
      "Epoch: 00017 loss_train: 1.8226 acc_train: 0.3245 loss_val: 1.7962 acc_val: 0.3247 time: 0.1451s\n",
      "valid current auc-roc score: 0.535730, current macro_F score: 0.095540\n",
      "Epoch: 00018 loss_train: 1.8358 acc_train: 0.3048 loss_val: 1.8129 acc_val: 0.3173 time: 0.1548s\n",
      "valid current auc-roc score: 0.574754, current macro_F score: 0.091085\n",
      "Epoch: 00019 loss_train: 1.7866 acc_train: 0.3374 loss_val: 1.7867 acc_val: 0.3137 time: 0.1433s\n",
      "valid current auc-roc score: 0.552730, current macro_F score: 0.081656\n",
      "Epoch: 00020 loss_train: 1.7930 acc_train: 0.3374 loss_val: 1.8116 acc_val: 0.3137 time: 0.1289s\n",
      "valid current auc-roc score: 0.570533, current macro_F score: 0.118228\n",
      "Epoch: 00021 loss_train: 1.7821 acc_train: 0.3399 loss_val: 1.7558 acc_val: 0.3358 time: 0.1425s\n",
      "valid current auc-roc score: 0.522593, current macro_F score: 0.102585\n",
      "Epoch: 00022 loss_train: 1.7816 acc_train: 0.3417 loss_val: 1.7874 acc_val: 0.3284 time: 0.1517s\n",
      "valid current auc-roc score: 0.554648, current macro_F score: 0.112785\n",
      "Epoch: 00023 loss_train: 1.7725 acc_train: 0.3405 loss_val: 1.7666 acc_val: 0.3321 time: 0.1362s\n",
      "valid current auc-roc score: 0.533634, current macro_F score: 0.094966\n",
      "Epoch: 00024 loss_train: 1.8019 acc_train: 0.3344 loss_val: 1.8016 acc_val: 0.3210 time: 0.1362s\n",
      "valid current auc-roc score: 0.568702, current macro_F score: 0.105805\n",
      "Epoch: 00025 loss_train: 1.7634 acc_train: 0.3399 loss_val: 1.7782 acc_val: 0.3284 time: 0.1346s\n",
      "valid current auc-roc score: 0.550258, current macro_F score: 0.099594\n",
      "Epoch: 00026 loss_train: 1.8080 acc_train: 0.3239 loss_val: 1.7844 acc_val: 0.3247 time: 0.1379s\n",
      "valid current auc-roc score: 0.576148, current macro_F score: 0.106436\n",
      "Epoch: 00027 loss_train: 1.7748 acc_train: 0.3374 loss_val: 1.7785 acc_val: 0.3284 time: 0.1455s\n",
      "valid current auc-roc score: 0.567265, current macro_F score: 0.128461\n",
      "Epoch: 00028 loss_train: 1.7775 acc_train: 0.3411 loss_val: 1.7473 acc_val: 0.3432 time: 0.1642s\n",
      "valid current auc-roc score: 0.544978, current macro_F score: 0.114420\n",
      "Epoch: 00029 loss_train: 1.7843 acc_train: 0.3362 loss_val: 1.7721 acc_val: 0.3358 time: 0.1724s\n",
      "valid current auc-roc score: 0.532029, current macro_F score: 0.101172\n",
      "Epoch: 00030 loss_train: 1.7822 acc_train: 0.3387 loss_val: 1.7864 acc_val: 0.3247 time: 0.1617s\n",
      "valid current auc-roc score: 0.545384, current macro_F score: 0.102585\n",
      "Epoch: 00031 loss_train: 1.7897 acc_train: 0.3356 loss_val: 1.7877 acc_val: 0.3284 time: 0.1474s\n",
      "valid current auc-roc score: 0.536589, current macro_F score: 0.067606\n",
      "Epoch: 00032 loss_train: 1.8147 acc_train: 0.3079 loss_val: 1.8053 acc_val: 0.3100 time: 0.1424s\n",
      "valid current auc-roc score: 0.567194, current macro_F score: 0.102585\n",
      "Epoch: 00033 loss_train: 1.7830 acc_train: 0.3479 loss_val: 1.7591 acc_val: 0.3284 time: 0.1444s\n",
      "valid current auc-roc score: 0.548777, current macro_F score: 0.067606\n",
      "Epoch: 00034 loss_train: 1.8304 acc_train: 0.3079 loss_val: 1.8112 acc_val: 0.3100 time: 0.1388s\n",
      "valid current auc-roc score: 0.554013, current macro_F score: 0.125265\n",
      "Epoch: 00035 loss_train: 1.8349 acc_train: 0.3381 loss_val: 1.7930 acc_val: 0.3432 time: 0.1720s\n",
      "valid current auc-roc score: 0.553595, current macro_F score: 0.108635\n",
      "Epoch: 00036 loss_train: 1.7574 acc_train: 0.3498 loss_val: 1.7554 acc_val: 0.3321 time: 0.1504s\n",
      "valid current auc-roc score: 0.584598, current macro_F score: 0.112785\n",
      "Epoch: 00037 loss_train: 1.7894 acc_train: 0.3171 loss_val: 1.7615 acc_val: 0.3321 time: 0.1418s\n",
      "valid current auc-roc score: 0.549426, current macro_F score: 0.108635\n",
      "Epoch: 00038 loss_train: 1.7917 acc_train: 0.3417 loss_val: 1.7773 acc_val: 0.3321 time: 0.1441s\n",
      "valid current auc-roc score: 0.592517, current macro_F score: 0.112785\n",
      "Epoch: 00039 loss_train: 1.7551 acc_train: 0.3411 loss_val: 1.7414 acc_val: 0.3321 time: 0.1346s\n",
      "valid current auc-roc score: 0.570681, current macro_F score: 0.114420\n",
      "Epoch: 00040 loss_train: 1.7595 acc_train: 0.3417 loss_val: 1.7578 acc_val: 0.3358 time: 0.1329s\n",
      "valid current auc-roc score: 0.587719, current macro_F score: 0.108635\n",
      "Epoch: 00041 loss_train: 1.7371 acc_train: 0.3399 loss_val: 1.7462 acc_val: 0.3321 time: 0.1407s\n",
      "valid current auc-roc score: 0.593680, current macro_F score: 0.128461\n",
      "Epoch: 00042 loss_train: 1.7388 acc_train: 0.3442 loss_val: 1.7264 acc_val: 0.3432 time: 0.1767s\n",
      "valid current auc-roc score: 0.541636, current macro_F score: 0.102585\n",
      "Epoch: 00043 loss_train: 1.7997 acc_train: 0.3387 loss_val: 1.8335 acc_val: 0.3284 time: 0.1417s\n",
      "valid current auc-roc score: 0.575719, current macro_F score: 0.108635\n",
      "Epoch: 00044 loss_train: 1.7466 acc_train: 0.3319 loss_val: 1.7350 acc_val: 0.3321 time: 0.1315s\n",
      "valid current auc-roc score: 0.582296, current macro_F score: 0.125265\n",
      "Epoch: 00045 loss_train: 1.7436 acc_train: 0.3374 loss_val: 1.7291 acc_val: 0.3432 time: 0.1382s\n",
      "valid current auc-roc score: 0.579342, current macro_F score: 0.112785\n",
      "Epoch: 00046 loss_train: 1.7560 acc_train: 0.3331 loss_val: 1.7616 acc_val: 0.3321 time: 0.1359s\n",
      "valid current auc-roc score: 0.585718, current macro_F score: 0.119958\n",
      "Epoch: 00047 loss_train: 1.7618 acc_train: 0.3424 loss_val: 1.7371 acc_val: 0.3395 time: 0.1355s\n",
      "valid current auc-roc score: 0.580441, current macro_F score: 0.108635\n",
      "Epoch: 00048 loss_train: 1.7655 acc_train: 0.3411 loss_val: 1.7418 acc_val: 0.3321 time: 0.1342s\n",
      "valid current auc-roc score: 0.565024, current macro_F score: 0.104008\n",
      "Epoch: 00049 loss_train: 1.7535 acc_train: 0.3264 loss_val: 1.7752 acc_val: 0.3137 time: 0.1552s\n",
      "valid current auc-roc score: 0.554294, current macro_F score: 0.089610\n",
      "Epoch: 00050 loss_train: 1.7542 acc_train: 0.3473 loss_val: 1.7877 acc_val: 0.3210 time: 0.1261s\n",
      "valid current auc-roc score: 0.557480, current macro_F score: 0.108635\n",
      "Epoch: 00051 loss_train: 1.7343 acc_train: 0.3356 loss_val: 1.7664 acc_val: 0.3321 time: 0.1305s\n",
      "valid current auc-roc score: 0.571821, current macro_F score: 0.108288\n",
      "Epoch: 00052 loss_train: 1.7600 acc_train: 0.3147 loss_val: 1.7603 acc_val: 0.3247 time: 0.1126s\n",
      "valid current auc-roc score: 0.575471, current macro_F score: 0.098513\n",
      "Epoch: 00053 loss_train: 1.7535 acc_train: 0.3208 loss_val: 1.7593 acc_val: 0.3100 time: 0.1250s\n",
      "valid current auc-roc score: 0.570268, current macro_F score: 0.104651\n",
      "Epoch: 00054 loss_train: 3.0209 acc_train: 0.3220 loss_val: 2.4165 acc_val: 0.3284 time: 0.1314s\n",
      "valid current auc-roc score: 0.575809, current macro_F score: 0.118228\n",
      "Epoch: 00055 loss_train: 1.7582 acc_train: 0.3553 loss_val: 1.7821 acc_val: 0.3358 time: 0.1354s\n",
      "valid current auc-roc score: 0.578762, current macro_F score: 0.124728\n",
      "Epoch: 00056 loss_train: 1.7991 acc_train: 0.3300 loss_val: 1.7425 acc_val: 0.3395 time: 0.1255s\n",
      "valid current auc-roc score: 0.574544, current macro_F score: 0.105998\n",
      "Epoch: 00057 loss_train: 1.7836 acc_train: 0.3140 loss_val: 1.7697 acc_val: 0.3173 time: 0.2002s\n",
      "valid current auc-roc score: 0.571626, current macro_F score: 0.081656\n",
      "Epoch: 00058 loss_train: 1.7676 acc_train: 0.3442 loss_val: 1.7926 acc_val: 0.3137 time: 0.1633s\n",
      "valid current auc-roc score: 0.567990, current macro_F score: 0.107106\n",
      "Epoch: 00059 loss_train: 1.8000 acc_train: 0.3387 loss_val: 1.8036 acc_val: 0.3284 time: 0.1660s\n",
      "valid current auc-roc score: 0.530528, current macro_F score: 0.102585\n",
      "Epoch: 00060 loss_train: 1.7901 acc_train: 0.3331 loss_val: 1.7881 acc_val: 0.3284 time: 0.1631s\n",
      "valid current auc-roc score: 0.561280, current macro_F score: 0.102585\n",
      "Epoch: 00061 loss_train: 1.7689 acc_train: 0.3405 loss_val: 1.7837 acc_val: 0.3284 time: 0.1567s\n",
      "valid current auc-roc score: 0.595474, current macro_F score: 0.101172\n",
      "Epoch: 00062 loss_train: 1.7688 acc_train: 0.3399 loss_val: 1.7757 acc_val: 0.3247 time: 0.1352s\n",
      "valid current auc-roc score: 0.590391, current macro_F score: 0.117603\n",
      "Epoch: 00063 loss_train: 1.7702 acc_train: 0.3411 loss_val: 1.7821 acc_val: 0.3321 time: 0.1686s\n",
      "valid current auc-roc score: 0.533319, current macro_F score: 0.134355\n",
      "Epoch: 00064 loss_train: 2.8656 acc_train: 0.3140 loss_val: 2.4812 acc_val: 0.3284 time: 0.1494s\n",
      "valid current auc-roc score: 0.576793, current macro_F score: 0.107698\n",
      "Epoch: 00065 loss_train: 1.7795 acc_train: 0.3405 loss_val: 1.7849 acc_val: 0.3284 time: 0.1635s\n",
      "valid current auc-roc score: 0.572954, current macro_F score: 0.123448\n",
      "Epoch: 00066 loss_train: 1.7764 acc_train: 0.3214 loss_val: 1.7491 acc_val: 0.3395 time: 0.1441s\n",
      "valid current auc-roc score: 0.551932, current macro_F score: 0.102585\n",
      "Epoch: 00067 loss_train: 1.7792 acc_train: 0.3319 loss_val: 1.7830 acc_val: 0.3284 time: 0.1589s\n",
      "valid current auc-roc score: 0.557440, current macro_F score: 0.108635\n",
      "Epoch: 00068 loss_train: 1.8173 acc_train: 0.3368 loss_val: 1.7654 acc_val: 0.3321 time: 0.1475s\n",
      "valid current auc-roc score: 0.588123, current macro_F score: 0.137911\n",
      "Epoch: 00069 loss_train: 1.8258 acc_train: 0.3485 loss_val: 1.7275 acc_val: 0.3506 time: 0.1683s\n",
      "valid current auc-roc score: 0.561148, current macro_F score: 0.093298\n",
      "Epoch: 00070 loss_train: 1.8121 acc_train: 0.3208 loss_val: 1.7820 acc_val: 0.3173 time: 0.1686s\n",
      "valid current auc-roc score: 0.561532, current macro_F score: 0.108635\n",
      "Epoch: 00071 loss_train: 1.8248 acc_train: 0.3516 loss_val: 1.7694 acc_val: 0.3321 time: 0.1535s\n",
      "valid current auc-roc score: 0.596448, current macro_F score: 0.101172\n",
      "Epoch: 00072 loss_train: 1.7789 acc_train: 0.3411 loss_val: 1.7713 acc_val: 0.3247 time: 0.1377s\n",
      "valid current auc-roc score: 0.557222, current macro_F score: 0.114420\n",
      "Epoch: 00073 loss_train: 1.7736 acc_train: 0.3362 loss_val: 1.7557 acc_val: 0.3358 time: 0.1535s\n",
      "valid current auc-roc score: 0.532481, current macro_F score: 0.067606\n",
      "Epoch: 00074 loss_train: 1.8309 acc_train: 0.3085 loss_val: 1.8220 acc_val: 0.3100 time: 0.1340s\n",
      "valid current auc-roc score: 0.555163, current macro_F score: 0.067606\n",
      "Epoch: 00075 loss_train: 1.7999 acc_train: 0.3085 loss_val: 1.7913 acc_val: 0.3100 time: 0.1301s\n",
      "valid current auc-roc score: 0.556807, current macro_F score: 0.067606\n",
      "Epoch: 00076 loss_train: 1.8114 acc_train: 0.3079 loss_val: 1.8049 acc_val: 0.3100 time: 0.1489s\n",
      "valid current auc-roc score: 0.593308, current macro_F score: 0.089610\n",
      "Epoch: 00077 loss_train: 1.7774 acc_train: 0.3251 loss_val: 1.7697 acc_val: 0.3210 time: 0.1440s\n",
      "valid current auc-roc score: 0.579295, current macro_F score: 0.114420\n",
      "Epoch: 00078 loss_train: 1.7684 acc_train: 0.3368 loss_val: 1.7605 acc_val: 0.3358 time: 0.1376s\n",
      "valid current auc-roc score: 0.542920, current macro_F score: 0.114420\n",
      "Epoch: 00079 loss_train: 1.7841 acc_train: 0.3374 loss_val: 1.7683 acc_val: 0.3358 time: 0.1289s\n",
      "valid current auc-roc score: 0.546742, current macro_F score: 0.101172\n",
      "Epoch: 00080 loss_train: 1.7958 acc_train: 0.3325 loss_val: 1.7850 acc_val: 0.3247 time: 0.1404s\n",
      "valid current auc-roc score: 0.559557, current macro_F score: 0.102585\n",
      "Epoch: 00081 loss_train: 1.7896 acc_train: 0.3399 loss_val: 1.7779 acc_val: 0.3284 time: 0.1340s\n",
      "valid current auc-roc score: 0.570132, current macro_F score: 0.107927\n",
      "Epoch: 00082 loss_train: 1.8049 acc_train: 0.3424 loss_val: 1.7847 acc_val: 0.3321 time: 0.1343s\n",
      "valid current auc-roc score: 0.580250, current macro_F score: 0.125265\n",
      "Epoch: 00083 loss_train: 1.7647 acc_train: 0.3498 loss_val: 1.7360 acc_val: 0.3432 time: 0.1739s\n",
      "valid current auc-roc score: 0.567597, current macro_F score: 0.108635\n",
      "Epoch: 00084 loss_train: 1.8080 acc_train: 0.3313 loss_val: 1.7635 acc_val: 0.3321 time: 0.1643s\n",
      "valid current auc-roc score: 0.603369, current macro_F score: 0.118228\n",
      "Epoch: 00085 loss_train: 1.7562 acc_train: 0.3393 loss_val: 1.7581 acc_val: 0.3358 time: 0.1585s\n",
      "valid current auc-roc score: 0.582527, current macro_F score: 0.120801\n",
      "Epoch: 00086 loss_train: 1.7429 acc_train: 0.3491 loss_val: 1.7547 acc_val: 0.3432 time: 0.1429s\n",
      "valid current auc-roc score: 0.597593, current macro_F score: 0.140244\n",
      "Epoch: 00087 loss_train: 1.8046 acc_train: 0.3411 loss_val: 1.7536 acc_val: 0.3506 time: 0.1458s\n",
      "valid current auc-roc score: 0.571952, current macro_F score: 0.153347\n",
      "Epoch: 00088 loss_train: 1.8000 acc_train: 0.3479 loss_val: 1.7542 acc_val: 0.3395 time: 0.1470s\n",
      "valid current auc-roc score: 0.572568, current macro_F score: 0.095552\n",
      "Epoch: 00089 loss_train: 1.7606 acc_train: 0.3411 loss_val: 1.8013 acc_val: 0.3210 time: 0.1387s\n",
      "valid current auc-roc score: 0.570822, current macro_F score: 0.096251\n",
      "Epoch: 00090 loss_train: 1.7902 acc_train: 0.3331 loss_val: 1.7704 acc_val: 0.3247 time: 0.1568s\n",
      "valid current auc-roc score: 0.574706, current macro_F score: 0.125265\n",
      "Epoch: 00091 loss_train: 1.7624 acc_train: 0.3528 loss_val: 1.7521 acc_val: 0.3432 time: 0.1618s\n",
      "valid current auc-roc score: 0.578388, current macro_F score: 0.108635\n",
      "Epoch: 00092 loss_train: 1.7720 acc_train: 0.3399 loss_val: 1.7638 acc_val: 0.3321 time: 0.1384s\n",
      "valid current auc-roc score: 0.548203, current macro_F score: 0.089610\n",
      "Epoch: 00093 loss_train: 1.7743 acc_train: 0.3454 loss_val: 1.7866 acc_val: 0.3210 time: 0.1393s\n",
      "valid current auc-roc score: 0.576224, current macro_F score: 0.107106\n",
      "Epoch: 00094 loss_train: 1.7841 acc_train: 0.3344 loss_val: 1.7628 acc_val: 0.3284 time: 0.1515s\n",
      "valid current auc-roc score: 0.571583, current macro_F score: 0.088468\n",
      "Epoch: 00095 loss_train: 1.7772 acc_train: 0.3331 loss_val: 1.7807 acc_val: 0.3173 time: 0.1316s\n",
      "valid current auc-roc score: 0.564470, current macro_F score: 0.128461\n",
      "Epoch: 00096 loss_train: 1.7546 acc_train: 0.3467 loss_val: 1.7607 acc_val: 0.3432 time: 0.1391s\n",
      "valid current auc-roc score: 0.582276, current macro_F score: 0.123448\n",
      "Epoch: 00097 loss_train: 1.7570 acc_train: 0.3491 loss_val: 1.7435 acc_val: 0.3395 time: 0.1603s\n",
      "valid current auc-roc score: 0.538346, current macro_F score: 0.067606\n",
      "Epoch: 00098 loss_train: 1.8107 acc_train: 0.3103 loss_val: 1.8132 acc_val: 0.3100 time: 0.1435s\n",
      "valid current auc-roc score: 0.587427, current macro_F score: 0.123012\n",
      "Epoch: 00099 loss_train: 1.7760 acc_train: 0.3288 loss_val: 1.7714 acc_val: 0.3358 time: 0.1291s\n",
      "valid current auc-roc score: 0.563502, current macro_F score: 0.123052\n",
      "Epoch: 00100 loss_train: 1.7634 acc_train: 0.3233 loss_val: 1.7623 acc_val: 0.3321 time: 0.1311s\n",
      "valid current auc-roc score: 0.584377, current macro_F score: 0.081656\n",
      "Epoch: 00101 loss_train: 1.7615 acc_train: 0.3171 loss_val: 1.7877 acc_val: 0.3137 time: 0.1276s\n",
      "valid current auc-roc score: 0.581929, current macro_F score: 0.115725\n",
      "Epoch: 00102 loss_train: 1.7983 acc_train: 0.3578 loss_val: 1.8096 acc_val: 0.3321 time: 0.1342s\n",
      "valid current auc-roc score: 0.577078, current macro_F score: 0.102585\n",
      "Epoch: 00103 loss_train: 1.7454 acc_train: 0.3467 loss_val: 1.7630 acc_val: 0.3284 time: 0.1295s\n",
      "valid current auc-roc score: 0.563871, current macro_F score: 0.108635\n",
      "Epoch: 00104 loss_train: 1.7563 acc_train: 0.3461 loss_val: 1.7615 acc_val: 0.3321 time: 0.1425s\n",
      "valid current auc-roc score: 0.580904, current macro_F score: 0.121616\n",
      "Epoch: 00105 loss_train: 1.7721 acc_train: 0.3491 loss_val: 1.7570 acc_val: 0.3395 time: 0.1452s\n",
      "valid current auc-roc score: 0.590066, current macro_F score: 0.112785\n",
      "Epoch: 00106 loss_train: 1.7724 acc_train: 0.3479 loss_val: 1.7735 acc_val: 0.3321 time: 0.1313s\n",
      "valid current auc-roc score: 0.545757, current macro_F score: 0.107106\n",
      "Epoch: 00107 loss_train: 1.7780 acc_train: 0.3454 loss_val: 1.7790 acc_val: 0.3284 time: 0.1299s\n",
      "valid current auc-roc score: 0.555127, current macro_F score: 0.105613\n",
      "Epoch: 00108 loss_train: 1.7705 acc_train: 0.3516 loss_val: 1.8001 acc_val: 0.3247 time: 0.1379s\n",
      "valid current auc-roc score: 0.548584, current macro_F score: 0.101172\n",
      "Epoch: 00109 loss_train: 1.7654 acc_train: 0.3461 loss_val: 1.7910 acc_val: 0.3247 time: 0.1400s\n",
      "valid current auc-roc score: 0.551055, current macro_F score: 0.108635\n",
      "Epoch: 00110 loss_train: 1.7936 acc_train: 0.3325 loss_val: 1.7800 acc_val: 0.3321 time: 0.1846s\n",
      "valid current auc-roc score: 0.553184, current macro_F score: 0.112465\n",
      "Epoch: 00111 loss_train: 1.7416 acc_train: 0.3504 loss_val: 1.7737 acc_val: 0.3321 time: 0.1792s\n",
      "valid current auc-roc score: 0.576042, current macro_F score: 0.112785\n",
      "Epoch: 00112 loss_train: 1.7561 acc_train: 0.3405 loss_val: 1.7618 acc_val: 0.3321 time: 0.1714s\n",
      "valid current auc-roc score: 0.574124, current macro_F score: 0.100546\n",
      "Epoch: 00113 loss_train: 1.7605 acc_train: 0.3294 loss_val: 1.7876 acc_val: 0.3210 time: 0.1678s\n",
      "valid current auc-roc score: 0.587958, current macro_F score: 0.120158\n",
      "Epoch: 00114 loss_train: 1.7371 acc_train: 0.3350 loss_val: 1.7365 acc_val: 0.3395 time: 0.1475s\n",
      "valid current auc-roc score: 0.583559, current macro_F score: 0.118427\n",
      "Epoch: 00115 loss_train: 1.7669 acc_train: 0.3411 loss_val: 1.7677 acc_val: 0.3358 time: 0.1611s\n",
      "valid current auc-roc score: 0.581318, current macro_F score: 0.113795\n",
      "Epoch: 00116 loss_train: 1.7585 acc_train: 0.3337 loss_val: 1.7521 acc_val: 0.3321 time: 0.1436s\n",
      "valid current auc-roc score: 0.564370, current macro_F score: 0.096251\n",
      "Epoch: 00117 loss_train: 1.7407 acc_train: 0.3442 loss_val: 1.7813 acc_val: 0.3247 time: 0.1633s\n",
      "valid current auc-roc score: 0.578486, current macro_F score: 0.107198\n",
      "Epoch: 00118 loss_train: 1.7691 acc_train: 0.3461 loss_val: 1.7623 acc_val: 0.3284 time: 0.1464s\n",
      "valid current auc-roc score: 0.563546, current macro_F score: 0.067606\n",
      "Epoch: 00119 loss_train: 1.8014 acc_train: 0.3097 loss_val: 1.7952 acc_val: 0.3100 time: 0.1447s\n",
      "valid current auc-roc score: 0.623433, current macro_F score: 0.119054\n",
      "Epoch: 00120 loss_train: 1.7556 acc_train: 0.3417 loss_val: 1.7318 acc_val: 0.3395 time: 0.1234s\n",
      "valid current auc-roc score: 0.594451, current macro_F score: 0.118228\n",
      "Epoch: 00121 loss_train: 1.7530 acc_train: 0.3374 loss_val: 1.7647 acc_val: 0.3358 time: 0.1400s\n",
      "valid current auc-roc score: 0.589082, current macro_F score: 0.119054\n",
      "Epoch: 00122 loss_train: 1.7706 acc_train: 0.3393 loss_val: 1.7454 acc_val: 0.3395 time: 0.1422s\n",
      "valid current auc-roc score: 0.571930, current macro_F score: 0.085670\n",
      "Epoch: 00123 loss_train: 1.8236 acc_train: 0.3300 loss_val: 1.7904 acc_val: 0.3100 time: 0.1272s\n",
      "valid current auc-roc score: 0.623310, current macro_F score: 0.132405\n",
      "Epoch: 00124 loss_train: 1.7506 acc_train: 0.3393 loss_val: 1.7664 acc_val: 0.3358 time: 0.1632s\n",
      "valid current auc-roc score: 0.563998, current macro_F score: 0.118228\n",
      "Epoch: 00125 loss_train: 1.7727 acc_train: 0.3454 loss_val: 1.7566 acc_val: 0.3358 time: 0.1505s\n",
      "valid current auc-roc score: 0.600584, current macro_F score: 0.112785\n",
      "Epoch: 00126 loss_train: 1.7382 acc_train: 0.3485 loss_val: 1.7517 acc_val: 0.3321 time: 0.1345s\n",
      "valid current auc-roc score: 0.613017, current macro_F score: 0.105211\n",
      "Epoch: 00127 loss_train: 1.7325 acc_train: 0.3350 loss_val: 1.7416 acc_val: 0.3284 time: 0.1395s\n",
      "valid current auc-roc score: 0.584645, current macro_F score: 0.108635\n",
      "Epoch: 00128 loss_train: 1.7653 acc_train: 0.3399 loss_val: 1.7690 acc_val: 0.3321 time: 0.1328s\n",
      "valid current auc-roc score: 0.586242, current macro_F score: 0.102585\n",
      "Epoch: 00129 loss_train: 1.7793 acc_train: 0.3393 loss_val: 1.7746 acc_val: 0.3284 time: 0.1298s\n",
      "valid current auc-roc score: 0.583971, current macro_F score: 0.119958\n",
      "Epoch: 00130 loss_train: 1.7470 acc_train: 0.3448 loss_val: 1.7418 acc_val: 0.3395 time: 0.1244s\n",
      "valid current auc-roc score: 0.550833, current macro_F score: 0.087625\n",
      "Epoch: 00131 loss_train: 1.7533 acc_train: 0.3270 loss_val: 1.7956 acc_val: 0.3173 time: 0.1276s\n",
      "valid current auc-roc score: 0.584556, current macro_F score: 0.127447\n",
      "Epoch: 00132 loss_train: 1.7422 acc_train: 0.3454 loss_val: 1.7491 acc_val: 0.3432 time: 0.1349s\n",
      "valid current auc-roc score: 0.591002, current macro_F score: 0.096207\n",
      "Epoch: 00133 loss_train: 1.7589 acc_train: 0.3374 loss_val: 1.7745 acc_val: 0.3137 time: 0.1259s\n",
      "valid current auc-roc score: 0.584033, current macro_F score: 0.112785\n",
      "Epoch: 00134 loss_train: 1.7424 acc_train: 0.3294 loss_val: 1.7623 acc_val: 0.3321 time: 0.1410s\n",
      "valid current auc-roc score: 0.622615, current macro_F score: 0.115785\n",
      "Epoch: 00135 loss_train: 1.7928 acc_train: 0.3344 loss_val: 1.7516 acc_val: 0.3358 time: 0.1319s\n",
      "valid current auc-roc score: 0.572724, current macro_F score: 0.107106\n",
      "Epoch: 00136 loss_train: 1.7730 acc_train: 0.3448 loss_val: 1.7740 acc_val: 0.3284 time: 0.1273s\n",
      "valid current auc-roc score: 0.596280, current macro_F score: 0.108505\n",
      "Epoch: 00137 loss_train: 1.7445 acc_train: 0.3547 loss_val: 1.7496 acc_val: 0.3284 time: 0.1259s\n",
      "valid current auc-roc score: 0.535287, current macro_F score: 0.067606\n",
      "Epoch: 00138 loss_train: 1.8375 acc_train: 0.3073 loss_val: 1.8201 acc_val: 0.3100 time: 0.1274s\n",
      "valid current auc-roc score: 0.593959, current macro_F score: 0.106436\n",
      "Epoch: 00139 loss_train: 1.7611 acc_train: 0.3350 loss_val: 1.7673 acc_val: 0.3284 time: 0.1618s\n",
      "valid current auc-roc score: 0.536968, current macro_F score: 0.067606\n",
      "Epoch: 00140 loss_train: 1.8277 acc_train: 0.3085 loss_val: 1.8158 acc_val: 0.3100 time: 0.1457s\n",
      "valid current auc-roc score: 0.554969, current macro_F score: 0.114420\n",
      "Epoch: 00141 loss_train: 1.7715 acc_train: 0.3337 loss_val: 1.7707 acc_val: 0.3358 time: 0.1575s\n",
      "valid current auc-roc score: 0.564023, current macro_F score: 0.102585\n",
      "Epoch: 00142 loss_train: 1.7653 acc_train: 0.3381 loss_val: 1.7730 acc_val: 0.3284 time: 0.1488s\n",
      "valid current auc-roc score: 0.560935, current macro_F score: 0.088468\n",
      "Epoch: 00143 loss_train: 1.7635 acc_train: 0.3350 loss_val: 1.7880 acc_val: 0.3173 time: 0.1381s\n",
      "valid current auc-roc score: 0.576423, current macro_F score: 0.107106\n",
      "Epoch: 00144 loss_train: 1.7741 acc_train: 0.3356 loss_val: 1.7620 acc_val: 0.3284 time: 0.1397s\n",
      "valid current auc-roc score: 0.575686, current macro_F score: 0.114420\n",
      "Epoch: 00145 loss_train: 1.7591 acc_train: 0.3436 loss_val: 1.7658 acc_val: 0.3358 time: 0.1390s\n",
      "valid current auc-roc score: 0.569931, current macro_F score: 0.101172\n",
      "Epoch: 00146 loss_train: 1.7535 acc_train: 0.3411 loss_val: 1.7760 acc_val: 0.3247 time: 0.1562s\n",
      "valid current auc-roc score: 0.563064, current macro_F score: 0.125265\n",
      "Epoch: 00147 loss_train: 1.7866 acc_train: 0.3337 loss_val: 1.7740 acc_val: 0.3432 time: 0.1534s\n",
      "valid current auc-roc score: 0.629212, current macro_F score: 0.127447\n",
      "Epoch: 00148 loss_train: 1.7522 acc_train: 0.3651 loss_val: 1.7287 acc_val: 0.3432 time: 0.1361s\n",
      "valid current auc-roc score: 0.581677, current macro_F score: 0.123448\n",
      "Epoch: 00149 loss_train: 1.7723 acc_train: 0.3362 loss_val: 1.7576 acc_val: 0.3395 time: 0.1462s\n",
      "valid current auc-roc score: 0.614029, current macro_F score: 0.133033\n",
      "Epoch: 00150 loss_train: 1.7214 acc_train: 0.3571 loss_val: 1.7117 acc_val: 0.3506 time: 0.1631s\n",
      "valid current auc-roc score: 0.581543, current macro_F score: 0.116541\n",
      "Epoch: 00151 loss_train: 1.7676 acc_train: 0.3337 loss_val: 1.7485 acc_val: 0.3321 time: 0.1502s\n",
      "valid current auc-roc score: 0.579514, current macro_F score: 0.115785\n",
      "Epoch: 00152 loss_train: 1.7711 acc_train: 0.3393 loss_val: 1.7602 acc_val: 0.3358 time: 0.1769s\n",
      "valid current auc-roc score: 0.572548, current macro_F score: 0.114420\n",
      "Epoch: 00153 loss_train: 1.7619 acc_train: 0.3374 loss_val: 1.7473 acc_val: 0.3358 time: 0.1491s\n",
      "valid current auc-roc score: 0.587118, current macro_F score: 0.133278\n",
      "Epoch: 00154 loss_train: 1.7410 acc_train: 0.3541 loss_val: 1.7466 acc_val: 0.3469 time: 0.1479s\n",
      "valid current auc-roc score: 0.605151, current macro_F score: 0.114420\n",
      "Epoch: 00155 loss_train: 1.7446 acc_train: 0.3485 loss_val: 1.7524 acc_val: 0.3358 time: 0.1411s\n",
      "valid current auc-roc score: 0.576657, current macro_F score: 0.123448\n",
      "Epoch: 00156 loss_train: 1.8164 acc_train: 0.3491 loss_val: 1.7895 acc_val: 0.3395 time: 0.1350s\n",
      "valid current auc-roc score: 0.593308, current macro_F score: 0.118228\n",
      "Epoch: 00157 loss_train: 1.7314 acc_train: 0.3504 loss_val: 1.7496 acc_val: 0.3358 time: 0.1696s\n",
      "valid current auc-roc score: 0.610147, current macro_F score: 0.067606\n",
      "Epoch: 00158 loss_train: 1.7898 acc_train: 0.3091 loss_val: 1.7670 acc_val: 0.3100 time: 0.1403s\n",
      "valid current auc-roc score: 0.606382, current macro_F score: 0.135244\n",
      "Epoch: 00159 loss_train: 1.7595 acc_train: 0.3522 loss_val: 1.7082 acc_val: 0.3506 time: 0.1661s\n",
      "valid current auc-roc score: 0.593290, current macro_F score: 0.112785\n",
      "Epoch: 00160 loss_train: 1.7465 acc_train: 0.3528 loss_val: 1.7616 acc_val: 0.3321 time: 0.1479s\n",
      "valid current auc-roc score: 0.577894, current macro_F score: 0.102585\n",
      "Epoch: 00161 loss_train: 1.7664 acc_train: 0.3288 loss_val: 1.7650 acc_val: 0.3284 time: 0.1329s\n",
      "valid current auc-roc score: 0.604904, current macro_F score: 0.137911\n",
      "Epoch: 00162 loss_train: 1.7774 acc_train: 0.3436 loss_val: 1.7411 acc_val: 0.3506 time: 0.1349s\n",
      "valid current auc-roc score: 0.596596, current macro_F score: 0.094966\n",
      "Epoch: 00163 loss_train: 1.7343 acc_train: 0.3424 loss_val: 1.7543 acc_val: 0.3210 time: 0.1493s\n",
      "valid current auc-roc score: 0.585771, current macro_F score: 0.114420\n",
      "Epoch: 00164 loss_train: 1.7446 acc_train: 0.3454 loss_val: 1.7470 acc_val: 0.3358 time: 0.1498s\n",
      "valid current auc-roc score: 0.640635, current macro_F score: 0.121616\n",
      "Epoch: 00165 loss_train: 1.7486 acc_train: 0.3498 loss_val: 1.7378 acc_val: 0.3395 time: 0.1462s\n",
      "valid current auc-roc score: 0.622570, current macro_F score: 0.133278\n",
      "Epoch: 00166 loss_train: 1.7809 acc_train: 0.3528 loss_val: 1.7102 acc_val: 0.3469 time: 0.1779s\n",
      "valid current auc-roc score: 0.581813, current macro_F score: 0.117369\n",
      "Epoch: 00167 loss_train: 1.7151 acc_train: 0.3627 loss_val: 1.7468 acc_val: 0.3358 time: 0.1681s\n",
      "valid current auc-roc score: 0.593364, current macro_F score: 0.119958\n",
      "Epoch: 00168 loss_train: 1.7566 acc_train: 0.3350 loss_val: 1.7436 acc_val: 0.3395 time: 0.1330s\n",
      "valid current auc-roc score: 0.581854, current macro_F score: 0.118228\n",
      "Epoch: 00169 loss_train: 1.7298 acc_train: 0.3528 loss_val: 1.7539 acc_val: 0.3358 time: 0.1523s\n",
      "valid current auc-roc score: 0.584946, current macro_F score: 0.112785\n",
      "Epoch: 00170 loss_train: 1.7552 acc_train: 0.3356 loss_val: 1.7498 acc_val: 0.3321 time: 0.1354s\n",
      "valid current auc-roc score: 0.603780, current macro_F score: 0.123448\n",
      "Epoch: 00171 loss_train: 1.7474 acc_train: 0.3510 loss_val: 1.7267 acc_val: 0.3395 time: 0.1354s\n",
      "valid current auc-roc score: 0.606345, current macro_F score: 0.107106\n",
      "Epoch: 00172 loss_train: 1.7555 acc_train: 0.3356 loss_val: 1.7470 acc_val: 0.3284 time: 0.1445s\n",
      "valid current auc-roc score: 0.594059, current macro_F score: 0.133278\n",
      "Epoch: 00173 loss_train: 1.7338 acc_train: 0.3479 loss_val: 1.7234 acc_val: 0.3469 time: 0.1372s\n",
      "valid current auc-roc score: 0.606796, current macro_F score: 0.128461\n",
      "Epoch: 00174 loss_train: 1.7445 acc_train: 0.3393 loss_val: 1.7475 acc_val: 0.3432 time: 0.1428s\n",
      "valid current auc-roc score: 0.656681, current macro_F score: 0.129253\n",
      "Epoch: 00175 loss_train: 1.7127 acc_train: 0.3547 loss_val: 1.6936 acc_val: 0.3469 time: 0.1359s\n",
      "valid current auc-roc score: 0.584163, current macro_F score: 0.128461\n",
      "Epoch: 00176 loss_train: 1.7412 acc_train: 0.3639 loss_val: 1.7346 acc_val: 0.3432 time: 0.1413s\n",
      "valid current auc-roc score: 0.629934, current macro_F score: 0.139942\n",
      "Epoch: 00177 loss_train: 1.7182 acc_train: 0.3510 loss_val: 1.7243 acc_val: 0.3542 time: 0.1551s\n",
      "valid current auc-roc score: 0.585106, current macro_F score: 0.112785\n",
      "Epoch: 00178 loss_train: 1.7388 acc_train: 0.3473 loss_val: 1.7506 acc_val: 0.3321 time: 0.1370s\n",
      "valid current auc-roc score: 0.594308, current macro_F score: 0.118228\n",
      "Epoch: 00179 loss_train: 1.6956 acc_train: 0.3651 loss_val: 1.7484 acc_val: 0.3358 time: 0.1370s\n",
      "valid current auc-roc score: 0.606362, current macro_F score: 0.123448\n",
      "Epoch: 00180 loss_train: 1.7026 acc_train: 0.3602 loss_val: 1.7157 acc_val: 0.3395 time: 0.1351s\n",
      "valid current auc-roc score: 0.632351, current macro_F score: 0.135244\n",
      "Epoch: 00181 loss_train: 1.6952 acc_train: 0.3522 loss_val: 1.6879 acc_val: 0.3506 time: 0.1347s\n",
      "valid current auc-roc score: 0.651903, current macro_F score: 0.107106\n",
      "Epoch: 00182 loss_train: 1.6691 acc_train: 0.3627 loss_val: 1.7334 acc_val: 0.3284 time: 0.1297s\n",
      "valid current auc-roc score: 0.614807, current macro_F score: 0.110660\n",
      "Epoch: 00183 loss_train: 1.6946 acc_train: 0.3467 loss_val: 1.7295 acc_val: 0.3284 time: 0.1284s\n",
      "valid current auc-roc score: 0.616766, current macro_F score: 0.118056\n",
      "Epoch: 00184 loss_train: 1.8099 acc_train: 0.3454 loss_val: 1.7757 acc_val: 0.3321 time: 0.1369s\n",
      "valid current auc-roc score: 0.611776, current macro_F score: 0.119126\n",
      "Epoch: 00185 loss_train: 1.6692 acc_train: 0.3615 loss_val: 1.7267 acc_val: 0.3358 time: 0.1294s\n",
      "valid current auc-roc score: 0.601724, current macro_F score: 0.123510\n",
      "Epoch: 00186 loss_train: 1.7312 acc_train: 0.3516 loss_val: 1.7325 acc_val: 0.3358 time: 0.1297s\n",
      "valid current auc-roc score: 0.648225, current macro_F score: 0.126664\n",
      "Epoch: 00187 loss_train: 1.6848 acc_train: 0.3571 loss_val: 1.7099 acc_val: 0.3432 time: 0.1442s\n",
      "valid current auc-roc score: 0.625920, current macro_F score: 0.122370\n",
      "Epoch: 00188 loss_train: 1.6975 acc_train: 0.3688 loss_val: 1.7459 acc_val: 0.3321 time: 0.1234s\n",
      "valid current auc-roc score: 0.616072, current macro_F score: 0.134005\n",
      "Epoch: 00189 loss_train: 1.7406 acc_train: 0.3559 loss_val: 1.7269 acc_val: 0.3469 time: 0.1409s\n",
      "valid current auc-roc score: 0.601093, current macro_F score: 0.134842\n",
      "Epoch: 00190 loss_train: 1.7365 acc_train: 0.3473 loss_val: 1.7292 acc_val: 0.3469 time: 0.1301s\n",
      "valid current auc-roc score: 0.600928, current macro_F score: 0.109773\n",
      "Epoch: 00191 loss_train: 1.7363 acc_train: 0.3534 loss_val: 1.7699 acc_val: 0.3284 time: 0.1440s\n",
      "valid current auc-roc score: 0.601997, current macro_F score: 0.112785\n",
      "Epoch: 00192 loss_train: 1.7273 acc_train: 0.3608 loss_val: 1.7539 acc_val: 0.3321 time: 0.1701s\n",
      "valid current auc-roc score: 0.605812, current macro_F score: 0.128461\n",
      "Epoch: 00193 loss_train: 1.7447 acc_train: 0.3461 loss_val: 1.7269 acc_val: 0.3432 time: 0.1607s\n",
      "valid current auc-roc score: 0.617188, current macro_F score: 0.132197\n",
      "Epoch: 00194 loss_train: 1.7260 acc_train: 0.3534 loss_val: 1.7312 acc_val: 0.3469 time: 0.1830s\n",
      "valid current auc-roc score: 0.608632, current macro_F score: 0.137911\n",
      "Epoch: 00195 loss_train: 1.7342 acc_train: 0.3559 loss_val: 1.7221 acc_val: 0.3506 time: 0.1714s\n",
      "valid current auc-roc score: 0.604784, current macro_F score: 0.137911\n",
      "Epoch: 00196 loss_train: 1.7150 acc_train: 0.3658 loss_val: 1.7244 acc_val: 0.3506 time: 0.1605s\n",
      "valid current auc-roc score: 0.579999, current macro_F score: 0.126671\n",
      "Epoch: 00197 loss_train: 1.7287 acc_train: 0.3516 loss_val: 1.7516 acc_val: 0.3395 time: 0.1619s\n",
      "valid current auc-roc score: 0.533454, current macro_F score: 0.066990\n",
      "Epoch: 00198 loss_train: 1.7941 acc_train: 0.3159 loss_val: 1.7985 acc_val: 0.3063 time: 0.1605s\n",
      "valid current auc-roc score: 0.606119, current macro_F score: 0.108635\n",
      "Epoch: 00199 loss_train: 1.7481 acc_train: 0.3417 loss_val: 1.7371 acc_val: 0.3321 time: 0.1561s\n",
      "valid current auc-roc score: 0.614886, current macro_F score: 0.118228\n",
      "Epoch: 00200 loss_train: 1.7198 acc_train: 0.3578 loss_val: 1.7380 acc_val: 0.3358 time: 0.1586s\n",
      "valid current auc-roc score: 0.618453, current macro_F score: 0.123448\n",
      "Epoch: 00201 loss_train: 1.6966 acc_train: 0.3571 loss_val: 1.7348 acc_val: 0.3395 time: 0.1488s\n",
      "valid current auc-roc score: 0.604432, current macro_F score: 0.118228\n",
      "Epoch: 00202 loss_train: 1.7340 acc_train: 0.3479 loss_val: 1.7645 acc_val: 0.3358 time: 0.1464s\n",
      "valid current auc-roc score: 0.608717, current macro_F score: 0.133278\n",
      "Epoch: 00203 loss_train: 1.7101 acc_train: 0.3565 loss_val: 1.7314 acc_val: 0.3469 time: 0.1401s\n",
      "valid current auc-roc score: 0.608526, current macro_F score: 0.132645\n",
      "Epoch: 00204 loss_train: 1.7415 acc_train: 0.3528 loss_val: 1.7432 acc_val: 0.3432 time: 0.1496s\n",
      "valid current auc-roc score: 0.609851, current macro_F score: 0.074505\n",
      "Epoch: 00205 loss_train: 1.7348 acc_train: 0.3356 loss_val: 1.7791 acc_val: 0.3100 time: 0.1604s\n",
      "valid current auc-roc score: 0.603705, current macro_F score: 0.129291\n",
      "Epoch: 00206 loss_train: 1.6968 acc_train: 0.3651 loss_val: 1.7258 acc_val: 0.3469 time: 0.1416s\n",
      "valid current auc-roc score: 0.588643, current macro_F score: 0.067606\n",
      "Epoch: 00207 loss_train: 1.7638 acc_train: 0.3220 loss_val: 1.7753 acc_val: 0.3100 time: 0.1529s\n",
      "valid current auc-roc score: 0.606339, current macro_F score: 0.111290\n",
      "Epoch: 00208 loss_train: 1.7371 acc_train: 0.3424 loss_val: 1.7662 acc_val: 0.3321 time: 0.1489s\n",
      "valid current auc-roc score: 0.598995, current macro_F score: 0.128461\n",
      "Epoch: 00209 loss_train: 1.7255 acc_train: 0.3602 loss_val: 1.7233 acc_val: 0.3432 time: 0.1462s\n",
      "valid current auc-roc score: 0.626888, current macro_F score: 0.129253\n",
      "Epoch: 00210 loss_train: 1.7092 acc_train: 0.3522 loss_val: 1.7080 acc_val: 0.3469 time: 0.1323s\n",
      "valid current auc-roc score: 0.617030, current macro_F score: 0.116541\n",
      "Epoch: 00211 loss_train: 1.7176 acc_train: 0.3430 loss_val: 1.7467 acc_val: 0.3321 time: 0.1415s\n",
      "valid current auc-roc score: 0.608074, current macro_F score: 0.128507\n",
      "Epoch: 00212 loss_train: 1.7623 acc_train: 0.3448 loss_val: 1.7460 acc_val: 0.3395 time: 0.1327s\n",
      "valid current auc-roc score: 0.625276, current macro_F score: 0.128461\n",
      "Epoch: 00213 loss_train: 1.7123 acc_train: 0.3491 loss_val: 1.7143 acc_val: 0.3432 time: 0.1301s\n",
      "valid current auc-roc score: 0.602912, current macro_F score: 0.115785\n",
      "Epoch: 00214 loss_train: 1.7354 acc_train: 0.3461 loss_val: 1.7404 acc_val: 0.3358 time: 0.1361s\n",
      "valid current auc-roc score: 0.577705, current macro_F score: 0.098064\n",
      "Epoch: 00215 loss_train: 1.6977 acc_train: 0.3436 loss_val: 1.7629 acc_val: 0.3173 time: 0.1336s\n",
      "valid current auc-roc score: 0.650675, current macro_F score: 0.102159\n",
      "Epoch: 00216 loss_train: 1.7091 acc_train: 0.3387 loss_val: 1.7244 acc_val: 0.3247 time: 0.1339s\n",
      "valid current auc-roc score: 0.624982, current macro_F score: 0.119932\n",
      "Epoch: 00217 loss_train: 1.7264 acc_train: 0.3356 loss_val: 1.7153 acc_val: 0.3358 time: 0.1387s\n",
      "valid current auc-roc score: 0.621565, current macro_F score: 0.125566\n",
      "Epoch: 00218 loss_train: 1.7164 acc_train: 0.3448 loss_val: 1.7151 acc_val: 0.3432 time: 0.1290s\n",
      "valid current auc-roc score: 0.611607, current macro_F score: 0.116541\n",
      "Epoch: 00219 loss_train: 1.6904 acc_train: 0.3565 loss_val: 1.7419 acc_val: 0.3321 time: 0.1451s\n",
      "valid current auc-roc score: 0.589679, current macro_F score: 0.102585\n",
      "Epoch: 00220 loss_train: 1.7473 acc_train: 0.3319 loss_val: 1.7735 acc_val: 0.3284 time: 0.1398s\n",
      "valid current auc-roc score: 0.622659, current macro_F score: 0.135244\n",
      "Epoch: 00221 loss_train: 1.7272 acc_train: 0.3461 loss_val: 1.7114 acc_val: 0.3506 time: 0.2369s\n",
      "valid current auc-roc score: 0.664168, current macro_F score: 0.122176\n",
      "Epoch: 00222 loss_train: 1.7152 acc_train: 0.3534 loss_val: 1.6969 acc_val: 0.3358 time: 0.1782s\n",
      "valid current auc-roc score: 0.641228, current macro_F score: 0.128507\n",
      "Epoch: 00223 loss_train: 1.7422 acc_train: 0.3559 loss_val: 1.7156 acc_val: 0.3395 time: 0.1582s\n",
      "valid current auc-roc score: 0.628255, current macro_F score: 0.133278\n",
      "Epoch: 00224 loss_train: 1.7121 acc_train: 0.3596 loss_val: 1.7127 acc_val: 0.3469 time: 0.1423s\n",
      "valid current auc-roc score: 0.591868, current macro_F score: 0.118228\n",
      "Epoch: 00225 loss_train: 1.7671 acc_train: 0.3461 loss_val: 1.7488 acc_val: 0.3358 time: 0.1473s\n",
      "valid current auc-roc score: 0.618905, current macro_F score: 0.125265\n",
      "Epoch: 00226 loss_train: 1.7405 acc_train: 0.3344 loss_val: 1.7224 acc_val: 0.3432 time: 0.1333s\n",
      "valid current auc-roc score: 0.603197, current macro_F score: 0.128461\n",
      "Epoch: 00227 loss_train: 1.7139 acc_train: 0.3559 loss_val: 1.7373 acc_val: 0.3432 time: 0.1539s\n",
      "valid current auc-roc score: 0.602823, current macro_F score: 0.133278\n",
      "Epoch: 00228 loss_train: 1.6965 acc_train: 0.3578 loss_val: 1.7194 acc_val: 0.3469 time: 0.1323s\n",
      "valid current auc-roc score: 0.616717, current macro_F score: 0.139942\n",
      "Epoch: 00229 loss_train: 1.7149 acc_train: 0.3522 loss_val: 1.6873 acc_val: 0.3542 time: 0.1286s\n",
      "valid current auc-roc score: 0.621442, current macro_F score: 0.109121\n",
      "Epoch: 00230 loss_train: 1.7579 acc_train: 0.3571 loss_val: 1.7318 acc_val: 0.3284 time: 0.1425s\n",
      "valid current auc-roc score: 0.603637, current macro_F score: 0.134644\n",
      "Epoch: 00231 loss_train: 1.6932 acc_train: 0.3695 loss_val: 1.7544 acc_val: 0.3506 time: 0.1403s\n",
      "valid current auc-roc score: 0.614806, current macro_F score: 0.118228\n",
      "Epoch: 00232 loss_train: 1.6930 acc_train: 0.3547 loss_val: 1.7315 acc_val: 0.3358 time: 0.1535s\n",
      "valid current auc-roc score: 0.630621, current macro_F score: 0.101367\n",
      "Epoch: 00233 loss_train: 1.7140 acc_train: 0.3417 loss_val: 1.7394 acc_val: 0.3247 time: 0.1485s\n",
      "valid current auc-roc score: 0.626027, current macro_F score: 0.107499\n",
      "Epoch: 00234 loss_train: 1.7176 acc_train: 0.3368 loss_val: 1.7311 acc_val: 0.3284 time: 0.1461s\n",
      "valid current auc-roc score: 0.604396, current macro_F score: 0.112785\n",
      "Epoch: 00235 loss_train: 1.6971 acc_train: 0.3541 loss_val: 1.7575 acc_val: 0.3321 time: 0.1460s\n",
      "valid current auc-roc score: 0.630578, current macro_F score: 0.113582\n",
      "Epoch: 00236 loss_train: 1.7185 acc_train: 0.3424 loss_val: 1.7402 acc_val: 0.3284 time: 0.1376s\n",
      "valid current auc-roc score: 0.601444, current macro_F score: 0.126671\n",
      "Epoch: 00237 loss_train: 1.7140 acc_train: 0.3387 loss_val: 1.7202 acc_val: 0.3395 time: 0.1385s\n",
      "valid current auc-roc score: 0.632346, current macro_F score: 0.114952\n",
      "Epoch: 00238 loss_train: 1.7178 acc_train: 0.3454 loss_val: 1.7339 acc_val: 0.3321 time: 0.1328s\n",
      "valid current auc-roc score: 0.660762, current macro_F score: 0.127516\n",
      "Epoch: 00239 loss_train: 1.7210 acc_train: 0.3436 loss_val: 1.7037 acc_val: 0.3432 time: 0.1313s\n",
      "valid current auc-roc score: 0.609914, current macro_F score: 0.119958\n",
      "Epoch: 00240 loss_train: 1.7007 acc_train: 0.3695 loss_val: 1.7211 acc_val: 0.3395 time: 0.1352s\n",
      "valid current auc-roc score: 0.622661, current macro_F score: 0.111290\n",
      "Epoch: 00241 loss_train: 1.6843 acc_train: 0.3615 loss_val: 1.7338 acc_val: 0.3321 time: 0.1594s\n",
      "valid current auc-roc score: 0.585829, current macro_F score: 0.126614\n",
      "Epoch: 00242 loss_train: 1.7384 acc_train: 0.3516 loss_val: 1.7732 acc_val: 0.3395 time: 0.1417s\n",
      "valid current auc-roc score: 0.628228, current macro_F score: 0.096251\n",
      "Epoch: 00243 loss_train: 1.7141 acc_train: 0.3399 loss_val: 1.7276 acc_val: 0.3247 time: 0.1425s\n",
      "valid current auc-roc score: 0.615142, current macro_F score: 0.089610\n",
      "Epoch: 00244 loss_train: 1.7184 acc_train: 0.3257 loss_val: 1.7420 acc_val: 0.3210 time: 0.1359s\n",
      "valid current auc-roc score: 0.599352, current macro_F score: 0.115908\n",
      "Epoch: 00245 loss_train: 1.7462 acc_train: 0.3356 loss_val: 1.7390 acc_val: 0.3284 time: 0.1321s\n",
      "valid current auc-roc score: 0.606124, current macro_F score: 0.119233\n",
      "Epoch: 00246 loss_train: 2.0418 acc_train: 0.3350 loss_val: 1.7820 acc_val: 0.3358 time: 0.1747s\n",
      "valid current auc-roc score: 0.623390, current macro_F score: 0.110604\n",
      "Epoch: 00247 loss_train: 1.7263 acc_train: 0.3405 loss_val: 1.7455 acc_val: 0.3321 time: 0.1536s\n",
      "valid current auc-roc score: 0.657782, current macro_F score: 0.127447\n",
      "Epoch: 00248 loss_train: 1.7435 acc_train: 0.3473 loss_val: 1.6884 acc_val: 0.3432 time: 0.1603s\n",
      "valid current auc-roc score: 0.645390, current macro_F score: 0.132197\n",
      "Epoch: 00249 loss_train: 1.7036 acc_train: 0.3417 loss_val: 1.6913 acc_val: 0.3469 time: 0.2090s\n",
      "valid current auc-roc score: 0.604901, current macro_F score: 0.122508\n",
      "Epoch: 00250 loss_train: 1.6792 acc_train: 0.3559 loss_val: 1.7179 acc_val: 0.3395 time: 0.2061s\n",
      "valid current auc-roc score: 0.611082, current macro_F score: 0.101960\n",
      "Epoch: 00251 loss_train: 1.7312 acc_train: 0.3387 loss_val: 1.7221 acc_val: 0.3247 time: 0.1964s\n",
      "valid current auc-roc score: 0.607188, current macro_F score: 0.101761\n",
      "Epoch: 00252 loss_train: 1.7300 acc_train: 0.3411 loss_val: 1.7752 acc_val: 0.3247 time: 0.2001s\n",
      "valid current auc-roc score: 0.671376, current macro_F score: 0.127447\n",
      "Epoch: 00253 loss_train: 1.6899 acc_train: 0.3498 loss_val: 1.6987 acc_val: 0.3432 time: 0.2104s\n",
      "valid current auc-roc score: 0.655744, current macro_F score: 0.126664\n",
      "Epoch: 00254 loss_train: 1.6895 acc_train: 0.3485 loss_val: 1.6928 acc_val: 0.3432 time: 0.1997s\n",
      "valid current auc-roc score: 0.665310, current macro_F score: 0.121380\n",
      "Epoch: 00255 loss_train: 1.6876 acc_train: 0.3498 loss_val: 1.6971 acc_val: 0.3358 time: 0.2000s\n",
      "valid current auc-roc score: 0.622255, current macro_F score: 0.128461\n",
      "Epoch: 00256 loss_train: 1.7030 acc_train: 0.3411 loss_val: 1.7214 acc_val: 0.3432 time: 0.1878s\n",
      "valid current auc-roc score: 0.610564, current macro_F score: 0.089805\n",
      "Epoch: 00257 loss_train: 1.6847 acc_train: 0.3454 loss_val: 1.7435 acc_val: 0.3210 time: 0.1885s\n",
      "valid current auc-roc score: 0.633914, current macro_F score: 0.132808\n",
      "Epoch: 00258 loss_train: 1.7000 acc_train: 0.3436 loss_val: 1.7054 acc_val: 0.3395 time: 0.2067s\n",
      "valid current auc-roc score: 0.652202, current macro_F score: 0.121604\n",
      "Epoch: 00259 loss_train: 1.6546 acc_train: 0.3664 loss_val: 1.6935 acc_val: 0.3432 time: 0.1901s\n",
      "valid current auc-roc score: 0.651616, current macro_F score: 0.128461\n",
      "Epoch: 00260 loss_train: 1.6846 acc_train: 0.3485 loss_val: 1.7041 acc_val: 0.3432 time: 0.1831s\n",
      "valid current auc-roc score: 0.611879, current macro_F score: 0.116541\n",
      "Epoch: 00261 loss_train: 1.6827 acc_train: 0.3510 loss_val: 1.7616 acc_val: 0.3321 time: 0.2718s\n",
      "valid current auc-roc score: 0.679619, current macro_F score: 0.132197\n",
      "Epoch: 00262 loss_train: 1.6616 acc_train: 0.3602 loss_val: 1.6672 acc_val: 0.3469 time: 0.1835s\n",
      "valid current auc-roc score: 0.620408, current macro_F score: 0.118228\n",
      "Epoch: 00263 loss_train: 1.7107 acc_train: 0.3578 loss_val: 1.7367 acc_val: 0.3358 time: 0.1826s\n",
      "valid current auc-roc score: 0.612854, current macro_F score: 0.118228\n",
      "Epoch: 00264 loss_train: 1.7278 acc_train: 0.3491 loss_val: 1.7373 acc_val: 0.3358 time: 0.1746s\n",
      "valid current auc-roc score: 0.665417, current macro_F score: 0.125647\n",
      "Epoch: 00265 loss_train: 1.6545 acc_train: 0.3627 loss_val: 1.6912 acc_val: 0.3395 time: 0.1463s\n",
      "valid current auc-roc score: 0.679326, current macro_F score: 0.110343\n",
      "Epoch: 00266 loss_train: 1.6708 acc_train: 0.3516 loss_val: 1.6858 acc_val: 0.3210 time: 0.1341s\n",
      "valid current auc-roc score: 0.601318, current macro_F score: 0.119958\n",
      "Epoch: 00267 loss_train: 1.7285 acc_train: 0.3510 loss_val: 1.7347 acc_val: 0.3395 time: 0.1449s\n",
      "valid current auc-roc score: 0.631279, current macro_F score: 0.133278\n",
      "Epoch: 00268 loss_train: 1.6925 acc_train: 0.3608 loss_val: 1.7027 acc_val: 0.3469 time: 0.1365s\n",
      "valid current auc-roc score: 0.644965, current macro_F score: 0.119950\n",
      "Epoch: 00269 loss_train: 1.6990 acc_train: 0.3571 loss_val: 1.7198 acc_val: 0.3321 time: 0.1791s\n",
      "valid current auc-roc score: 0.658703, current macro_F score: 0.115785\n",
      "Epoch: 00270 loss_train: 1.6786 acc_train: 0.3553 loss_val: 1.7060 acc_val: 0.3358 time: 0.1555s\n",
      "valid current auc-roc score: 0.656482, current macro_F score: 0.130355\n",
      "Epoch: 00271 loss_train: 1.6808 acc_train: 0.3498 loss_val: 1.6972 acc_val: 0.3469 time: 0.1736s\n",
      "valid current auc-roc score: 0.635553, current macro_F score: 0.114119\n",
      "Epoch: 00272 loss_train: 1.6548 acc_train: 0.3553 loss_val: 1.7298 acc_val: 0.3284 time: 0.1724s\n",
      "valid current auc-roc score: 0.628267, current macro_F score: 0.112785\n",
      "Epoch: 00273 loss_train: 1.7236 acc_train: 0.3325 loss_val: 1.7378 acc_val: 0.3321 time: 0.1481s\n",
      "valid current auc-roc score: 0.677731, current macro_F score: 0.128461\n",
      "Epoch: 00274 loss_train: 1.6743 acc_train: 0.3553 loss_val: 1.6965 acc_val: 0.3432 time: 0.2969s\n",
      "valid current auc-roc score: 0.667800, current macro_F score: 0.120769\n",
      "Epoch: 00275 loss_train: 1.6774 acc_train: 0.3541 loss_val: 1.6683 acc_val: 0.3395 time: 0.1795s\n",
      "valid current auc-roc score: 0.642217, current macro_F score: 0.119332\n",
      "Epoch: 00276 loss_train: 1.6904 acc_train: 0.3516 loss_val: 1.7118 acc_val: 0.3358 time: 0.1739s\n",
      "valid current auc-roc score: 0.620391, current macro_F score: 0.089572\n",
      "Epoch: 00277 loss_train: 1.7544 acc_train: 0.3319 loss_val: 1.8275 acc_val: 0.3210 time: 0.1906s\n",
      "valid current auc-roc score: 0.631718, current macro_F score: 0.114579\n",
      "Epoch: 00278 loss_train: 1.6584 acc_train: 0.3522 loss_val: 1.7202 acc_val: 0.3284 time: 0.2318s\n",
      "valid current auc-roc score: 0.660074, current macro_F score: 0.119903\n",
      "Epoch: 00279 loss_train: 1.6596 acc_train: 0.3424 loss_val: 1.7393 acc_val: 0.3284 time: 0.1583s\n",
      "valid current auc-roc score: 0.635765, current macro_F score: 0.117212\n",
      "Epoch: 00280 loss_train: 1.7046 acc_train: 0.3436 loss_val: 1.7174 acc_val: 0.3284 time: 0.2135s\n",
      "valid current auc-roc score: 0.658507, current macro_F score: 0.126483\n",
      "Epoch: 00281 loss_train: 1.6994 acc_train: 0.3571 loss_val: 1.6952 acc_val: 0.3432 time: 0.1996s\n",
      "valid current auc-roc score: 0.655156, current macro_F score: 0.127722\n",
      "Epoch: 00282 loss_train: 1.6912 acc_train: 0.3639 loss_val: 1.7000 acc_val: 0.3432 time: 0.1880s\n",
      "valid current auc-roc score: 0.636526, current macro_F score: 0.137203\n",
      "Epoch: 00283 loss_train: 1.7033 acc_train: 0.3590 loss_val: 1.7256 acc_val: 0.3506 time: 0.1577s\n",
      "valid current auc-roc score: 0.595425, current macro_F score: 0.129496\n",
      "Epoch: 00284 loss_train: 1.7180 acc_train: 0.3528 loss_val: 1.7389 acc_val: 0.3395 time: 0.1543s\n",
      "valid current auc-roc score: 0.654262, current macro_F score: 0.135885\n",
      "Epoch: 00285 loss_train: 1.7065 acc_train: 0.3528 loss_val: 1.7314 acc_val: 0.3395 time: 0.1677s\n",
      "valid current auc-roc score: 0.587557, current macro_F score: 0.113795\n",
      "Epoch: 00286 loss_train: 1.7076 acc_train: 0.3454 loss_val: 1.7596 acc_val: 0.3321 time: 0.1633s\n",
      "valid current auc-roc score: 0.643982, current macro_F score: 0.132645\n",
      "Epoch: 00287 loss_train: 1.6964 acc_train: 0.3719 loss_val: 1.7221 acc_val: 0.3432 time: 0.1581s\n",
      "valid current auc-roc score: 0.655284, current macro_F score: 0.143906\n",
      "Epoch: 00288 loss_train: 1.6895 acc_train: 0.3498 loss_val: 1.6780 acc_val: 0.3469 time: 0.1470s\n",
      "valid current auc-roc score: 0.604609, current macro_F score: 0.095636\n",
      "Epoch: 00289 loss_train: 1.7021 acc_train: 0.3498 loss_val: 1.7737 acc_val: 0.3247 time: 0.1450s\n",
      "valid current auc-roc score: 0.654173, current macro_F score: 0.135370\n",
      "Epoch: 00290 loss_train: 1.7285 acc_train: 0.3294 loss_val: 1.7121 acc_val: 0.3432 time: 0.1444s\n",
      "valid current auc-roc score: 0.634558, current macro_F score: 0.128229\n",
      "Epoch: 00291 loss_train: 1.6701 acc_train: 0.3596 loss_val: 1.7097 acc_val: 0.3395 time: 0.1445s\n",
      "valid current auc-roc score: 0.690596, current macro_F score: 0.147654\n",
      "Epoch: 00292 loss_train: 1.6830 acc_train: 0.3528 loss_val: 1.6800 acc_val: 0.3542 time: 0.1621s\n",
      "valid current auc-roc score: 0.629952, current macro_F score: 0.102457\n",
      "Epoch: 00293 loss_train: 1.7189 acc_train: 0.3270 loss_val: 1.7253 acc_val: 0.3210 time: 0.1352s\n",
      "valid current auc-roc score: 0.654941, current macro_F score: 0.101367\n",
      "Epoch: 00294 loss_train: 1.6965 acc_train: 0.3559 loss_val: 1.7211 acc_val: 0.3247 time: 0.1681s\n",
      "valid current auc-roc score: 0.672118, current macro_F score: 0.126671\n",
      "Epoch: 00295 loss_train: 1.6786 acc_train: 0.3510 loss_val: 1.6838 acc_val: 0.3395 time: 0.1500s\n",
      "valid current auc-roc score: 0.613486, current macro_F score: 0.123448\n",
      "Epoch: 00296 loss_train: 1.7095 acc_train: 0.3405 loss_val: 1.7665 acc_val: 0.3395 time: 0.1952s\n",
      "valid current auc-roc score: 0.630407, current macro_F score: 0.093492\n",
      "Epoch: 00297 loss_train: 1.6663 acc_train: 0.3239 loss_val: 1.7716 acc_val: 0.3173 time: 0.2092s\n",
      "valid current auc-roc score: 0.613673, current macro_F score: 0.128461\n",
      "Epoch: 00298 loss_train: 1.6979 acc_train: 0.3541 loss_val: 1.7100 acc_val: 0.3432 time: 0.2128s\n",
      "valid current auc-roc score: 0.607800, current macro_F score: 0.118228\n",
      "Epoch: 00299 loss_train: 1.7290 acc_train: 0.3479 loss_val: 1.7500 acc_val: 0.3358 time: 0.1686s\n",
      "valid current auc-roc score: 0.616523, current macro_F score: 0.107106\n",
      "Epoch: 00300 loss_train: 1.6776 acc_train: 0.3504 loss_val: 1.7265 acc_val: 0.3284 time: 0.1831s\n"
     ]
    }
   ],
   "source": [
    "acc_trains = []\n",
    "acc_vals = []\n",
    "loss_trains = []\n",
    "loss_vals = []\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "        acc_train, acc_val, loss_train, loss_val = train(epoch)\n",
    "        acc_trains.append(acc_train)\n",
    "        acc_vals.append(acc_val)\n",
    "        loss_trains.append(loss_train)\n",
    "        loss_vals.append(loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAACRB0lEQVR4nO2deZwU9Z3+n76752YYZpiB4UZQUSQehBARlajEZWMu3cTfmsREY4KJxsTdsJvVmOwG102ySTau2ZwkWY9oNmpijBEPwAMPkFERQU4ZYGaAGebs6bt+f1R/q75VXdVdPcx098w879drXjDdVd3VNd39fer5XC5FURQQQgghhBQJd7EPgBBCCCHjG4oRQgghhBQVihFCCCGEFBWKEUIIIYQUFYoRQgghhBQVihFCCCGEFBWKEUIIIYQUFYoRQgghhBQVb7EPwAmpVApHjhxBZWUlXC5XsQ+HEEIIIQ5QFAV9fX1oamqC223vf4wKMXLkyBE0NzcX+zAIIYQQMgRaW1sxdepU2/tHhRiprKwEoL6YqqqqIh8NIYQQQpzQ29uL5uZmbR23Y1SIERGaqaqqohghhBBCRhm5UiyYwEoIIYSQokIxQgghhJCiQjFCCCGEkKJCMUIIIYSQokIxQgghhJCiQjFCCCGEkKJCMUIIIYSQokIxQgghhJCiQjFCCCGEkKKSlxhZu3Ytzj33XFRWVqK+vh5XXHEFdu3a5Xj/Bx54AC6XC1dccUW+x0kIIYSQMUpeYmTjxo1YvXo1XnrpJaxfvx7xeByXXHIJBgYGcu574MABfO1rX8P5558/5IMlhBBCyNgjr9k0TzzxhOH3devWob6+Hlu3bsWyZcts90smk7j66qtxxx134LnnnkN3d/eQDpYQQgghY4+Tyhnp6ekBANTW1mbd7lvf+hbq6+vx2c9+1tHjRqNR9Pb2Gn5Ggv/begjf/ONbeHlf54g8PiGEEEJyM2QxkkqlcPPNN2Pp0qVYsGCB7XbPP/88fvGLX+BnP/uZ48deu3YtqqurtZ/m5uahHmZWNrxzDOtePIC3joyM2CGEEEJIboYsRlavXo3t27fjgQcesN2mr68Pf//3f4+f/exnqKurc/zYa9asQU9Pj/bT2to61MPMStCrvvxIIjkij08IIYSQ3OSVMyK48cYb8dhjj2HTpk2YOnWq7XZ79+7FgQMHsGrVKu22VCqlPrHXi127dmH27NkZ+wUCAQQCgaEcWl4EfR4AQCSeGvHnIoQQQog1eYkRRVHwpS99CQ8//DA2bNiAmTNnZt1+/vz5ePPNNw23feMb30BfXx9++MMfjlj4xSmBtDMSjdMZIYQQQopFXmJk9erVuO+++/Doo4+isrIS7e3tAIDq6mqEQiEAwDXXXIMpU6Zg7dq1CAaDGfkkNTU1AJA1z6RQCGckmqAzQgghhBSLvMTIPffcAwBYvny54fZf/epX+PSnPw0AOHjwINzu0dHYNehL54zQGSGEEEKKRt5hmlxs2LAh6/3r1q3L5ylHlIBX5IxQjBBCCCHFYnRYGCOEcEYYpiGEEEKKx7gWIwEfnRFCCCGk2IxrMcLSXkIIIaT4jGsxEmDTM0IIIaTojGsxopX20hkhhBBCisb4FiN0RgghhJCiM67FSIDOCCGEEFJ0xrUY0Ut76YwQQgghxWJ8ixEvq2kIIYSQYjOuxUiA7eAJIYSQojOuxYhwRhIpBYkk3RFCCCGkGIxvMZJOYAXYEp4QQggpFuNajIimZwBDNYQQQkixGNdixO12we8RvUbojBBCCCHFYFyLEUBPYo3SGSGEEEKKwrgXIxyWRwghhBSXcS9GOCyPEEIIKS7jXozozgjFCCGEEFIMKEa0lvAM0xBCCCHFgGLEK4bl0RkhhBBCisG4FyN6S3g6I4QQQkgxGPdiRHNGmMBKCCGEFAWKEZb2EkIIIUVl3IsRrbSXOSOEEEJIUaAYoTNCCCGEFJVxL0b00l46I4QQQkgxoBihM0IIIYQUlXEvRtgOnhBCCCku416MCGckSmeEEEIIKQoUI3RGCCGEkKIy7sVIwMd28IQQQkgxGfdiJMh28IQQQkhRoRhhO3hCCCGkqFCMsLSXEEIIKSrjXoywHTwhhBBSXPISI2vXrsW5556LyspK1NfX44orrsCuXbuy7vOzn/0M559/PiZMmIAJEyZgxYoVeOWVV07qoIcTLYE1QWeEEEIIKQZ5iZGNGzdi9erVeOmll7B+/XrE43FccsklGBgYsN1nw4YN+MQnPoFnn30WmzdvRnNzMy655BIcPnz4pA9+ONATWOmMEEIIIcXApSiKMtSdjx07hvr6emzcuBHLli1ztE8ymcSECRPw4x//GNdcc42jfXp7e1FdXY2enh5UVVUN9XAt2XO0Hyu+vxFVQS/e+Oalw/rYhBBCyHjG6frtPZkn6enpAQDU1tY63iccDiMej2fdJxqNIhqNar/39vYO/SBzEPKnE1gZpiGEEEKKwpATWFOpFG6++WYsXboUCxYscLzfP/7jP6KpqQkrVqyw3Wbt2rWorq7Wfpqbm4d6mDkRHVhjiRRSqSGbRIQQQggZIkMWI6tXr8b27dvxwAMPON7nzjvvxAMPPICHH34YwWDQdrs1a9agp6dH+2ltbR3qYeZEOCMAW8ITQgghxWBIYZobb7wRjz32GDZt2oSpU6c62ue73/0u7rzzTjz11FM488wzs24bCAQQCASGcmh5I5qeAcBgLIky/0lFrgghhBCSJ3k5I4qi4MYbb8TDDz+MZ555BjNnznS031133YVvf/vbeOKJJ3DOOecM6UBHCrfbBb82LI95I4QQQkihycsGWL16Ne677z48+uijqKysRHt7OwCguroaoVAIAHDNNddgypQpWLt2LQDg3//933Hbbbfhvvvuw4wZM7R9KioqUFFRMZyvZcgEvW7EEikMxhimIYQQQgpNXs7IPffcg56eHixfvhyNjY3az+9+9zttm4MHD6Ktrc2wTywWw8c+9jHDPt/97neH71WcJFpFDXuNEEIIIQUnL2fESUuSDRs2GH4/cOBAPk9RFPT5NBQjhBBCSKEZ97NpACDEYXmEEEJI0aAYgT6fZpDOCCGEEFJwKEYAhDifhhBCCCkaFCPQc0bojBBCCCGFh2IEes5IlGKEEEIIKTgUI6AzQgghhBQTihHIpb2spiGEEEIKDcUIgGA6gZXOCCGEEFJ4KEYg9xmhGCGEEEIKDcUI2IGVEEIIKSYUI2AHVkIIIaSYUIxAyhnh1F5CCCGk4FCMQArTJChGCCGEkEJDMQKpzwidEUIIIaTgUIxAyhlJMGeEEEIIKTQUI5DCNHRGCCGEkIJDMQIg5E9P7WXOCCGEEFJwKEYABLzMGSGEEEKKBcUIgJCfTc8IIYSQYkExAg7KI4QQQooJxQj0appYMoVkSiny0RBCCCHjC4oR6B1YAYZqCCGEkEJDMQIgmE5gBShGCCGEkEJDMQLA7XbB703Pp6EYIYQQQgoKxUgaTu4lhBBCigPFSBqRN8IwDSGEEFJYKEbS6M4IxQghhBBSSChG0miTeylGCCGEkIJCMZKGjc8IIYSQ4kAxkkbkjNAZIYQQQgoLxUga5owQQgghxYFiJE2QYoQQQggpChQjacTk3nCMYoQQQggpJBQjaSoDXgBAXyRe5CMhhBBCxhcUI2mqQj4AQF8kUeQjIYQQQsYXeYmRtWvX4txzz0VlZSXq6+txxRVXYNeuXTn3e+ihhzB//nwEg0GcccYZePzxx4d8wCNFZVA4IxQjhBBCSCHJS4xs3LgRq1evxksvvYT169cjHo/jkksuwcDAgO0+L774Ij7xiU/gs5/9LLZt24YrrrgCV1xxBbZv337SBz+cVAaFM8IwDSGEEFJIXIqiKEPd+dixY6ivr8fGjRuxbNkyy22uuuoqDAwM4LHHHtNue+9734uzzjoLP/nJTxw9T29vL6qrq9HT04OqqqqhHm5WHnvjCG68bxvOm1mLBz+/ZESegxBCCBlPOF2/TypnpKenBwBQW1tru83mzZuxYsUKw22XXnopNm/ebLtPNBpFb2+v4WekqUo7I72DdEYIIYSQQjJkMZJKpXDzzTdj6dKlWLBgge127e3taGhoMNzW0NCA9vZ2233Wrl2L6upq7ae5uXmoh+kY5owQQgghxWHIYmT16tXYvn07HnjggeE8HgDAmjVr0NPTo/20trYO+3OYYc4IIYQQUhy8Q9npxhtvxGOPPYZNmzZh6tSpWbedPHkyOjo6DLd1dHRg8uTJtvsEAgEEAoGhHNqQqUo7I/3RBFIpBW63q6DPTwghhIxX8nJGFEXBjTfeiIcffhjPPPMMZs6cmXOfJUuW4Omnnzbctn79eixZUlpJoqLPSEoBBmIM1RBCCCGFIi9nZPXq1bjvvvvw6KOPorKyUsv7qK6uRigUAgBcc801mDJlCtauXQsAuOmmm3DBBRfge9/7Hi6//HI88MAD2LJlC376058O80s5OQJeN3weF+JJBX2RhBa2IYQQQsjIkpczcs8996CnpwfLly9HY2Oj9vO73/1O2+bgwYNoa2vTfn/f+96H++67Dz/96U+xcOFC/P73v8cjjzySNem1GLhcLilvhM4IIYQQUijyckactCTZsGFDxm0f//jH8fGPfzyfpyoKlUEvugZiTGIlhBBCCghn00hU0RkhhBBCCg7FiIToNdJLZ4QQQggpGBQjEroYoTNCCCGEFAqKEQk2PiOEEEIKD8WIBHNGCCGEkMJDMSKhhWk4LI8QQggpGBQjEhyWRwghhBQeihGJKuaMEEIIIQWHYkSiKkRnhBBCCCk0FCMSbAdPCCGEFB6KEQmrpmeKoqC1K+yoFT4hhBBC8odiRELkjMjVND/ZuA/n3/Us/vj6kWIdFiGEEDKmoRiRmFQZAAAMxJJaEus7HX0AgL1H+4t2XIQQQsYvbx7qwf9tPVTswxhR8praO9YpD3hRHfKhZzCOtp4IKoM+9EfV/JFIIlXkoyOEEDIeufX3r2Nnex/OnFqNuQ2VxT6cEYHOiInG6iAA4Ej3IAAgHEuLkXiyaMdECCFk/NIdVp1689y0h7cdwld+14LYGLhYphgx0VQTAgAc6Y4AAPqjqgihGCGEEFIM4klVbJgLKe7ZsBcPbzuM1w91F+GohheKERNNNaoz0taTdkZEmCY++pUnIYSQ0YcQI8mUYrpd/T1OZ2Ts0VhtdEYGogzTEEIIKR6JtAgxaRFNnJhvH41QjJgQzojIGWECKyGEkGJiF6YRYiQ5BvpgUYyYaEo7I209g1AUBeEYc0YIIYQUB0VRtHCMWXSkFMXw72iGYsSElsDaE0E0kdLssSjFCCGEkAKTkGIwdmGasdAhnGLERENVEC4XEEuk0NoV1m5nAishhJBCk0jKYsTaGUmOgeWJYsSE3+vGpAq1E+tuqetqJEFnhBBCSGGJp3SlkUpZ54wwTDNGaUyHanZ3SGKEYRpCCCEFRi7bNYdpxO9mkTIaoRixoCndhXX30T7tNoZpCCGEFBpjzogpTMPS3rFNQ5UqRt7tlHNG6IwQQggpLHKr94zSXoWlvWOaieV+AMBBKYE1mkiNCSuMEELI6EF2RsyJqqymGePUVqhipGcwbrg9ysZnhBBCCkgiKeeMsM/IuGJiecDydoZqCCGEFJJYFjGidWAdA9fJFCMW1KWdETMs7yWEEFJIsvcZsb59NEIxYsHECjtnxFp+RhNJvLSvU5sfQAghhAwHCUOfEUj/Vyz/P1qhGLFgop0zYhOm+ZdHtuPvfvoS/nP9OyN5WIQQQsYZsYS1MyJX0IwBLUIxYkVlwAu/J/PU2ImRB7ccAgD8dNO+ET0uQggh4wuDMyKLkZS1MBmtUIxY4HK5UFue6Y7kanw2Od0sjRBCCBkO4knrDqyyMGFp7xjGKlRjlcAqx+qaqkMjekyEEELGF3GbBNbkeM8Z2bRpE1atWoWmpia4XC488sgjOfe59957sXDhQpSVlaGxsRHXXnstOjs7h3K8BcMqiTVqEaY50jMo7WOda0IIIYQMBUM1jUGA6NskR78WyV+MDAwMYOHChbj77rsdbf/CCy/gmmuuwWc/+1m89dZbeOihh/DKK6/guuuuy/tgC0mdFKZxudR/rcI0B47rXVrjY+EdQQghpGQYL2Eab747rFy5EitXrnS8/ebNmzFjxgx8+ctfBgDMnDkTn//85/Hv//7v+T51QZFdjgllfnQNxCwTWPcf1yf7RtmHhBBCyDASt2l6lrQJ2YxWRjxnZMmSJWhtbcXjjz8ORVHQ0dGB3//+9/jgBz9ou080GkVvb6/hp9DUSl1YxawaazEiza/hZF9CCCHDiOy42+WJjAEtMvJiZOnSpbj33ntx1VVXwe/3Y/Lkyaiurs4a5lm7di2qq6u1n+bm5pE+zAxkZ0RU1kQsZtMc6BzQ/s8OrYQQQoYTubRXjsYY+4yMfjUy4mJkx44duOmmm3Dbbbdh69ateOKJJ3DgwAHccMMNtvusWbMGPT092k9ra+tIH2YGckv4unQyq7UzoosR2Rl5ZNth/H7roRE8QkIIIWOd8VJNk3fOSL6sXbsWS5cuxa233goAOPPMM1FeXo7zzz8f//qv/4rGxsaMfQKBAAIB65bshUIelidcEnMCayKZQmuXHqYRzkgknsTXHnodKUXBZQsmoyIw4qeZEELIGETOGTG4IYZqmtEvRkbcGQmHw3C7jU/j8XgAlHYGsGhgVub3oDKoigmzM9I5EENCUqTi/oFoAomUgpQC9A7GC3TEhBBCxhqJpHWYJjXG2sHnfcne39+PPXv2aL/v378fLS0tqK2txbRp07BmzRocPnwYv/nNbwAAq1atwnXXXYd77rkHl156Kdra2nDzzTfjvPPOQ1NT0/C9kmGmoSqIb3/odNSWB7DvmFoxYxYjJ8Ixw+/RdE5JOKZvNxBNjPCREkIIGavEbPqMJMd7ae+WLVtw4YUXar/fcsstAIBPfepTWLduHdra2nDw4EHt/k9/+tPo6+vDj3/8Y3z1q19FTU0NLrroopIv7QWAv18yAwDws/TMGbMY6RpQxUjQ50YkntLul8VIP8UIIYSQIZKwDdOMrdLevMXI8uXLs6qwdevWZdz2pS99CV/60pfyfaqSIehTw0zmnJHusBqCaawOYf/xAUQTKSiKgnBMFyADUVbYEEIIGRoJmxJeTu0dhwR8ao6LuXRXOCOTq9T8EkUBYskUnRFCCCHDQiwh54zYVNOMgTANxYgDgkKMmMI03emckUZpWm80YRQjsktCCCGE5IPcZyRlU00zFkp7KUYcEPRah2m6BtQwzaSqgDS/JmkK01CMEEIIGRrxhOyG6LfbtYYfrVCMOCDkV52RltZuLPrWk3hpnzpxWDgjtWV+BNKCJRo3h2mYM0IIIWRoxFM2YRpDNU1BD2lEoBhxgAjTAMCJcBx/ev0IAKArLUYmlPm1baKJpMENoTNCCCFkqCRsOrCmmDMy/gh6PYbfd3eofUdOpKtpJpTrzkgknsIgE1gJIYQMA4YOrHLX1TFW2ksx4gBR2it452gfFEXBiQHhjPgMzkg4zqZnhBBCTh7b2TQs7R1/yGEaQO0vcrw/pnVgnVDu19yTSDyFsBymYTUNIYSQIRJPWueMsJpmHFJT5tP+L3qKvN3Wi76IKjQmlPkRSLsn0USSCayEEEKGBbm0N2nrjIx+McJxsg6oDPrwxxuXIujz4K4ndqG9N4ItB7oAAC4XUB3yGZ0RzqYhhBAyDBjDNJD+z9LeccmZU2twSkMl5jZUAABe3q+KkeqQDx63y+SMsJqGEELIyWMfpmFp77hmbr0qRl5JOyMTyvwAgIDkjAywmoYQQsgwIJf22lXQjIUwDcVInpzSUAlAV6IT0vkkAW2YXtJQ2iuckY7eCL71px042Bku4NESQggZzcjOiG2Yhgms44859RWoDOipNsIZETkj0UTKUEEjpvb+0x/exC9f2I/b/7i9gEdLCCFkNGMUI9at4ceAMUIxki9Bnwc3LJ+t/V6eFiZBG2cklkzhhT3H8fTOowCADe8coztCCCHEEYmUdZ5Iks4IuXbpTO3/QrUGZGfElCdy+x/fAgC4XaqCvfeVdwt0pIQQQkYz8YR1mEYZY6W9FCNDIOT34FefORfzJ1fi+mWzAJickbixt8ieo2r7+G99aAEA4MFXWxFLGCcAE0IIIWbiNomqTGAlAIAL59XjiZuXYdG0CQB0Z6Q/ktDqwn0el7Z9c20If3duMyoCXpwIx/Fu50DhD5oQQsioImGbM8J28MQC4YyIFvEAMKkioP3/lPpKeD1uTJ9YBgA4wLwRQgghOTA0PZNbwDNMQ6wQU3u70sPzfB4XqtOVNgAwN10SPKOuHADojBBCCMmJk2oaJrASDTFM70Q4DgAo83tREdAH7J2S7tw6I+2M7D9OMUIIISQ7tmJE+v8YMEYoRoYL0fRMOCNlfo9W9gvozdJmTBTOCMM0hBBC7EmlFFOjM+N9AjojREM0PesZFM6IBxGpqmZOuo28CNMcYJiGEEJIFuIpY9WlXZ4Ic0aIhgjTCMr8XhzpjmTcLxJYj3QPIpowlgATQggZO/z1rXbc+/LQ+0rJyasAZ9MQB4gEVkGZ34Mj3YMZ202qCKDc70FKAVq7Mu8nhBAyNvjaQ6/jnx/ejuP90SHtL5f1AsbcEKMzMqSHLykoRoaJQIYz4sF3PnwGAOCrHzhFu93lcmF6Om/kmZ0d2HGkt3AHSQghpCAoioK+iNqNWx4Rkg+xpH2YJmlT5jta8ebehDghwxkJeHHluc14/9w6NFYHDffNqCvDjrZefOfxnfB738HWb6xAZdBXyMMlhBAygkSlLtuJIVoXCVOYxjZnZAxYI3RGhomMnJH07001IbhcLsN9M9NJrAAQS6S0ChxCCCFjA1mMDLXaJUOM2PQWGQNahGJkuDA7I3JZr5m/O3caPrJoivZ7eIgWHiGEkNIklrDuD5LXY2QJ09i1hh+tUIwME2ZnZGFzte22zbVl+P5VZ6G5NgSAYoQQQsYacrXkkJ2RbKW9rKYhVoT8uhj5yHum4IqzpmTZWqXMp7onQ01uIoQQUpoMR5gmnjCV9iry/8eWGGEC6zBREfDiuvNnYjCexO2rTs/IE7FCCJjBOMUIIYSMBX7w1Ds41hfF1Yuna7cNWYykzKW9dtU0Q3r4koJiZBj558tPy2v7UDq0E44lRuJwCCGEFJBEMoUfPr0bigKcP3eSdntyiM6F42qaMeCMMExTRMqEM5IO0/RF4vjF8/vR1sNmaIQQMtroHoxrjcm6w3qV5FBLb+OmBFa7Sb0s7SUnhQjTiATWu5/di28/tgMfu2dzMQ+LEELIEJAFiJhTBgy9z4hZjCi2zsiQHr6kyFuMbNq0CatWrUJTUxNcLhceeeSRnPtEo1H88z//M6ZPn45AIIAZM2bgl7/85VCOd0xRZsoZeWlfJwDgcPeg4U1HCCGk9Oka0AWILEaG7oxkCdOMsam9eeeMDAwMYOHChbj22mvxkY98xNE+V155JTo6OvCLX/wCc+bMQVtbG1KmxJzxSJnfWE0zY2IZWlq7AQCHTgyiubasWIdGCCEkT07YOCNDzxkxh2kkASI95lAvXhVFcVRsUQjyFiMrV67EypUrHW//xBNPYOPGjdi3bx9qa2sBADNmzMj3acck5jCN3OBmy7tdFCOEEDKKODFgI0aGXE2j7ufzuBBPKoZBeYb8kSGIkR89vRu/fvEAHv7iUkybWPy1ZsRzRv74xz/inHPOwV133YUpU6bglFNOwde+9jUMDjJJU1TTDMbVaprusP7mffXAiaIcEyGEkKFxImwdphl6nxFVcQS86lph3/Qs/8d+ZudRdA7E0HKoe0jHNtyMeGnvvn378PzzzyMYDOLhhx/G8ePH8cUvfhGdnZ341a9+ZblPNBpFNKqPXO7tHZuTbctMzogsRrYc6CrKMRFCCDFysDOMnz63F9efPzuriyCHaXojesuGk+3AGvC60R81OiAnG6YR6QFy2/piMuLOSCqVgsvlwr333ovzzjsPH/zgB/H9738fv/71r23dkbVr16K6ulr7aW5uHunDLArmMI2spN/p6EePJE4IIYQUh/tfPYj/fekg7n/1YNbt5DBNr5zAOsScDpHAKmafyamWJ5vAOpDub2Wu2CkWIy5GGhsbMWXKFFRX67NaTj31VCiKgkOHDlnus2bNGvT09Gg/ra2tI32YRUE4I5F4phgBgLZehrIIIaTY9EXU7+ZcoztkZ0Qu8x3qei+Egj8tRoaztHfcOSNLly7FkSNH0N/fr932zjvvwO12Y+rUqZb7BAIBVFVVGX7GIqH0bJpwLIl4MoX+qKpUJ5T5AIDOCCGElACDMXXBzuUiyDkjcpjGPPDOKQnNGVEvXI1hGn27oZQOh0e7GOnv70dLSwtaWloAAPv370dLSwsOHlTtqzVr1uCaa67Rtv/kJz+JiRMn4jOf+Qx27NiBTZs24dZbb8W1116LUCg0PK9ilCKHaWRXRFTRmJ0SQgghhUe41+b27GbkME1yGKbqigrLgC8dprERIPk+fiqlaP2tYqM1TLNlyxYsWrQIixYtAgDccsstWLRoEW677TYAQFtbmyZMAKCiogLr169Hd3c3zjnnHFx99dVYtWoVfvSjHw3TSxi96O3gE5rwqAp6MaHMD0BtLUwIIUSnGA0hxcJtHlxnRg7TyAx1vU+YckaMg/Ksk1mdIA9njZaIM5J3Nc3y5cuzvhnWrVuXcdv8+fOxfv36fJ9qzKMPyktqlTQ1ZX5Uh9QwTS/FCCGEaPzqhf24+9k9uP+692JuQ2XBnlfkV2RzRpIpxfYCUrgYiqJgR1sv5tZXankg2RDhHbGtnQDJN0oTlnJfRm2Yhgwf8qC8nkFVUVeHfKgROSMUI4QQovHMzqM43h/DlncL24cpkkiLkSzOSK80JM+MmE3zl+3tuPxHz+P7699x9LxamEbrM6LfJ4dp8nWL5EnxFCNEbwcfl50Rn+aMUIwQQohOWHMoCruACmfEPCtGpssmRAPoLsbBrjAA4MDxAUfPaw7TpGyqafIt7TU4I8nsFUKFgmKkiIgwTSKl4Hi/2uStOqSLkW5W0xBCiEbYgSgYCfQEVnsR1J1FjAgXQ+wfjjsTAObSXkNvEdklYZiGnAyimgYAjnRHAKjOSBWdEUIIyUCEF4ZaKjtUtATWbM7IgP33tXAuxP6DUpgkGxlNz7KU8+ZT3sswDTHg97rhdasTE9t61AZnsjNCMUIIITrFckb0MI39wm1XSQPoYkSIqHCO5mmCREbOiH1oJp/yXmOYhmKEQHdH2nvSzkjIjxpW0xBCSAZORMFIEImrz5fI4j6IHiPiYlJG5IwkNGdkaGEaw9Rek/jIp7x3kGEaYkZU1LSlxUh1mQ/V6Woa9hkhhBAVRVH0ME0BnZFkStHcg2w5I33pjqsNVQHLxwB0R8epMxJPGcM0SZupvQBsK3msGJDCNKXSZ4RipMiIJNajfWoCa40pTFOMBj+EEFJqRBMpLWciV/Ox4SQiJZtmCw+JcR4TyzPFSCojTOMwZySRJUyjDD1MQ2eEZBDyG/vOyU3PkikFAw4VNCGEjGVkNyGeKNxFmtytNFvi7IAQIxX+jPsS5gRWh9U0Yj85TCMuUM0Ro3zKeweizBkhJsqkihpAjTeGfB74PeqfhkmshBBidBMKWU0juwjZwkNCLNVVWDgjWs6IGLinOMp7iWsJrPpSLTRHRjVNHvosHGc1DTFhFiP1lQG4XC6tvDdb7TohhIwXZFFQyGoaQ5gmiwjSwzSZzoieM6Lv78QdiZsG5QG6sMmopslDjRjPJcUIgZ4zAgBz6iswIf1Grg6p4Rs6I4QQAkPIupALqCFMk9UZUcVIrUWYRhMjkmBwUlGjd2DV14mUFqYZes6IIUxDZ4QAxsZn582s1f7PYXmEEKJjCNMUUIyIsl4gVwKrusBbJbAmTR1YAWcVNZZhmpTxMbXnyCeBtQTDNHlP7SXDixymWSyJkZoyVV3TGSGEEFNoId/+5yfzvA4TWIVYskpgNfcZkbfPhhA/8oTfgVgCXeFYhvjIp/CyFJueUYwUGVndWjkjnE9DCCHGME0hnRGDCMriIohqmsqgF36v2+A4pIYapkllOiPX/WYLXm/thtdjDGzkU00TlsI07DNCAABvt/Vp/2+sDmn/Z0t4QgjRkee5FC+B1f55RR5Gud+LoNe4tCaGHKbJzBnZe7QfKSUzvJJXO/gSDNNQjBSZFac2AAAWTq023M5heYQQohMuiQRW6+dNphRtu/KAF0GfsUoyZRmmcZ4zIodp7JyMkwnTlEJzTYZpisznL5iFGXVluOCUSYbbJ6RbwmcbvkQIIeOFsMN+H8ONHE5JKWrIxZ0ecCqQ26uX+T0ZYkSvppFLe53kjGSGaezEyFDDNIqiOjc+jyvLHiMPnZEiE/R58KGzpmgJq4L6yiAA4GhvtBiHRQghJUXRmp6Z+oFY9RoRi7vX7ULA6za0bAAAYajkckb+7c87cOVPNiOaSBq293nccOXQCvlN7TUKoVII1VCMlChi2JKYWUMIIeMZY2ihcM5I1CRGrFwZ0fCszO+By+VC0GdOLhWdVyVnxCRGesJx/Oy5/XjlQBe2H+4xbO/zuODJoUbymk1jek0UI8QW4Yx09EZKIp5HCCHFZLBY1TQOxIhwGioCauZDwOyMpHdJSKGU3kgCT77Vjp50xeSm3ce0+zxudWmOS86IO6cYyflSAKjCw5wAXArlvcwZKVHq085INJFC72AC1ekcEkIIGY8ULWfEQZhGc0bSYiQjgdWimuZHT+8GoLZ0ePDzS7Bhly5GhCMiwlFejytnmMZpzogs6nweF+JJhc4IsSfo86AqqL6xj/ZFinw0hBBSXMKG0t5C9hkxPpelMxLVK2kAZJT2Jk1Te2Ve2d+FVErBxneMYkRRFIMz4nEPT5hGlPX6PC4tt6UUeo1QjJQwDVUiVMO8EULI+MZQ2luABNb9xwew5g9v4p2OPsPtVkJIVNOUpztqm52RhMWgPJkdbb043q9/zyeSiiGk43PnDtM4jeaLfighnwf+dP+SUnBGGKYpYRqqgth9tJ/OCCFk3FPoMM1ND2zDG4d6Mm5PWIRDRJhGOCPmahqtz4hNKKWltdvwezyZMrxGn3f4wzTlAa8mcJgzQrJSX6nmjdAZIYSMd4xj70dejOxs67O83crd0MI0mjNiF6bJ3NftygyTxJOKQSB43fZhGq/bhURKcR6mSbs4Ib9Hc1MKGfayg2GaEqa+Sq+oIYSQ8cxAgXNGmmtDlrdbPbfZGXHSgVVQWx7IqA5SnRH9Np/HZRum8aVn1DgVIyIhN+j1wJ/etxTCNBQjJYxwRo6x1wghZJxT6NLeabVllrfnU9orupqKfayatU0s92cInEQqpYV0vG4XXC4X7PJXvennyKe0F1DdG9FmnmKEZKXBoTPS3hPB66aYIyGEjCWMCawjH6aRh9PJCEHxyLbDuP+VgwCA/nSYpsyvipHZk8rT/1YAAJKKYqiOkfF73Rm3y+W2QmzYOSPC3ciVM9IdjiGZUrSQkN+ri5FSqKZhzkgJ47QL63W/2YLtR3qw6dYL0Wyj5gkhZLSSkgbRAYUJ09gldcaTCnoG4/jqQ68jpSj44IJGzRkpD6gC5m8XNuGMKdXY2d6HL977GlIpxVYsxJOpDMdEvS1d1ptugGYnRnRnxF6MHDg+gBXf34hVC5uwdE4dAFVsuZDK+loLCZ2REkZ0YW3vieBgZ9j2A/hu5wAUBXi3M1zIwyOEkIJgbjymKPkNhhsK5tCFHHJ581APkikFigIc649gwJQz4nK5MGtSBbzp2EpSUWwraRKpTMckkVT0VvBeIUasj9ObFivZUka2H+lBIqXg7bZebe5NwMswDXGI6MIaS6aw7D+exQ+f2p2xjaIoGEjbl5zwSwgZi1gNlRtpd0Qs2oLKoNoFO55K4fVD3drtXQNxrXeHECMCUQGTTCm2x5tIpjLui0u3CUFjnhQsECIpmzg7MaCuDZF4EtF4ehKwz0MxQpwR9HkwpUbP6H5uz/GMbSLxlPYm7KYYIYSMQUTyqlzeauc0DBfmBboy3RE7kVQMOXpdA9GMpmcCtyRG7HqjxJOZ98m3iWoZ+zBN7mqazrQYiSZSes6Ixy1V02SKvUJDMVLi/PxT5+DmFXMBAHuP9mcMzRMlZQBwIj1wiRBCxhJisRcjMgAgPsJX8+akzuqQ6owkkpnOiLm0V+CVnRGbrrFxC2dEdkt8WgKr9XE6Ke2VnREhsgJyNQ1zRkguTm2swheXz4HX7UJ/NIF2U2WNUYzQGSGEjD1Ezkh5wKt1Ih3plvBigf7Y2VNx10fPRHm6UuZw96ChEWXXQFRqemYK07j05FLd6TCqCquckbh0m3A+coVpsp2OrvSFquqMSDkj7DNC8sHvdWP6RLVKZndHv+G+AVmMDFCMEELGHpGYKJ31aNUlI90SXuRWXL14Gq48t1mrWtly4IRhOzVnxFhNIxACIiHljPg8bkO7eCtnJG5wRnKEaaQkWTtkZyQicka8ozxnZNOmTVi1ahWamprgcrnwyCOPON73hRdegNfrxVlnnZXv04575tZXAgB2HzWKkb4IwzSEEOckkils3ttpmIJb6mhdQ30eTRSMtBgRzojoNyJEwRvpEI3QBp1yzohNAmtKdjrcLnzwjEYtB0Uu7RVt5BPSbdnCNG6X/hzmEL6MyBlJKXqDNrmaJjoawzQDAwNYuHAh7r777rz26+7uxjXXXIOLL74436ckAOY2qM1z9hw1zkuQnREmsBJCcvGnN47gEz97ybI6r1QRV/NBn0cTBSOd5xCTmoMBugNxvF/9nm1It17Y1d6HlKKKgtpyv+ExPIbSXt3p+N6VC/HkV5YBEGW8qpAQTdPi0m25nBGXFgqyfy2ya94biWuvq5Sckbybnq1cuRIrV67M+4luuOEGfPKTn4TH48nLTSEqc+pVMWIO0zCBlRCSD4dPDAIAjvSMnplXwhkJ+Tx6v4+RzhkRiZ7pBdssgqZOCKG9N4J3OtQLxKaaoLaNQMsZSelOjnB2xLZyCEeEbyxLey3ESErRn8OutFdRFHRJF6q9g7ozEkuUjhgpSM7Ir371K+zbtw+33367o+2j0Sh6e3sNP+MdIUa2vHsCtz26HW8dUUdb9zGBlRCSB8JlKIVyTqdEtDCNW2vyVagwjeaMmBJPp05Q2y4IDdA8IbP7tcetCyddXKTFjVtffsXrK0uXBiesSnttVmtxu101TTiWNIgN4YyMuz4ju3fvxte//nX87//+L7xeZ0bM2rVrUV1drf00NzeP8FGWPmLGAQD8ZvO7uPMvOwEYwzR9kURBBkgRQkYvYuErhQXIKRHZGfGqC/xIhmkSSb1/k6g48ZrUwFST+LAarKc3PdP7oghnRxY3oo9KyK87IzFTaa/HJkzjlip2rOgyFTb0DKbFiNetuT5jvrQ3mUzik5/8JO644w6ccsopjvdbs2YNenp6tJ/W1tYRPMrRQdDnwQdOa9B+f721G4qioD9iTELrHmSohhBiTyTtiFgNbStV5MW6ENU08uIcSCeV+r3WzojAai6YlsCq6KEYUaorixHRYVYL00hN0sT2rlxixEZPmMVIryRGhDNSiFk/uRjRQXl9fX3YsmULtm3bhhtvvBEAkEqloCgKvF4vnnzySVx00UUZ+wUCAQQCgZE8tFHJz645B/FkCqff/lf0RhI40Bk25IwAahJrXQXPHSHEGj1MU/wFyCkRrTeGXE1jPP6BaCKjmmWoyOfGzhmZVBmA3+PWhIuVM+KW8jkSUjUNYAzThGPmMI2zahr5drvS3i5T+L43IlXTjJc+I1VVVXjzzTfR0tKi/dxwww2YN28eWlpasHjx4pF8+jGJz+PG6U1VANQSM7MYGUoSa2d/FJf9YBN+tmnfsBwjIaR00cI0JXA17JTBWDrB0+/RREFcSti8+9k9OPOOJ/Hyvs5heT6xOLtd1k4GoFa+yNUz2ZyRZMpYTQOoPUjE/XrOiF7uK45BbO+xUSO5SnvN/adE+EnuM2LuNlsM8paR/f392LNnj/b7/v370dLSgtraWkybNg1r1qzB4cOH8Zvf/AZutxsLFiww7F9fX49gMJhxO3HOwqk12HawGy2t3YacEcB547NIPIk7/7ITl5zWgN5IAjvb+/DQ1lZct2zWSBwyIaREEAtPKVwNO8VQTSNCC9Lxb333BJIpBTvaerF41sSTfr6oqawXQEalTHnAgwnlfq0rtpUzYmgHb6qmEfcnU4r++rScEX3KrxBfdmGaXKW95jCNYNRP7d2yZQsWLVqERYsWAQBuueUWLFq0CLfddhsAoK2tDQcPHhzeoyQGFjZXAwDeONRjEaZx5oxs2HUU6148gO+vf0drgiPq5wkhY5ehOiMD0QQOdw9m3P7wtkO45cGWEc07iErVND6pQkUgvgeH6xiiWlmv3inV6850RiamnZGKgBcTynwZj+OW+4yYqmPk/8tiC1BfW0Kr5skepslV2msnRvxymKYEXLK8xcjy5cuhKErGz7p16wAA69atw4YNG2z3/+Y3v4mWlpYhHi4BVGcEALYf7tHER2U6VmqOD9pxKN1roDcSx0A6XnkiHGM1DiFjHNHmPN+F+zPrXsUFdz2LDtN8rB8/swd/eO0wWqRJtsONvFgLZ0FOwBWJ/MN1hW9ueAbo4RpBmV91RgA1RGPlXOh9RpSMHBD1MUWIRX9MAIgnFMSSRmfELkwjUk9swzQ2a8KobwdPis+MieWoDHoRTaTw5mG138jUtEXotNdIe7rh0UA0icG0M6IozsUMIWR0IpJB812A3j7Si0RKwaETYePjpcWNEDkjgRAjAakDqyymhDMSG6YKG63HiOximMRAueSMNJsqawRCKCRSina+5URYc1KsFqaRnBGvlsCaPUyTrzMS8LkRTDsx3eF41nbyhYBiZBTidrsMfUcAvcyse8A6THPXEztx+Y+e0xreiDjnQCyBgaje/Oh4H8UIIWMZEabJxxmJJpJag0Wz6BAL90hO0TX0GRGdS2VnZJjDNObuq0CmMxLyezBvsjoz7KxpNZaPI4uNuMXUXvME3zJ/ZgdWf47SXk+OnJET6TXBbKwEvGoxRNDnxuHuQbx+qMf6AQoExcgoZWZdueF30f3vUHcYfZE4fvjUbmw7qE6XPNobwX9v2Iu3jvRiw65jAKBZreFo0jAw63i/Ohr7sTeO4LrfbMGOI+x+S0ipEYkn8czODq3/Rn77pp2MPJyRE9JFjnk/sXCPZN+PwbjeLl3kbsjiR4Rp4sMUboim3SNjAqtRRPi9blx1TjOeuPl8XH++deK/3KhMPKYsUMxJsaF0NY08r8arNT2zPlYhMuyangmhZp6bE/B6UBn04bLTJwMAHtpS3H5eFCOjlOkTjZnbF82vh9sFvLCnE5/82cv4z6fewSd+9hK2HOjCH7Yd1rYTDW/a0mGaWDJlSHoVYuSnm/Zh/Y4OfPBHz+HPb7SN9MshhOTBbze/i2vXbcEvX9if977RIYRpxPeCvL9AXMGPZL5ZJKZP7TU7I9FEUndnRtIZkawFkWjqdrswf3JVhmsikKMwQgR6LXJGzI8bN/QZyT4ozy01VrNC/L2qgsYEWyG0Pn6O2uH8j68f0RyoYkAxMkoxOyOLptXgE+dNAwAtjyQST+Ezv3oVv3xe/8Lq6I1AURQc7dW/XI5JXzSd6YoakeAKAD946p3hfwGEkCEjwqzmZFInRIaQwCrnHZidEfE4I1mRIfJcQn635lCI55XDzMOWM2JV2iv932lzNTnpVIgCQzWNKWekTCrtjSeM1Tc5O7DavHTx96oMGcWIEFpLZk3ElJoQ+iIJPLmjI/eLGiEoRkYp0yfqYsTlUt/EX7tkHmrS5WX/eNl8LJ5Zi75oAkf7dLHR3hNB10DM8MVxTLpfvgIStI2i6Z6EjAdiJ9ErRFz9phTnboZBjEg5Iympf8aIhmkkZ8SrJbCqzyePxBg2ZyRpIUYk4SBEQy6MYsQ4hRewcEakDqwiDCW2tzFfcpb2ivdIVdAooIQYcbtd+NjZU3H+3DrUVfgz9i8UI9oOnowcMyUx4na54HK5MKHcj3s/txj7jw/g8jMa8bnzZ+Lnz+3Hz5/bh/KAFwe7wmjvjWSIC1mMHOuPQlEULZwDqDHH/mgCFcPUapkQcnJoYkRafCPxJFKKonXxtEJRFIOzEU8q8DpYVzsNzojuRMh5G4kCJLCqYRpjO/i+qP5dNVwlqkJwydU0snDIdo5lDDkjWpgmS7mwNJsmbp7aaxumUf+1q4YRf+8qyRnxuF2G5755xVxb56VQ0BkZpVRLDXZkRXx6UzX+5swmuFwu+DxufGH5bGz9lw/g3z6sdrzt6I1kWLvyF83x/hgG40mt+58Q8UOxgwkhI4MQIWLxVRQFl//oOVz03Y1ZF2S75NNcdBpyRoxiRj+mkXNGIlICq1bamxo5ZyRq4YzIi/dQnJGIFqbRb/NbtJgH0jkjpqm9uUt7rY9BiMdqSYz4TSKo2EIEoBgZN0yuCgJQwzRmZ0QWM539UfQOqh9uj9ul5aZ0MFRDiC1vHupBW09md9KRwhym6Q7HsffYANp7I1l7DZnLcqNJZwmLdjkjspgZqQTWZErRxJdaTWPsMyJ3oR7+BFZddMh9RpyKEZfLBbHOa85I1j4jenJu3DS11203m8Zln8AqO2FyAquYRFxKlN4REceUO/xAAEBDtSpGeiMJHDg+YLvd8f6o1oukKujF5PR+HX0UI4RY0dYziA/d/TyuXbelYM8ZNYVp5LywbOW+kYxKGGduRqeNGJEX/5HKGZErPKzCNLIYGckEVoMzkkfIWuR8aAmsXvucESF+5D4jepjG+vGzlfbGk4rW3VV2RuQqoVKh9I6IOGZSZcDxtpUBr6bmXz/UbbtdZ39MK/WtCvnQUCkclczEVkKIWnmWUoCDnfYif7gxh2mOShcLg1nKM82lm0ML00jVK7JLMkLOiPx6Al53Rjv4PjlMM6Lt4CVnxOf8QlCEV4SI89n0GRG9SwBzaW/2ME220l75b1UV0gVUwEmiUIGhGBnF3P63pwMArl06M+e2LpdLC9W83mrfaS+RUtDapbZ7rgr6NEeFOSOji8feODKis0JOhs17O/H4m2Ond01f2kkciCULNtspljB2UZVL9bOLEeuy3FzYVdPEhuCM7Gzvxa9fPGBb/WFGr6Rxw+12ZbSDHxiBMI3W9MymDNdpaS+g540IIWie2qs9vset/Z5S9POcM4E1S2mv7GLJBQh+OiNkOLlwXj1e+aeL8Y3LT3W0fUNajIgvkKa00BCIz8X+dBinOuRDQ9p9oRgZPbR2hXHjfdtw0wPbin0olqy+7zWsvu81w9X2aEa+MjdP0R4pzDkjcpgmki1MM1RnxEmYxmE1zR1/3IHb//gWXtrX6Wh7IQzEHBVz07NsOSNqT6X8v7u0nBGfjTOSR4hciBGzuACMvUu8bpfhdyEqhUCRwzTfuPxU1FUE8PWV87XHT1moEX36sFtrqCZ+LzVK74hIXtRXBW0Tm8xMlsRHXYUfy06ZZLi/sVqdb7PveD8A1dYTAqajN4K3jvRY9iEhpYVIYJRLtkuJE+EYFEXNXxqtROJJXHH3C7jzLzsNr6Mvy2sazkFk4oIiepJhGict4WOJlOF1RRNJxJMptV/REMI04ljlzs9W26zf0YFkSsFgTE9eBZDRDl4+NnPOyN3P7sF533kaT+XZzEu8loDHOqQyJDGSMIoLwJgU6/O4De6LcISsnJE59RV49Z8vxg0XzNYSZC3DNHG9rX2AYoSUCkJYAMCHF00xJDR53C5t2N7ujrQYkcI0rx3sxqr/eh43/HZrAY+YDAWxwIRjScurpWKSTOkJdea24qOJ7Yd70NLajQe3tGphGgBa8reZaCKJS3+wadg+P+Y+I4YE1ixixK57ajbMU1+jiRSu/80WvPc7Txs6NTsN0+gTdu2P844/7sB1v9mC5/cc116PcEa8WZyRmOk9tbO9DwDwztE+R8emP45F07Mh9BkB9GoXremZTZ8Rn8dtcF/CZjFiEi6iHNedpbQ3KlUFBaXXwpwRUlRkRX7Vuc2GuGeZ34MpNcIZUcM0VSGfQcCkFGDLuydwwmYkNSkN5Jh+uIizJqyQF7/halBVDITo6BmMa6XwAAz/l9lztB/vdPTjibfabUe654M5THNMyhkx54XIDCVM0zlgdNii8RR2tPUilkzhnQ59kXeaLyP6gmR77sPdqsg52hsxNDwD9N4cWmmvoc+IURBFTefJKZYJrEPowAroIkK8DrupvV6Py/AdLQaYej2ZYRrZpbEq7Y0lUjjSPWiYsSM7I8wZIUXl/Ll1AIDG6iDm1FcaPlDlfi8aa1ThIRLLqoJe1FtU7LxyoKsARzs6+NfHduCyH2wyJNEVG9lxCJfQcQFGKz+fqbGlRk+6Q3EypaBd6i/SZ+OMyMmaLa0nTvr5xSKjJbA6DdMMgzMSS6a0q/ZsIRIrkikFA+l9s20vPk/RREp7PaF0/kZGO/gsOSPiPSb+dRoqE9v7PTbOyJBKe7P3GfGn3Q7xPJEsCayyg2JV2nvz77Zh6b8/g7fb1KnrAZ/bEJphmIYUlcWzJuL+696Lx798PgBjRnhZwIOmtDMiqAr5MkZcA3CceDYeePT1I9jZ3pe1XLrQyIt8oRIqnSKXXhbDGekJx3HV/2zGfS8fPOnHEbSekMWI9fmWh7m1HOw+qecGrEp7Ry6B1SxGIvGkls8giy+zMxJLpNBuapZoDKnYP7cQI7FEKsMZEYu7SJjtyyZG4vqE4j+8dghnfWs9Xtmf+2JKC29IboKhz8hJlPZ6PcZwi/74LsNtMa3PiJhNI+ea6PtZlfbuPToARQF2CDHi9Wjnz/y6SgWKkXHGktkTMaFcHYYki5FyvxdN1SYxYho5LXhpH50RgbCI5dLKYiN/yYezLEzFwNA+vAhi5IW9x/Hy/i7c98q7J/U4ctKqKIVXb7d2Rgbj+vbbhqHkWg4/9EcThr9z1pwRsxhx4IwcT0/yDqadif5IQhsXIYuvhCk/6cv3b8P77nxaq84DnIuRPi2vRBcjIoFVhBjEax/I8pjyeXpu93H0DMbx4t7j6I8m8MzODtu8JW1QniwW5A6sgaFU0+QI06QFhtdUkCDyU+TKXqMzklnaK45fCMmAl84IKWHkDq4hv0cL0whEk5xvfeh0nNZYhUdXLwWg9gnoztJyeryQSOoWcimVPstfsKUUPgKMV67FSGAV5cTZupQ6oUcaJCm7Eo6ckdbuk04slhNYzaWrg/Ekntt9DH+x6OVizifpGYzjVy/s13I0rOhK54yIixX5s28M0xgfe2d7L1IKsO9Yv7R97qF2iqLoYZp4Su8z4hfOiLpsvbi3EwvveBJ7juqPb5czEk0ktfdb72ACP35mD65dtwUPbTlkeQwiEdaYwCr1GckngVXkjFiFaWRhkn4usxstpu3KYRpDzohFaa88JgBQxUeQ1TSkVJEzwsv9FmGatDNyzZIZePym87GwuQZz6iugKMCWAycf9x7tyAvM0RIqo5XDNAOx0hIjxc4ZEVf5wylGZOxyRsLS36EvktDK54eCouizWuJJBR0mVy4cTeCG327F6vteM4STgEwB+Puth3DHn3bgv57ebft84upafD+ckB4zW5hGuEeya2MeaheJJw3OCaAKJrGuxpJJbREPekU1jb4omxunZeaM6GEakdjdMxjHwS71Oc3Pre+XowPrEEp7xbEaQjNyN1a3K+N+AKhMfw8bwjTSsViV9or3hyjzD/g8BgHCBFZSUlQYcka8qAr6DLfJpb+COZMqAABHCjgUrFSRR5eXlDMiXf3KgqkUkMs/iyFGxMKaLZThhF5bMWIt/szhsm0nkTeSkMqjAeCIydXoHIhhIJZESskMG5mdkcPpfBch0qwQ9zWmy/zlc2cI00h/W0VRNKFi2D5qdFK+/n9v4MLvbsCbh/Su0OZQjhCOYoiczzTPRSaRUgwOgfgsxJIp7f3WG4lrYtKu8Z5laa9cTZNPB1ZT51S7MI0QIbLo8bhdWnjMGKaRckYsSnuFKBOVj36POUzDnBFSQshxTxGyaZJCNVUWYqSuUs03OV5CToAVm/d2Yumdz+CZnfk1O8qH0nVGpGqaEnNGil3aK8pUT1aM2DkjdjkjZjEi55nki/m8yb0+AFMyq+l1mn8XV87m22WEgGs0OaeAMXdGdr0i8ZQWMhm0cUZiiZTmTMhOkRxajCYyc0askuplrNy3WCIlhWniWvii06bMWi6JFcgD7vJKYDXlgJh7i+i3ZzojlUFvRj8RdRtJsKRvV5TMMI1wsQI+N7xSu3mGaUhJIcc9RcimUUpitUpgnVShipVjJd6JddPuYzjcPYj1eXZezId+yRkZSsvpkcJYTVNazkixwzSd/WLxTZ1U3oZd91h7Z8R4+7EsTkQuzGKkvVcVI+Iq/niffc8R89RecQqyiVYtTGMaHwGYwzT6+ZRFmZ2TEk3oboVBsJickcxqmuzLllVekvxcPYOyM6K+tlRKwbcf24EfP6OGq7QOrNKiHfJ5cP7cOiyeWYuaMuvkfivM2knuumolTGShURnUv6Nlh0V2acTNSUXR/o7iHIhzL16H9q+v9Jb+0jsiUjDKJWekzOSM+Dy6PSgjnJFjfaWdwCq+wOyaUA0H8hdrR290WNt9nwyGappSS2Atcmlvl82MlXyxC9PYiRThoonQ58nM5TEnioqr/InpKjmDM5IwOyPWrzlb1ZU4VnNOGWA8h/JsGlmkGHJGosYEVrlbsMBcHWPuwCov1ktmTcw4prhFKDAq5Yz0RRJaLo1wyja+cwy/eH4/vvvkO4gnU3qYxqN/R7pcLvzm2vPwwPXv1dwKJ3hM4slr07tE/F8WWxUBXfS4DWEaYygHAB5tOYKzv/0UDncPZiTyirCM3jiu9Jb+0jsiUjAMCazpGKjImK8K+iw/cHUVahO0Up9RI8eHndAXiePnz+3LWlVgRr6CG4wnS6anhzGBtbSckWKX9sq2/MmEamwTWG1uF1f+02rLAJzc58d83sSxTChTxYj8PrQL05jHWdmFaWKJlCawmmoynRHDttLftmfQ+hjMCayi3FX+W/SbwjSDceNsGllQ/edVZ+HKc6bijr89XVuUhSugKIqhU61wSboGYlruSmd/DIqi4LE39MqjwXjSMoEVUAVJPkIEAMwpLl6Lcl719uzOiMummkYO3wzGk3hk2+GMY8h0RpgzQkoIOTlKOCMiLmyVLwIAk9IdWUt1CJtAXAXZXcGaeWTbYfzrn9/WbFon9Juugs1VDcNBIplCW57JwoUu7f35c/vwk417HW1bzNLeZErRciSAoYuRRDJlKzxtnZG0fT5tohAj6nEoioJv/vGtvN53ZkdHiJGJFf6Mbc1OiNi30hSCNTsjwuUT58vjdmkhWjvkahqjMyK1yzfljOQK00QtwjSnNlbC73Fj9qRyTK4O4q6PLcSn3jdDW8RjkhsiP472XNLfPZFScLw/hqfe1sO5kVjSMmdkqHhMys9nU9rr18SIfn+VHKZx24kR4/NZhZBEWEaIEOaMkJJDVM+I/JGFU6vhcgGnNFRYbj9JckZKJSxhhVjo7K5gzQhxZe4YmQ3zgiS35B4urv/tVixZ+wy2vuu8lNpQTTPCCayDsST+7fG3cedfdtqWtcrEipjAKqYFCwaHeG6s8kLEQmh3DuyckUMnBrHuxQP4z6d2O/485XJGZMyCTyzs8hW3fHwAcNMD27DsP55FOJbQciomlPkR9GdfLow5I5JrGLPuCCw3NDOGaZKW24hqmokVAWxecxH+nO4kLRALtBC8UUNIMGkblvvDa4cM3xNhSYwMRwms2+SkWAkQQG92Jt8vVzcK0eFyGYWJOUHWKhdKhGnMDkkp4bw+iYxJ1FBNTKusmdtQief+4ULNATEjwjTRRAp90YRtl9Zio4dpnC04Yrtuh+IFsBAjI+CMPLPzKADgvpcP4uzpExztI3/phkc4gbVnMK4t8P3RRMYVt5l4ERNYzW3N5UUyH6wE7uTqIFq7BtNX4MmM0knNGUmLkXAsiXAsoQnYZEpBJJ5CyEH/CnPOiMh/qC134Iykf1c/t7rjJrsF63d0IBxLYt+xAUM+Sq48g7iNMyJ3nzVX01i5FYZqmnhS688RlM7pxIrM7ye/JkbU7WUhFpNCQmYe3NJq+D0cS+odWIdh0faa4jTm4Xj6/zOdEfnzJMI0PlMOilns9Fm4dkJ8iHB8iGEaUmqIKyRZgU+dUGZbhx7ye7RtS7m8V09gjTu64hRXu+YmUdnIDNMMrzMiH3dtuXPRV8imZ3aJinYkipgzYs7TGGqYRuQhyRekchWalXMizs2kioC2MBzvixnCneaKlp5wXBO8O9t7sbNdnTNiPm9i8bEWIyZnJGHtjCRSipZXIY41Ek9qCZ615X64XK6sV9RxKYFVThy3C8EMxpNaC3nZpcpwTxLGDqx2aDNdRJhGEmLReMpW/O49Zmx8JovNEXFGbAflWZf2CjxaUzTj45n7mJi/lwBdjHzhgtn4yKIpWDqnLq/XUAjojIxzvnTRXDyzswPvtchKt6Ouwo/+aALH+qKYNck6nFNsxBdPIqVgMJ40JOtaIbL8T+TR5l58abpcgKIMf68R2dWpsbDg7ShkzojRjs+9uBvCNA5Hzg8XGc7IEMWIWKyaakJaj4/qkA+VAS/6ogn0RRKagygQC3x5wIu6igAOdw/i+EDU8J4Jx5IQn8JYIoWLv78RA9EErlg0Bb979SBSCnDFWU245PTJlsc1wUaMPLG9HSfCMXzivGmaOLHKCRuMJw3iZTCe1MI0tel8lIDXbbuoy0LTTqTKt8uLpp0zIpf25rqa12bWWIRpZOFjh/gc9wzq75PhqDox54zIAsNn4YzIs2kqgplhGq/pmMz5tFb5TEKMrDitAStOa8jj6AsHxcg457IFk3HZAusvNzsmVQZwoDOctWtjsZG/iHoG4znFiOaMDMaRSikZcVjLfdIf+qkTQmjtGhx2Z8TcWdMpBmdkhMM08uLiRPgUM4G1s98cpjlJMVIdQkdvBPGkgsqgF5VBIUYy3TVRYl3m96CuMi1G+qImZ0Q/np7BuObk3P+KPmH4kZYj2GfTwrzWMmckha8+2IKBWBIXn1qvhW3Mzgigno9uaSEejCU1AVeXFjoBnwewCX3Kf1u5ik0WOHIIwU6wyG6emsCabgefQ4yIhV3PGbF2ZKzwul2YN7kSbx3p1Squ3K7hya0wD76TO1tb9hnxWodphMOS4Yy4nTgjpReWMcMwDckbcdV3bAQSNocLOT7spNeI+LJKKdYxV8t9IsY8gHxcFSfIYiSfhbOwYRr98cMOnIZC9xnZfrgHv33pXSiKktFtM1vX0WyI91NVyIfqkLpIVwV92sJh9X4T56Y84MGktMtwvN8YppH/VvLCPmNiGb59xQJ8YflsAPYi1SpM0zsY18q7u8NxbYG2yvUKxxI4MSCJiERKCtOon/msYRo5gVU6B3azaeT3jkGwRIbmjGRLYM0VqZ01qVw7J+JvUh7w5l3Ga4UcpqkKeo0CxGLejHxblcEZsZ5dY8YyZ6QEm5yZoTNC8kYkt5aaM7L13S78yyNv4fZVpxm+iJz0GpG/AHvCccu5PGaEgBEVRnYNpYbKEamyJ5+FUxZidnkciqIMyxdtX55hGquGVCNxXIDqLvzNfz0PADitsTKj0djJhmmqQl7UlPlwvD+KyqBXm3Jt7YyIihCvoVePLEbk8ycW1IqAFxtuvRCAWkINZIabBFZiRN62L5LQ3qNVVs5IPGmYyBuJZYZpsuVQ2JX22nVg7Y9ZCxa7pmdOwzSaGMnxeQz5PNpjz22o1M6/cKQq8pg/kw3ZuTCH0mQXRJ9NIzc9swrTGD8f5jYL2XJGSpnSP0JScujOSGklsP71rQ7saOvFX7a3m5wRJ2JE30a2qrMhvjSFODvZSbBmDM5IHgun7DhY2dMPbWnFom+vz6tc2I58wzTZ2sF/5XctuOwHzw1b+ObuZ/do/2/viVpU06jPoygK9hztw9Z3uxz9DYUYqQ75UJMWrWqYJu2MmMRIPJnSXne532MUI5JAks+fWFCtGmDZpT5UBr0ZFr78mvujCe19ZJkzEksaJvJGEhZhmix2f9y2tFd9zkQyZXgfG8usrUt7o4mk1Gck+3KlJ7BmVtNYMbOuXPv/vIZKrZLpeLq7dPkwiRE55GvO/fIaWsNbJbBKYRqRwGqqpmkztSOwzhkZg2GaTZs2YdWqVWhqaoLL5cIjjzySdfs//OEP+MAHPoBJkyahqqoKS5YswV//+tehHi8pAXRnpLTEiPhCC8cSJ+WMdDusqBH7iPNh5V4MxpJD7sfSNkQxEjWFQsxj1W/9/RvoDsfx+d9uGdJxyfTZJCHaka2094nt7djV0Yd3O4c+RE5wuHsQ6144YDg2cZUvhkKK4/3nR7Zjxfc34aP3bMaX7n8t52OL91N1yIeG9LyWSZUB7SrWnKcjX/WH/B6tOVmGMyKdP7Gg+gxXydndupDPk5FXIYemTgzENKFq1SAtHEsam8JJOSO15XoCqx1xm3bw4nVly1+y68DaH01o4it3NY05ZyS7MzK7Xk++P6WhQnNexPdauYMyayfIgmOCqSGZzxCyyd6BVYRpzM7I/3vvdINrlC2BtZTJ+wgHBgawcOFC3H333Y6237RpEz7wgQ/g8ccfx9atW3HhhRdi1apV2LZtW94HS0oDzRkpNTEiNVAyJLDmEBdyvwPAea8R8aGvr8wcrQ4Au9r7sPBbT+KOP+1w9HhmjnQPMUxj+hK2C9UMR5it1+CMDL20V1EUrYRzOBymre+eMLgwA9GE5niJGSvieV6THKK32/pyPrYWpgn68LVL5uGfPjgfl53eqM16Mpfoit+9bhf8HrfBWTTkjJiafQH2ZZ5WhPyejFCGLC6OSJ18raqzMsI08ZTuAqUX0WyLmqJA6wliKO2Nq4I820WBXQKr7LY4zRmx6sBqxexJujNySkOl1oVafK8NlzMil96aG9N5c86myZ0zMqe+Ai23fwBf/cApAKzDhGMyZ2TlypVYuXKl4+1/8IMfGH7/zne+g0cffRR/+tOfsGjRonyfnpQAM+vUhM0dR3rR2hVGczqBc6T45h/fQk2ZDzevOCXrdkIMROJJg0Wbq/GZ+Uqix0EiqqIo2n5icTGLkTcP9yCWSOFPrx/B7atOyzsXQl488slHMdvTA9GEoxyYoWDMGcmvmiaWSOLuZ/dg37EB/NuHF2i2fTaHpbUrjLaeCM6bWZv1ecwDAvvTJbcAUF8VwO6j/drzyGE8J0nI4nGqQj7MrCvH9cvUxFJRsWWeByQW2pDfA5fLpb1f9hztN5Sbhi0SWOUcjYosYsSVrvwwN03rkgSnCPtVBryGBmICc5hmMJ7UhIHo0Jxrpkk8mYLH7TEsiIqiCoNsFS12pb0Cj9uVM3HTb0pgzZUgPX9yFfweN8oCHkyfWC6FaYZXjBjDNMbPodVsGpmqYOagPKvtAl6PJjis+tyMyTDNyZJKpdDX14faWvsvk2g0it7eXsMPKR3m1Ffi/Ll1SKQU/PcGZzNJhsqxvijWvXgAP3x6d0a4wUwk/aXfF0mYMvuzOx3mK4kTDsI0kXhKuwq0yxkRj9s5ELMtx7QjmVIMremHWk0DZB8Pb0U+YaVsTc9ufeh1fO7Xrxoez5wz8l/P7Mb/vXYIuzv6tduziZHrf7sVV/7PZrR2ZQ/lmAWBQYyYnCxzK/BcuQZC6FQEjF/wwtY3CyGRvCoW9Enpydfm95l8/kTVkcGyz7I4hnyq0DG7B3JlhXg/VQa9lomo4ZjRGQnH9IRXsTDnsvvjyRQSyZSlIBNixOp1xBL658lKtDjpGJqRwJrj79hcG8L9178X91/3Xnjc+rkTxz5sCaxZnBG5j4n4vzxp2dBnxJ1ZbWP1WFaO0JgM05ws3/3ud9Hf348rr7zSdpu1a9eiurpa+2lubi7gERInfOmiuQCA329txZHuQWze24lbHmwxfJkNB3qSYe4ESbG4mHM+cuWMmK8knOSM9KWbpLlcejw9mkgZ5kLIj/vK/q6cjylzvD9quGp2mjMiTyoVX0Dm8Em2FiqJZAqrfvw8PvXLVxw9n+w6yQtQdziGh7YewlNvHzVMQpYFZX9UX+y6TFUcduw/roqWXD1dzC5Nz6DezbS+KqA9T9xi4cz19x/QnA7jYlUWsHNG0j1G0uKlubbMckGWxYhVO/JszogIMWTrxSHCflUhn2Uzr8G40RmR803E4+da1BJJxSAmRL7EYDyp5QLZjZoYjCeRSKYsXcBcPUYAKUwj2sHncBNryvw4e/oEnNpYBUB/jYLywPC4CR6Pfc6I16I1vBySNcygyVHam821Go5OsiNNQY/wvvvuwx133IEHH3wQ9fX1ttutWbMGPT092k9ra6vttqQ4nDezFmc11yCeVPD87uO4+ucv4Q+vHcZND7QM6/PIVzdW9qOMWLDNVnvPYDw9Q8X6ij9DjDiophHlcxV+r+FLK2LTaOnVPMXIYVMvCac5I7LzIESSWcTJIRvzOWnriWD74V5sfOdYzkZRgH2YRm6xLdvl8YT+fPKi3+1gmq58pZ5LnJkFwVFJvMjOiOyaCQvdrnRWPg4gM8FR/G4+30Jk6Au6B5daNBoMW+RK+GzKPM2IxTpbxYmY/mznjAzGEobPjiiF9rhd0oC13GEakS8S8nk0R2UwlsDvt6rf43YdZMOxhG3eUa5KGiB7nxGB/Dczhy7N7stI5IxkVNNYdGC1E1HCibPLHcrWLZZhGokHHngAn/vc5/Dggw9ixYoVWbcNBAKoqqoy/JDSY1Y6Aez4QFTLeN/4zrFhfQ75KimXwyFcFPOV7V/f6sDCO57EvS8ftNotI0zjZD6N+NKsCBrj73I4RX7cl/MUI12m5FKnYkT+AhaWsHlhlss6zffJ4qLNQQdYuzDNfiksZQg/2ITaTgzkFiNyB1W7sJUQV+L+iWlBJlwBv9etLUKD8aTm7FQE9P4fufJGxN/e3NU3V86IvP2HzmrKeFyr8ySLkXK/N6P1t0AspNnCGcL1qAz6rMVIPGn47AhRVpbOdQFyX2HHU3qialXIqwmwt9v68NK+LrhcwNWLp1nuG4mltN4jfo/b4MI4C9Okq2kS9mGaxnTycsDrzhCTZqerIkfXZqcY+oyYxIjPYjaN3ft/+bx6rFk5H7deOs/y/mxJqgzTpLn//vvxmc98Bvfffz8uv/zyQjwlKQDiy7uzP2Z4s+891m+3S97k44yIBdtu5sk3HtlueXumM+I8TFMR8MItXTnKXyRyCONw92Be7d3FMdSlSzCdhmnkqypxpW/OGZG/HM29YmRxcaQnd4ddQwdWaTHdd8w6B8Tub9MlJ07aCI3OHILl3c4BLP7O0/ifjXszesC0p52RqqBXW9jCsaShZ4hopy53IbVCOEBmG1+rpjE5IyIJVA4DLLGYBWWZwCqJEbfbZVgg5XCbeGwnU3+rLPqRAKrI6jY4I6IUWn9O8T53uayv0BPJlCZGKoM+7Vz/ZvMBAMD5cyehubYso4U5AITjCe3vVh7wGISPk9flxBmZXluGNSvn4zsfPiMjodwseMqGK4HVlSWBVXZG0sLE7sIj6PPg8xfMxtyGSsv7szojo6CaJu8j7O/vR0tLC1paWgAA+/fvR0tLCw4eVK8616xZg2uuuUbb/r777sM111yD733ve1i8eDHa29vR3t6Onp6e4XkFpGiIq87j/VEt+QxQ+0UMF7Iz4jRMY0edRW8FQA+niNfjJO9FhGm0kdzpL0u7ttYA8OoB5+6IWCQnp/tYOE1gFeIt4HVrx2YOt8hhE3OvGHnbXM6IoigmZ0Tfd9+x/JwRY0lpEk/t6MBPNxmTo7sGooZtzLy0rxNH+6JYv6NDa79eXxVM76s+fmXQh5Bf/9LXu6n6tIUimzOSSinaYzt1RsTfTl7UvR43Pvv+mQCAi+arIWv5PEUtElgBY96IHEbQwzTqv9kcDLMzIpyijt6IoaGaOA+y6BKLWsiXWUYMqH9f8b6vDHq1z8WrB9Ty6Y++Z4p6fFY5K1KSa3nAawgtWFX/mHGSMxLwufH5C2bjo2dPzbjPnDNiTlAeKvJLNXfJNfQZ8WYXI7nImjMyDAP/Rpq8j3DLli1YtGiRVpZ7yy23YNGiRbjtttsAAG1tbZowAYCf/vSnSCQSWL16NRobG7Wfm266aZheAikWE9POyP7jA4ZkyyffGk4xkhn2UBQF+48PZOQ75Fqw7eKm4nGnpkuUexw4I1plQHpxEF/MgzEpQTP9uGJ2TT6hGlFePDm9mDot7Y1KyasixyBsisPLV4yZzoguKHI5IwOxpGHxMjgjxyVnRBIpcp8RGXNJ6T89/Ca+8/hO7Dmq9/3IFabpSjsafZGE5k7Um5IlK4NebcEeNDgjXs1CzyZGI4mkVoJsl/AYjiXw7K6j+MRPX8LBzrDmjJiv7v/5g6fima9egI++R10Y5b+TVZgGMOaNyEmw4rHF+3BShXWSKJDOGZEeV7hHZudO/G1l0SM+Q2V+j+XVdjypGGbJmAXL6U1qyN06ZyWJdztVEdtYHTS4rbkangFWfUYy3yPZcifMSbLDlTNiFToVGJueqcLz9lWnw+t24Ss5WhmYsRMcXrfLshy41Mj7bC9fvjxr6d+6desMv2/YsCHfpyCjBNHFUS7LBIB3OvrzmjFy6EQYv996CJ87f1ZGkp78QRYL5S9fOIBvP7YD//bhBbh68XTtfvOCXRHwGq70O3ojSKaUDItYnr77ems3usPxnMev2cl+kxixcEYuml+PdS8eyCuJVYRpGtJiJJZMWR67GXE1GPB5tMXSPCwvmzPSl4czYs61EWIkmVJwQOqialUlYsaQwBpLaVflR7ojmFOv2tLGME3m44h9+qMJ7TmtxIj8t5IbmIm5IV1ZwjRygmWGrS+ckWgS9798EJv3dWL92x1Saa9xe7fbhVmTKvBuukw5HJfCNInMahrA6IxUBL1Aj3huoxgRk4GtqAoZnZFJFQHsOdpvKz5l0SUEQpnfaxALfq8bsUQKiaSifWb9XnfG+1U0nLMrLd5+WG3jcHpTtaEpX9BBzoPfQQfWbLkTmeJyeMSInCRtFqQetwsul1otKATDwuYavPWtS/NOOrULxYyGfBGAs2nISVBXbmz21VitVyk4bakOALc8+Dp+8NRu/Hbzuxn3yc6IEBZvHVG/gbcd7NbuS6aUjIXOXEKYSCkZw9IAXTQ0TyjTtstVSSKsePGFFcwiRi5M2/C7j/bnrNQQiEVSnFPAmX0bk3INyrX25PZiJFvOiHnmhRlzGEoIgMMnBg3P4SiBVRIjPYNxrZpEFktdOXJGxP19kbitGKkIeA0htV4pZ0SUXWZzRsJS/ofbtNAKYRqOJTQxOSAJI3OCpKBM5LAYnBH19ZuvdmWxXmERphELai5nxGfhjNjNmrLKGTE7I+J546mUobRcFmwTy/2aYLMrLd5+WP1sn95UZUxgdeCMZPYZyU+MmJ9juPqM5Gq6aNUGfijVL3bOSK5GdaUCxQgZMrWmHIwpNSEtL0PuHmrFS/s68dl1r+KBVw5qPTi2H8nMI7KaMSOumA5Kja+sFuqqkA+fff9MfPQ9U7VFyWqBFYtqXYVf+7LK2WtCSrQD9C8yOXwgBM302jLMTc/BcJo3Ip5f5DwAzpJYxYDAgM+tLSLmHAZZtGWb+JnrbyiEi1iTRThm73GjU2acRmsTppHcCFmAyMcnh2ms/t6iIqc/mtDcIPn8AWq+RJlPlJuaxUjaGUmLkV8+vx8Xf2+DocGaVWWMoEwL0+iJoAOxhG0psECIRisHyRymkTtyylfuQgxcfmYTls6ZiP/3XuuKFUA9B970FTmQKdrrTEJGTuQMSKJHzuMQ77V4Qhcjfq/H4DZMnRDS/m/tjCSw44jujPjzrKbRc0bE1F6LME2Wx8ko7R2mappcTRetBuQNBXP5s3i/jYZ8EYBihJwEE03JWBMr/GisVr9w5LkqVvxk4148vfMovv6HN7XbdrVnzgWxSggV7sYhaZGwWqgDXjf+5W9Ow/euXIgp6S9CKzEicjuqgj6t7DVXGbG5vFN8kYnjTUruSmXQi3PT7cudhmrElfWEMl0gOUli1XNGPJbVHcmUYkg2Fgt/z2Acg7GkqbQ3kjUk26uJOHXxCqdnkMjJq0D+Cay2YkRKYLXMGUk/RkrRW3pb5oz49conuZpGhGlE/sovnt+PvccG8NAWvc9R2KaSBjAuXuJ9NhBNSE3SrBfCkEU4TcsZ8ZoSWOWcESlkI95/8yZX4t7PvRdL59RZPhegVtO4XC5tkTKLEVk0qK9LTiRV9ykPeA05FuI1JFKKIW9Jfs1TZDFisUDuau9HXzQBv8eNuQ0Vhm3yaXomBO/JOiPD1fQsV+K9OG7zALx88XuMxyt6moyGShqAYoScBEGfx/DlWFseQFONeiXaluOq+qBFO+/9xwcyrnitckbEYtXWG9GuwqwWJ/mLR4Q72i2OS87+r0p/wef6AhGLksi4N4dp5DBPRdCLc2dMAAC0tHZnfVyBuJqqKfNpX5K52lur2+gLgRBK/fIANtMX9LG+KMKxBJb/x7O44u4XDMctL9ZWiHMkKn4URc3b2d1hFJVyLoTdvBDZvZHFyPH+KFIptatsrjCN3KtECKWaMr9pCqpebppSdLFTXWYM0xzuHtRyLp7dpffOsesxAqhXpsJtEOcmHE1qLprsasgIESNPeI4lrJ0RQ85IIFOMCLxul22nXTGWfnJ1ED6PCzPryg33L5xabfhdfq3nz52E82bU4qpzm7XPl9wULZ6UnRE3Qj5936kT9BlWVs7IlndVoT5vciV8HrdhEXUkRsQxmBJYrXJerBipnBGrwXUyl5zWgFMaKjBjYnnW7XJhFh2iSoo5I2RcII8ir6vwawlqdslzAvFlPXVCCJ+/YBZqynxIphTsOWq0+M3VNIqiaHa9ougVAFa2vRx3FYmgbRZtxMUCXBH0al/UuaxVsY/mjJjCNOILyO91I+D1YGadGqY5dMJZrxHhFFSHfJaVOnaIL2C/1205RdYsBo73x7Dv2ABOhOPY1dGXEbY50h1B10AM//vSuxlukXiNsvswEEvg7bTDNSu9yA06cEZk5HDMsf4orvvNFrzvzmdyzq+xyscp8xsFc1XQeEUvHIzqkE+7kuwaiBkcrDcP92jnJWzRM0TgcrkyrP3+aELv1mvTOVN2FUSIwarPCGDOGdHFjTkfxeVy2S7g1SF1299euxj/94X3YUqN0Qk5a1qN4XfZIZhcHcSDNyzB35zZpJcRe9xa8mU8qSCWTGq3izJqwD5MI5Jc3zikhmkXTKnKeO2Omp7ZJLDKIjBrNY3pvuHKGbnrYwvhdgHfuPxUy/v/4+ML8deblzkSXNkwv1dqtEnLzBkh4wA5VDOx3I8mB2GaWCKlXf0+unop1qw8FfPSjXx2HOnFtoMntFCC2RnpGYwbyohbT6gOi9XiJMdQdWfEPmekMujTrO/czohxmFbIZ2x61q9dDav3C8eooy+Sc0FOpRTNkaiRxYiTBFbJGdFyRiS3I5o0tUnvi+DQCd2l2m8a6NfWM4ifP7cP33hke0aCsWj7XR3ya+d6IJrAO2kx8p7pqhskh2nkv50d8jZHuiPY8M4xHO+PGl6/eX5NPJmyTBQs93sNV7gieVO4JR1aMzSf1gOiL5LAi3uPGx5nU7qzsO6MWH/Bm28Px5JahZLd4ibvI4SblsBquqqtNFfTpAlZWPF2i5sQ3NMmluHMqTUZ4YmzmieYjs/6uMUVt8/j0oRAIpmSKrrchn1l0SO7VTWmtuynNanOjPza82kHr+eMqP/K5yxbyMLtdmnPI7s9J8v759Zhx7cuw+fOn2W7Tb4Tva0wv7alc+pwelMVPrxoykk/diGgGCEnxUQp2W1iRUBzRrKVhXb0RqAo6peNWADmT1bFyD/83xv48H+/iIe3HQaQ6YwcN7VJb+1Sn8c6TCNf0dnnjIgr/oqAV8sZyWWtas5IQCT06Va7ur9xAaorD8DvdUNRrAWR4bFjCa3HQ1XIpyXdOUpglXJGxLHJIRDd/nfB63YhnlQMVUkiaVV8ER/piWhOhegBIdA7bXq11/92Wy8G40kEvG5tAJnBGckx1t3M/uMDhhwXgflc2CUch0zOiFiIxUItyoWrQj5Uh3xamGX9jg4A+vtyQ1qMiIZndsmNZmu/P5pAf7pbr53t7/O4tavavccGcLw/apvAmqvPiIxcDmsMVZmbtXkM982YWGZoO2+XOyHel36vW+seGpfcnYDHbRBExjCNfnu1qSvpWVNrMrbJpwOruc+IQYzkEBhC+JdLLfCHg5N1PZxgdkYaqoL485fPx7Xp5nqlDsUIOSkMzkiFH41pByBb63MhCBqrg9oHft5k4/whMeNGdkb6I4mMvhjZnJGAhTNinvaqKIrBxRBORq5yPL1Cwrq0t09qiQ2oV11N6WPIFcISs3GCPvXLXFz1Ointlatp9KZnmWGaoM+jJRS+tK9Tu1/kq86apIaVjvXpjsRRUwhnZ5ta+TB9Ypm2oG19V+20OW9ypbZYGsJE6St+J7Z7Nsznwqprqs/jgl9q/gZkNqkTVId88LhdmqUvkli/eok6B+S53ceQTCnauSyzWaAznRE9TGM34AzQF9uP3vMiLvzuBtuckUqbahqrsmF5ARTDAb1uV2Z/FCmvY/akCjXEIwkBO2dEuAhqmEafCyMcCb/XjWRK//zaJbDKjcDK/B6c2qgKQEPTs7wSWE1hmpCzMI36/OprHa4QTSHxeox9Xaxa/pcyFCPkpJBzRiaWBzQrtqMvioRNOEIkt8o9NOY3GuctiNBC1FRN02lyRkQirHXOiP72Fp1M23qMFSIDMb2jZmXQpy1GuZwRrZFVwLi46WIkcwESrlGuGTXiKr8mpJ5bq1bzViiKgohlAqsUppHuF51ht6fLKWUaqgLac2pipFcXI4qiYFs6Gfc90yZoi/BraZdl/uRKQ6mrQCwUJ5scaG56ZpUvIv4mcjhDLOZm0SCS/eQQ2hlTqnHhvEmoCnrRHY6jpbVb7y9j54yYbh+IJvWhilles1yx0hdJaG5StnbwFRbVNDJyGWt9+u9Zma6kkQlKeR3TJ6rvCdmJsCtJFgu7z6s7O4lUSndGvB5DAzn59cufzQmSM3JWc42Wf+LPU4zoSbTGEG+lIWckhzOSfq3DNZem0Mgib7QkrgpG19GSkmNiuRym8WNSRQA+jwvJlJJxJS3QnRH9Sun0piosbK7R7GGRxxCRKkj6Ywkc7dOnrwJ6ea91aW9mAmsskcKJcBy/33oIP9m4V7tq9aTjxUI8iHwIO/QEVtFnJO1e2IRpAD1mnkuM9EiVNIDcat5ejHQNxHDed57GnX/ZCUDMptHFgLlKw+9xa7a5VRhENM0ajCU1EST/PfcfH0B3OK6FY8SV+WsHVWfk1MYq7dxYiZGTnfuR4YxYiBEheMw5I0Dm4ibEiAjLAMD3rlwIr8eN8+dOAgBs3HVUd0bsckZMr6trIKYtznYJrEBmGEK8BzI6sNqEaayORzgXLpdefl1pUdEjL2BCoMohHruFWTy+T3ZGkoqhmkbkSmU8p/T4NZIzcs50PV8l3wTWDGckbhGmyZF7ooVpRqkYkV/fyfYtKTSj62hJySGcEZdLtVvdbpdeuSKV0YZjCe1LSuSTyM5IwOvBo6uX4ulbLgCgVp0oimIYdqUowLvpNuML0jMuWk+IappMF0ZOevN73dqXd3c4hn9++E3c+Zed2J2efSKuGMWXtZjKa4dYYHM7I/qXv9NKo+5BPY8BgKOcked2HzNUwqh9RtRjk6s0tA6tkjNihbiSHozrYqRzQHe7RJ7JGVPU5lTi6lm4TPMnV2llnVbTaE/aGTEJsy6LMI1Y4CstxIicTBny6RNib1pxCj5+9lS8+PWLcEo6qXr5PFWMbHjnmOaM2IUuzM6I/DfL1kTLfD5EPk5mmMbaGbFyDkSopdzv1c5BVSjzGGSnRLzmYB7OiLGaJmUY1njVuc344vLZePDzSwz72iWwnj2jVn98X75iRH3M2BCraQD9PTNcQ/IKjSzgsg1LLEVG19GSkkNccdWW+bV4pVh0n9zRAUVRcLQ3gvf/+7P4+1+8DMCYM2JG7BuOJXEiHDc4IwBwIJ1EubC5BoB65TkYS+ZMYAX0xb2tJ6J9UQlxU2H6ss5WTaMoitagqtymz0iflNwpEDHzwzkawulhGqMzkm1YnsjVEAS8bq3NOKBXgcSkBFc7MSJfSavOiLqPoujdb4UDsihdBipfmbtcwKmNldpt4m+jKIpmoecbk//Ntefhovn1+Je/OU19TJMw6+q3cEb8mc6IWJhWXzRHu01+rAtOmYT/+PhC7X0IABekxcgbh3o0x84uqdPOMSn3e7LOFTIvtuL9ly2BNVufEUAX4yG/RxMulYFMZwQAbrp4Li47fTIuWzBZ3TePnBFDmMY0mybg9eAfLpuP82bWGvaVF0q5emqRVFYcMDQ9c1BNI/U6URRFCtMMJYGVzkihGZ1nnJQMC5qq0VQd1L6wAeDS0yfjlf1d+J+N+xCOJtFUE0LXQAwv7+9Ca1fYMkwjCPo8qK8M4GhfFIdOhDPGgIvS01l15fC6XUikFJwIx2w7sMpUhXw43D1oaO8tXArhYIgv62x9Rgbjep5JuU2fEXNpLzAMYZoszoiVGPF63Ah43YgmUhiIJlBb7jdY6HZipMLv1RtxSTkjgFoKPLk6qDkj75mm2urygvX+OXWoKfPrvTnixnJVID8x4nIB582sxbJTJuFw9yC+/diOTDGSdkbcLn3arH6Vqz6Xz6OXa75n2gTMn1yJnRZdf83UVwZxelMV3jrSi+d2H894vTJ2jk+2EA2QWQ3UaxOmMTgjOcI0Ac0Z8WSIbTNf+YBxQqwhZ8RGeOl9RtTKLMA4mybblbncLfRMqcma7GLkmzMiBFE8YZxTVWUQI7kSWI3vmdHGaHZGRucZJyVDdZkPL3z9IoPVe+3SGfC4gDse24HfvvSuoeLmud3HNTEy2cIZAdTmSKoYGcxwRoSTUVcRQE2ZH8f7ozgRjlknsJqupsSXUqvUV+PwCSFGxJe1SGC1d0aEy+By6ULB3A6+z6LRlRamSYeg7EoH5RblQO4E1v5oAm+3GZNQxRdRRcCLaCKmhZWiDsSI2jJdF1ey63S0N4pIPImd7erziQZZsvC76txmw3GL505IlRW5FmcAqC33o2sghqkTQtpiJM5zLGGcYixyRppqQlpjuXLTwlIRMCZv/uaz5+FrD72BlWk3IBunNapiRGC3QNvdnmtxe+eoURSJMI3flMBaGVTnLaUURWtfD9iU9qbf/2V+r+Z0mVu/2yE7LXbCSyzcQZ9HD9MkFEN5uR3yQnnezFrc97nFmGHqBCvvn081TTiWMLiIhmqasZ4zIp2z0TKTRjA6zzgpKcyLqsvlwqeXzsSOtl48uOWQYfT70293aOW5TTWZzgig9iN47WC3pTMiqKsMoLbch+P9UXSH49qCKZwA9f/WYRrRmwTQE2VFTL3SQWmvqPQp8+mTWzNzRoylvUDmVOOaMh8UBRnTX0X3VZHYJ5IJ7RJYX2/tRkpRxYsQMuIclAU86BzQnRp5qm91mQ9VQS96Iwk0VAXQka6WqQh6Da9HbkN/tC+KY31RpBT1XIsqJbnN/QdOa1CfO72ICeEQT+jOiJZc6vdkDPITzJ5Ujq6BGOaky4wB4yIZiSe1x+lKOwvTass0MaKVaYoQhSl5s74yiN9ce57lc5sxCze7HAa7hbvCphW8dn/AaxDAwkWystpFqCqRTKHc70E8pVi2mg9qC6sHHz17KuLJFP5mYVPW49D31Z/XTmAtn1ePj7xnCj68aAqeSvdlSTh1RqT7Al4P3mcxS8cwKM9Bn5FptWUI+tzojSS0MCJgPXXYDvE8o1WMyOdstDkjo+toyajiKx84Rfvwz56kXvWI5lEBr9tQ0icj2kbLzog5Zjyx3G9o3y1EgOzCmPcRToPBGek2OiO6GFEXt3AsgZ9t2oeDnfo+Il9ErjLQnIT0cfRalPYGfR7tCvXQiUF845HtOPtf12f0PhGCQoinYA5nZMsB9Yv3glP0UJkoeZbH2gPIWCimpUs5z0w3mlKP2WdwegzOSF9Eq6qZVBnQhOg1S6YDAP7mzEZNBMqhg3AsoQkhlwtaPku2K/Wrzp2Gvzu3GV+6eK52m7yYyKEa4YzIoqHMtLBk6/ORi2aTGLFbrOySPStzLG7/8//ONlSTCbLF/b0eN371mfOw7tPn2jgj4u/gRXXIh89fMDuj9bsdYl+XK7NNuqA65MP3rzwL58+dZGgHLyew2iHfZ+dW5Du1N+T34MJ59QCAR9JNEwNeY+O1XGGalQsaMX9ypSaoRxvyeR1tOSOj62jJqKKxOoR/vGw+6ioC+P6VZ6Eq6NXKSK86t9k2TCG++A+dGNSckYwx55UBw2AzsTDVSn1PMpyRYKYzIhbWClOYJpZIIRJP4pFtR/Bvj7+N7z65S9vH3AoekMtv1ePttyjtBfTS0W//eQfuffkgToTjeNk0yVc03KoOOcsZ2X5EnemxaFoNbr10HoI+Nz6zVO26KBZNcwKrJkbS5/rUyZWarVsR8GqlyuFYUutdAgAdvVEcS5dXyzNprjp3Gn53/Xvxw79bpN0W8OqD4wZjSX0SrTQEzTyuXqZ5Qgh3fvRMLS8FMLbslkWSEHDy/BMhRhY116Ay6MUySazli1mM2Jf22jgjOcTI++bU4dHVS3HudGOiZ64F5byZtZauAqAv8kOZPivec7L7lw2vNBdGrtiyQ66msRM7xqZnzpaqlWc0AgD++PoRAGpJv9GFyf44759bhyduXoazpRLj0cRodkZGpxdFRg3Xvn+m1o54+bx6/PH1I1hxagNuS1vNVujOSFhzA1QhoYqIc2dMQGXAq3VuPBGOa9vVSn1PMhNY1be73MVVbngGqMmbLpd6e18kgf3H+wEYW6Gbe4wAmTkj8qA7mZtWzMXze47jFUmApEx9PkS7eBECMT+2GeEKTK4KYuUZjbh+2SxtERPHKEJLMWmQHgBcvXg6Ovtj+NuzmvDQ1kNo64moOSPp5+yLxA19SI71RbTEVFkg+r1uLJ410XBcLpcLZT41DBOOJTVh4nO7tARGMVVXhCWCPrcW77dzH0I+DyLxlOF8CIFYX6XnIQlh0FxbhpbbLslazZILc5jG3hmRK3e8mkPm1PY3uwR+79CPWSzy8uRcx/sKMeLwuPVqmpShl02u7V0u+06hhgRWh8PeLppfD7/XrR3DP31wvlGMOBQ1oxX5AowdWAmx4fZVp+HHn1yEu69epNm6VggrWQ3TqF8qouTvvbNq8ctPnwuXy6WFaU6EY9pVshymyRAjWeL2wsJ3u13aVWxfJK7lH8jluFr3VWnhCUlhmlRKwbG04JEXRwA4d0YtLj+z0XCb7HikUorWn0WUApvLhs2YE17lq2mtJXw6TKPl06S3WTqnDr/7/BLMqa+UGmPpOSPdpqoikTMC6C3GsxHSwkSSM+LVm8tNLPcbbHS5Nbidm2DlFA2mX1+DLEakxz0ZIQKoE6mNSZ25m57JOVFOQ0TmcIRcdZIvy06pQ1N1EB84rT7vfbXcCQe5GgAMs2nEeyybmyHmzqjumY0YSb9HA163I3cGUN8zF6VDNR87eyouW9Bo+B4YbUmd+TKaXyudEVIwJlYE8Ddn5k6gEwu43LnzyxfNxdWLp2NeQ6X2xVRbLsI0cW1hkhczuy6bVsgx/aqgD32RBPoiCS2n5Hi/WkUS9Hk0l0G2v8VzJdNCRFzpT7IIQ3zj8lNxrC+quSPhmDFBNJ5Uq0Qa0s5DUHNG9HDJy/s68UjLEXx95fyMHBMZkVApkkSzJRfWpUNclUGfthgppuasR3ujhpyRXGi9RuIJiK8bn8eNKxZNwdG+KD5+zlQ8u+uolrxZU+bXqq3sKm7kSh/1GBWtfFgOHQ1nS2+Xy4WmmiD2HlMdMift4KfUhLTSYaeloubcD99JOCNnT6/Fi2suHtK+ImnaLiHXjDybRndGclfTZMvhEM3+8h0y960rTsdFp9bjb9PJuuK5vG5X1ougsUBgFIdpRtfRknFBud+T8UEK+T04tbHKcIVkTGBVvwDlWTkZpb3ZxIjkmshJrKL0F9DDJ1YJrPIVrSg/nlDms/xCaKwO4cHPL8FV56glsINSh9LD3eq+k6uC2henuYcJAHz3yV24/5WDePKt9gxnREYIpgFzNY3FcYkr+dpyv2F4msyx/ija0wm3+YiRcCyplfb6Peq05q+vnI/ZkyoMC7Cc1OzUGYkmUppoko/Jzr0YKnJ+i111h3jOMr/H0ObcSSkzkOmMFCsJMagl/zo7h/psGr0dfLaQiC5Gcody8h2qWF8ZxJXnNGsipq48AL/HrQ3xHMv4R3ECK50RUnK4XC5MLNevkAHrqyPhgnSHY5o1LDsjmQms9m/3CpMzAqgugFyWfKR7EDPqyvUEVumq0edxweNWZ/KI/JJcYYyQqQIHgBYWmmKRiClEUCqlYEe658Xh7kHttZtHsQP2CaxWi8ANF8zGxHI/Pn72VMPwNEAVKKJ/w2vpBmv1DsSI3GtEvA5zLDskVW6Ic+9xu2wXKnMOjSzSakI++D1uxJKpERUjdsc2a1I5pk4IYeHUGsNC7tQZMb/Pi2W1awmseToj0URS66iaPWdE3T6bYBGl8HbzbZxSXebDH774vqzO6FhBvC9dLmiN6EYLFCOkJKmVxIjb5oMlrqJPhONacmRtlpwRq8VaIMf0xf9FYy+BCNn0W4yRd7nU0ez90YRWVivmu9hhNUhOPIdcgim+RIUD8m5XWAu7HEh3pHW5jOJIUK49hzFnxMoZaa4twy2XzAOghj7kbqZlfg+mTgjhjUM9WlJmXmGaWBKxhHXvDLmhWZmUq2CXS2DOoREhGjEjpTLoRedAzPFC6pQ6yXWzO7Yyvxebbr0QbrdLG1oIOM8ZMYuRYl3dium9Mybazy+SES6eEL2Asz4j2RJTZ9SV4/++sARTapwdQzYWTKnOvdEYQJxXn8c+F6dUoRghJUltuTH3w+qDJSewiiu5bGIkewJrZpjG3Cr8SDqJVUxuNecNhPyqGBFhmlyLtdU0XhEWksWIaAvfM6hWtryVLuUFgP3p56oK+iyT/MSC3BdJoLUrLDU9y+4aCHElRE/I58EpDZV445D+3E7EiD4sz1jaKyMSHYM+jxYeyOYkmHNoxPkTjyPEiNPkS6c47V4q/g4VQ3BGMsM0xVlQLpxXj8e+9H7Mqa/IvTF0p0OEA4HsIZiZdRVwuYDZk7I//tmmUmeSHeEGB0ZZiAagGCElSjZRIRDOSF8kgUQ6YXRihR+nNlYhmkgaYvZArpwRb8Z25hbrT7zVjl++sF9zKMzlmuV+D44B2H1ULQceSphGc0akME1NSH0diqLOLJHbkgtnxM6CFovgn99sw5/fbNMWVCfJbSGpO2rQ59F6pAiy9QgRlEnOjFxNY3gekajodTtqx23OoRH/CuF1/bLZeGbnUbxnmHtFXL14On770ruG5nLZkJ0Z52Eac2lvcRYVl8uVl5sgqmmEa+h2IWuy6My6crzwjxcZcrzIySO+K82fsdEAxQgpSczOiBXVIZ/WE0Qs6GV+D/5041IoyCznFJNTk6a+HoB1mEZMqK0Mqq26zeLEnNw3a1IFDnSGte1y5VSUSWWvgiMWYRq/142KgBf90QROhGNavgiQWdab8RymYxRluU4WOfm8C2dEUFvudxRCkMM0cc2VMeWMSDNOHIkR0fRMhGlixr4vn1w8DZ9cPC3nseXLhHI/Nn/94rzKTLX/O01gNVfTjJIrXLH4CTGSq9MpYD8Oggwd8bkebWW9AKtpSIky0YEY8XrcGaGXUHpol9WXuMvlMiSxyh9YqzHzArtujOYwzamNRucgV86I6HIql6getkhgBXSx0W1yRsz35zpGgSNnRDrvQb/RGbEqWbZ8DOGMxJOI2cxbEX/fgM+jbZ8txyIjgTWuuzcjjVMhAhiFoJgGnYtSyRnJFxESEw34RltZ6VhBd0ZGV74IQDFCSpRsnVRl5FLQMmlUuh0iBON2QSv1C/k8hi/9pXPqDK7KuTOs49ZmZ+S0RqOtnTNMk86nEItpz2BcC4uYZ4hMSPdU2d3RZ+ggK7AVIzbnw0lMWb5KD3rdmFQZ0PJXcgkt7fmF+xNNIJ5OnjXb91qYxqfPEbETUYBedtoXSSCaSEphmpEXI/kgn3unJbKyAPS4XSfdrK1QiM+VeP9SjBQH0UyOzgghw4RoaAbozY+skPNCLjmtIWdTI+F6VAZ9qAmJ/xsXvgVTqvHVS07Rfj9HckbkD7m5WsPsjORKeDRX04iy3roKf8YVsihZfjU9FE8OYwH2+TB2i0K+zkgoXd0yLx2qceqMNKTLM/d3hqU+I9alvSGfBxfOm4SFzTX4yHum5DyudS8ewDn/+pSWZ+NksmshkQWV0zCN/HcfTe28zW5irhkwZGQISNU0o43Rd8RkXODUGZEdgVUOxqOL+TTVIZ+2gFstFDcsm41PLp6GZadMwnumT9B6HnzvyoXaNuar1ukTyw1X57lyRvRETDXO/tgbbQCsKwyE6BL5KPMnV0J+ejtnZE59RYZwAZwnsGr/Ty+SIqlx6gRn8f6z0tOAX2/t1sqKzV+Ucs7IrEkVeHT1Ulxy+mT745IW7D5pXHy+zbFGGvFe8HvcjnIoAONrGE0Livn9R2ekODhpJleqMIGVlCROElgBYE+6cgUAzp+bu8pBfGnKYqTSouTX7XbhOx8+Q/v9d9cvQVc4hrOaa3DPhr3Yd7w/o7rE43Zh/uRKvHawG+V+T87haHIn0aN9Eax7cT8A4LrzZ2VsK1yc3R3q622qCWFCmV9rypatmmbzmovw1pFefOS/X9Rud2LjGnJG0v///AWzUFcRwJXnTM25PwDMb6xEwOtGz2Ac73SopdJ2OSNOJ7MmTAnIR3vVsFWphWmm1ITg97oxq67c8T4hqdncaLLahcgXOBVfZHgRFwnmnLPRAMUIKUkMCaxZVP6S2RPx+62HcEpDhaOrMWEnV4d82gJe6aDsctrEMkxLN4D6wxffh8FYEhMsHIdTG6vw2sHujAF5Vshhmp9s2IdIPIWzmmtw8amZg81EbozoE9JYHcSE8txiBFAXBuHsaLc5WPitxEh9ZRBfWD47574Cn8eNM6dW49UDJ7RZPGYxMjO9WE+rdbZoz5ho3E60pw8Nc5Ozk2VCuR/rv7LMUuzaIS/io8ldCPk88LpdevfVUXTsY4mzmmvwyOqlmDXJuQAuFUrr00tImuqQT+sAmi1nZM3K+Zg1qRxXnzfd0eMKN6Qq5NXFiMN4viDo89i6Nac3qWGMBgcJnnK/jM37OgEA1y+blbXBm2BydRC10m25Wl1PMO3v5Ko7aBGmGQpnNdfg1QMn8E7a1TGfm5ULJuPxL5+PuQ3OGmx94LQGfHPVafjj60fw2sFudAgxUmJhGkAN3eWDHBobTWEal8uFqpAPXWlxPBqbbo0FXC4XzmquKfZhDAm+Y0hJ4na7tAU0mzMysSKALy6fk7XVu4w276I6pPU5aKwePktz1cJGXHnOVHz5ork5txXD6BIpRev/YZeLMaHc+Poaq4OGUFYuMRL0eQwdSfMu7XUYQrFi0TQ9ATjk8+DT75thuN/lcuG0pirHi6/f68anl87UhJ+YkFxqYZqhEBqlCayAcfaTE+eNEBk6I6RkqU2HIYbzi+2qc5tREfDi4lMbUOb3oDLgddxR0wmVQR/u+tjC3BvCeBUsynXNDoYgwxmpChnCRE6GgNVW+DHQpVaeDKWaZqgsmlaj/f+6ZbMchbCcYH7NpVZNMxRGawIrYKzoGk35LqQ0yPsds2nTJqxatQpNTU1wuVx45JFHcu6zYcMGvOc970EgEMCcOXOwbt26IRwqGW+IK/9sw7TypczvxcfPaUZtuVo+e8WiKZa5H4XA73VnDACssXF4akJWzoh+mzmB0AqnFUoCQ5+RkwiBNFaHcMlpDThzajWuX5aZnDtUzK+5FMM0+SKf59GWdyGX99IZIfmS9ztmYGAACxcuxN133+1o+/379+Pyyy/HhRdeiJaWFtx888343Oc+h7/+9a95HywZX4i5FYXorFkszLa8XdM22TEJeN2oKfMZxIUTZ0ROCs41KA8wnveT/Rv89Jpz8Mcb3+94RosTzK95LIRpZJE4+pwR6+7GhDgh72+GlStXYuXKlY63/8lPfoKZM2fie9/7HgDg1FNPxfPPP4///M//xKWXXprv05NxhKiymFw9PLZ+KRLye9CXnudRU+a3Hfsti5HG6iBcLpfBGXFSsSE/hpOr7rJhSmAdKTJGAYwBMeJ2uxD0uRGJp0bdgi7/PUabq0OKz4jnjGzevBkrVqww3HbppZfi5ptvtt0nGo0iGtVbXvf2Zs7iIGOf1RfOwbkzavG+2XXFPpQRQ17wa23yRQC14kdUFwlxJsRFZdDrqG24HALKO2ekFMVIhjMyNlLggj4PIvHUqJu8Kv892GeE5MuIv9vb29vR0NBguK2hoQG9vb0YHBy03Gft2rWorq7Wfpqbm0f6MEkJUub3Yvm8+jF9lSWHP+zyRQD1ilmEJZrS1T+ibHRabZmj55JLmPOd2nsy1TQjRUYCawkKpqEgXoe5bX6pU5Xn+4sQmZJ8x6xZswY9PT3aT2tra7EPiZARQXZG7CppzPcLZ2RmXTnu+9xi3HP12Y6eS87XcNSBdZgSWEeKsRimAXQxMvpyRhimIUNnxH3NyZMno6Ojw3BbR0cHqqqqEApZ91QIBAIIBJwN4iJkNCOHFnJV9QjnRO6m+r45zkNYshhx0sNiuEp7RwpzNc1YSGAFdOE36sSIXE1DMULyZMTfMUuWLMHTTz9tuG39+vVYsmTJSD81ISWP7DhMyNG4bfm8elQGvHjvrIlDei55IKBdoqyMVTv4UsKctDtWwjQiJDbqxEiIYRoydPJ+x/T396OlpQUtLS0A1NLdlpYWHDx4EIAaYrnmmmu07W+44Qbs27cP//AP/4CdO3fiv//7v/Hggw/iK1/5yvC8AkJGMYYE1hzOyJcvnouW2y/B3IbKrNvZcUZ64q5T5KFtpbjQe9wuw1yhseKMCBdqtC3oRmdkbPwtSOHIO0yzZcsWXHjhhdrvt9xyCwDgU5/6FNatW4e2tjZNmADAzJkz8ec//xlf+cpX8MMf/hBTp07Fz3/+c5b1EgLjAmrusmqFk6oZO6ZPLMeDn1+SU/QIgiVeTQOoeQqiNLoUQ0lDYdQmsDJnhJwEeYuR5cuXQ1EU2/utuqsuX74c27Zty/epCBnzhPzOwzTDwXkzax1vWx3ywet2IeB1l2wOQFXIh8PdalVeqQqmfAmMhZyRUXbspPiMjcJ8QkYp8gJarLb0dlQGffjZNecg4HPDfRKOzEgiykn9Hje8Y2QB1KppSlQA2iHnjLAdPMkXihFCikg+pb3F4ML59cU+hKyIXiNjJUQD6LlDTlr8lxIhnwdetwuJlDLquseS4kMxQkgRCUmlvdk6sBJrRJ7CWAnRAMDn3j8TdRV+fPzs0dXs0eVyoSrkQ9cwT9om4wO+YwgpImIRdbuMHVKJM0SewlippAGA+qogrl82u+TCdk7Qw2Zj5+9BCgPFCCFFRCyiNWX+ks3LKGXGYphmNPOxs6fi9KYqnNmcXxk5IbwUI6SIiEW0EJU0YxGRNDmWwjSjmRsvmosbL5pb7MMgoxA6I4QUkdMaq1Du92DJ7KF1VR3viNb4dRUcH0HIaMalZGsaUiL09vaiuroaPT09qKqqKvbhEDKsRBNJdqwcIrFECg9uacX5c+u0KcaEkNLB6frNMA0hRYZCZOj4vW78v/dOL/ZhEEJOEoZpCCGEEFJUKEYIIYQQUlQoRgghhBBSVChGCCGEEFJUKEYIIYQQUlQoRgghhBBSVChGCCGEEFJUKEYIIYQQUlQoRgghhBBSVChGCCGEEFJUKEYIIYQQUlQoRgghhBBSVChGCCGEEFJURsXUXkVRAKijiAkhhBAyOhDrtljH7RgVYqSvrw8A0NzcXOQjIYQQQki+9PX1obq62vZ+l5JLrpQAqVQKR44cQWVlJVwu17A9bm9vL5qbm9Ha2oqqqqphe9yxCs+Xc3iu8oPnyzk8V87hucqPkThfiqKgr68PTU1NcLvtM0NGhTPidrsxderUEXv8qqoqvlHzgOfLOTxX+cHz5RyeK+fwXOXHcJ+vbI6IgAmshBBCCCkqFCOEEEIIKSrjWowEAgHcfvvtCAQCxT6UUQHPl3N4rvKD58s5PFfO4bnKj2Ker1GRwEoIIYSQscu4dkYIIYQQUnwoRgghhBBSVChGCCGEEFJUKEYIIYQQUlTGtRi5++67MWPGDASDQSxevBivvPJKsQ+p6Hzzm9+Ey+Uy/MyfP1+7PxKJYPXq1Zg4cSIqKirw0Y9+FB0dHUU84sKyadMmrFq1Ck1NTXC5XHjkkUcM9yuKgttuuw2NjY0IhUJYsWIFdu/ebdimq6sLV199NaqqqlBTU4PPfvaz6O/vL+CrKAy5ztWnP/3pjPfaZZddZthmvJyrtWvX4txzz0VlZSXq6+txxRVXYNeuXYZtnHz2Dh48iMsvvxxlZWWor6/HrbfeikQiUciXMuI4OVfLly/PeG/dcMMNhm3Gw7kCgHvuuQdnnnmm1shsyZIl+Mtf/qLdXyrvq3ErRn73u9/hlltuwe23347XXnsNCxcuxKWXXoqjR48W+9CKzumnn462tjbt5/nnn9fu+8pXvoI//elPeOihh7Bx40YcOXIEH/nIR4p4tIVlYGAACxcuxN133215/1133YUf/ehH+MlPfoKXX34Z5eXluPTSSxGJRLRtrr76arz11ltYv349HnvsMWzatAnXX399oV5Cwch1rgDgsssuM7zX7r//fsP94+Vcbdy4EatXr8ZLL72E9evXIx6P45JLLsHAwIC2Ta7PXjKZxOWXX45YLIYXX3wRv/71r7Fu3TrcdtttxXhJI4aTcwUA1113neG9ddddd2n3jZdzBQBTp07FnXfeia1bt2LLli246KKL8KEPfQhvvfUWgBJ6XynjlPPOO09ZvXq19nsymVSampqUtWvXFvGois/tt9+uLFy40PK+7u5uxefzKQ899JB229tvv60AUDZv3lygIywdACgPP/yw9nsqlVImT56s/Md//Id2W3d3txIIBJT7779fURRF2bFjhwJAefXVV7Vt/vKXvygul0s5fPhwwY690JjPlaIoyqc+9SnlQx/6kO0+4/VcKYqiHD16VAGgbNy4UVEUZ5+9xx9/XHG73Up7e7u2zT333KNUVVUp0Wi0sC+ggJjPlaIoygUXXKDcdNNNtvuM13MlmDBhgvLzn/+8pN5X49IZicVi2Lp1K1asWKHd5na7sWLFCmzevLmIR1Ya7N69G01NTZg1axauvvpqHDx4EACwdetWxONxw3mbP38+pk2bxvMGYP/+/Whvbzecn+rqaixevFg7P5s3b0ZNTQ3OOeccbZsVK1bA7Xbj5ZdfLvgxF5sNGzagvr4e8+bNwxe+8AV0dnZq943nc9XT0wMAqK2tBeDss7d582acccYZaGho0La59NJL0dvbq10Fj0XM50pw7733oq6uDgsWLMCaNWsQDoe1+8bruUomk3jggQcwMDCAJUuWlNT7alQMyhtujh8/jmQyaTi5ANDQ0ICdO3cW6ahKg8WLF2PdunWYN28e2tracMcdd+D888/H9u3b0d7eDr/fj5qaGsM+DQ0NaG9vL84BlxDiHFi9r8R97e3tqK+vN9zv9XpRW1s77s7hZZddho985COYOXMm9u7di3/6p3/CypUrsXnzZng8nnF7rlKpFG6++WYsXboUCxYsAABHn7329nbL9564byxida4A4JOf/CSmT5+OpqYmvPHGG/jHf/xH7Nq1C3/4wx8AjL9z9eabb2LJkiWIRCKoqKjAww8/jNNOOw0tLS0l874al2KE2LNy5Urt/2eeeSYWL16M6dOn48EHH0QoFCrikZGxxt/93d9p/z/jjDNw5plnYvbs2diwYQMuvvjiIh5ZcVm9ejW2b99uyNUi1tidKzmv6IwzzkBjYyMuvvhi7N27F7Nnzy70YRadefPmoaWlBT09Pfj973+PT33qU9i4cWOxD8vAuAzT1NXVwePxZGQMd3R0YPLkyUU6qtKkpqYGp5xyCvbs2YPJkycjFouhu7vbsA3Pm4o4B9neV5MnT85Ikk4kEujq6hr353DWrFmoq6vDnj17AIzPc3XjjTfisccew7PPPoupU6dqtzv57E2ePNnyvSfuG2vYnSsrFi9eDACG99Z4Old+vx9z5szB2WefjbVr12LhwoX44Q9/WFLvq3EpRvx+P84++2w8/fTT2m2pVApPP/00lixZUsQjKz36+/uxd+9eNDY24uyzz4bP5zOct127duHgwYM8bwBmzpyJyZMnG85Pb28vXn75Ze38LFmyBN3d3di6dau2zTPPPINUKqV9YY5XDh06hM7OTjQ2NgIYX+dKURTceOONePjhh/HMM89g5syZhvudfPaWLFmCN9980yDg1q9fj6qqKpx22mmFeSEFINe5sqKlpQUADO+t8XCu7EilUohGo6X1vhq2VNhRxgMPPKAEAgFl3bp1yo4dO5Trr79eqampMWQMj0e++tWvKhs2bFD279+vvPDCC8qKFSuUuro65ejRo4qiKMoNN9ygTJs2TXnmmWeULVu2KEuWLFGWLFlS5KMuHH19fcq2bduUbdu2KQCU73//+8q2bduUd999V1EURbnzzjuVmpoa5dFHH1XeeOMN5UMf+pAyc+ZMZXBwUHuMyy67TFm0aJHy8ssvK88//7wyd+5c5ROf+ESxXtKIke1c9fX1KV/72teUzZs3K/v371eeeuop5T3veY8yd+5cJRKJaI8xXs7VF77wBaW6ulrZsGGD0tbWpv2Ew2Ftm1yfvUQioSxYsEC55JJLlJaWFuWJJ55QJk2apKxZs6YYL2nEyHWu9uzZo3zrW99StmzZouzfv1959NFHlVmzZinLli3THmO8nCtFUZSvf/3rysaNG5X9+/crb7zxhvL1r39dcblcypNPPqkoSum8r8atGFEURfmv//ovZdq0aYrf71fOO+885aWXXir2IRWdq666SmlsbFT8fr8yZcoU5aqrrlL27Nmj3T84OKh88YtfVCZMmKCUlZUpH/7wh5W2trYiHnFhefbZZxUAGT+f+tSnFEVRy3v/5V/+RWloaFACgYBy8cUXK7t27TI8Rmdnp/KJT3xCqaioUKqqqpTPfOYzSl9fXxFezciS7VyFw2HlkksuUSZNmqT4fD5l+vTpynXXXZdxMTBezpXVeQKg/OpXv9K2cfLZO3DggLJy5UolFAopdXV1yle/+lUlHo8X+NWMLLnO1cGDB5Vly5YptbW1SiAQUObMmaPceuutSk9Pj+FxxsO5UhRFufbaa5Xp06crfr9fmTRpknLxxRdrQkRRSud95VIURRk+n4UQQgghJD/GZc4IIYQQQkoHihFCCCGEFBWKEUIIIYQUFYoRQgghhBQVihFCCCGEFBWKEUIIIYQUFYoRQgghhBQVihFCCCGEFBWKEUIIIYQUFYoRQgghhBQVihFCCCGEFBWKEUIIIYQUlf8PmW7MKLMGaLYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# %matplotlib notebook\n",
    "# %matplotlib inline\n",
    "\n",
    "plt.plot(loss_vals)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GraphSMOTE's implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 00001 loss_train: 1.9431 loss_rec: 1.9431 acc_train: 0.1589 loss_val: 1.9431 acc_val: 0.1611 time: 0.1057s\n",
      "Epoch: 00002 loss_train: 1.8532 loss_rec: 1.8532 acc_train: 0.3282 loss_val: 1.8851 acc_val: 0.2891 time: 0.1044s\n",
      "Epoch: 00003 loss_train: 1.7596 loss_rec: 1.7596 acc_train: 0.3787 loss_val: 1.8070 acc_val: 0.3432 time: 0.0990s\n",
      "Epoch: 00004 loss_train: 1.6494 loss_rec: 1.6494 acc_train: 0.4181 loss_val: 1.7405 acc_val: 0.3641 time: 0.0863s\n",
      "Epoch: 00005 loss_train: 1.5616 loss_rec: 1.5616 acc_train: 0.4433 loss_val: 1.6536 acc_val: 0.3875 time: 0.1121s\n",
      "Epoch: 00006 loss_train: 1.4922 loss_rec: 1.4922 acc_train: 0.4507 loss_val: 1.6175 acc_val: 0.3838 time: 0.1199s\n",
      "Epoch: 00007 loss_train: 1.3763 loss_rec: 1.3763 acc_train: 0.5425 loss_val: 1.5626 acc_val: 0.4440 time: 0.0888s\n",
      "Epoch: 00008 loss_train: 1.2871 loss_rec: 1.2871 acc_train: 0.6108 loss_val: 1.4611 acc_val: 0.5240 time: 0.0866s\n",
      "Epoch: 00009 loss_train: 1.1963 loss_rec: 1.1963 acc_train: 0.6626 loss_val: 1.4249 acc_val: 0.5572 time: 0.0839s\n",
      "Epoch: 00010 loss_train: 1.1951 loss_rec: 1.1951 acc_train: 0.6601 loss_val: 1.3667 acc_val: 0.5843 time: 0.0787s\n",
      "Epoch: 00011 loss_train: 1.1034 loss_rec: 1.1034 acc_train: 0.6866 loss_val: 1.3053 acc_val: 0.6113 time: 0.0857s\n",
      "Epoch: 00012 loss_train: 1.0619 loss_rec: 1.0619 acc_train: 0.7254 loss_val: 1.3110 acc_val: 0.6298 time: 0.1246s\n",
      "Epoch: 00013 loss_train: 1.0348 loss_rec: 1.0348 acc_train: 0.7137 loss_val: 1.2790 acc_val: 0.6273 time: 0.0985s\n",
      "Epoch: 00014 loss_train: 0.9764 loss_rec: 0.9764 acc_train: 0.7346 loss_val: 1.2244 acc_val: 0.6433 time: 0.0861s\n",
      "Epoch: 00015 loss_train: 0.9526 loss_rec: 0.9526 acc_train: 0.7297 loss_val: 1.1688 acc_val: 0.6519 time: 0.1052s\n",
      "Epoch: 00016 loss_train: 0.8813 loss_rec: 0.8813 acc_train: 0.7241 loss_val: 1.1689 acc_val: 0.6101 time: 0.1155s\n",
      "Epoch: 00017 loss_train: 0.8607 loss_rec: 0.8607 acc_train: 0.7457 loss_val: 1.1153 acc_val: 0.6704 time: 0.1019s\n",
      "Epoch: 00018 loss_train: 0.8280 loss_rec: 0.8280 acc_train: 0.7672 loss_val: 1.0855 acc_val: 0.6691 time: 0.1221s\n",
      "Epoch: 00019 loss_train: 0.7461 loss_rec: 0.7461 acc_train: 0.7802 loss_val: 1.0345 acc_val: 0.6900 time: 0.1151s\n",
      "Epoch: 00020 loss_train: 0.7582 loss_rec: 0.7582 acc_train: 0.7876 loss_val: 1.0254 acc_val: 0.6777 time: 0.1324s\n",
      "Epoch: 00021 loss_train: 0.7133 loss_rec: 0.7133 acc_train: 0.7839 loss_val: 0.9791 acc_val: 0.6986 time: 0.1282s\n",
      "Epoch: 00022 loss_train: 0.7111 loss_rec: 0.7111 acc_train: 0.7722 loss_val: 0.9955 acc_val: 0.6777 time: 0.1359s\n",
      "Epoch: 00023 loss_train: 0.6775 loss_rec: 0.6775 acc_train: 0.7974 loss_val: 0.9733 acc_val: 0.6925 time: 0.1157s\n",
      "Epoch: 00024 loss_train: 0.6329 loss_rec: 0.6329 acc_train: 0.8159 loss_val: 0.9476 acc_val: 0.7294 time: 0.1373s\n",
      "Epoch: 00025 loss_train: 0.6112 loss_rec: 0.6112 acc_train: 0.8190 loss_val: 0.9002 acc_val: 0.7392 time: 0.1099s\n",
      "Epoch: 00026 loss_train: 0.5701 loss_rec: 0.5701 acc_train: 0.8300 loss_val: 0.8854 acc_val: 0.7269 time: 0.1036s\n",
      "Epoch: 00027 loss_train: 0.5699 loss_rec: 0.5699 acc_train: 0.8424 loss_val: 0.8392 acc_val: 0.7540 time: 0.0925s\n",
      "Epoch: 00028 loss_train: 0.5659 loss_rec: 0.5659 acc_train: 0.8430 loss_val: 0.8337 acc_val: 0.7405 time: 0.0994s\n",
      "Epoch: 00029 loss_train: 0.5620 loss_rec: 0.5620 acc_train: 0.8467 loss_val: 0.8298 acc_val: 0.7515 time: 0.1259s\n",
      "Epoch: 00030 loss_train: 0.5068 loss_rec: 0.5068 acc_train: 0.8645 loss_val: 0.8453 acc_val: 0.7454 time: 0.1005s\n",
      "Epoch: 00031 loss_train: 0.5054 loss_rec: 0.5054 acc_train: 0.8498 loss_val: 0.8432 acc_val: 0.7491 time: 0.1113s\n",
      "Epoch: 00032 loss_train: 0.4883 loss_rec: 0.4883 acc_train: 0.8498 loss_val: 0.8072 acc_val: 0.7614 time: 0.1130s\n",
      "Epoch: 00033 loss_train: 0.4700 loss_rec: 0.4700 acc_train: 0.8565 loss_val: 0.7586 acc_val: 0.7749 time: 0.0787s\n",
      "Epoch: 00034 loss_train: 0.4478 loss_rec: 0.4478 acc_train: 0.8621 loss_val: 0.8049 acc_val: 0.7688 time: 0.0764s\n",
      "Epoch: 00035 loss_train: 0.4477 loss_rec: 0.4477 acc_train: 0.8688 loss_val: 0.7624 acc_val: 0.7749 time: 0.0872s\n",
      "Epoch: 00036 loss_train: 0.4364 loss_rec: 0.4364 acc_train: 0.8719 loss_val: 0.7312 acc_val: 0.7761 time: 0.0672s\n",
      "Epoch: 00037 loss_train: 0.4254 loss_rec: 0.4254 acc_train: 0.8799 loss_val: 0.7471 acc_val: 0.7761 time: 0.0712s\n",
      "Epoch: 00038 loss_train: 0.4154 loss_rec: 0.4154 acc_train: 0.8799 loss_val: 0.7635 acc_val: 0.7749 time: 0.0766s\n",
      "Epoch: 00039 loss_train: 0.4136 loss_rec: 0.4136 acc_train: 0.8781 loss_val: 0.8118 acc_val: 0.7921 time: 0.0745s\n",
      "Epoch: 00040 loss_train: 0.3931 loss_rec: 0.3931 acc_train: 0.8812 loss_val: 0.8267 acc_val: 0.7835 time: 0.0892s\n",
      "Epoch: 00041 loss_train: 0.3830 loss_rec: 0.3830 acc_train: 0.8787 loss_val: 0.8150 acc_val: 0.7614 time: 0.0736s\n",
      "Epoch: 00042 loss_train: 0.3736 loss_rec: 0.3736 acc_train: 0.8959 loss_val: 0.7773 acc_val: 0.7884 time: 0.0678s\n",
      "Epoch: 00043 loss_train: 0.3661 loss_rec: 0.3661 acc_train: 0.8867 loss_val: 0.8037 acc_val: 0.7638 time: 0.0734s\n",
      "Epoch: 00044 loss_train: 0.3983 loss_rec: 0.3983 acc_train: 0.8719 loss_val: 0.8068 acc_val: 0.7675 time: 0.0825s\n",
      "Epoch: 00045 loss_train: 0.3540 loss_rec: 0.3540 acc_train: 0.8941 loss_val: 0.7503 acc_val: 0.8020 time: 0.1075s\n",
      "Epoch: 00046 loss_train: 0.3540 loss_rec: 0.3540 acc_train: 0.8892 loss_val: 0.7628 acc_val: 0.7786 time: 0.0994s\n",
      "Epoch: 00047 loss_train: 0.3643 loss_rec: 0.3643 acc_train: 0.8768 loss_val: 0.7670 acc_val: 0.7811 time: 0.0719s\n",
      "Epoch: 00048 loss_train: 0.3659 loss_rec: 0.3659 acc_train: 0.8781 loss_val: 0.7629 acc_val: 0.7749 time: 0.0733s\n",
      "Epoch: 00049 loss_train: 0.3394 loss_rec: 0.3394 acc_train: 0.8916 loss_val: 0.7523 acc_val: 0.7860 time: 0.0695s\n",
      "Epoch: 00050 loss_train: 0.3182 loss_rec: 0.3182 acc_train: 0.9002 loss_val: 0.7630 acc_val: 0.7860 time: 0.0678s\n",
      "Epoch: 00051 loss_train: 0.3244 loss_rec: 0.3244 acc_train: 0.8996 loss_val: 0.7820 acc_val: 0.7798 time: 0.0685s\n",
      "Epoch: 00052 loss_train: 0.3142 loss_rec: 0.3142 acc_train: 0.9064 loss_val: 0.7404 acc_val: 0.7786 time: 0.0640s\n",
      "Epoch: 00053 loss_train: 0.3010 loss_rec: 0.3010 acc_train: 0.9095 loss_val: 0.7568 acc_val: 0.7823 time: 0.0768s\n",
      "Epoch: 00054 loss_train: 0.2955 loss_rec: 0.2955 acc_train: 0.9144 loss_val: 0.7365 acc_val: 0.8007 time: 0.0797s\n",
      "Epoch: 00055 loss_train: 0.2932 loss_rec: 0.2932 acc_train: 0.9070 loss_val: 0.7249 acc_val: 0.7983 time: 0.0705s\n",
      "Epoch: 00056 loss_train: 0.3127 loss_rec: 0.3127 acc_train: 0.9101 loss_val: 0.8103 acc_val: 0.7749 time: 0.0877s\n",
      "Epoch: 00057 loss_train: 0.2938 loss_rec: 0.2938 acc_train: 0.9039 loss_val: 0.7892 acc_val: 0.7847 time: 0.0878s\n",
      "Epoch: 00058 loss_train: 0.2702 loss_rec: 0.2702 acc_train: 0.9175 loss_val: 0.7911 acc_val: 0.7921 time: 0.0712s\n",
      "Epoch: 00059 loss_train: 0.2684 loss_rec: 0.2684 acc_train: 0.9175 loss_val: 0.7583 acc_val: 0.7688 time: 0.0796s\n",
      "Epoch: 00060 loss_train: 0.2895 loss_rec: 0.2895 acc_train: 0.9144 loss_val: 0.8127 acc_val: 0.7761 time: 0.0667s\n",
      "Epoch: 00061 loss_train: 0.2648 loss_rec: 0.2648 acc_train: 0.9200 loss_val: 0.7948 acc_val: 0.7688 time: 0.0706s\n",
      "Epoch: 00062 loss_train: 0.2601 loss_rec: 0.2601 acc_train: 0.9206 loss_val: 0.8000 acc_val: 0.7847 time: 0.0728s\n",
      "Epoch: 00063 loss_train: 0.2770 loss_rec: 0.2770 acc_train: 0.9187 loss_val: 0.8185 acc_val: 0.7786 time: 0.0678s\n",
      "Epoch: 00064 loss_train: 0.2827 loss_rec: 0.2827 acc_train: 0.9150 loss_val: 0.7847 acc_val: 0.7983 time: 0.0767s\n",
      "Epoch: 00065 loss_train: 0.2539 loss_rec: 0.2539 acc_train: 0.9212 loss_val: 0.8376 acc_val: 0.7847 time: 0.0680s\n",
      "Epoch: 00066 loss_train: 0.2648 loss_rec: 0.2648 acc_train: 0.9243 loss_val: 0.8442 acc_val: 0.7786 time: 0.0747s\n",
      "Epoch: 00067 loss_train: 0.2386 loss_rec: 0.2386 acc_train: 0.9292 loss_val: 0.7471 acc_val: 0.7897 time: 0.0775s\n",
      "Epoch: 00068 loss_train: 0.2459 loss_rec: 0.2459 acc_train: 0.9243 loss_val: 0.7942 acc_val: 0.7872 time: 0.0823s\n",
      "Epoch: 00069 loss_train: 0.2669 loss_rec: 0.2669 acc_train: 0.9187 loss_val: 0.8549 acc_val: 0.7675 time: 0.0803s\n",
      "Epoch: 00070 loss_train: 0.2513 loss_rec: 0.2513 acc_train: 0.9292 loss_val: 0.8344 acc_val: 0.7909 time: 0.0857s\n",
      "Epoch: 00071 loss_train: 0.2510 loss_rec: 0.2510 acc_train: 0.9181 loss_val: 0.8239 acc_val: 0.7651 time: 0.0729s\n",
      "Epoch: 00072 loss_train: 0.2674 loss_rec: 0.2674 acc_train: 0.9169 loss_val: 0.8272 acc_val: 0.7724 time: 0.0763s\n",
      "Epoch: 00073 loss_train: 0.2422 loss_rec: 0.2422 acc_train: 0.9310 loss_val: 0.7976 acc_val: 0.7995 time: 0.0775s\n",
      "Epoch: 00074 loss_train: 0.2426 loss_rec: 0.2426 acc_train: 0.9347 loss_val: 0.8631 acc_val: 0.7921 time: 0.0734s\n",
      "Epoch: 00075 loss_train: 0.2401 loss_rec: 0.2401 acc_train: 0.9335 loss_val: 0.8295 acc_val: 0.7601 time: 0.0672s\n",
      "Epoch: 00076 loss_train: 0.2562 loss_rec: 0.2562 acc_train: 0.9212 loss_val: 0.8221 acc_val: 0.7847 time: 0.0728s\n",
      "Epoch: 00077 loss_train: 0.2207 loss_rec: 0.2207 acc_train: 0.9366 loss_val: 0.7759 acc_val: 0.7995 time: 0.0728s\n",
      "Epoch: 00078 loss_train: 0.2448 loss_rec: 0.2448 acc_train: 0.9261 loss_val: 0.8229 acc_val: 0.7860 time: 0.0710s\n",
      "Epoch: 00079 loss_train: 0.2265 loss_rec: 0.2265 acc_train: 0.9298 loss_val: 0.8206 acc_val: 0.7823 time: 0.0689s\n",
      "Epoch: 00080 loss_train: 0.2250 loss_rec: 0.2250 acc_train: 0.9323 loss_val: 0.8298 acc_val: 0.7700 time: 0.0766s\n",
      "Epoch: 00081 loss_train: 0.2322 loss_rec: 0.2322 acc_train: 0.9298 loss_val: 0.8153 acc_val: 0.7749 time: 0.0731s\n",
      "Epoch: 00082 loss_train: 0.2176 loss_rec: 0.2176 acc_train: 0.9341 loss_val: 0.8132 acc_val: 0.7847 time: 0.0645s\n",
      "Epoch: 00083 loss_train: 0.2266 loss_rec: 0.2266 acc_train: 0.9261 loss_val: 0.8169 acc_val: 0.7761 time: 0.0733s\n",
      "Epoch: 00084 loss_train: 0.2448 loss_rec: 0.2448 acc_train: 0.9249 loss_val: 0.8290 acc_val: 0.7835 time: 0.0737s\n",
      "Epoch: 00085 loss_train: 0.2078 loss_rec: 0.2078 acc_train: 0.9372 loss_val: 0.8185 acc_val: 0.7983 time: 0.0842s\n",
      "Epoch: 00086 loss_train: 0.2144 loss_rec: 0.2144 acc_train: 0.9390 loss_val: 0.8241 acc_val: 0.7798 time: 0.0967s\n",
      "Epoch: 00087 loss_train: 0.2082 loss_rec: 0.2082 acc_train: 0.9304 loss_val: 0.8398 acc_val: 0.7860 time: 0.0757s\n",
      "Epoch: 00088 loss_train: 0.2152 loss_rec: 0.2152 acc_train: 0.9329 loss_val: 0.8530 acc_val: 0.7700 time: 0.0636s\n",
      "Epoch: 00089 loss_train: 0.2016 loss_rec: 0.2016 acc_train: 0.9372 loss_val: 0.8614 acc_val: 0.7774 time: 0.0550s\n",
      "Epoch: 00090 loss_train: 0.2164 loss_rec: 0.2164 acc_train: 0.9304 loss_val: 0.8426 acc_val: 0.7823 time: 0.0515s\n",
      "Epoch: 00091 loss_train: 0.2054 loss_rec: 0.2054 acc_train: 0.9390 loss_val: 0.8446 acc_val: 0.7958 time: 0.0562s\n",
      "Epoch: 00092 loss_train: 0.2180 loss_rec: 0.2180 acc_train: 0.9310 loss_val: 0.8391 acc_val: 0.7872 time: 0.0498s\n",
      "Epoch: 00093 loss_train: 0.1976 loss_rec: 0.1976 acc_train: 0.9378 loss_val: 0.8371 acc_val: 0.7835 time: 0.0549s\n",
      "Epoch: 00094 loss_train: 0.2127 loss_rec: 0.2127 acc_train: 0.9415 loss_val: 0.8802 acc_val: 0.7601 time: 0.1149s\n",
      "Epoch: 00095 loss_train: 0.1878 loss_rec: 0.1878 acc_train: 0.9514 loss_val: 0.7854 acc_val: 0.7761 time: 0.1508s\n",
      "Epoch: 00096 loss_train: 0.2050 loss_rec: 0.2050 acc_train: 0.9353 loss_val: 0.8088 acc_val: 0.7712 time: 0.0847s\n",
      "Epoch: 00097 loss_train: 0.1833 loss_rec: 0.1833 acc_train: 0.9452 loss_val: 0.8222 acc_val: 0.7884 time: 0.0731s\n",
      "Epoch: 00098 loss_train: 0.2152 loss_rec: 0.2152 acc_train: 0.9366 loss_val: 0.8498 acc_val: 0.7970 time: 0.0712s\n",
      "Epoch: 00099 loss_train: 0.1841 loss_rec: 0.1841 acc_train: 0.9464 loss_val: 0.9017 acc_val: 0.7761 time: 0.0737s\n",
      "Epoch: 00100 loss_train: 0.2015 loss_rec: 0.2015 acc_train: 0.9421 loss_val: 0.8417 acc_val: 0.7934 time: 0.0578s\n",
      "Epoch: 00101 loss_train: 0.1973 loss_rec: 0.1973 acc_train: 0.9452 loss_val: 0.8223 acc_val: 0.7970 time: 0.0560s\n",
      "Epoch: 00102 loss_train: 0.1839 loss_rec: 0.1839 acc_train: 0.9514 loss_val: 0.8897 acc_val: 0.7737 time: 0.0556s\n",
      "Epoch: 00103 loss_train: 0.1952 loss_rec: 0.1952 acc_train: 0.9458 loss_val: 0.8885 acc_val: 0.7884 time: 0.0628s\n",
      "Epoch: 00104 loss_train: 0.2073 loss_rec: 0.2073 acc_train: 0.9366 loss_val: 0.8973 acc_val: 0.7675 time: 0.0701s\n",
      "Epoch: 00105 loss_train: 0.2005 loss_rec: 0.2005 acc_train: 0.9397 loss_val: 0.8435 acc_val: 0.7737 time: 0.0634s\n",
      "Epoch: 00106 loss_train: 0.2099 loss_rec: 0.2099 acc_train: 0.9372 loss_val: 0.9192 acc_val: 0.7663 time: 0.0637s\n",
      "Epoch: 00107 loss_train: 0.1740 loss_rec: 0.1740 acc_train: 0.9514 loss_val: 0.9008 acc_val: 0.7651 time: 0.0654s\n",
      "Epoch: 00108 loss_train: 0.1962 loss_rec: 0.1962 acc_train: 0.9366 loss_val: 0.9290 acc_val: 0.7749 time: 0.0829s\n",
      "Epoch: 00109 loss_train: 0.1713 loss_rec: 0.1713 acc_train: 0.9477 loss_val: 0.8973 acc_val: 0.7774 time: 0.0642s\n",
      "Epoch: 00110 loss_train: 0.1931 loss_rec: 0.1931 acc_train: 0.9415 loss_val: 0.8969 acc_val: 0.7884 time: 0.0601s\n",
      "Epoch: 00111 loss_train: 0.2027 loss_rec: 0.2027 acc_train: 0.9347 loss_val: 0.8655 acc_val: 0.7835 time: 0.0658s\n",
      "Epoch: 00112 loss_train: 0.1806 loss_rec: 0.1806 acc_train: 0.9446 loss_val: 0.9087 acc_val: 0.7835 time: 0.0720s\n",
      "Epoch: 00113 loss_train: 0.1845 loss_rec: 0.1845 acc_train: 0.9452 loss_val: 0.9550 acc_val: 0.7872 time: 0.0797s\n",
      "Epoch: 00114 loss_train: 0.1840 loss_rec: 0.1840 acc_train: 0.9458 loss_val: 0.9083 acc_val: 0.7823 time: 0.0855s\n",
      "Epoch: 00115 loss_train: 0.1760 loss_rec: 0.1760 acc_train: 0.9526 loss_val: 0.8547 acc_val: 0.7761 time: 0.0726s\n",
      "Epoch: 00116 loss_train: 0.2084 loss_rec: 0.2084 acc_train: 0.9372 loss_val: 0.8972 acc_val: 0.7749 time: 0.0673s\n",
      "Epoch: 00117 loss_train: 0.1727 loss_rec: 0.1727 acc_train: 0.9483 loss_val: 0.8684 acc_val: 0.7860 time: 0.0614s\n",
      "Epoch: 00118 loss_train: 0.1736 loss_rec: 0.1736 acc_train: 0.9520 loss_val: 0.8893 acc_val: 0.7995 time: 0.0686s\n",
      "Epoch: 00119 loss_train: 0.2004 loss_rec: 0.2004 acc_train: 0.9390 loss_val: 0.8828 acc_val: 0.7884 time: 0.0650s\n",
      "Epoch: 00120 loss_train: 0.2023 loss_rec: 0.2023 acc_train: 0.9390 loss_val: 0.9782 acc_val: 0.7761 time: 0.0542s\n",
      "Epoch: 00121 loss_train: 0.1900 loss_rec: 0.1900 acc_train: 0.9397 loss_val: 0.8902 acc_val: 0.7823 time: 0.0617s\n",
      "Epoch: 00122 loss_train: 0.1824 loss_rec: 0.1824 acc_train: 0.9433 loss_val: 0.9145 acc_val: 0.7835 time: 0.0721s\n",
      "Epoch: 00123 loss_train: 0.1814 loss_rec: 0.1814 acc_train: 0.9452 loss_val: 0.8840 acc_val: 0.7737 time: 0.0689s\n",
      "Epoch: 00124 loss_train: 0.1758 loss_rec: 0.1758 acc_train: 0.9507 loss_val: 0.9132 acc_val: 0.7811 time: 0.0790s\n",
      "Epoch: 00125 loss_train: 0.1856 loss_rec: 0.1856 acc_train: 0.9458 loss_val: 0.8809 acc_val: 0.7749 time: 0.0804s\n",
      "Epoch: 00126 loss_train: 0.1789 loss_rec: 0.1789 acc_train: 0.9409 loss_val: 0.9517 acc_val: 0.7786 time: 0.0655s\n",
      "Epoch: 00127 loss_train: 0.1730 loss_rec: 0.1730 acc_train: 0.9421 loss_val: 0.8999 acc_val: 0.7934 time: 0.0660s\n",
      "Epoch: 00128 loss_train: 0.1830 loss_rec: 0.1830 acc_train: 0.9403 loss_val: 0.9030 acc_val: 0.7897 time: 0.0753s\n",
      "Epoch: 00129 loss_train: 0.1751 loss_rec: 0.1751 acc_train: 0.9550 loss_val: 0.9482 acc_val: 0.7872 time: 0.0576s\n",
      "Epoch: 00130 loss_train: 0.1743 loss_rec: 0.1743 acc_train: 0.9520 loss_val: 0.8903 acc_val: 0.7737 time: 0.0568s\n",
      "Epoch: 00131 loss_train: 0.1732 loss_rec: 0.1732 acc_train: 0.9526 loss_val: 0.9136 acc_val: 0.7835 time: 0.0540s\n",
      "Epoch: 00132 loss_train: 0.1677 loss_rec: 0.1677 acc_train: 0.9544 loss_val: 0.9231 acc_val: 0.7798 time: 0.0571s\n",
      "Epoch: 00133 loss_train: 0.1668 loss_rec: 0.1668 acc_train: 0.9507 loss_val: 0.9386 acc_val: 0.7700 time: 0.0561s\n",
      "Epoch: 00134 loss_train: 0.2009 loss_rec: 0.2009 acc_train: 0.9464 loss_val: 0.9831 acc_val: 0.7823 time: 0.0547s\n",
      "Epoch: 00135 loss_train: 0.1885 loss_rec: 0.1885 acc_train: 0.9495 loss_val: 0.8625 acc_val: 0.7897 time: 0.0532s\n",
      "Epoch: 00136 loss_train: 0.1639 loss_rec: 0.1639 acc_train: 0.9446 loss_val: 0.9588 acc_val: 0.7823 time: 0.0547s\n",
      "Epoch: 00137 loss_train: 0.2000 loss_rec: 0.2000 acc_train: 0.9347 loss_val: 0.9177 acc_val: 0.7626 time: 0.0575s\n",
      "Epoch: 00138 loss_train: 0.1839 loss_rec: 0.1839 acc_train: 0.9384 loss_val: 0.9097 acc_val: 0.7860 time: 0.0548s\n",
      "Epoch: 00139 loss_train: 0.1574 loss_rec: 0.1574 acc_train: 0.9501 loss_val: 0.9067 acc_val: 0.7983 time: 0.0528s\n",
      "Epoch: 00140 loss_train: 0.1606 loss_rec: 0.1606 acc_train: 0.9544 loss_val: 0.9180 acc_val: 0.7774 time: 0.0603s\n",
      "Epoch: 00141 loss_train: 0.1724 loss_rec: 0.1724 acc_train: 0.9489 loss_val: 1.0170 acc_val: 0.7601 time: 0.0487s\n",
      "Epoch: 00142 loss_train: 0.1679 loss_rec: 0.1679 acc_train: 0.9501 loss_val: 0.9017 acc_val: 0.7798 time: 0.0510s\n",
      "Epoch: 00143 loss_train: 0.1815 loss_rec: 0.1815 acc_train: 0.9452 loss_val: 1.0134 acc_val: 0.7626 time: 0.0557s\n",
      "Epoch: 00144 loss_train: 0.1697 loss_rec: 0.1697 acc_train: 0.9477 loss_val: 0.9576 acc_val: 0.7884 time: 0.0615s\n",
      "Epoch: 00145 loss_train: 0.1632 loss_rec: 0.1632 acc_train: 0.9446 loss_val: 0.9886 acc_val: 0.7884 time: 0.0654s\n",
      "Epoch: 00146 loss_train: 0.1763 loss_rec: 0.1763 acc_train: 0.9501 loss_val: 0.9709 acc_val: 0.7712 time: 0.0561s\n",
      "Epoch: 00147 loss_train: 0.1484 loss_rec: 0.1484 acc_train: 0.9563 loss_val: 0.9557 acc_val: 0.7761 time: 0.0610s\n",
      "Epoch: 00148 loss_train: 0.1515 loss_rec: 0.1515 acc_train: 0.9520 loss_val: 0.9736 acc_val: 0.7749 time: 0.0595s\n",
      "Epoch: 00149 loss_train: 0.1703 loss_rec: 0.1703 acc_train: 0.9421 loss_val: 0.9792 acc_val: 0.7823 time: 0.0557s\n",
      "Epoch: 00150 loss_train: 0.1779 loss_rec: 0.1779 acc_train: 0.9415 loss_val: 1.0264 acc_val: 0.7663 time: 0.0510s\n",
      "Epoch: 00151 loss_train: 0.2280 loss_rec: 0.2280 acc_train: 0.9446 loss_val: 0.9848 acc_val: 0.7872 time: 0.0587s\n",
      "Epoch: 00152 loss_train: 0.2013 loss_rec: 0.2013 acc_train: 0.9347 loss_val: 0.9743 acc_val: 0.7663 time: 0.0589s\n",
      "Epoch: 00153 loss_train: 0.1838 loss_rec: 0.1838 acc_train: 0.9403 loss_val: 0.9958 acc_val: 0.7774 time: 0.0601s\n",
      "Epoch: 00154 loss_train: 0.1833 loss_rec: 0.1833 acc_train: 0.9483 loss_val: 1.0425 acc_val: 0.7466 time: 0.0556s\n",
      "Epoch: 00155 loss_train: 0.1846 loss_rec: 0.1846 acc_train: 0.9427 loss_val: 0.9215 acc_val: 0.7749 time: 0.0619s\n",
      "Epoch: 00156 loss_train: 0.1740 loss_rec: 0.1740 acc_train: 0.9433 loss_val: 0.8847 acc_val: 0.7823 time: 0.0636s\n",
      "Epoch: 00157 loss_train: 0.1790 loss_rec: 0.1790 acc_train: 0.9489 loss_val: 0.9547 acc_val: 0.7626 time: 0.0546s\n",
      "Epoch: 00158 loss_train: 0.1915 loss_rec: 0.1915 acc_train: 0.9415 loss_val: 0.9817 acc_val: 0.7761 time: 0.0497s\n",
      "Epoch: 00159 loss_train: 0.1723 loss_rec: 0.1723 acc_train: 0.9477 loss_val: 0.9669 acc_val: 0.7651 time: 0.0481s\n",
      "Epoch: 00160 loss_train: 0.1598 loss_rec: 0.1598 acc_train: 0.9495 loss_val: 0.9466 acc_val: 0.7614 time: 0.0522s\n",
      "Epoch: 00161 loss_train: 0.1580 loss_rec: 0.1580 acc_train: 0.9520 loss_val: 0.9848 acc_val: 0.7688 time: 0.0426s\n",
      "Epoch: 00162 loss_train: 0.1696 loss_rec: 0.1696 acc_train: 0.9507 loss_val: 0.9560 acc_val: 0.7798 time: 0.0577s\n",
      "Epoch: 00163 loss_train: 0.1648 loss_rec: 0.1648 acc_train: 0.9446 loss_val: 0.9161 acc_val: 0.7897 time: 0.0506s\n",
      "Epoch: 00164 loss_train: 0.1648 loss_rec: 0.1648 acc_train: 0.9433 loss_val: 0.9623 acc_val: 0.7700 time: 0.0613s\n",
      "Epoch: 00165 loss_train: 0.1622 loss_rec: 0.1622 acc_train: 0.9520 loss_val: 0.9849 acc_val: 0.7860 time: 0.0550s\n",
      "Epoch: 00166 loss_train: 0.1772 loss_rec: 0.1772 acc_train: 0.9433 loss_val: 1.0240 acc_val: 0.7798 time: 0.0547s\n",
      "Epoch: 00167 loss_train: 0.1463 loss_rec: 0.1463 acc_train: 0.9575 loss_val: 1.0174 acc_val: 0.7872 time: 0.0456s\n",
      "Epoch: 00168 loss_train: 0.1495 loss_rec: 0.1495 acc_train: 0.9520 loss_val: 0.9521 acc_val: 0.7860 time: 0.0526s\n",
      "Epoch: 00169 loss_train: 0.1600 loss_rec: 0.1600 acc_train: 0.9514 loss_val: 1.0009 acc_val: 0.7811 time: 0.0536s\n",
      "Epoch: 00170 loss_train: 0.1530 loss_rec: 0.1530 acc_train: 0.9507 loss_val: 0.9056 acc_val: 0.7749 time: 0.0507s\n",
      "Epoch: 00171 loss_train: 0.1598 loss_rec: 0.1598 acc_train: 0.9501 loss_val: 0.9904 acc_val: 0.7626 time: 0.0489s\n",
      "Epoch: 00172 loss_train: 0.1783 loss_rec: 0.1783 acc_train: 0.9489 loss_val: 0.9260 acc_val: 0.7614 time: 0.0487s\n",
      "Epoch: 00173 loss_train: 0.1700 loss_rec: 0.1700 acc_train: 0.9520 loss_val: 1.0243 acc_val: 0.7638 time: 0.0557s\n",
      "Epoch: 00174 loss_train: 0.1530 loss_rec: 0.1530 acc_train: 0.9544 loss_val: 1.0312 acc_val: 0.7700 time: 0.0618s\n",
      "Epoch: 00175 loss_train: 0.1755 loss_rec: 0.1755 acc_train: 0.9452 loss_val: 1.0103 acc_val: 0.7761 time: 0.0508s\n",
      "Epoch: 00176 loss_train: 0.1872 loss_rec: 0.1872 acc_train: 0.9421 loss_val: 0.9450 acc_val: 0.7811 time: 0.0474s\n",
      "Epoch: 00177 loss_train: 0.1982 loss_rec: 0.1982 acc_train: 0.9409 loss_val: 0.9800 acc_val: 0.7774 time: 0.0516s\n",
      "Epoch: 00178 loss_train: 0.1697 loss_rec: 0.1697 acc_train: 0.9366 loss_val: 1.0218 acc_val: 0.7749 time: 0.0553s\n",
      "Epoch: 00179 loss_train: 0.1789 loss_rec: 0.1789 acc_train: 0.9470 loss_val: 0.9447 acc_val: 0.7786 time: 0.0438s\n",
      "Epoch: 00180 loss_train: 0.1913 loss_rec: 0.1913 acc_train: 0.9384 loss_val: 1.0188 acc_val: 0.7601 time: 0.0537s\n",
      "Epoch: 00181 loss_train: 0.1636 loss_rec: 0.1636 acc_train: 0.9477 loss_val: 0.8997 acc_val: 0.7688 time: 0.0508s\n",
      "Epoch: 00182 loss_train: 0.1836 loss_rec: 0.1836 acc_train: 0.9507 loss_val: 0.9673 acc_val: 0.7724 time: 0.0503s\n",
      "Epoch: 00183 loss_train: 0.1676 loss_rec: 0.1676 acc_train: 0.9514 loss_val: 0.9947 acc_val: 0.7774 time: 0.0555s\n",
      "Epoch: 00184 loss_train: 0.2164 loss_rec: 0.2164 acc_train: 0.9477 loss_val: 0.9989 acc_val: 0.7688 time: 0.0500s\n",
      "Epoch: 00185 loss_train: 0.1877 loss_rec: 0.1877 acc_train: 0.9507 loss_val: 0.9936 acc_val: 0.7700 time: 0.0453s\n",
      "Epoch: 00186 loss_train: 0.1801 loss_rec: 0.1801 acc_train: 0.9440 loss_val: 1.0063 acc_val: 0.7663 time: 0.0506s\n",
      "Epoch: 00187 loss_train: 0.1664 loss_rec: 0.1664 acc_train: 0.9470 loss_val: 1.0266 acc_val: 0.7614 time: 0.0478s\n",
      "Epoch: 00188 loss_train: 0.1514 loss_rec: 0.1514 acc_train: 0.9532 loss_val: 0.9350 acc_val: 0.7712 time: 0.0480s\n",
      "Epoch: 00189 loss_train: 0.1455 loss_rec: 0.1455 acc_train: 0.9550 loss_val: 0.9411 acc_val: 0.7675 time: 0.0507s\n",
      "Epoch: 00190 loss_train: 0.1649 loss_rec: 0.1649 acc_train: 0.9507 loss_val: 1.0289 acc_val: 0.7626 time: 0.0498s\n",
      "Epoch: 00191 loss_train: 0.1465 loss_rec: 0.1465 acc_train: 0.9569 loss_val: 0.9550 acc_val: 0.7700 time: 0.0505s\n",
      "Epoch: 00192 loss_train: 0.1943 loss_rec: 0.1943 acc_train: 0.9495 loss_val: 1.0273 acc_val: 0.7700 time: 0.0586s\n",
      "Epoch: 00193 loss_train: 0.1477 loss_rec: 0.1477 acc_train: 0.9557 loss_val: 0.9643 acc_val: 0.7761 time: 0.0699s\n",
      "Epoch: 00194 loss_train: 0.1618 loss_rec: 0.1618 acc_train: 0.9557 loss_val: 1.0253 acc_val: 0.7675 time: 0.0632s\n",
      "Epoch: 00195 loss_train: 0.1477 loss_rec: 0.1477 acc_train: 0.9483 loss_val: 0.9411 acc_val: 0.7626 time: 0.0581s\n",
      "Epoch: 00196 loss_train: 0.1906 loss_rec: 0.1906 acc_train: 0.9378 loss_val: 0.9867 acc_val: 0.7798 time: 0.0572s\n",
      "Epoch: 00197 loss_train: 0.1466 loss_rec: 0.1466 acc_train: 0.9544 loss_val: 1.0176 acc_val: 0.7897 time: 0.0552s\n",
      "Epoch: 00198 loss_train: 0.1576 loss_rec: 0.1576 acc_train: 0.9544 loss_val: 0.9411 acc_val: 0.7823 time: 0.0546s\n",
      "Epoch: 00199 loss_train: 0.1522 loss_rec: 0.1522 acc_train: 0.9618 loss_val: 0.9659 acc_val: 0.7811 time: 0.0478s\n",
      "Epoch: 00200 loss_train: 0.1736 loss_rec: 0.1736 acc_train: 0.9452 loss_val: 1.0082 acc_val: 0.7712 time: 0.0601s\n",
      "Epoch: 00201 loss_train: 0.1636 loss_rec: 0.1636 acc_train: 0.9544 loss_val: 0.8978 acc_val: 0.7823 time: 0.0620s\n",
      "Epoch: 00202 loss_train: 0.1612 loss_rec: 0.1612 acc_train: 0.9514 loss_val: 1.0195 acc_val: 0.7884 time: 0.0570s\n",
      "Epoch: 00203 loss_train: 0.1712 loss_rec: 0.1712 acc_train: 0.9464 loss_val: 0.9144 acc_val: 0.7798 time: 0.0516s\n",
      "Epoch: 00204 loss_train: 0.1820 loss_rec: 0.1820 acc_train: 0.9470 loss_val: 0.9899 acc_val: 0.7946 time: 0.0570s\n",
      "Epoch: 00205 loss_train: 0.1589 loss_rec: 0.1589 acc_train: 0.9507 loss_val: 1.0656 acc_val: 0.7786 time: 0.0538s\n",
      "Epoch: 00206 loss_train: 0.1735 loss_rec: 0.1735 acc_train: 0.9452 loss_val: 1.0434 acc_val: 0.7614 time: 0.0515s\n",
      "Epoch: 00207 loss_train: 0.1549 loss_rec: 0.1549 acc_train: 0.9557 loss_val: 0.9154 acc_val: 0.7749 time: 0.0547s\n",
      "Epoch: 00208 loss_train: 0.1608 loss_rec: 0.1608 acc_train: 0.9520 loss_val: 0.9617 acc_val: 0.7688 time: 0.0599s\n",
      "Epoch: 00209 loss_train: 0.1671 loss_rec: 0.1671 acc_train: 0.9458 loss_val: 1.0247 acc_val: 0.7528 time: 0.0542s\n",
      "Epoch: 00210 loss_train: 0.1581 loss_rec: 0.1581 acc_train: 0.9483 loss_val: 0.9894 acc_val: 0.7798 time: 0.0575s\n",
      "Epoch: 00211 loss_train: 0.1524 loss_rec: 0.1524 acc_train: 0.9612 loss_val: 1.0126 acc_val: 0.7724 time: 0.0589s\n",
      "Epoch: 00212 loss_train: 0.1573 loss_rec: 0.1573 acc_train: 0.9532 loss_val: 0.9857 acc_val: 0.7737 time: 0.0565s\n",
      "Epoch: 00213 loss_train: 0.1623 loss_rec: 0.1623 acc_train: 0.9594 loss_val: 1.0150 acc_val: 0.7528 time: 0.0499s\n",
      "Epoch: 00214 loss_train: 0.1873 loss_rec: 0.1873 acc_train: 0.9409 loss_val: 1.0241 acc_val: 0.7835 time: 0.0536s\n",
      "Epoch: 00215 loss_train: 0.1617 loss_rec: 0.1617 acc_train: 0.9532 loss_val: 0.9153 acc_val: 0.7884 time: 0.0507s\n",
      "Epoch: 00216 loss_train: 0.1552 loss_rec: 0.1552 acc_train: 0.9520 loss_val: 0.9654 acc_val: 0.7823 time: 0.0545s\n",
      "Epoch: 00217 loss_train: 0.1561 loss_rec: 0.1561 acc_train: 0.9520 loss_val: 0.9733 acc_val: 0.7688 time: 0.0479s\n",
      "Epoch: 00218 loss_train: 0.1355 loss_rec: 0.1355 acc_train: 0.9581 loss_val: 0.9076 acc_val: 0.7688 time: 0.0535s\n",
      "Epoch: 00219 loss_train: 0.1623 loss_rec: 0.1623 acc_train: 0.9532 loss_val: 0.9673 acc_val: 0.7811 time: 0.0572s\n",
      "Epoch: 00220 loss_train: 0.1442 loss_rec: 0.1442 acc_train: 0.9563 loss_val: 1.0402 acc_val: 0.7749 time: 0.0574s\n",
      "Epoch: 00221 loss_train: 0.1613 loss_rec: 0.1613 acc_train: 0.9507 loss_val: 0.9089 acc_val: 0.7675 time: 0.0466s\n",
      "Epoch: 00222 loss_train: 0.1467 loss_rec: 0.1467 acc_train: 0.9532 loss_val: 0.9470 acc_val: 0.7983 time: 0.0591s\n",
      "Epoch: 00223 loss_train: 0.1567 loss_rec: 0.1567 acc_train: 0.9544 loss_val: 0.9390 acc_val: 0.7946 time: 0.0544s\n",
      "Epoch: 00224 loss_train: 0.1553 loss_rec: 0.1553 acc_train: 0.9501 loss_val: 1.1101 acc_val: 0.7626 time: 0.0487s\n",
      "Epoch: 00225 loss_train: 0.1533 loss_rec: 0.1533 acc_train: 0.9544 loss_val: 0.9974 acc_val: 0.7601 time: 0.0474s\n",
      "Epoch: 00226 loss_train: 0.1443 loss_rec: 0.1443 acc_train: 0.9606 loss_val: 1.0195 acc_val: 0.7786 time: 0.0549s\n",
      "Epoch: 00227 loss_train: 0.1308 loss_rec: 0.1308 acc_train: 0.9649 loss_val: 0.9922 acc_val: 0.7847 time: 0.0520s\n",
      "Epoch: 00228 loss_train: 0.1556 loss_rec: 0.1556 acc_train: 0.9520 loss_val: 1.0390 acc_val: 0.7638 time: 0.0480s\n",
      "Epoch: 00229 loss_train: 0.1534 loss_rec: 0.1534 acc_train: 0.9550 loss_val: 1.0524 acc_val: 0.7601 time: 0.0626s\n",
      "Epoch: 00230 loss_train: 0.1527 loss_rec: 0.1527 acc_train: 0.9526 loss_val: 1.0633 acc_val: 0.7638 time: 0.0599s\n",
      "Epoch: 00231 loss_train: 0.1292 loss_rec: 0.1292 acc_train: 0.9587 loss_val: 1.0599 acc_val: 0.7675 time: 0.0523s\n",
      "Epoch: 00232 loss_train: 0.1353 loss_rec: 0.1353 acc_train: 0.9631 loss_val: 1.0396 acc_val: 0.7884 time: 0.0490s\n",
      "Epoch: 00233 loss_train: 0.1611 loss_rec: 0.1611 acc_train: 0.9477 loss_val: 1.0460 acc_val: 0.7884 time: 0.0519s\n",
      "Epoch: 00234 loss_train: 0.1571 loss_rec: 0.1571 acc_train: 0.9483 loss_val: 1.1399 acc_val: 0.7909 time: 0.0545s\n",
      "Epoch: 00235 loss_train: 0.1285 loss_rec: 0.1285 acc_train: 0.9594 loss_val: 1.0640 acc_val: 0.7811 time: 0.0524s\n",
      "Epoch: 00236 loss_train: 0.1642 loss_rec: 0.1642 acc_train: 0.9501 loss_val: 1.1222 acc_val: 0.7651 time: 0.0476s\n",
      "Epoch: 00237 loss_train: 0.1371 loss_rec: 0.1371 acc_train: 0.9538 loss_val: 0.9161 acc_val: 0.7897 time: 0.0529s\n",
      "Epoch: 00238 loss_train: 0.1433 loss_rec: 0.1433 acc_train: 0.9575 loss_val: 0.9691 acc_val: 0.7737 time: 0.0553s\n",
      "Epoch: 00239 loss_train: 0.1382 loss_rec: 0.1382 acc_train: 0.9569 loss_val: 0.9739 acc_val: 0.7823 time: 0.0535s\n",
      "Epoch: 00240 loss_train: 0.1418 loss_rec: 0.1418 acc_train: 0.9594 loss_val: 1.1460 acc_val: 0.7651 time: 0.0519s\n",
      "Epoch: 00241 loss_train: 0.1325 loss_rec: 0.1325 acc_train: 0.9612 loss_val: 1.0600 acc_val: 0.7638 time: 0.0470s\n",
      "Epoch: 00242 loss_train: 0.1441 loss_rec: 0.1441 acc_train: 0.9600 loss_val: 0.9963 acc_val: 0.7847 time: 0.0512s\n",
      "Epoch: 00243 loss_train: 0.1628 loss_rec: 0.1628 acc_train: 0.9489 loss_val: 1.0677 acc_val: 0.7872 time: 0.0498s\n",
      "Epoch: 00244 loss_train: 0.1365 loss_rec: 0.1365 acc_train: 0.9569 loss_val: 1.0145 acc_val: 0.7835 time: 0.0485s\n",
      "Epoch: 00245 loss_train: 0.1335 loss_rec: 0.1335 acc_train: 0.9606 loss_val: 1.0318 acc_val: 0.7823 time: 0.0509s\n",
      "Epoch: 00246 loss_train: 0.1473 loss_rec: 0.1473 acc_train: 0.9575 loss_val: 0.9744 acc_val: 0.7847 time: 0.0432s\n",
      "Epoch: 00247 loss_train: 0.1516 loss_rec: 0.1516 acc_train: 0.9532 loss_val: 1.0593 acc_val: 0.7700 time: 0.0490s\n",
      "Epoch: 00248 loss_train: 0.1510 loss_rec: 0.1510 acc_train: 0.9501 loss_val: 1.0379 acc_val: 0.7897 time: 0.0459s\n",
      "Epoch: 00249 loss_train: 0.1841 loss_rec: 0.1841 acc_train: 0.9477 loss_val: 1.0955 acc_val: 0.7786 time: 0.0569s\n",
      "Epoch: 00250 loss_train: 0.1495 loss_rec: 0.1495 acc_train: 0.9501 loss_val: 0.9979 acc_val: 0.7811 time: 0.0571s\n",
      "Epoch: 00251 loss_train: 0.1598 loss_rec: 0.1598 acc_train: 0.9514 loss_val: 0.9718 acc_val: 0.7884 time: 0.0485s\n",
      "Epoch: 00252 loss_train: 0.1510 loss_rec: 0.1510 acc_train: 0.9538 loss_val: 1.0557 acc_val: 0.7724 time: 0.0526s\n",
      "Epoch: 00253 loss_train: 0.1550 loss_rec: 0.1550 acc_train: 0.9581 loss_val: 1.1085 acc_val: 0.7761 time: 0.0537s\n",
      "Epoch: 00254 loss_train: 0.1714 loss_rec: 0.1714 acc_train: 0.9495 loss_val: 1.0843 acc_val: 0.7626 time: 0.0462s\n",
      "Epoch: 00255 loss_train: 0.1597 loss_rec: 0.1597 acc_train: 0.9587 loss_val: 1.0701 acc_val: 0.7761 time: 0.0483s\n",
      "Epoch: 00256 loss_train: 0.1435 loss_rec: 0.1435 acc_train: 0.9520 loss_val: 0.9353 acc_val: 0.7909 time: 0.0464s\n",
      "Epoch: 00257 loss_train: 0.1427 loss_rec: 0.1427 acc_train: 0.9538 loss_val: 1.0525 acc_val: 0.7688 time: 0.0580s\n",
      "Epoch: 00258 loss_train: 0.1400 loss_rec: 0.1400 acc_train: 0.9569 loss_val: 1.0021 acc_val: 0.7712 time: 0.0530s\n",
      "Epoch: 00259 loss_train: 0.1385 loss_rec: 0.1385 acc_train: 0.9624 loss_val: 0.9348 acc_val: 0.7934 time: 0.0557s\n",
      "Epoch: 00260 loss_train: 0.1400 loss_rec: 0.1400 acc_train: 0.9575 loss_val: 0.9762 acc_val: 0.7934 time: 0.0532s\n",
      "Epoch: 00261 loss_train: 0.1975 loss_rec: 0.1975 acc_train: 0.9569 loss_val: 1.0230 acc_val: 0.7835 time: 0.0522s\n",
      "Epoch: 00262 loss_train: 0.1882 loss_rec: 0.1882 acc_train: 0.9581 loss_val: 1.0490 acc_val: 0.7934 time: 0.0503s\n",
      "Epoch: 00263 loss_train: 0.1864 loss_rec: 0.1864 acc_train: 0.9514 loss_val: 0.9754 acc_val: 0.7700 time: 0.0564s\n",
      "Epoch: 00264 loss_train: 0.1600 loss_rec: 0.1600 acc_train: 0.9520 loss_val: 1.0086 acc_val: 0.7835 time: 0.0511s\n",
      "Epoch: 00265 loss_train: 0.1533 loss_rec: 0.1533 acc_train: 0.9538 loss_val: 1.0539 acc_val: 0.7897 time: 0.0518s\n",
      "Epoch: 00266 loss_train: 0.1493 loss_rec: 0.1493 acc_train: 0.9575 loss_val: 1.0260 acc_val: 0.7897 time: 0.0550s\n",
      "Epoch: 00267 loss_train: 0.1462 loss_rec: 0.1462 acc_train: 0.9587 loss_val: 0.9925 acc_val: 0.7811 time: 0.0511s\n",
      "Epoch: 00268 loss_train: 0.1388 loss_rec: 0.1388 acc_train: 0.9581 loss_val: 0.9878 acc_val: 0.7909 time: 0.0565s\n",
      "Epoch: 00269 loss_train: 0.1291 loss_rec: 0.1291 acc_train: 0.9667 loss_val: 1.0369 acc_val: 0.7724 time: 0.0530s\n",
      "Epoch: 00270 loss_train: 0.1445 loss_rec: 0.1445 acc_train: 0.9550 loss_val: 0.9731 acc_val: 0.7847 time: 0.0523s\n",
      "Epoch: 00271 loss_train: 0.1550 loss_rec: 0.1550 acc_train: 0.9514 loss_val: 0.9658 acc_val: 0.7663 time: 0.0525s\n",
      "Epoch: 00272 loss_train: 0.1428 loss_rec: 0.1428 acc_train: 0.9600 loss_val: 0.9686 acc_val: 0.7872 time: 0.0483s\n",
      "Epoch: 00273 loss_train: 0.1454 loss_rec: 0.1454 acc_train: 0.9563 loss_val: 1.0554 acc_val: 0.7601 time: 0.0466s\n",
      "Epoch: 00274 loss_train: 0.1590 loss_rec: 0.1590 acc_train: 0.9520 loss_val: 1.0063 acc_val: 0.7761 time: 0.0487s\n",
      "Epoch: 00275 loss_train: 0.1377 loss_rec: 0.1377 acc_train: 0.9606 loss_val: 0.8971 acc_val: 0.7774 time: 0.0532s\n",
      "Epoch: 00276 loss_train: 0.1496 loss_rec: 0.1496 acc_train: 0.9514 loss_val: 0.9949 acc_val: 0.7872 time: 0.0565s\n",
      "Epoch: 00277 loss_train: 0.1421 loss_rec: 0.1421 acc_train: 0.9606 loss_val: 1.0298 acc_val: 0.7651 time: 0.0604s\n",
      "Epoch: 00278 loss_train: 0.1187 loss_rec: 0.1187 acc_train: 0.9674 loss_val: 0.9524 acc_val: 0.7724 time: 0.0519s\n",
      "Epoch: 00279 loss_train: 0.1270 loss_rec: 0.1270 acc_train: 0.9649 loss_val: 1.0243 acc_val: 0.7811 time: 0.0551s\n",
      "Epoch: 00280 loss_train: 0.1498 loss_rec: 0.1498 acc_train: 0.9618 loss_val: 1.0003 acc_val: 0.7847 time: 0.0581s\n",
      "Epoch: 00281 loss_train: 0.1315 loss_rec: 0.1315 acc_train: 0.9643 loss_val: 1.0480 acc_val: 0.7503 time: 0.0501s\n",
      "Epoch: 00282 loss_train: 0.1323 loss_rec: 0.1323 acc_train: 0.9581 loss_val: 0.9424 acc_val: 0.7811 time: 0.0523s\n",
      "Epoch: 00283 loss_train: 0.1269 loss_rec: 0.1269 acc_train: 0.9637 loss_val: 1.0214 acc_val: 0.7798 time: 0.0529s\n",
      "Epoch: 00284 loss_train: 0.1235 loss_rec: 0.1235 acc_train: 0.9606 loss_val: 1.0100 acc_val: 0.7774 time: 0.0499s\n",
      "Epoch: 00285 loss_train: 0.1452 loss_rec: 0.1452 acc_train: 0.9507 loss_val: 1.0384 acc_val: 0.7872 time: 0.0469s\n",
      "Epoch: 00286 loss_train: 0.1287 loss_rec: 0.1287 acc_train: 0.9618 loss_val: 1.1096 acc_val: 0.7712 time: 0.0530s\n",
      "Epoch: 00287 loss_train: 0.1335 loss_rec: 0.1335 acc_train: 0.9618 loss_val: 1.0459 acc_val: 0.7700 time: 0.0555s\n",
      "Epoch: 00288 loss_train: 0.1177 loss_rec: 0.1177 acc_train: 0.9680 loss_val: 1.1422 acc_val: 0.7614 time: 0.0536s\n",
      "Epoch: 00289 loss_train: 0.1189 loss_rec: 0.1189 acc_train: 0.9655 loss_val: 1.1170 acc_val: 0.7712 time: 0.0540s\n",
      "Epoch: 00290 loss_train: 0.1397 loss_rec: 0.1397 acc_train: 0.9594 loss_val: 1.0208 acc_val: 0.7897 time: 0.0544s\n",
      "Epoch: 00291 loss_train: 0.1165 loss_rec: 0.1165 acc_train: 0.9624 loss_val: 1.1059 acc_val: 0.7884 time: 0.0544s\n",
      "Epoch: 00292 loss_train: 0.1169 loss_rec: 0.1169 acc_train: 0.9661 loss_val: 1.0129 acc_val: 0.7860 time: 0.0537s\n",
      "Epoch: 00293 loss_train: 0.1686 loss_rec: 0.1686 acc_train: 0.9526 loss_val: 1.0913 acc_val: 0.7712 time: 0.0556s\n",
      "Epoch: 00294 loss_train: 0.1215 loss_rec: 0.1215 acc_train: 0.9618 loss_val: 1.0011 acc_val: 0.7724 time: 0.0444s\n",
      "Epoch: 00295 loss_train: 0.1224 loss_rec: 0.1224 acc_train: 0.9637 loss_val: 1.0280 acc_val: 0.7774 time: 0.0663s\n",
      "Epoch: 00296 loss_train: 0.1273 loss_rec: 0.1273 acc_train: 0.9600 loss_val: 1.0938 acc_val: 0.7761 time: 0.0543s\n",
      "Epoch: 00297 loss_train: 0.1474 loss_rec: 0.1474 acc_train: 0.9538 loss_val: 1.0928 acc_val: 0.7774 time: 0.0550s\n",
      "Epoch: 00298 loss_train: 0.1277 loss_rec: 0.1277 acc_train: 0.9600 loss_val: 1.0820 acc_val: 0.7651 time: 0.0534s\n",
      "Epoch: 00299 loss_train: 0.1190 loss_rec: 0.1190 acc_train: 0.9661 loss_val: 0.9971 acc_val: 0.7823 time: 0.0582s\n",
      "Epoch: 00300 loss_train: 0.1500 loss_rec: 0.1500 acc_train: 0.9544 loss_val: 1.0253 acc_val: 0.7749 time: 0.0554s\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "encoder = GCN_Encoder_s(nfeat=features.shape[1],\n",
    "        nhid=args.n_hidden,\n",
    "        nembed=args.n_hidden,\n",
    "        dropout=args.dropout)\n",
    "classifier = GCN_Classifier_s(nembed=args.n_hidden, \n",
    "        nhid=args.n_hidden, \n",
    "        nclass=labels.max().item() + 1, \n",
    "        dropout=args.dropout)\n",
    "decoder = Decoder_s(nembed=args.n_hidden,\n",
    "        dropout=args.dropout)\n",
    "optimizer_en = optim.Adam(encoder.parameters(),\n",
    "                       lr=args.learning_rate, weight_decay=args.weight_decay)\n",
    "optimizer_cls = optim.Adam(classifier.parameters(),\n",
    "                       lr=args.learning_rate, weight_decay=args.weight_decay)\n",
    "optimizer_de = optim.Adam(decoder.parameters(),\n",
    "                       lr=args.learning_rate, weight_decay=args.weight_decay)\n",
    "def train(epoch):\n",
    "    t = time.time()\n",
    "    encoder.train()\n",
    "    classifier.train()\n",
    "    decoder.train()\n",
    "    optimizer_en.zero_grad()\n",
    "    optimizer_cls.zero_grad()\n",
    "    optimizer_de.zero_grad()\n",
    "\n",
    "    embed = encoder(features, adj_mtx)\n",
    "\n",
    "    if args.setting == 'recon_newG' or args.setting == 'recon' or args.setting == 'newG_cls':\n",
    "        ori_num = labels.shape[0]\n",
    "        embed, labels_new, idx_train_new, adj_up = utils.recon_upsample(embed, labels, train_idx, adj=adj_mtx.detach().to_dense(),portion=args.up_scale, im_class_num=args.im_class_num)\n",
    "        generated_G = decoder(embed)\n",
    "\n",
    "        loss_rec = utils.adj_mse_loss(generated_G[:ori_num, :][:, :ori_num], adj_mtx.detach().to_dense())\n",
    "        \n",
    "        #ipdb.set_trace()\n",
    "\n",
    "\n",
    "        if not args.opt_new_G:\n",
    "            adj_new = copy.deepcopy(generated_G.detach())\n",
    "            threshold = 0.5\n",
    "            adj_new[adj_new<threshold] = 0.0\n",
    "            adj_new[adj_new>=threshold] = 1.0\n",
    "\n",
    "            #ipdb.set_trace()\n",
    "            edge_ac = adj_new[:ori_num, :ori_num].eq(adj_mtx.to_dense()).double().sum()/(ori_num**2)\n",
    "        else:\n",
    "            adj_new = generated_G\n",
    "            edge_ac = F.l1_loss(adj_new[:ori_num, :ori_num], adj_mtx.to_dense(), reduction='mean')\n",
    "\n",
    "\n",
    "        #calculate generation information\n",
    "        exist_edge_prob = adj_new[:ori_num, :ori_num].mean() #edge prob for existing nodes\n",
    "        generated_edge_prob = adj_new[ori_num:, :ori_num].mean() #edge prob for generated nodes\n",
    "        print(\"edge acc: {:.4f}, exist_edge_prob: {:.4f}, generated_edge_prob: {:.4f}\".format(edge_ac.item(), exist_edge_prob.item(), generated_edge_prob.item()))\n",
    "\n",
    "\n",
    "        adj_new = torch.mul(adj_up, adj_new)\n",
    "\n",
    "        exist_edge_prob = adj_new[:ori_num, :ori_num].mean() #edge prob for existing nodes\n",
    "        generated_edge_prob = adj_new[ori_num:, :ori_num].mean() #edge prob for generated nodes\n",
    "        print(\"after filtering, edge acc: {:.4f}, exist_edge_prob: {:.4f}, generated_edge_prob: {:.4f}\".format(edge_ac.item(), exist_edge_prob.item(), generated_edge_prob.item()))\n",
    "\n",
    "\n",
    "        adj_new[:ori_num, :][:, :ori_num] = adj_mtx.detach().to_dense()\n",
    "        #adj_new = adj_new.to_sparse()\n",
    "        #ipdb.set_trace()\n",
    "\n",
    "        if not args.opt_new_G:\n",
    "            adj_new = adj_new.detach()\n",
    "\n",
    "        if args.setting == 'newG_cls':\n",
    "            idx_train_new = train_idx\n",
    "\n",
    "    elif args.setting == 'embed_up':\n",
    "        #perform SMOTE in embedding space\n",
    "        embed, labels_new, idx_train_new = utils.recon_upsample(embed, labels, train_idx, portion=args.up_scale, im_class_num = args.im_class_num)\n",
    "        adj_new = adj_mtx\n",
    "    else:\n",
    "        labels_new = labels\n",
    "        idx_train_new = train_idx\n",
    "        adj_new = adj_mtx\n",
    "\n",
    "    #ipdb.set_trace()\n",
    "    output = classifier(embed, adj_new)\n",
    "\n",
    "\n",
    "\n",
    "    if args.setting == 'reweight':\n",
    "        weight = features.new((labels.max().item() + 1)).fill_(1)\n",
    "        weight[-args.im_class_num:] = 1 + args.up_scale\n",
    "        loss_train = F.cross_entropy(output[idx_train_new], labels_new[idx_train_new], weight=weight)\n",
    "    else:\n",
    "        loss_train = F.cross_entropy(output[idx_train_new], labels_new[idx_train_new])\n",
    "\n",
    "    acc_train = accuracy(output[train_idx], labels_new[train_idx])\n",
    "    if args.setting == 'recon_newG':\n",
    "        loss = loss_train + loss_rec * args.rec_weight\n",
    "    elif args.setting == 'recon':\n",
    "        loss = loss_rec + 0 * loss_train\n",
    "    else:\n",
    "        loss = loss_train\n",
    "        loss_rec = loss_train\n",
    "\n",
    "    loss.backward()\n",
    "    if args.setting == 'newG_cls':\n",
    "        optimizer_en.zero_grad()\n",
    "        optimizer_de.zero_grad()\n",
    "    else:\n",
    "        optimizer_en.step()\n",
    "\n",
    "    optimizer_cls.step()\n",
    "\n",
    "    if args.setting == 'recon_newG' or args.setting == 'recon':\n",
    "        optimizer_de.step()\n",
    "\n",
    "    loss_val = F.cross_entropy(output[val_idx], labels[val_idx])\n",
    "    acc_val = accuracy(output[val_idx], labels[val_idx])\n",
    "\n",
    "    print('Epoch: {:05d}'.format(epoch+1),\n",
    "          'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "          'loss_rec: {:.4f}'.format(loss_rec.item()),\n",
    "          'acc_train: {:.4f}'.format(acc_train.item()),\n",
    "          'loss_val: {:.4f}'.format(loss_val.item()),\n",
    "          'acc_val: {:.4f}'.format(acc_val.item()),\n",
    "          'time: {:.4f}s'.format(time.time() - t))\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train & eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import networkx as nx\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "import pickle\n",
    "\n",
    "\n",
    "def encode_onehot_torch(labels):\n",
    "    num_classes = int(labels.max() + 1)\n",
    "    y = torch.eye(num_classes)\n",
    "    return y[labels]\n",
    "\n",
    "\n",
    "def encode_onehot(labels):\n",
    "    classes = set(labels)\n",
    "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in\n",
    "                    enumerate(classes)}\n",
    "    labels_onehot = np.array(list(map(classes_dict.get, labels)),\n",
    "                             dtype=np.int32)\n",
    "    return labels_onehot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('arc_selection-master')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "04f122987ad9a59b0c863ec73977cb4833edd644652b774e5b01a9e2fe636c23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
