{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils.GraphConvolution import GCN_Encoder_s, GCN_Classifier_s, Decoder_s\n",
    "from utils.GraphConvolution import GraphConvolution, GCN_Encoder3\n",
    "import argparse\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "import torch\n",
    "import ipdb\n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.io import loadmat\n",
    "import utils\n",
    "from collections import defaultdict\n",
    "from utils.GraphConvolution import GCN_Encoder3, GCN_Classifier, GCN_Encoder_w, sigmoid\n",
    "import time\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from utils.evaluation import accuracy, print_class_acc\n",
    "import matplotlib.pyplot as plt\n",
    "from visualization import confusion_matrix_vis\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    weight_decay = 5e-4\n",
    "    epochs = 1000\n",
    "    learning_rate = 0.01\n",
    "    learning_rate_W = 0.01\n",
    "    dropout = 0.5\n",
    "    dropout_W = 0.5\n",
    "    gamma = 1\n",
    "    no_cuda = False\n",
    "    train_ratio=0.6\n",
    "    test_ratio=0.2\n",
    "    n_classes = 2\n",
    "    seed = 1234\n",
    "    torch.manual_seed(seed)\n",
    "    # -----------------------\n",
    "    dataset = \"cora\"\n",
    "    # dataset = \"haberman\"\n",
    "    # dataset = \"diabetes\"\n",
    "    # -----------------------\n",
    "    order = 4\n",
    "    n_features = 0\n",
    "    w_val_size = 10\n",
    "    # imbalance_ratio = None\n",
    "    imbalance_ratio = 0.05\n",
    "    n_hidden = 64\n",
    "    setting = None\n",
    "    im_class_num = 1\n",
    "    setting = \"upsampling\"\n",
    "    opt_new_G = False\n",
    "    up_scale = 1\n",
    "    im_ratio = 0.5\n",
    "    val_size = 10\n",
    "    # -----------------------\n",
    "    # momentum = 0 # For SGD\n",
    "    momentum = 0\n",
    "    # momentum = 0.5\n",
    "    # momentum = 0.9\n",
    "    # momentum = 0.95\n",
    "    # -----------------------\n",
    "    optimizer_alg = \"ADAM\"\n",
    "    # optimizer_alg = \"Momentum\"\n",
    "    # optimizer_alg = \"RMSProp\"\n",
    "    # -----------------------\n",
    "    # activation_func = \"ReLU\"\n",
    "    # activation_func = \"Sigmoid\"\n",
    "    activation_func = \"LeakyReLU\"\n",
    "    # activation_func = \"PReLU\"\n",
    "    # -----------------------\n",
    "    initalization = \"Xavier Uniform\"\n",
    "    # initalization = \"Xavier Normal\"\n",
    "    # initalization = \"Kaiming Uniform\"\n",
    "    # initalization = \"Kaiming Normal\"\n",
    "    # initalization = \"Uniform\" # Uniform with 1 over squre root of the fan in \n",
    "    # -----------------------\n",
    "    res_connection = False\n",
    "    # res_connection = True\n",
    "args = Args()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset specific variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_loader import data_loader_diabetes, data_loader_haberman, data_loader_cora\n",
    "\n",
    "cora_adj_mtx, cora_labels_df, cora_features_df, \\\n",
    "        cora_train_idx, cora_val_idx, cora_test_idx, cora_n_features = data_loader_cora(args)\n",
    "        \n",
    "diabetes_adj_mtx, diabetes_labels_df, diabetes_features_df, \\\n",
    "        diabetes_train_idx, diabetes_val_idx, diabetes_test_idx, diabetes_n_features = data_loader_diabetes(args)\n",
    "\n",
    "haberman_adj_mtx, haberman_labels_df, haberman_features_df, \\\n",
    "        haberman_train_idx, haberman_val_idx, haberman_test_idx, haberman_n_features = data_loader_haberman(args)\n",
    "\n",
    "if args.dataset == \"diabetes\":\n",
    "    adj_mtx = diabetes_adj_mtx\n",
    "    n_hidden = [64, 64, 64]\n",
    "    n_features = diabetes_n_features\n",
    "    features = diabetes_features_df\n",
    "    labels = diabetes_labels_df\n",
    "    # train_X = diabetes_train_X_df\n",
    "    # train_Y = diabetes_train_Y_df\n",
    "    # val_X = diabetes_val_X_df\n",
    "    # val_Y = diabetes_val_Y_df\n",
    "    # test_X = diabetes_test_X_df\n",
    "    # test_Y = diabetes_test_Y_df\n",
    "    train_idx = diabetes_train_idx\n",
    "    val_idx = diabetes_val_idx\n",
    "    test_idx = diabetes_test_idx\n",
    "elif args.dataset == \"cora\":\n",
    "    adj_mtx = cora_adj_mtx\n",
    "    n_hidden = [64, 64, 64]\n",
    "    n_features = cora_n_features\n",
    "    features = cora_features_df\n",
    "    labels = cora_labels_df\n",
    "    # train_X = diabetes_train_X_df\n",
    "    # train_Y = diabetes_train_Y_df\n",
    "    # val_X = diabetes_val_X_df\n",
    "    # val_Y = diabetes_val_Y_df\n",
    "    # test_X = diabetes_test_X_df\n",
    "    # test_Y = diabetes_test_Y_df\n",
    "    train_idx = cora_train_idx\n",
    "    val_idx = cora_val_idx\n",
    "    test_idx = cora_test_idx\n",
    "elif args.dataset == \"haberman\":\n",
    "    adj_mtx = haberman_adj_mtx\n",
    "    n_hidden = [64]\n",
    "    n_features = haberman_n_features\n",
    "    features = haberman_features_df\n",
    "    labels = haberman_labels_df\n",
    "    # train_X = haberman_train_X_df\n",
    "    # train_Y = haberman_train_Y_df\n",
    "    # val_X = haberman_val_X_df\n",
    "    # val_Y = haberman_val_Y_df\n",
    "    # test_X = haberman_test_X_df\n",
    "    # test_Y = haberman_test_Y_df\n",
    "    train_idx = haberman_train_idx\n",
    "    val_idx = haberman_val_idx\n",
    "    test_idx = haberman_test_idx\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert len(pd.DataFrame(labels[train_idx])[0].unique()) == len(pd.DataFrame(labels[val_idx])[0].unique()) == len(pd.DataFrame(labels[test_idx])[0].unique()), \\\n",
    "    # \"There are some classes missing in one the 3 partitiones of the dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if False else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe to Tensor transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = torch.from_numpy(np.concatenate((train_X, val_X, test_X), axis=0)).to(device)\n",
    "# labels = torch.from_numpy(np.int64(np.concatenate((train_Y, val_Y, test_Y), axis=0))).to(device)\n",
    "train_idx = torch.from_numpy(np.array(train_idx, dtype = np.int64)).to(device)\n",
    "val_idx = torch.from_numpy(np.array(val_idx, dtype = np.int64)).to(device)\n",
    "test_idx = torch.from_numpy(np.array(test_idx, dtype = np.int64)).to(device)\n",
    "features = torch.from_numpy(np.array(features, dtype = np.float64)).to(device)\n",
    "labels = torch.from_numpy(np.array(labels, dtype = np.int64)).to(device)\n",
    "try:\n",
    "    adj_mtx = torch.from_numpy(np.array(adj_mtx, dtype = np.float64)).to(device)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline 2 layer Classifier trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.GraphConvolution import GCN_Encoder3, GCN_Classifier, GCN_Encoder_w\n",
    "import time\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from utils.evaluation import accuracy, print_class_acc\n",
    "\n",
    "encoder_n = GCN_Encoder3(nfeat = n_features,\n",
    "        nhid = n_hidden,\n",
    "        nembed = n_hidden[-1],\n",
    "        dropout = args.dropout,\n",
    "        nclass = args.n_classes, \n",
    "        init = args.initalization,\n",
    "        order = 1, \n",
    "        res_connection = args.res_connection)\n",
    "classifier_n = GCN_Classifier(nembed = n_hidden[-1], \n",
    "        nhid = n_hidden[-1], \n",
    "        nclass = int(labels.max().item()) + 1, \n",
    "        dropout = args.dropout, init = args.initalization,\n",
    "        device = device)\n",
    "\n",
    "# encoder = GCN_Encoder_s(nfeat = n_features, nhid = n_hidden[-1], nembed = n_hidden[-1], dropout = args.dropout)\n",
    "# classifier = GCN_Classifier_s(nembed = n_hidden[-1], nhid = n_hidden[-1], nclass = int(labels.max().item()) + 1, dropout = args.dropout, device = device)\n",
    "# encoder_n = GCN_Encoder_w(nfeat = n_features, nembed = n_hidden[-1], nhid = n_hidden[-1], nclass = int(labels.max().item()) + 1, dropout = args.dropout, device = device)\n",
    "# optimizer_n = optim.Adam(encoder_n.parameters(),\n",
    "#                        lr = args.learning_rate, weight_decay = args.weight_decay)\n",
    "if args.optimizer_alg == \"ADAM\":\n",
    "        optimizer_en = optim.Adam(encoder_n.parameters(),\n",
    "                        lr = args.learning_rate, weight_decay = args.weight_decay)\n",
    "        optimizer_cls = optim.Adam(classifier_n.parameters(),\n",
    "                        lr = args.learning_rate, weight_decay = args.weight_decay)\n",
    "elif args.optimizer_alg == \"Momentum\":\n",
    "        optimizer_en = optim.SGD(encoder_n.parameters(),\n",
    "                        lr = args.learning_rate, momentum = args.momentum)\n",
    "        optimizer_cls = optim.SGD(classifier_n.parameters(),\n",
    "                        lr = args.learning_rate, momentum = args.momentum)\n",
    "elif args.optimizer_alg == \"RMSProp\":\n",
    "        optimizer_en = optim.SGD(encoder_n.parameters(),\n",
    "                        lr = args.learning_rate, weight_decay = args.weight_decay)\n",
    "        optimizer_cls = optim.SGD(classifier_n.parameters(),\n",
    "                        lr = args.learning_rate, weight_decay = args.weight_decay)\n",
    "else:\n",
    "        optimizer_en = optim.Adam(encoder_n.parameters(),\n",
    "                        lr = args.learning_rate, weight_decay = args.weight_decay)\n",
    "        optimizer_cls = optim.Adam(classifier_n.parameters(),\n",
    "                        lr = args.learning_rate, weight_decay = args.weight_decay)\n",
    "def train(epoch):\n",
    "        encoder_n.train()\n",
    "        classifier_n.train()\n",
    "        t = time.time()\n",
    "        optimizer_en.zero_grad()\n",
    "        optimizer_cls.zero_grad()\n",
    "        # optimizer_n.zero_grad()\n",
    "        embed = encoder_n(features, adj_mtx, funct = args.activation_func)\n",
    "        output = classifier_n(embed, adj_mtx, funct = args.activation_func)\n",
    "        # output = encoder_n(features, adj_mtx)\n",
    "        out = output[train_idx]\n",
    "        gt = labels[train_idx].reshape(-1)\n",
    "        if args.setting == 'reweight':\n",
    "                weight = \"STH\"\n",
    "                loss_train = F.cross_entropy(out, gt, weight = weight)\n",
    "        else:\n",
    "                loss_train = F.cross_entropy(out, gt)\n",
    "        acc_train = accuracy(out, gt)\n",
    "        loss_train.backward()\n",
    "        optimizer_en.step()\n",
    "        optimizer_cls.step()\n",
    "        # encoder_n.step()\n",
    "        gt_v = labels[val_idx].reshape(-1)\n",
    "        out_v = output[val_idx]\n",
    "        loss_val = F.cross_entropy(out_v, gt_v)\n",
    "        acc_val = accuracy(out_v, gt_v)\n",
    "        # print_class_acc(out_v, gt_v)\n",
    "        print('Epoch: {:05d}'.format(epoch + 1),\n",
    "          'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "          'acc_train: {:.4f}'.format(acc_train.item()),\n",
    "          'loss_val: {:.4f}'.format(loss_val.item()),\n",
    "          'acc_val: {:.4f}'.format(acc_val.item()),\n",
    "          'time: {:.4f}s'.format(time.time() - t))\n",
    "        print_class_acc(output[val_idx], labels[val_idx])\n",
    "        return acc_train.item(), acc_val.item(), loss_train.item(), loss_val.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline 2 layer Classifier test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch = 0):\n",
    "    encoder_n.eval()\n",
    "    classifier_n.eval()\n",
    "#     outputs = encoder(features, adj_mtx)\n",
    "    embed = encoder_n(features, adj_mtx, funct = args.activation_func)\n",
    "    outputs = classifier_n(embed, adj_mtx, funct = args.activation_func)\n",
    "    loss_test = F.cross_entropy(outputs[test_idx], labels[test_idx].reshape(-1))\n",
    "    acc_test = accuracy(outputs[test_idx], labels[test_idx])\n",
    "    print(\"Test set results:\",\n",
    "          \"loss= {:.4f}\".format(loss_test.item()),\n",
    "          \"accuracy= {:.4f}\".format(acc_test.item()))\n",
    "    print_class_acc(outputs[test_idx], labels[test_idx], pre='test')\n",
    "    return loss_test.item(), acc_test.item(), outputs, embed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Baseline 2 layer Classifier training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 00001 loss_train: 0.2685 acc_train: 0.9120 loss_val: 1.5867 acc_val: 0.6919 time: 0.0243s\n",
      "valid current auc-roc score: 0.913504, current macro_F score: 0.654118\n",
      "Test set results: loss= 1.5024 accuracy= 738.2804\n",
      "test current auc-roc score: 0.924501, current macro_F score: 0.694383\n",
      "Epoch: 00002 loss_train: 0.2265 acc_train: 0.9313 loss_val: 1.7060 acc_val: 0.6937 time: 0.0205s\n",
      "valid current auc-roc score: 0.915669, current macro_F score: 0.668103\n",
      "Epoch: 00003 loss_train: 0.2215 acc_train: 0.9328 loss_val: 1.6507 acc_val: 0.6956 time: 0.0258s\n",
      "valid current auc-roc score: 0.911734, current macro_F score: 0.675966\n",
      "Epoch: 00004 loss_train: 0.2487 acc_train: 0.9177 loss_val: 1.6948 acc_val: 0.7048 time: 0.0260s\n",
      "valid current auc-roc score: 0.912686, current macro_F score: 0.673854\n",
      "Epoch: 00005 loss_train: 0.2708 acc_train: 0.9113 loss_val: 1.8983 acc_val: 0.7011 time: 0.0201s\n",
      "valid current auc-roc score: 0.908346, current macro_F score: 0.682624\n",
      "Epoch: 00006 loss_train: 0.2462 acc_train: 0.9192 loss_val: 1.9519 acc_val: 0.6974 time: 0.0249s\n",
      "valid current auc-roc score: 0.906542, current macro_F score: 0.685775\n",
      "Epoch: 00007 loss_train: 0.2364 acc_train: 0.9185 loss_val: 1.6171 acc_val: 0.7048 time: 0.0205s\n",
      "valid current auc-roc score: 0.917505, current macro_F score: 0.687962\n",
      "Epoch: 00008 loss_train: 0.2328 acc_train: 0.9249 loss_val: 1.7816 acc_val: 0.6956 time: 0.0232s\n",
      "valid current auc-roc score: 0.913026, current macro_F score: 0.673939\n",
      "Epoch: 00009 loss_train: 0.2390 acc_train: 0.9163 loss_val: 1.8734 acc_val: 0.7066 time: 0.0202s\n",
      "valid current auc-roc score: 0.906992, current macro_F score: 0.690923\n",
      "Epoch: 00010 loss_train: 0.2662 acc_train: 0.9134 loss_val: 1.5629 acc_val: 0.7048 time: 0.0221s\n",
      "valid current auc-roc score: 0.918302, current macro_F score: 0.682870\n",
      "Epoch: 00011 loss_train: 0.2656 acc_train: 0.9120 loss_val: 1.5200 acc_val: 0.7066 time: 0.0218s\n",
      "valid current auc-roc score: 0.918421, current macro_F score: 0.676166\n",
      "Test set results: loss= 1.4167 accuracy= 724.2159\n",
      "test current auc-roc score: 0.927630, current macro_F score: 0.707448\n",
      "Epoch: 00012 loss_train: 0.2571 acc_train: 0.9177 loss_val: 1.5550 acc_val: 0.6937 time: 0.0185s\n",
      "valid current auc-roc score: 0.913216, current macro_F score: 0.670878\n",
      "Epoch: 00013 loss_train: 0.2607 acc_train: 0.9249 loss_val: 1.7786 acc_val: 0.6919 time: 0.0182s\n",
      "valid current auc-roc score: 0.908434, current macro_F score: 0.671621\n",
      "Epoch: 00014 loss_train: 0.2258 acc_train: 0.9335 loss_val: 1.5735 acc_val: 0.7048 time: 0.0219s\n",
      "valid current auc-roc score: 0.909318, current macro_F score: 0.682972\n",
      "Epoch: 00015 loss_train: 0.2302 acc_train: 0.9313 loss_val: 1.6509 acc_val: 0.7251 time: 0.0209s\n",
      "valid current auc-roc score: 0.922997, current macro_F score: 0.705032\n",
      "Epoch: 00016 loss_train: 0.2149 acc_train: 0.9263 loss_val: 1.7285 acc_val: 0.7306 time: 0.0189s\n",
      "valid current auc-roc score: 0.919039, current macro_F score: 0.716254\n",
      "Epoch: 00017 loss_train: 0.2267 acc_train: 0.9177 loss_val: 1.5494 acc_val: 0.7325 time: 0.0197s\n",
      "valid current auc-roc score: 0.916983, current macro_F score: 0.717895\n",
      "Epoch: 00018 loss_train: 0.2229 acc_train: 0.9263 loss_val: 1.4097 acc_val: 0.7196 time: 0.0229s\n",
      "valid current auc-roc score: 0.921179, current macro_F score: 0.699362\n",
      "Epoch: 00019 loss_train: 0.2260 acc_train: 0.9206 loss_val: 1.4733 acc_val: 0.7399 time: 0.0186s\n",
      "valid current auc-roc score: 0.922093, current macro_F score: 0.725741\n",
      "Epoch: 00020 loss_train: 0.2312 acc_train: 0.9256 loss_val: 1.5138 acc_val: 0.7048 time: 0.0241s\n",
      "valid current auc-roc score: 0.926289, current macro_F score: 0.681042\n",
      "Epoch: 00021 loss_train: 0.2391 acc_train: 0.9299 loss_val: 1.6947 acc_val: 0.7269 time: 0.0197s\n",
      "valid current auc-roc score: 0.915581, current macro_F score: 0.714297\n",
      "Test set results: loss= 1.3935 accuracy= 735.8911\n",
      "test current auc-roc score: 0.930308, current macro_F score: 0.718765\n",
      "Epoch: 00022 loss_train: 0.2249 acc_train: 0.9285 loss_val: 1.3081 acc_val: 0.7306 time: 0.0199s\n",
      "valid current auc-roc score: 0.932663, current macro_F score: 0.708326\n",
      "Epoch: 00023 loss_train: 0.2292 acc_train: 0.9235 loss_val: 1.4298 acc_val: 0.7159 time: 0.0191s\n",
      "valid current auc-roc score: 0.920132, current macro_F score: 0.694386\n",
      "Epoch: 00024 loss_train: 0.2507 acc_train: 0.9199 loss_val: 1.3738 acc_val: 0.7269 time: 0.0218s\n",
      "valid current auc-roc score: 0.927638, current macro_F score: 0.710925\n",
      "Epoch: 00025 loss_train: 0.2333 acc_train: 0.9242 loss_val: 1.5015 acc_val: 0.7122 time: 0.0190s\n",
      "valid current auc-roc score: 0.913001, current macro_F score: 0.689399\n",
      "Epoch: 00026 loss_train: 0.2460 acc_train: 0.9227 loss_val: 1.5792 acc_val: 0.7232 time: 0.0250s\n",
      "valid current auc-roc score: 0.916904, current macro_F score: 0.708471\n",
      "Epoch: 00027 loss_train: 0.2321 acc_train: 0.9270 loss_val: 1.6941 acc_val: 0.7085 time: 0.0326s\n",
      "valid current auc-roc score: 0.912679, current macro_F score: 0.688318\n",
      "Epoch: 00028 loss_train: 0.2430 acc_train: 0.9149 loss_val: 1.8337 acc_val: 0.7196 time: 0.0227s\n",
      "valid current auc-roc score: 0.910555, current macro_F score: 0.694424\n",
      "Epoch: 00029 loss_train: 0.2404 acc_train: 0.9199 loss_val: 1.5689 acc_val: 0.6974 time: 0.0228s\n",
      "valid current auc-roc score: 0.915760, current macro_F score: 0.671076\n",
      "Epoch: 00030 loss_train: 0.2577 acc_train: 0.9213 loss_val: 1.8006 acc_val: 0.6956 time: 0.0208s\n",
      "valid current auc-roc score: 0.900297, current macro_F score: 0.669481\n",
      "Epoch: 00031 loss_train: 0.2461 acc_train: 0.9249 loss_val: 1.6806 acc_val: 0.7048 time: 0.0271s\n",
      "valid current auc-roc score: 0.909083, current macro_F score: 0.681853\n",
      "Test set results: loss= 1.4935 accuracy= 723.4280\n",
      "test current auc-roc score: 0.924494, current macro_F score: 0.710359\n",
      "Epoch: 00032 loss_train: 0.2513 acc_train: 0.9142 loss_val: 1.6473 acc_val: 0.6956 time: 0.0197s\n",
      "valid current auc-roc score: 0.907679, current macro_F score: 0.665617\n",
      "Epoch: 00033 loss_train: 0.2290 acc_train: 0.9292 loss_val: 1.6286 acc_val: 0.7011 time: 0.0263s\n",
      "valid current auc-roc score: 0.916490, current macro_F score: 0.680555\n",
      "Epoch: 00034 loss_train: 0.2829 acc_train: 0.9156 loss_val: 1.6595 acc_val: 0.6882 time: 0.0201s\n",
      "valid current auc-roc score: 0.916503, current macro_F score: 0.655356\n",
      "Epoch: 00035 loss_train: 0.2406 acc_train: 0.9192 loss_val: 1.6909 acc_val: 0.7011 time: 0.0265s\n",
      "valid current auc-roc score: 0.911692, current macro_F score: 0.681281\n",
      "Epoch: 00036 loss_train: 0.2357 acc_train: 0.9227 loss_val: 1.6485 acc_val: 0.7214 time: 0.0230s\n",
      "valid current auc-roc score: 0.913842, current macro_F score: 0.708583\n",
      "Epoch: 00037 loss_train: 0.2300 acc_train: 0.9192 loss_val: 1.6581 acc_val: 0.7048 time: 0.0222s\n",
      "valid current auc-roc score: 0.914091, current macro_F score: 0.683736\n",
      "Epoch: 00038 loss_train: 0.2339 acc_train: 0.9256 loss_val: 1.7022 acc_val: 0.7048 time: 0.0212s\n",
      "valid current auc-roc score: 0.915907, current macro_F score: 0.684676\n",
      "Epoch: 00039 loss_train: 0.2280 acc_train: 0.9206 loss_val: 1.4832 acc_val: 0.6882 time: 0.0201s\n",
      "valid current auc-roc score: 0.919324, current macro_F score: 0.664101\n",
      "Epoch: 00040 loss_train: 0.2232 acc_train: 0.9185 loss_val: 1.6756 acc_val: 0.7048 time: 0.0210s\n",
      "valid current auc-roc score: 0.905472, current macro_F score: 0.679511\n",
      "Epoch: 00041 loss_train: 0.2174 acc_train: 0.9278 loss_val: 1.6642 acc_val: 0.7306 time: 0.0215s\n",
      "valid current auc-roc score: 0.917327, current macro_F score: 0.705390\n",
      "Test set results: loss= 1.4090 accuracy= 730.2343\n",
      "test current auc-roc score: 0.928423, current macro_F score: 0.722683\n",
      "Epoch: 00042 loss_train: 0.2256 acc_train: 0.9306 loss_val: 1.5880 acc_val: 0.7288 time: 0.0211s\n",
      "valid current auc-roc score: 0.928846, current macro_F score: 0.713272\n",
      "Epoch: 00043 loss_train: 0.2341 acc_train: 0.9199 loss_val: 1.6576 acc_val: 0.7196 time: 0.0215s\n",
      "valid current auc-roc score: 0.915098, current macro_F score: 0.694897\n",
      "Epoch: 00044 loss_train: 0.2829 acc_train: 0.9163 loss_val: 1.5162 acc_val: 0.7325 time: 0.0210s\n",
      "valid current auc-roc score: 0.922785, current macro_F score: 0.706390\n",
      "Epoch: 00045 loss_train: 0.2749 acc_train: 0.9199 loss_val: 1.6949 acc_val: 0.7269 time: 0.0189s\n",
      "valid current auc-roc score: 0.920581, current macro_F score: 0.704698\n",
      "Epoch: 00046 loss_train: 0.2487 acc_train: 0.9206 loss_val: 1.5131 acc_val: 0.7159 time: 0.0196s\n",
      "valid current auc-roc score: 0.913238, current macro_F score: 0.703592\n",
      "Epoch: 00047 loss_train: 0.2783 acc_train: 0.9070 loss_val: 1.6011 acc_val: 0.7196 time: 0.0189s\n",
      "valid current auc-roc score: 0.912136, current macro_F score: 0.698551\n",
      "Epoch: 00048 loss_train: 0.2233 acc_train: 0.9270 loss_val: 1.5613 acc_val: 0.7177 time: 0.0279s\n",
      "valid current auc-roc score: 0.915653, current macro_F score: 0.699555\n",
      "Epoch: 00049 loss_train: 0.2406 acc_train: 0.9185 loss_val: 1.7324 acc_val: 0.7232 time: 0.0234s\n",
      "valid current auc-roc score: 0.903674, current macro_F score: 0.694943\n",
      "Epoch: 00050 loss_train: 0.2431 acc_train: 0.9242 loss_val: 1.6409 acc_val: 0.7085 time: 0.0215s\n",
      "valid current auc-roc score: 0.908741, current macro_F score: 0.687414\n",
      "Epoch: 00051 loss_train: 0.2574 acc_train: 0.9199 loss_val: 1.6495 acc_val: 0.7196 time: 0.0188s\n",
      "valid current auc-roc score: 0.918405, current macro_F score: 0.704961\n",
      "Test set results: loss= 1.4834 accuracy= 730.7380\n",
      "test current auc-roc score: 0.925149, current macro_F score: 0.698651\n",
      "Epoch: 00052 loss_train: 0.2463 acc_train: 0.9142 loss_val: 1.5868 acc_val: 0.7103 time: 0.0192s\n",
      "valid current auc-roc score: 0.921075, current macro_F score: 0.684689\n",
      "Epoch: 00053 loss_train: 0.2563 acc_train: 0.9220 loss_val: 1.5936 acc_val: 0.7251 time: 0.0198s\n",
      "valid current auc-roc score: 0.907337, current macro_F score: 0.690004\n",
      "Epoch: 00054 loss_train: 0.2418 acc_train: 0.9285 loss_val: 1.5961 acc_val: 0.7030 time: 0.0218s\n",
      "valid current auc-roc score: 0.908082, current macro_F score: 0.676094\n",
      "Epoch: 00055 loss_train: 0.2572 acc_train: 0.9163 loss_val: 1.6272 acc_val: 0.7399 time: 0.0230s\n",
      "valid current auc-roc score: 0.910760, current macro_F score: 0.713109\n",
      "Epoch: 00056 loss_train: 0.2366 acc_train: 0.9220 loss_val: 1.9383 acc_val: 0.7030 time: 0.0265s\n",
      "valid current auc-roc score: 0.908875, current macro_F score: 0.680766\n",
      "Epoch: 00057 loss_train: 0.2590 acc_train: 0.9170 loss_val: 1.6863 acc_val: 0.7380 time: 0.0229s\n",
      "valid current auc-roc score: 0.917782, current macro_F score: 0.726544\n",
      "Epoch: 00058 loss_train: 0.2470 acc_train: 0.9177 loss_val: 1.9747 acc_val: 0.7030 time: 0.0252s\n",
      "valid current auc-roc score: 0.904576, current macro_F score: 0.687960\n",
      "Epoch: 00059 loss_train: 0.2633 acc_train: 0.9177 loss_val: 1.8156 acc_val: 0.7251 time: 0.0228s\n",
      "valid current auc-roc score: 0.907505, current macro_F score: 0.699576\n",
      "Epoch: 00060 loss_train: 0.2576 acc_train: 0.9134 loss_val: 1.8497 acc_val: 0.7103 time: 0.0278s\n",
      "valid current auc-roc score: 0.901527, current macro_F score: 0.695616\n",
      "Epoch: 00061 loss_train: 0.2693 acc_train: 0.9056 loss_val: 1.7011 acc_val: 0.7103 time: 0.0354s\n",
      "valid current auc-roc score: 0.917830, current macro_F score: 0.689136\n",
      "Test set results: loss= 1.5215 accuracy= 736.2786\n",
      "test current auc-roc score: 0.923253, current macro_F score: 0.716749\n",
      "Epoch: 00062 loss_train: 0.2258 acc_train: 0.9256 loss_val: 1.5450 acc_val: 0.7325 time: 0.0217s\n",
      "valid current auc-roc score: 0.915490, current macro_F score: 0.721398\n",
      "Epoch: 00063 loss_train: 0.2704 acc_train: 0.9063 loss_val: 1.6995 acc_val: 0.7306 time: 0.0217s\n",
      "valid current auc-roc score: 0.907399, current macro_F score: 0.708961\n",
      "Epoch: 00064 loss_train: 0.2361 acc_train: 0.9242 loss_val: 1.7026 acc_val: 0.7122 time: 0.0247s\n",
      "valid current auc-roc score: 0.908671, current macro_F score: 0.694539\n",
      "Epoch: 00065 loss_train: 0.2294 acc_train: 0.9285 loss_val: 1.6348 acc_val: 0.7177 time: 0.0210s\n",
      "valid current auc-roc score: 0.911383, current macro_F score: 0.693157\n",
      "Epoch: 00066 loss_train: 0.2509 acc_train: 0.9106 loss_val: 1.7250 acc_val: 0.7066 time: 0.0241s\n",
      "valid current auc-roc score: 0.905014, current macro_F score: 0.674847\n",
      "Epoch: 00067 loss_train: 0.2788 acc_train: 0.9092 loss_val: 1.5566 acc_val: 0.7103 time: 0.0271s\n",
      "valid current auc-roc score: 0.902711, current macro_F score: 0.684190\n",
      "Epoch: 00068 loss_train: 0.2562 acc_train: 0.9127 loss_val: 1.7133 acc_val: 0.6956 time: 0.0232s\n",
      "valid current auc-roc score: 0.909110, current macro_F score: 0.684814\n",
      "Epoch: 00069 loss_train: 0.2451 acc_train: 0.9242 loss_val: 1.5661 acc_val: 0.7103 time: 0.0217s\n",
      "valid current auc-roc score: 0.915699, current macro_F score: 0.681044\n",
      "Epoch: 00070 loss_train: 0.2801 acc_train: 0.9127 loss_val: 1.7679 acc_val: 0.7103 time: 0.0238s\n",
      "valid current auc-roc score: 0.903495, current macro_F score: 0.678448\n",
      "Epoch: 00071 loss_train: 0.2320 acc_train: 0.9278 loss_val: 1.4730 acc_val: 0.7306 time: 0.0193s\n",
      "valid current auc-roc score: 0.922326, current macro_F score: 0.702688\n",
      "Test set results: loss= 1.5106 accuracy= 724.7841\n",
      "test current auc-roc score: 0.922771, current macro_F score: 0.717499\n",
      "Epoch: 00072 loss_train: 0.2517 acc_train: 0.9163 loss_val: 1.8604 acc_val: 0.7030 time: 0.0195s\n",
      "valid current auc-roc score: 0.903130, current macro_F score: 0.682347\n",
      "Epoch: 00073 loss_train: 0.2205 acc_train: 0.9242 loss_val: 1.6562 acc_val: 0.6827 time: 0.0187s\n",
      "valid current auc-roc score: 0.906867, current macro_F score: 0.647657\n",
      "Epoch: 00074 loss_train: 0.2794 acc_train: 0.9092 loss_val: 1.5742 acc_val: 0.6827 time: 0.0225s\n",
      "valid current auc-roc score: 0.911735, current macro_F score: 0.652715\n",
      "Epoch: 00075 loss_train: 0.2356 acc_train: 0.9227 loss_val: 1.7473 acc_val: 0.7214 time: 0.0206s\n",
      "valid current auc-roc score: 0.915955, current macro_F score: 0.699606\n",
      "Epoch: 00076 loss_train: 0.2276 acc_train: 0.9235 loss_val: 1.9108 acc_val: 0.7011 time: 0.0241s\n",
      "valid current auc-roc score: 0.910093, current macro_F score: 0.670573\n",
      "Epoch: 00077 loss_train: 0.2188 acc_train: 0.9270 loss_val: 1.7530 acc_val: 0.7362 time: 0.0190s\n",
      "valid current auc-roc score: 0.917213, current macro_F score: 0.718101\n",
      "Epoch: 00078 loss_train: 0.2500 acc_train: 0.9170 loss_val: 1.5850 acc_val: 0.7232 time: 0.0186s\n",
      "valid current auc-roc score: 0.926129, current macro_F score: 0.706735\n",
      "Epoch: 00079 loss_train: 0.2474 acc_train: 0.9213 loss_val: 1.8579 acc_val: 0.7140 time: 0.0187s\n",
      "valid current auc-roc score: 0.915207, current macro_F score: 0.696916\n",
      "Epoch: 00080 loss_train: 0.2684 acc_train: 0.9227 loss_val: 1.6887 acc_val: 0.7196 time: 0.0193s\n",
      "valid current auc-roc score: 0.914657, current macro_F score: 0.697741\n",
      "Epoch: 00081 loss_train: 0.2082 acc_train: 0.9320 loss_val: 1.7179 acc_val: 0.7399 time: 0.0199s\n",
      "valid current auc-roc score: 0.910728, current macro_F score: 0.717702\n",
      "Test set results: loss= 1.5117 accuracy= 740.2565\n",
      "test current auc-roc score: 0.923520, current macro_F score: 0.710950\n",
      "Epoch: 00082 loss_train: 0.2192 acc_train: 0.9235 loss_val: 1.5359 acc_val: 0.7159 time: 0.0204s\n",
      "valid current auc-roc score: 0.911477, current macro_F score: 0.690966\n",
      "Epoch: 00083 loss_train: 0.2544 acc_train: 0.9142 loss_val: 1.7339 acc_val: 0.7343 time: 0.0181s\n",
      "valid current auc-roc score: 0.914957, current macro_F score: 0.700532\n",
      "Epoch: 00084 loss_train: 0.2630 acc_train: 0.9106 loss_val: 1.3478 acc_val: 0.7232 time: 0.0260s\n",
      "valid current auc-roc score: 0.924476, current macro_F score: 0.692557\n",
      "Epoch: 00085 loss_train: 0.2693 acc_train: 0.9120 loss_val: 1.4931 acc_val: 0.7232 time: 0.0221s\n",
      "valid current auc-roc score: 0.916481, current macro_F score: 0.700534\n",
      "Epoch: 00086 loss_train: 0.2252 acc_train: 0.9285 loss_val: 1.7434 acc_val: 0.7122 time: 0.0200s\n",
      "valid current auc-roc score: 0.914907, current macro_F score: 0.690138\n",
      "Epoch: 00087 loss_train: 0.2342 acc_train: 0.9235 loss_val: 1.5143 acc_val: 0.7269 time: 0.0226s\n",
      "valid current auc-roc score: 0.919841, current macro_F score: 0.709886\n",
      "Epoch: 00088 loss_train: 0.2427 acc_train: 0.9235 loss_val: 1.4429 acc_val: 0.7269 time: 0.0189s\n",
      "valid current auc-roc score: 0.930561, current macro_F score: 0.702542\n",
      "Epoch: 00089 loss_train: 0.2389 acc_train: 0.9199 loss_val: 1.6432 acc_val: 0.7159 time: 0.0220s\n",
      "valid current auc-roc score: 0.914992, current macro_F score: 0.694107\n",
      "Epoch: 00090 loss_train: 0.2363 acc_train: 0.9270 loss_val: 1.6420 acc_val: 0.7066 time: 0.0260s\n",
      "valid current auc-roc score: 0.910976, current macro_F score: 0.678782\n",
      "Epoch: 00091 loss_train: 0.2113 acc_train: 0.9278 loss_val: 1.5413 acc_val: 0.7251 time: 0.0241s\n",
      "valid current auc-roc score: 0.914293, current macro_F score: 0.703006\n",
      "Test set results: loss= 1.5525 accuracy= 730.5572\n",
      "test current auc-roc score: 0.922747, current macro_F score: 0.685027\n",
      "Epoch: 00092 loss_train: 0.2213 acc_train: 0.9270 loss_val: 1.5682 acc_val: 0.6974 time: 0.0224s\n",
      "valid current auc-roc score: 0.911652, current macro_F score: 0.675544\n",
      "Epoch: 00093 loss_train: 0.2138 acc_train: 0.9342 loss_val: 1.5949 acc_val: 0.7011 time: 0.0257s\n",
      "valid current auc-roc score: 0.916219, current macro_F score: 0.668537\n",
      "Epoch: 00094 loss_train: 0.2456 acc_train: 0.9156 loss_val: 1.5813 acc_val: 0.7030 time: 0.0195s\n",
      "valid current auc-roc score: 0.918575, current macro_F score: 0.680981\n",
      "Epoch: 00095 loss_train: 0.2394 acc_train: 0.9192 loss_val: 1.7726 acc_val: 0.7140 time: 0.0189s\n",
      "valid current auc-roc score: 0.916421, current macro_F score: 0.687008\n",
      "Epoch: 00096 loss_train: 0.2559 acc_train: 0.9070 loss_val: 1.9761 acc_val: 0.7030 time: 0.0233s\n",
      "valid current auc-roc score: 0.899588, current macro_F score: 0.672586\n",
      "Epoch: 00097 loss_train: 0.2431 acc_train: 0.9206 loss_val: 1.9486 acc_val: 0.7103 time: 0.0246s\n",
      "valid current auc-roc score: 0.913785, current macro_F score: 0.689731\n",
      "Epoch: 00098 loss_train: 0.2278 acc_train: 0.9220 loss_val: 1.7173 acc_val: 0.7122 time: 0.0233s\n",
      "valid current auc-roc score: 0.918487, current macro_F score: 0.687557\n",
      "Epoch: 00099 loss_train: 0.2168 acc_train: 0.9270 loss_val: 1.8291 acc_val: 0.7140 time: 0.0245s\n",
      "valid current auc-roc score: 0.913918, current macro_F score: 0.680454\n",
      "Epoch: 00100 loss_train: 0.2237 acc_train: 0.9235 loss_val: 1.8032 acc_val: 0.7085 time: 0.0200s\n",
      "valid current auc-roc score: 0.914631, current macro_F score: 0.685889\n",
      "Epoch: 00101 loss_train: 0.2734 acc_train: 0.9170 loss_val: 1.7074 acc_val: 0.7122 time: 0.0247s\n",
      "valid current auc-roc score: 0.916191, current macro_F score: 0.689691\n",
      "Test set results: loss= 1.4218 accuracy= 727.9483\n",
      "test current auc-roc score: 0.927330, current macro_F score: 0.705696\n",
      "Epoch: 00102 loss_train: 0.2429 acc_train: 0.9220 loss_val: 1.5421 acc_val: 0.7085 time: 0.0193s\n",
      "valid current auc-roc score: 0.907591, current macro_F score: 0.674645\n",
      "Epoch: 00103 loss_train: 0.2472 acc_train: 0.9213 loss_val: 1.2475 acc_val: 0.7417 time: 0.0188s\n",
      "valid current auc-roc score: 0.932342, current macro_F score: 0.723309\n",
      "Epoch: 00104 loss_train: 0.3100 acc_train: 0.9063 loss_val: 1.5933 acc_val: 0.6900 time: 0.0252s\n",
      "valid current auc-roc score: 0.908390, current macro_F score: 0.667341\n",
      "Epoch: 00105 loss_train: 0.2305 acc_train: 0.9249 loss_val: 1.5290 acc_val: 0.7122 time: 0.0216s\n",
      "valid current auc-roc score: 0.911577, current macro_F score: 0.686915\n",
      "Epoch: 00106 loss_train: 0.2273 acc_train: 0.9199 loss_val: 1.4967 acc_val: 0.7140 time: 0.0239s\n",
      "valid current auc-roc score: 0.915670, current macro_F score: 0.684515\n",
      "Epoch: 00107 loss_train: 0.2323 acc_train: 0.9235 loss_val: 1.5804 acc_val: 0.7085 time: 0.0246s\n",
      "valid current auc-roc score: 0.909887, current macro_F score: 0.683958\n",
      "Epoch: 00108 loss_train: 0.2414 acc_train: 0.9213 loss_val: 1.6171 acc_val: 0.7140 time: 0.0219s\n",
      "valid current auc-roc score: 0.911210, current macro_F score: 0.700585\n",
      "Epoch: 00109 loss_train: 0.2518 acc_train: 0.9120 loss_val: 1.5112 acc_val: 0.7085 time: 0.0217s\n",
      "valid current auc-roc score: 0.913629, current macro_F score: 0.684094\n",
      "Epoch: 00110 loss_train: 0.2149 acc_train: 0.9278 loss_val: 1.5866 acc_val: 0.7030 time: 0.0200s\n",
      "valid current auc-roc score: 0.911337, current macro_F score: 0.664787\n",
      "Epoch: 00111 loss_train: 0.2387 acc_train: 0.9134 loss_val: 1.5854 acc_val: 0.7066 time: 0.0205s\n",
      "valid current auc-roc score: 0.909737, current macro_F score: 0.679522\n",
      "Test set results: loss= 1.5498 accuracy= 728.7232\n",
      "test current auc-roc score: 0.920811, current macro_F score: 0.693682\n",
      "Epoch: 00112 loss_train: 0.2388 acc_train: 0.9270 loss_val: 1.6999 acc_val: 0.7011 time: 0.0193s\n",
      "valid current auc-roc score: 0.907011, current macro_F score: 0.682065\n",
      "Epoch: 00113 loss_train: 0.2350 acc_train: 0.9270 loss_val: 1.5794 acc_val: 0.7214 time: 0.0194s\n",
      "valid current auc-roc score: 0.911108, current macro_F score: 0.700582\n",
      "Epoch: 00114 loss_train: 0.2398 acc_train: 0.9249 loss_val: 1.6632 acc_val: 0.6993 time: 0.0216s\n",
      "valid current auc-roc score: 0.905368, current macro_F score: 0.668716\n",
      "Epoch: 00115 loss_train: 0.2181 acc_train: 0.9285 loss_val: 1.5576 acc_val: 0.6919 time: 0.0224s\n",
      "valid current auc-roc score: 0.907742, current macro_F score: 0.666245\n",
      "Epoch: 00116 loss_train: 0.2424 acc_train: 0.9278 loss_val: 1.8273 acc_val: 0.6863 time: 0.0214s\n",
      "valid current auc-roc score: 0.908192, current macro_F score: 0.661888\n",
      "Epoch: 00117 loss_train: 0.2384 acc_train: 0.9206 loss_val: 1.9999 acc_val: 0.7066 time: 0.0203s\n",
      "valid current auc-roc score: 0.909773, current macro_F score: 0.688867\n",
      "Epoch: 00118 loss_train: 0.2389 acc_train: 0.9249 loss_val: 1.9012 acc_val: 0.7122 time: 0.0241s\n",
      "valid current auc-roc score: 0.911821, current macro_F score: 0.699239\n",
      "Epoch: 00119 loss_train: 0.2544 acc_train: 0.9256 loss_val: 1.5600 acc_val: 0.7048 time: 0.0278s\n",
      "valid current auc-roc score: 0.926741, current macro_F score: 0.693727\n",
      "Epoch: 00120 loss_train: 0.2381 acc_train: 0.9227 loss_val: 1.5251 acc_val: 0.7159 time: 0.0220s\n",
      "valid current auc-roc score: 0.923706, current macro_F score: 0.696713\n",
      "Epoch: 00121 loss_train: 0.2299 acc_train: 0.9313 loss_val: 1.6329 acc_val: 0.7066 time: 0.0291s\n",
      "valid current auc-roc score: 0.916439, current macro_F score: 0.680722\n",
      "Test set results: loss= 1.4652 accuracy= 726.1273\n",
      "test current auc-roc score: 0.925592, current macro_F score: 0.703411\n",
      "Epoch: 00122 loss_train: 0.2419 acc_train: 0.9220 loss_val: 1.5953 acc_val: 0.7048 time: 0.0255s\n",
      "valid current auc-roc score: 0.914599, current macro_F score: 0.677726\n",
      "Epoch: 00123 loss_train: 0.2300 acc_train: 0.9213 loss_val: 1.3860 acc_val: 0.7214 time: 0.0218s\n",
      "valid current auc-roc score: 0.924382, current macro_F score: 0.706397\n",
      "Epoch: 00124 loss_train: 0.2337 acc_train: 0.9170 loss_val: 1.5164 acc_val: 0.7306 time: 0.0200s\n",
      "valid current auc-roc score: 0.917403, current macro_F score: 0.708819\n",
      "Epoch: 00125 loss_train: 0.2277 acc_train: 0.9285 loss_val: 1.5620 acc_val: 0.7214 time: 0.0259s\n",
      "valid current auc-roc score: 0.922334, current macro_F score: 0.698596\n",
      "Epoch: 00126 loss_train: 0.2387 acc_train: 0.9206 loss_val: 1.6503 acc_val: 0.7085 time: 0.0229s\n",
      "valid current auc-roc score: 0.904275, current macro_F score: 0.688794\n",
      "Epoch: 00127 loss_train: 0.2239 acc_train: 0.9213 loss_val: 1.4108 acc_val: 0.7122 time: 0.0233s\n",
      "valid current auc-roc score: 0.919998, current macro_F score: 0.689047\n",
      "Epoch: 00128 loss_train: 0.2458 acc_train: 0.9163 loss_val: 1.4608 acc_val: 0.7140 time: 0.0213s\n",
      "valid current auc-roc score: 0.913963, current macro_F score: 0.688427\n",
      "Epoch: 00129 loss_train: 0.2056 acc_train: 0.9292 loss_val: 1.6722 acc_val: 0.7362 time: 0.0238s\n",
      "valid current auc-roc score: 0.916695, current macro_F score: 0.719596\n",
      "Epoch: 00130 loss_train: 0.2161 acc_train: 0.9313 loss_val: 1.5762 acc_val: 0.7048 time: 0.0203s\n",
      "valid current auc-roc score: 0.916173, current macro_F score: 0.682604\n",
      "Epoch: 00131 loss_train: 0.2253 acc_train: 0.9220 loss_val: 1.7201 acc_val: 0.7269 time: 0.0273s\n",
      "valid current auc-roc score: 0.920255, current macro_F score: 0.703358\n",
      "Test set results: loss= 1.5538 accuracy= 732.6882\n",
      "test current auc-roc score: 0.922465, current macro_F score: 0.703868\n",
      "Epoch: 00132 loss_train: 0.2319 acc_train: 0.9142 loss_val: 1.6693 acc_val: 0.7159 time: 0.0240s\n",
      "valid current auc-roc score: 0.913977, current macro_F score: 0.689570\n",
      "Epoch: 00133 loss_train: 0.2235 acc_train: 0.9342 loss_val: 1.4624 acc_val: 0.7177 time: 0.0196s\n",
      "valid current auc-roc score: 0.912361, current macro_F score: 0.693102\n",
      "Epoch: 00134 loss_train: 0.2396 acc_train: 0.9256 loss_val: 1.6309 acc_val: 0.6974 time: 0.0219s\n",
      "valid current auc-roc score: 0.908268, current macro_F score: 0.668899\n",
      "Epoch: 00135 loss_train: 0.2327 acc_train: 0.9227 loss_val: 1.5512 acc_val: 0.7159 time: 0.0237s\n",
      "valid current auc-roc score: 0.912141, current macro_F score: 0.690603\n",
      "Epoch: 00136 loss_train: 0.2298 acc_train: 0.9235 loss_val: 1.7721 acc_val: 0.7122 time: 0.0206s\n",
      "valid current auc-roc score: 0.913763, current macro_F score: 0.689787\n",
      "Epoch: 00137 loss_train: 0.2169 acc_train: 0.9270 loss_val: 1.5589 acc_val: 0.7214 time: 0.0206s\n",
      "valid current auc-roc score: 0.918276, current macro_F score: 0.695075\n",
      "Epoch: 00138 loss_train: 0.2318 acc_train: 0.9213 loss_val: 1.5316 acc_val: 0.7251 time: 0.0231s\n",
      "valid current auc-roc score: 0.916271, current macro_F score: 0.707686\n",
      "Epoch: 00139 loss_train: 0.2147 acc_train: 0.9335 loss_val: 1.6950 acc_val: 0.7214 time: 0.0246s\n",
      "valid current auc-roc score: 0.912804, current macro_F score: 0.702516\n",
      "Epoch: 00140 loss_train: 0.2266 acc_train: 0.9185 loss_val: 1.6414 acc_val: 0.7048 time: 0.0285s\n",
      "valid current auc-roc score: 0.913011, current macro_F score: 0.676770\n",
      "Epoch: 00141 loss_train: 0.2265 acc_train: 0.9256 loss_val: 1.5859 acc_val: 0.7140 time: 0.0214s\n",
      "valid current auc-roc score: 0.912668, current macro_F score: 0.679394\n",
      "Test set results: loss= 1.5174 accuracy= 738.6808\n",
      "test current auc-roc score: 0.925134, current macro_F score: 0.708055\n",
      "Epoch: 00142 loss_train: 0.2112 acc_train: 0.9320 loss_val: 1.6937 acc_val: 0.7196 time: 0.0178s\n",
      "valid current auc-roc score: 0.915078, current macro_F score: 0.696246\n",
      "Epoch: 00143 loss_train: 0.2321 acc_train: 0.9227 loss_val: 1.6450 acc_val: 0.7269 time: 0.0346s\n",
      "valid current auc-roc score: 0.923355, current macro_F score: 0.705775\n",
      "Epoch: 00144 loss_train: 0.2489 acc_train: 0.9170 loss_val: 1.4823 acc_val: 0.7122 time: 0.0224s\n",
      "valid current auc-roc score: 0.928163, current macro_F score: 0.683514\n",
      "Epoch: 00145 loss_train: 0.2068 acc_train: 0.9285 loss_val: 1.3553 acc_val: 0.7565 time: 0.0258s\n",
      "valid current auc-roc score: 0.927502, current macro_F score: 0.739410\n",
      "Epoch: 00146 loss_train: 0.2451 acc_train: 0.9270 loss_val: 1.5976 acc_val: 0.7103 time: 0.0221s\n",
      "valid current auc-roc score: 0.919194, current macro_F score: 0.691373\n",
      "Epoch: 00147 loss_train: 0.2376 acc_train: 0.9185 loss_val: 1.6020 acc_val: 0.7232 time: 0.0243s\n",
      "valid current auc-roc score: 0.915444, current macro_F score: 0.705979\n",
      "Epoch: 00148 loss_train: 0.2407 acc_train: 0.9185 loss_val: 1.6568 acc_val: 0.7232 time: 0.0223s\n",
      "valid current auc-roc score: 0.908741, current macro_F score: 0.703062\n",
      "Epoch: 00149 loss_train: 0.2144 acc_train: 0.9371 loss_val: 1.6496 acc_val: 0.7343 time: 0.0250s\n",
      "valid current auc-roc score: 0.918060, current macro_F score: 0.729310\n",
      "Epoch: 00150 loss_train: 0.2228 acc_train: 0.9220 loss_val: 1.6094 acc_val: 0.7269 time: 0.0251s\n",
      "valid current auc-roc score: 0.908846, current macro_F score: 0.695942\n",
      "Epoch: 00151 loss_train: 0.2226 acc_train: 0.9249 loss_val: 1.6351 acc_val: 0.7232 time: 0.0240s\n",
      "valid current auc-roc score: 0.914670, current macro_F score: 0.693949\n",
      "Test set results: loss= 1.5224 accuracy= 716.1052\n",
      "test current auc-roc score: 0.926380, current macro_F score: 0.715093\n",
      "Epoch: 00152 loss_train: 0.2447 acc_train: 0.9156 loss_val: 1.3868 acc_val: 0.7085 time: 0.0222s\n",
      "valid current auc-roc score: 0.928352, current macro_F score: 0.693245\n",
      "Epoch: 00153 loss_train: 0.2162 acc_train: 0.9256 loss_val: 1.4327 acc_val: 0.7177 time: 0.0282s\n",
      "valid current auc-roc score: 0.925124, current macro_F score: 0.695304\n",
      "Epoch: 00154 loss_train: 0.2472 acc_train: 0.9220 loss_val: 1.5135 acc_val: 0.7140 time: 0.0384s\n",
      "valid current auc-roc score: 0.920220, current macro_F score: 0.689525\n",
      "Epoch: 00155 loss_train: 0.1945 acc_train: 0.9385 loss_val: 1.5314 acc_val: 0.7454 time: 0.0213s\n",
      "valid current auc-roc score: 0.926718, current macro_F score: 0.721336\n",
      "Epoch: 00156 loss_train: 0.2208 acc_train: 0.9320 loss_val: 1.5858 acc_val: 0.7288 time: 0.0212s\n",
      "valid current auc-roc score: 0.915386, current macro_F score: 0.698140\n",
      "Epoch: 00157 loss_train: 0.2209 acc_train: 0.9235 loss_val: 1.8194 acc_val: 0.7122 time: 0.0267s\n",
      "valid current auc-roc score: 0.916486, current macro_F score: 0.688836\n",
      "Epoch: 00158 loss_train: 0.2349 acc_train: 0.9170 loss_val: 1.6673 acc_val: 0.7288 time: 0.0198s\n",
      "valid current auc-roc score: 0.921244, current macro_F score: 0.709683\n",
      "Epoch: 00159 loss_train: 0.2036 acc_train: 0.9335 loss_val: 1.8321 acc_val: 0.7011 time: 0.0210s\n",
      "valid current auc-roc score: 0.909219, current macro_F score: 0.682103\n",
      "Epoch: 00160 loss_train: 0.2220 acc_train: 0.9227 loss_val: 1.6376 acc_val: 0.7177 time: 0.0246s\n",
      "valid current auc-roc score: 0.921922, current macro_F score: 0.698494\n",
      "Epoch: 00161 loss_train: 0.2137 acc_train: 0.9213 loss_val: 1.5290 acc_val: 0.7232 time: 0.0227s\n",
      "valid current auc-roc score: 0.918431, current macro_F score: 0.693477\n",
      "Test set results: loss= 1.5556 accuracy= 726.9539\n",
      "test current auc-roc score: 0.926627, current macro_F score: 0.713605\n",
      "Epoch: 00162 loss_train: 0.2636 acc_train: 0.9235 loss_val: 1.6892 acc_val: 0.7288 time: 0.0212s\n",
      "valid current auc-roc score: 0.921461, current macro_F score: 0.705438\n",
      "Epoch: 00163 loss_train: 0.2222 acc_train: 0.9227 loss_val: 1.7006 acc_val: 0.7196 time: 0.0225s\n",
      "valid current auc-roc score: 0.911643, current macro_F score: 0.703295\n",
      "Epoch: 00164 loss_train: 0.2147 acc_train: 0.9249 loss_val: 1.4764 acc_val: 0.7472 time: 0.0237s\n",
      "valid current auc-roc score: 0.927842, current macro_F score: 0.727167\n",
      "Epoch: 00165 loss_train: 0.2226 acc_train: 0.9328 loss_val: 1.4517 acc_val: 0.7343 time: 0.0244s\n",
      "valid current auc-roc score: 0.920782, current macro_F score: 0.723259\n",
      "Epoch: 00166 loss_train: 0.2366 acc_train: 0.9185 loss_val: 1.4536 acc_val: 0.7251 time: 0.0229s\n",
      "valid current auc-roc score: 0.922048, current macro_F score: 0.708268\n",
      "Epoch: 00167 loss_train: 0.2262 acc_train: 0.9256 loss_val: 1.6057 acc_val: 0.7103 time: 0.0228s\n",
      "valid current auc-roc score: 0.915069, current macro_F score: 0.689010\n",
      "Epoch: 00168 loss_train: 0.2182 acc_train: 0.9278 loss_val: 1.5108 acc_val: 0.7251 time: 0.0243s\n",
      "valid current auc-roc score: 0.920510, current macro_F score: 0.709276\n",
      "Epoch: 00169 loss_train: 0.2573 acc_train: 0.9270 loss_val: 1.4888 acc_val: 0.7269 time: 0.0231s\n",
      "valid current auc-roc score: 0.921492, current macro_F score: 0.699763\n",
      "Epoch: 00170 loss_train: 0.2167 acc_train: 0.9263 loss_val: 1.4775 acc_val: 0.7103 time: 0.0245s\n",
      "valid current auc-roc score: 0.923207, current macro_F score: 0.684809\n",
      "Epoch: 00171 loss_train: 0.1933 acc_train: 0.9406 loss_val: 1.5347 acc_val: 0.7251 time: 0.0243s\n",
      "valid current auc-roc score: 0.921297, current macro_F score: 0.704627\n",
      "Test set results: loss= 1.4084 accuracy= 731.0351\n",
      "test current auc-roc score: 0.931064, current macro_F score: 0.728818\n",
      "Epoch: 00172 loss_train: 0.2843 acc_train: 0.9013 loss_val: 1.4226 acc_val: 0.7325 time: 0.0281s\n",
      "valid current auc-roc score: 0.932788, current macro_F score: 0.716387\n",
      "Epoch: 00173 loss_train: 0.2257 acc_train: 0.9242 loss_val: 1.5530 acc_val: 0.7122 time: 0.0246s\n",
      "valid current auc-roc score: 0.913680, current macro_F score: 0.691602\n",
      "Epoch: 00174 loss_train: 0.2330 acc_train: 0.9242 loss_val: 1.5626 acc_val: 0.7159 time: 0.0225s\n",
      "valid current auc-roc score: 0.923395, current macro_F score: 0.689486\n",
      "Epoch: 00175 loss_train: 0.2057 acc_train: 0.9320 loss_val: 1.4737 acc_val: 0.7251 time: 0.0224s\n",
      "valid current auc-roc score: 0.920293, current macro_F score: 0.702514\n",
      "Epoch: 00176 loss_train: 0.2045 acc_train: 0.9371 loss_val: 1.6034 acc_val: 0.7251 time: 0.0228s\n",
      "valid current auc-roc score: 0.923295, current macro_F score: 0.704776\n",
      "Epoch: 00177 loss_train: 0.2222 acc_train: 0.9285 loss_val: 1.6356 acc_val: 0.7159 time: 0.0221s\n",
      "valid current auc-roc score: 0.920062, current macro_F score: 0.693031\n",
      "Epoch: 00178 loss_train: 0.2326 acc_train: 0.9185 loss_val: 1.6151 acc_val: 0.7177 time: 0.0257s\n",
      "valid current auc-roc score: 0.914728, current macro_F score: 0.688561\n",
      "Epoch: 00179 loss_train: 0.2115 acc_train: 0.9342 loss_val: 1.5427 acc_val: 0.7362 time: 0.0229s\n",
      "valid current auc-roc score: 0.927283, current macro_F score: 0.721669\n",
      "Epoch: 00180 loss_train: 0.2193 acc_train: 0.9249 loss_val: 1.5799 acc_val: 0.7306 time: 0.0229s\n",
      "valid current auc-roc score: 0.930186, current macro_F score: 0.709199\n",
      "Epoch: 00181 loss_train: 0.2202 acc_train: 0.9320 loss_val: 1.6557 acc_val: 0.7122 time: 0.0247s\n",
      "valid current auc-roc score: 0.915014, current macro_F score: 0.690892\n",
      "Test set results: loss= 1.5457 accuracy= 728.2841\n",
      "test current auc-roc score: 0.928367, current macro_F score: 0.707160\n",
      "Epoch: 00182 loss_train: 0.2087 acc_train: 0.9313 loss_val: 1.4596 acc_val: 0.7177 time: 0.0240s\n",
      "valid current auc-roc score: 0.922372, current macro_F score: 0.698946\n",
      "Epoch: 00183 loss_train: 0.2069 acc_train: 0.9328 loss_val: 1.6346 acc_val: 0.7362 time: 0.0225s\n",
      "valid current auc-roc score: 0.923915, current macro_F score: 0.722450\n",
      "Epoch: 00184 loss_train: 0.2047 acc_train: 0.9235 loss_val: 1.7539 acc_val: 0.7214 time: 0.0327s\n",
      "valid current auc-roc score: 0.917853, current macro_F score: 0.697002\n",
      "Epoch: 00185 loss_train: 0.1987 acc_train: 0.9328 loss_val: 1.5265 acc_val: 0.7306 time: 0.0288s\n",
      "valid current auc-roc score: 0.918459, current macro_F score: 0.708069\n",
      "Epoch: 00186 loss_train: 0.2277 acc_train: 0.9249 loss_val: 1.5730 acc_val: 0.7325 time: 0.0233s\n",
      "valid current auc-roc score: 0.925511, current macro_F score: 0.705152\n",
      "Epoch: 00187 loss_train: 0.2284 acc_train: 0.9235 loss_val: 1.5400 acc_val: 0.7232 time: 0.0271s\n",
      "valid current auc-roc score: 0.924334, current macro_F score: 0.705827\n",
      "Epoch: 00188 loss_train: 0.2376 acc_train: 0.9185 loss_val: 1.7165 acc_val: 0.7030 time: 0.0235s\n",
      "valid current auc-roc score: 0.908360, current macro_F score: 0.665865\n",
      "Epoch: 00189 loss_train: 0.2545 acc_train: 0.9192 loss_val: 1.6960 acc_val: 0.6956 time: 0.0222s\n",
      "valid current auc-roc score: 0.921378, current macro_F score: 0.673711\n",
      "Epoch: 00190 loss_train: 0.2029 acc_train: 0.9335 loss_val: 1.7304 acc_val: 0.7269 time: 0.0276s\n",
      "valid current auc-roc score: 0.925753, current macro_F score: 0.714889\n",
      "Epoch: 00191 loss_train: 0.2328 acc_train: 0.9249 loss_val: 1.5048 acc_val: 0.7196 time: 0.0224s\n",
      "valid current auc-roc score: 0.925441, current macro_F score: 0.702391\n",
      "Test set results: loss= 1.4741 accuracy= 743.2399\n",
      "test current auc-roc score: 0.927724, current macro_F score: 0.709800\n",
      "Epoch: 00192 loss_train: 0.2944 acc_train: 0.8984 loss_val: 1.9404 acc_val: 0.7103 time: 0.0228s\n",
      "valid current auc-roc score: 0.913563, current macro_F score: 0.690676\n",
      "Epoch: 00193 loss_train: 0.2289 acc_train: 0.9278 loss_val: 1.6455 acc_val: 0.7435 time: 0.0256s\n",
      "valid current auc-roc score: 0.921170, current macro_F score: 0.719649\n",
      "Epoch: 00194 loss_train: 0.2390 acc_train: 0.9213 loss_val: 1.6771 acc_val: 0.7269 time: 0.0247s\n",
      "valid current auc-roc score: 0.928865, current macro_F score: 0.708864\n",
      "Epoch: 00195 loss_train: 0.2113 acc_train: 0.9342 loss_val: 1.5121 acc_val: 0.7435 time: 0.0235s\n",
      "valid current auc-roc score: 0.926881, current macro_F score: 0.724769\n",
      "Epoch: 00196 loss_train: 0.2559 acc_train: 0.9106 loss_val: 1.6751 acc_val: 0.7288 time: 0.0217s\n",
      "valid current auc-roc score: 0.921655, current macro_F score: 0.718888\n",
      "Epoch: 00197 loss_train: 0.2130 acc_train: 0.9299 loss_val: 1.6650 acc_val: 0.7251 time: 0.0229s\n",
      "valid current auc-roc score: 0.917557, current macro_F score: 0.702584\n",
      "Epoch: 00198 loss_train: 0.2381 acc_train: 0.9199 loss_val: 1.9122 acc_val: 0.7030 time: 0.0246s\n",
      "valid current auc-roc score: 0.916461, current macro_F score: 0.682398\n",
      "Epoch: 00199 loss_train: 0.2138 acc_train: 0.9292 loss_val: 1.6168 acc_val: 0.7325 time: 0.0221s\n",
      "valid current auc-roc score: 0.919484, current macro_F score: 0.710885\n",
      "Epoch: 00200 loss_train: 0.2383 acc_train: 0.9242 loss_val: 1.7219 acc_val: 0.7030 time: 0.0213s\n",
      "valid current auc-roc score: 0.913173, current macro_F score: 0.686013\n",
      "Epoch: 00201 loss_train: 0.2432 acc_train: 0.9127 loss_val: 1.6476 acc_val: 0.7103 time: 0.0238s\n",
      "valid current auc-roc score: 0.919863, current macro_F score: 0.686682\n",
      "Test set results: loss= 1.5052 accuracy= 729.2657\n",
      "test current auc-roc score: 0.923956, current macro_F score: 0.725004\n",
      "Epoch: 00202 loss_train: 0.2270 acc_train: 0.9213 loss_val: 1.7290 acc_val: 0.7251 time: 0.0211s\n",
      "valid current auc-roc score: 0.919323, current macro_F score: 0.708580\n",
      "Epoch: 00203 loss_train: 0.2293 acc_train: 0.9220 loss_val: 1.4978 acc_val: 0.7491 time: 0.0232s\n",
      "valid current auc-roc score: 0.930306, current macro_F score: 0.722622\n",
      "Epoch: 00204 loss_train: 0.2345 acc_train: 0.9278 loss_val: 1.5295 acc_val: 0.7435 time: 0.0226s\n",
      "valid current auc-roc score: 0.922998, current macro_F score: 0.729507\n",
      "Epoch: 00205 loss_train: 0.1956 acc_train: 0.9399 loss_val: 1.5187 acc_val: 0.7454 time: 0.0215s\n",
      "valid current auc-roc score: 0.929370, current macro_F score: 0.729520\n",
      "Epoch: 00206 loss_train: 0.2269 acc_train: 0.9306 loss_val: 1.6786 acc_val: 0.7251 time: 0.0209s\n",
      "valid current auc-roc score: 0.917782, current macro_F score: 0.698011\n",
      "Epoch: 00207 loss_train: 0.2129 acc_train: 0.9320 loss_val: 1.7035 acc_val: 0.7177 time: 0.0215s\n",
      "valid current auc-roc score: 0.917903, current macro_F score: 0.692087\n",
      "Epoch: 00208 loss_train: 0.2008 acc_train: 0.9328 loss_val: 1.6635 acc_val: 0.7362 time: 0.0237s\n",
      "valid current auc-roc score: 0.916276, current macro_F score: 0.720948\n",
      "Epoch: 00209 loss_train: 0.2118 acc_train: 0.9270 loss_val: 1.6298 acc_val: 0.7140 time: 0.0269s\n",
      "valid current auc-roc score: 0.916839, current macro_F score: 0.694968\n",
      "Epoch: 00210 loss_train: 0.2054 acc_train: 0.9306 loss_val: 1.5481 acc_val: 0.7343 time: 0.0206s\n",
      "valid current auc-roc score: 0.921091, current macro_F score: 0.716161\n",
      "Epoch: 00211 loss_train: 0.2094 acc_train: 0.9335 loss_val: 1.6386 acc_val: 0.7325 time: 0.0213s\n",
      "valid current auc-roc score: 0.911131, current macro_F score: 0.721879\n",
      "Test set results: loss= 1.6809 accuracy= 732.3911\n",
      "test current auc-roc score: 0.918453, current macro_F score: 0.705241\n",
      "Epoch: 00212 loss_train: 0.1934 acc_train: 0.9356 loss_val: 1.6249 acc_val: 0.7085 time: 0.0216s\n",
      "valid current auc-roc score: 0.918393, current macro_F score: 0.697455\n",
      "Epoch: 00213 loss_train: 0.2299 acc_train: 0.9285 loss_val: 1.5919 acc_val: 0.7122 time: 0.0235s\n",
      "valid current auc-roc score: 0.921058, current macro_F score: 0.691894\n",
      "Epoch: 00214 loss_train: 0.2088 acc_train: 0.9342 loss_val: 1.6958 acc_val: 0.7030 time: 0.0259s\n",
      "valid current auc-roc score: 0.919703, current macro_F score: 0.687849\n",
      "Epoch: 00215 loss_train: 0.1935 acc_train: 0.9363 loss_val: 1.8473 acc_val: 0.7159 time: 0.0221s\n",
      "valid current auc-roc score: 0.914140, current macro_F score: 0.697362\n",
      "Epoch: 00216 loss_train: 0.2220 acc_train: 0.9256 loss_val: 1.6128 acc_val: 0.6956 time: 0.0240s\n",
      "valid current auc-roc score: 0.917370, current macro_F score: 0.675991\n",
      "Epoch: 00217 loss_train: 0.2355 acc_train: 0.9256 loss_val: 1.4520 acc_val: 0.7343 time: 0.0231s\n",
      "valid current auc-roc score: 0.925017, current macro_F score: 0.717069\n",
      "Epoch: 00218 loss_train: 0.2412 acc_train: 0.9235 loss_val: 1.4203 acc_val: 0.7159 time: 0.0203s\n",
      "valid current auc-roc score: 0.920180, current macro_F score: 0.688672\n",
      "Epoch: 00219 loss_train: 0.2042 acc_train: 0.9335 loss_val: 1.5714 acc_val: 0.7085 time: 0.0207s\n",
      "valid current auc-roc score: 0.914833, current macro_F score: 0.677332\n",
      "Epoch: 00220 loss_train: 0.2523 acc_train: 0.9120 loss_val: 1.5879 acc_val: 0.7030 time: 0.0221s\n",
      "valid current auc-roc score: 0.920484, current macro_F score: 0.673930\n",
      "Epoch: 00221 loss_train: 0.2242 acc_train: 0.9292 loss_val: 1.4964 acc_val: 0.7269 time: 0.0227s\n",
      "valid current auc-roc score: 0.921744, current macro_F score: 0.710487\n",
      "Test set results: loss= 1.5184 accuracy= 733.5406\n",
      "test current auc-roc score: 0.925635, current macro_F score: 0.697300\n",
      "Epoch: 00222 loss_train: 0.2564 acc_train: 0.9220 loss_val: 1.5677 acc_val: 0.7251 time: 0.0220s\n",
      "valid current auc-roc score: 0.916496, current macro_F score: 0.708947\n",
      "Epoch: 00223 loss_train: 0.2337 acc_train: 0.9278 loss_val: 1.6017 acc_val: 0.7140 time: 0.0217s\n",
      "valid current auc-roc score: 0.913247, current macro_F score: 0.696125\n",
      "Epoch: 00224 loss_train: 0.2334 acc_train: 0.9156 loss_val: 1.7080 acc_val: 0.7380 time: 0.0250s\n",
      "valid current auc-roc score: 0.923991, current macro_F score: 0.733598\n",
      "Epoch: 00225 loss_train: 0.2187 acc_train: 0.9227 loss_val: 1.5040 acc_val: 0.7343 time: 0.0223s\n",
      "valid current auc-roc score: 0.926375, current macro_F score: 0.723777\n",
      "Epoch: 00226 loss_train: 0.1808 acc_train: 0.9428 loss_val: 1.6221 acc_val: 0.7251 time: 0.0235s\n",
      "valid current auc-roc score: 0.922171, current macro_F score: 0.708732\n",
      "Epoch: 00227 loss_train: 0.2447 acc_train: 0.9177 loss_val: 1.8331 acc_val: 0.7011 time: 0.0234s\n",
      "valid current auc-roc score: 0.908882, current macro_F score: 0.679658\n",
      "Epoch: 00228 loss_train: 0.2513 acc_train: 0.9213 loss_val: 1.9037 acc_val: 0.6974 time: 0.0211s\n",
      "valid current auc-roc score: 0.915380, current macro_F score: 0.672045\n",
      "Epoch: 00229 loss_train: 0.2152 acc_train: 0.9313 loss_val: 1.7527 acc_val: 0.7048 time: 0.0229s\n",
      "valid current auc-roc score: 0.912447, current macro_F score: 0.680781\n",
      "Epoch: 00230 loss_train: 0.2452 acc_train: 0.9206 loss_val: 1.5792 acc_val: 0.7251 time: 0.0237s\n",
      "valid current auc-roc score: 0.923059, current macro_F score: 0.697999\n",
      "Epoch: 00231 loss_train: 0.2644 acc_train: 0.9185 loss_val: 1.6640 acc_val: 0.7103 time: 0.0223s\n",
      "valid current auc-roc score: 0.910330, current macro_F score: 0.678032\n",
      "Test set results: loss= 1.5535 accuracy= 724.8745\n",
      "test current auc-roc score: 0.921502, current macro_F score: 0.708873\n",
      "Epoch: 00232 loss_train: 0.1989 acc_train: 0.9399 loss_val: 1.5060 acc_val: 0.7122 time: 0.0202s\n",
      "valid current auc-roc score: 0.923032, current macro_F score: 0.686449\n",
      "Epoch: 00233 loss_train: 0.2372 acc_train: 0.9199 loss_val: 1.3503 acc_val: 0.7214 time: 0.0211s\n",
      "valid current auc-roc score: 0.929402, current macro_F score: 0.712642\n",
      "Epoch: 00234 loss_train: 0.2507 acc_train: 0.9106 loss_val: 1.7113 acc_val: 0.7177 time: 0.0256s\n",
      "valid current auc-roc score: 0.915469, current macro_F score: 0.710218\n",
      "Epoch: 00235 loss_train: 0.2604 acc_train: 0.9227 loss_val: 1.6585 acc_val: 0.7269 time: 0.0216s\n",
      "valid current auc-roc score: 0.913336, current macro_F score: 0.709071\n",
      "Epoch: 00236 loss_train: 0.2195 acc_train: 0.9192 loss_val: 1.3978 acc_val: 0.7122 time: 0.0211s\n",
      "valid current auc-roc score: 0.925748, current macro_F score: 0.699432\n",
      "Epoch: 00237 loss_train: 0.2147 acc_train: 0.9249 loss_val: 1.4078 acc_val: 0.6993 time: 0.0234s\n",
      "valid current auc-roc score: 0.922782, current macro_F score: 0.688552\n",
      "Epoch: 00238 loss_train: 0.2489 acc_train: 0.9099 loss_val: 1.6027 acc_val: 0.7066 time: 0.0221s\n",
      "valid current auc-roc score: 0.921687, current macro_F score: 0.698788\n",
      "Epoch: 00239 loss_train: 0.2408 acc_train: 0.9235 loss_val: 1.2833 acc_val: 0.7085 time: 0.0219s\n",
      "valid current auc-roc score: 0.931840, current macro_F score: 0.694408\n",
      "Epoch: 00240 loss_train: 0.2463 acc_train: 0.9206 loss_val: 1.6110 acc_val: 0.7011 time: 0.0247s\n",
      "valid current auc-roc score: 0.913497, current macro_F score: 0.682587\n",
      "Epoch: 00241 loss_train: 0.2455 acc_train: 0.9192 loss_val: 1.7634 acc_val: 0.6882 time: 0.0224s\n",
      "valid current auc-roc score: 0.912177, current macro_F score: 0.666421\n",
      "Test set results: loss= 1.4956 accuracy= 721.2066\n",
      "test current auc-roc score: 0.926538, current macro_F score: 0.714906\n",
      "Epoch: 00242 loss_train: 0.2038 acc_train: 0.9342 loss_val: 1.5135 acc_val: 0.7177 time: 0.0222s\n",
      "valid current auc-roc score: 0.919541, current macro_F score: 0.701111\n",
      "Epoch: 00243 loss_train: 0.1953 acc_train: 0.9371 loss_val: 1.7797 acc_val: 0.6900 time: 0.0259s\n",
      "valid current auc-roc score: 0.910839, current macro_F score: 0.667123\n",
      "Epoch: 00244 loss_train: 0.2247 acc_train: 0.9199 loss_val: 1.6302 acc_val: 0.7140 time: 0.0226s\n",
      "valid current auc-roc score: 0.920048, current macro_F score: 0.705567\n",
      "Epoch: 00245 loss_train: 0.2265 acc_train: 0.9213 loss_val: 1.4953 acc_val: 0.7103 time: 0.0225s\n",
      "valid current auc-roc score: 0.913804, current macro_F score: 0.689048\n",
      "Epoch: 00246 loss_train: 0.2604 acc_train: 0.9206 loss_val: 1.4915 acc_val: 0.7325 time: 0.0223s\n",
      "valid current auc-roc score: 0.923465, current macro_F score: 0.710615\n",
      "Epoch: 00247 loss_train: 0.2044 acc_train: 0.9299 loss_val: 1.6906 acc_val: 0.6937 time: 0.0226s\n",
      "valid current auc-roc score: 0.916730, current macro_F score: 0.677169\n",
      "Epoch: 00248 loss_train: 0.2152 acc_train: 0.9278 loss_val: 1.7642 acc_val: 0.7011 time: 0.0233s\n",
      "valid current auc-roc score: 0.917149, current macro_F score: 0.683894\n",
      "Epoch: 00249 loss_train: 0.1965 acc_train: 0.9349 loss_val: 1.5255 acc_val: 0.7011 time: 0.0254s\n",
      "valid current auc-roc score: 0.922310, current macro_F score: 0.680097\n",
      "Epoch: 00250 loss_train: 0.2326 acc_train: 0.9149 loss_val: 1.5841 acc_val: 0.7030 time: 0.0268s\n",
      "valid current auc-roc score: 0.917429, current macro_F score: 0.684279\n",
      "Epoch: 00251 loss_train: 0.2023 acc_train: 0.9256 loss_val: 1.6702 acc_val: 0.7103 time: 0.0225s\n",
      "valid current auc-roc score: 0.917788, current macro_F score: 0.688447\n",
      "Test set results: loss= 1.5864 accuracy= 724.1255\n",
      "test current auc-roc score: 0.923303, current macro_F score: 0.699507\n",
      "Epoch: 00252 loss_train: 0.2039 acc_train: 0.9292 loss_val: 1.7822 acc_val: 0.7122 time: 0.0213s\n",
      "valid current auc-roc score: 0.914542, current macro_F score: 0.687518\n",
      "Epoch: 00253 loss_train: 0.2151 acc_train: 0.9299 loss_val: 1.7472 acc_val: 0.6937 time: 0.0220s\n",
      "valid current auc-roc score: 0.907575, current macro_F score: 0.664703\n",
      "Epoch: 00254 loss_train: 0.1993 acc_train: 0.9292 loss_val: 1.7216 acc_val: 0.7343 time: 0.0211s\n",
      "valid current auc-roc score: 0.912728, current macro_F score: 0.711390\n",
      "Epoch: 00255 loss_train: 0.2142 acc_train: 0.9256 loss_val: 1.8713 acc_val: 0.7232 time: 0.0224s\n",
      "valid current auc-roc score: 0.910080, current macro_F score: 0.706790\n",
      "Epoch: 00256 loss_train: 0.2356 acc_train: 0.9213 loss_val: 1.5832 acc_val: 0.7214 time: 0.0220s\n",
      "valid current auc-roc score: 0.922294, current macro_F score: 0.698347\n",
      "Epoch: 00257 loss_train: 0.2347 acc_train: 0.9213 loss_val: 1.6993 acc_val: 0.7232 time: 0.0210s\n",
      "valid current auc-roc score: 0.921686, current macro_F score: 0.701556\n",
      "Epoch: 00258 loss_train: 0.2418 acc_train: 0.9149 loss_val: 1.8629 acc_val: 0.7066 time: 0.0223s\n",
      "valid current auc-roc score: 0.910047, current macro_F score: 0.679920\n",
      "Epoch: 00259 loss_train: 0.2059 acc_train: 0.9235 loss_val: 1.7267 acc_val: 0.7030 time: 0.0207s\n",
      "valid current auc-roc score: 0.914038, current macro_F score: 0.679568\n",
      "Epoch: 00260 loss_train: 0.2085 acc_train: 0.9328 loss_val: 1.6438 acc_val: 0.7269 time: 0.0225s\n",
      "valid current auc-roc score: 0.921282, current macro_F score: 0.700786\n",
      "Epoch: 00261 loss_train: 0.2022 acc_train: 0.9285 loss_val: 1.4805 acc_val: 0.7251 time: 0.0207s\n",
      "valid current auc-roc score: 0.927422, current macro_F score: 0.703457\n",
      "Test set results: loss= 1.5729 accuracy= 715.7565\n",
      "test current auc-roc score: 0.923343, current macro_F score: 0.713570\n",
      "Epoch: 00262 loss_train: 0.2123 acc_train: 0.9349 loss_val: 1.6818 acc_val: 0.6956 time: 0.0217s\n",
      "valid current auc-roc score: 0.914241, current macro_F score: 0.675227\n",
      "Epoch: 00263 loss_train: 0.2089 acc_train: 0.9299 loss_val: 1.8285 acc_val: 0.7343 time: 0.0214s\n",
      "valid current auc-roc score: 0.912518, current macro_F score: 0.707813\n",
      "Epoch: 00264 loss_train: 0.2561 acc_train: 0.9220 loss_val: 1.5460 acc_val: 0.7232 time: 0.0260s\n",
      "valid current auc-roc score: 0.928180, current macro_F score: 0.710311\n",
      "Epoch: 00265 loss_train: 0.2089 acc_train: 0.9342 loss_val: 1.7837 acc_val: 0.6993 time: 0.0217s\n",
      "valid current auc-roc score: 0.901473, current macro_F score: 0.670829\n",
      "Epoch: 00266 loss_train: 0.2334 acc_train: 0.9256 loss_val: 1.8868 acc_val: 0.6974 time: 0.0219s\n",
      "valid current auc-roc score: 0.910947, current macro_F score: 0.684123\n",
      "Epoch: 00267 loss_train: 0.2241 acc_train: 0.9220 loss_val: 1.6212 acc_val: 0.7122 time: 0.0252s\n",
      "valid current auc-roc score: 0.918240, current macro_F score: 0.698862\n",
      "Epoch: 00268 loss_train: 0.2173 acc_train: 0.9249 loss_val: 1.6735 acc_val: 0.7122 time: 0.0242s\n",
      "valid current auc-roc score: 0.908077, current macro_F score: 0.685219\n",
      "Epoch: 00269 loss_train: 0.2371 acc_train: 0.9299 loss_val: 1.9730 acc_val: 0.6974 time: 0.0208s\n",
      "valid current auc-roc score: 0.911003, current macro_F score: 0.682637\n",
      "Epoch: 00270 loss_train: 0.2231 acc_train: 0.9213 loss_val: 1.5775 acc_val: 0.7325 time: 0.0207s\n",
      "valid current auc-roc score: 0.918029, current macro_F score: 0.712747\n",
      "Epoch: 00271 loss_train: 0.2097 acc_train: 0.9292 loss_val: 1.6374 acc_val: 0.7140 time: 0.0266s\n",
      "valid current auc-roc score: 0.919812, current macro_F score: 0.703025\n",
      "Test set results: loss= 1.5538 accuracy= 719.8247\n",
      "test current auc-roc score: 0.922824, current macro_F score: 0.713735\n",
      "Epoch: 00272 loss_train: 0.2084 acc_train: 0.9421 loss_val: 1.5003 acc_val: 0.7159 time: 0.0206s\n",
      "valid current auc-roc score: 0.924848, current macro_F score: 0.688361\n",
      "Epoch: 00273 loss_train: 0.2061 acc_train: 0.9313 loss_val: 1.8865 acc_val: 0.7048 time: 0.0212s\n",
      "valid current auc-roc score: 0.903770, current macro_F score: 0.677786\n",
      "Epoch: 00274 loss_train: 0.1895 acc_train: 0.9428 loss_val: 2.1360 acc_val: 0.7122 time: 0.0232s\n",
      "valid current auc-roc score: 0.908224, current macro_F score: 0.685759\n",
      "Epoch: 00275 loss_train: 0.2140 acc_train: 0.9306 loss_val: 1.7237 acc_val: 0.7325 time: 0.0208s\n",
      "valid current auc-roc score: 0.918394, current macro_F score: 0.705946\n",
      "Epoch: 00276 loss_train: 0.2047 acc_train: 0.9285 loss_val: 1.8441 acc_val: 0.7122 time: 0.0185s\n",
      "valid current auc-roc score: 0.913537, current macro_F score: 0.687339\n",
      "Epoch: 00277 loss_train: 0.2176 acc_train: 0.9270 loss_val: 1.7244 acc_val: 0.7343 time: 0.0197s\n",
      "valid current auc-roc score: 0.917019, current macro_F score: 0.710130\n",
      "Epoch: 00278 loss_train: 0.2296 acc_train: 0.9185 loss_val: 1.8235 acc_val: 0.7048 time: 0.0210s\n",
      "valid current auc-roc score: 0.909275, current macro_F score: 0.684907\n",
      "Epoch: 00279 loss_train: 0.1947 acc_train: 0.9356 loss_val: 1.7257 acc_val: 0.7214 time: 0.0277s\n",
      "valid current auc-roc score: 0.915789, current macro_F score: 0.706018\n",
      "Epoch: 00280 loss_train: 0.2228 acc_train: 0.9299 loss_val: 1.7349 acc_val: 0.7214 time: 0.0294s\n",
      "valid current auc-roc score: 0.913689, current macro_F score: 0.705761\n",
      "Epoch: 00281 loss_train: 0.1943 acc_train: 0.9328 loss_val: 1.8974 acc_val: 0.7066 time: 0.0267s\n",
      "valid current auc-roc score: 0.909614, current macro_F score: 0.683616\n",
      "Test set results: loss= 1.5218 accuracy= 726.5277\n",
      "test current auc-roc score: 0.925384, current macro_F score: 0.708226\n",
      "Epoch: 00282 loss_train: 0.1956 acc_train: 0.9378 loss_val: 1.8421 acc_val: 0.6974 time: 0.0188s\n",
      "valid current auc-roc score: 0.907330, current macro_F score: 0.669000\n",
      "Epoch: 00283 loss_train: 0.2437 acc_train: 0.9163 loss_val: 1.4341 acc_val: 0.7140 time: 0.0237s\n",
      "valid current auc-roc score: 0.920140, current macro_F score: 0.686772\n",
      "Epoch: 00284 loss_train: 0.1853 acc_train: 0.9371 loss_val: 1.6620 acc_val: 0.7140 time: 0.0216s\n",
      "valid current auc-roc score: 0.922116, current macro_F score: 0.696201\n",
      "Epoch: 00285 loss_train: 0.1998 acc_train: 0.9270 loss_val: 1.6024 acc_val: 0.7177 time: 0.0219s\n",
      "valid current auc-roc score: 0.926592, current macro_F score: 0.712328\n",
      "Epoch: 00286 loss_train: 0.2140 acc_train: 0.9313 loss_val: 1.9019 acc_val: 0.6993 time: 0.0209s\n",
      "valid current auc-roc score: 0.901594, current macro_F score: 0.668923\n",
      "Epoch: 00287 loss_train: 0.2129 acc_train: 0.9342 loss_val: 1.7081 acc_val: 0.7103 time: 0.0223s\n",
      "valid current auc-roc score: 0.918368, current macro_F score: 0.685570\n",
      "Epoch: 00288 loss_train: 0.1937 acc_train: 0.9378 loss_val: 1.6124 acc_val: 0.7140 time: 0.0307s\n",
      "valid current auc-roc score: 0.923057, current macro_F score: 0.699238\n",
      "Epoch: 00289 loss_train: 0.2112 acc_train: 0.9278 loss_val: 1.7053 acc_val: 0.7122 time: 0.0242s\n",
      "valid current auc-roc score: 0.918192, current macro_F score: 0.698718\n",
      "Epoch: 00290 loss_train: 0.2105 acc_train: 0.9363 loss_val: 1.7398 acc_val: 0.7251 time: 0.0213s\n",
      "valid current auc-roc score: 0.917649, current macro_F score: 0.706826\n",
      "Epoch: 00291 loss_train: 0.1844 acc_train: 0.9363 loss_val: 1.7100 acc_val: 0.7214 time: 0.0200s\n",
      "valid current auc-roc score: 0.920937, current macro_F score: 0.701717\n",
      "Test set results: loss= 1.7721 accuracy= 725.5720\n",
      "test current auc-roc score: 0.920219, current macro_F score: 0.701668\n",
      "Epoch: 00292 loss_train: 0.2134 acc_train: 0.9399 loss_val: 1.8339 acc_val: 0.7325 time: 0.0195s\n",
      "valid current auc-roc score: 0.923261, current macro_F score: 0.712394\n",
      "Epoch: 00293 loss_train: 0.1937 acc_train: 0.9335 loss_val: 1.8667 acc_val: 0.7232 time: 0.0182s\n",
      "valid current auc-roc score: 0.923090, current macro_F score: 0.702433\n",
      "Epoch: 00294 loss_train: 0.2146 acc_train: 0.9220 loss_val: 1.6873 acc_val: 0.7140 time: 0.0198s\n",
      "valid current auc-roc score: 0.918056, current macro_F score: 0.688612\n",
      "Epoch: 00295 loss_train: 0.2210 acc_train: 0.9199 loss_val: 1.8352 acc_val: 0.7196 time: 0.0261s\n",
      "valid current auc-roc score: 0.917210, current macro_F score: 0.701924\n",
      "Epoch: 00296 loss_train: 0.2189 acc_train: 0.9342 loss_val: 1.8402 acc_val: 0.7140 time: 0.0247s\n",
      "valid current auc-roc score: 0.923865, current macro_F score: 0.686622\n",
      "Epoch: 00297 loss_train: 0.1894 acc_train: 0.9356 loss_val: 1.7715 acc_val: 0.6956 time: 0.0285s\n",
      "valid current auc-roc score: 0.911677, current macro_F score: 0.673847\n",
      "Epoch: 00298 loss_train: 0.2107 acc_train: 0.9256 loss_val: 1.6284 acc_val: 0.7196 time: 0.0259s\n",
      "valid current auc-roc score: 0.914027, current macro_F score: 0.700963\n",
      "Epoch: 00299 loss_train: 0.2286 acc_train: 0.9299 loss_val: 1.8789 acc_val: 0.7066 time: 0.0209s\n",
      "valid current auc-roc score: 0.913331, current macro_F score: 0.676226\n",
      "Epoch: 00300 loss_train: 0.1933 acc_train: 0.9349 loss_val: 1.6220 acc_val: 0.7325 time: 0.0234s\n",
      "valid current auc-roc score: 0.920706, current macro_F score: 0.702496\n",
      "Epoch: 00301 loss_train: 0.2426 acc_train: 0.9199 loss_val: 1.8551 acc_val: 0.7066 time: 0.0305s\n",
      "valid current auc-roc score: 0.911287, current macro_F score: 0.689713\n",
      "Test set results: loss= 1.8332 accuracy= 738.3579\n",
      "test current auc-roc score: 0.915130, current macro_F score: 0.688212\n",
      "Epoch: 00302 loss_train: 0.2031 acc_train: 0.9192 loss_val: 2.0931 acc_val: 0.7214 time: 0.0231s\n",
      "valid current auc-roc score: 0.910360, current macro_F score: 0.692442\n",
      "Epoch: 00303 loss_train: 0.2010 acc_train: 0.9263 loss_val: 1.9154 acc_val: 0.7085 time: 0.0216s\n",
      "valid current auc-roc score: 0.909451, current macro_F score: 0.688228\n",
      "Epoch: 00304 loss_train: 0.2270 acc_train: 0.9249 loss_val: 1.7185 acc_val: 0.7048 time: 0.0203s\n",
      "valid current auc-roc score: 0.915219, current macro_F score: 0.678120\n",
      "Epoch: 00305 loss_train: 0.2187 acc_train: 0.9299 loss_val: 1.7858 acc_val: 0.6993 time: 0.0199s\n",
      "valid current auc-roc score: 0.914785, current macro_F score: 0.677717\n",
      "Epoch: 00306 loss_train: 0.2323 acc_train: 0.9242 loss_val: 1.8570 acc_val: 0.7103 time: 0.0180s\n",
      "valid current auc-roc score: 0.915145, current macro_F score: 0.676169\n",
      "Epoch: 00307 loss_train: 0.2141 acc_train: 0.9270 loss_val: 1.4852 acc_val: 0.6956 time: 0.0201s\n",
      "valid current auc-roc score: 0.928723, current macro_F score: 0.675508\n",
      "Epoch: 00308 loss_train: 0.2047 acc_train: 0.9328 loss_val: 1.9859 acc_val: 0.7066 time: 0.0254s\n",
      "valid current auc-roc score: 0.920574, current macro_F score: 0.673008\n",
      "Epoch: 00309 loss_train: 0.1929 acc_train: 0.9320 loss_val: 1.7606 acc_val: 0.7232 time: 0.0225s\n",
      "valid current auc-roc score: 0.915934, current macro_F score: 0.697847\n",
      "Epoch: 00310 loss_train: 0.1909 acc_train: 0.9320 loss_val: 1.6455 acc_val: 0.7380 time: 0.0197s\n",
      "valid current auc-roc score: 0.928728, current macro_F score: 0.718258\n",
      "Epoch: 00311 loss_train: 0.2093 acc_train: 0.9335 loss_val: 1.8059 acc_val: 0.7269 time: 0.0323s\n",
      "valid current auc-roc score: 0.911834, current macro_F score: 0.703308\n",
      "Test set results: loss= 1.7684 accuracy= 741.8063\n",
      "test current auc-roc score: 0.917258, current macro_F score: 0.702224\n",
      "Epoch: 00312 loss_train: 0.2138 acc_train: 0.9235 loss_val: 2.0539 acc_val: 0.7232 time: 0.0206s\n",
      "valid current auc-roc score: 0.916575, current macro_F score: 0.697857\n",
      "Epoch: 00313 loss_train: 0.2298 acc_train: 0.9199 loss_val: 1.8244 acc_val: 0.7177 time: 0.0217s\n",
      "valid current auc-roc score: 0.915871, current macro_F score: 0.689124\n",
      "Epoch: 00314 loss_train: 0.2140 acc_train: 0.9306 loss_val: 1.7063 acc_val: 0.7214 time: 0.0272s\n",
      "valid current auc-roc score: 0.922093, current macro_F score: 0.703887\n",
      "Epoch: 00315 loss_train: 0.2053 acc_train: 0.9335 loss_val: 1.6025 acc_val: 0.7232 time: 0.0207s\n",
      "valid current auc-roc score: 0.926640, current macro_F score: 0.699044\n",
      "Epoch: 00316 loss_train: 0.1898 acc_train: 0.9371 loss_val: 1.6340 acc_val: 0.6900 time: 0.0185s\n",
      "valid current auc-roc score: 0.914055, current macro_F score: 0.661364\n",
      "Epoch: 00317 loss_train: 0.2227 acc_train: 0.9278 loss_val: 1.7378 acc_val: 0.7159 time: 0.0191s\n",
      "valid current auc-roc score: 0.919132, current macro_F score: 0.697008\n",
      "Epoch: 00318 loss_train: 0.2191 acc_train: 0.9192 loss_val: 1.4982 acc_val: 0.6993 time: 0.0221s\n",
      "valid current auc-roc score: 0.913579, current macro_F score: 0.673003\n",
      "Epoch: 00319 loss_train: 0.2352 acc_train: 0.9177 loss_val: 1.8914 acc_val: 0.7030 time: 0.0219s\n",
      "valid current auc-roc score: 0.911368, current macro_F score: 0.684606\n",
      "Epoch: 00320 loss_train: 0.1816 acc_train: 0.9413 loss_val: 1.4515 acc_val: 0.7288 time: 0.0227s\n",
      "valid current auc-roc score: 0.924978, current macro_F score: 0.705197\n",
      "Epoch: 00321 loss_train: 0.2338 acc_train: 0.9199 loss_val: 1.8138 acc_val: 0.6974 time: 0.0256s\n",
      "valid current auc-roc score: 0.905526, current macro_F score: 0.675926\n",
      "Test set results: loss= 1.7901 accuracy= 747.9022\n",
      "test current auc-roc score: 0.915099, current macro_F score: 0.710887\n",
      "Epoch: 00322 loss_train: 0.2077 acc_train: 0.9285 loss_val: 2.1358 acc_val: 0.6863 time: 0.0202s\n",
      "valid current auc-roc score: 0.904672, current macro_F score: 0.667893\n",
      "Epoch: 00323 loss_train: 0.2042 acc_train: 0.9299 loss_val: 1.9776 acc_val: 0.7159 time: 0.0193s\n",
      "valid current auc-roc score: 0.914895, current macro_F score: 0.699430\n",
      "Epoch: 00324 loss_train: 0.1909 acc_train: 0.9306 loss_val: 1.5440 acc_val: 0.7103 time: 0.0176s\n",
      "valid current auc-roc score: 0.919408, current macro_F score: 0.685046\n",
      "Epoch: 00325 loss_train: 0.1973 acc_train: 0.9306 loss_val: 1.6581 acc_val: 0.7030 time: 0.0186s\n",
      "valid current auc-roc score: 0.912027, current macro_F score: 0.668968\n",
      "Epoch: 00326 loss_train: 0.2311 acc_train: 0.9235 loss_val: 1.6884 acc_val: 0.6993 time: 0.0204s\n",
      "valid current auc-roc score: 0.909063, current macro_F score: 0.670291\n",
      "Epoch: 00327 loss_train: 0.2109 acc_train: 0.9270 loss_val: 1.6137 acc_val: 0.7030 time: 0.0196s\n",
      "valid current auc-roc score: 0.915329, current macro_F score: 0.681497\n",
      "Epoch: 00328 loss_train: 0.2102 acc_train: 0.9306 loss_val: 1.7764 acc_val: 0.7269 time: 0.0213s\n",
      "valid current auc-roc score: 0.913919, current macro_F score: 0.707233\n",
      "Epoch: 00329 loss_train: 0.2011 acc_train: 0.9335 loss_val: 1.6262 acc_val: 0.7214 time: 0.0203s\n",
      "valid current auc-roc score: 0.914882, current macro_F score: 0.699286\n",
      "Epoch: 00330 loss_train: 0.3531 acc_train: 0.9263 loss_val: 1.6770 acc_val: 0.7140 time: 0.0235s\n",
      "valid current auc-roc score: 0.920522, current macro_F score: 0.690885\n",
      "Epoch: 00331 loss_train: 0.2055 acc_train: 0.9285 loss_val: 1.6435 acc_val: 0.7196 time: 0.0220s\n",
      "valid current auc-roc score: 0.919673, current macro_F score: 0.695595\n",
      "Test set results: loss= 1.6185 accuracy= 708.3173\n",
      "test current auc-roc score: 0.923305, current macro_F score: 0.717161\n",
      "Epoch: 00332 loss_train: 0.2525 acc_train: 0.9192 loss_val: 1.7900 acc_val: 0.6845 time: 0.0176s\n",
      "valid current auc-roc score: 0.912507, current macro_F score: 0.666664\n",
      "Epoch: 00333 loss_train: 0.2410 acc_train: 0.9120 loss_val: 1.6806 acc_val: 0.6974 time: 0.0186s\n",
      "valid current auc-roc score: 0.915538, current macro_F score: 0.675181\n",
      "Epoch: 00334 loss_train: 0.2232 acc_train: 0.9227 loss_val: 1.6617 acc_val: 0.7048 time: 0.0237s\n",
      "valid current auc-roc score: 0.924222, current macro_F score: 0.681935\n",
      "Epoch: 00335 loss_train: 0.2039 acc_train: 0.9285 loss_val: 1.6589 acc_val: 0.7030 time: 0.0235s\n",
      "valid current auc-roc score: 0.915791, current macro_F score: 0.682586\n",
      "Epoch: 00336 loss_train: 0.2004 acc_train: 0.9292 loss_val: 1.7301 acc_val: 0.7103 time: 0.0245s\n",
      "valid current auc-roc score: 0.916670, current macro_F score: 0.692453\n",
      "Epoch: 00337 loss_train: 0.2203 acc_train: 0.9249 loss_val: 1.9508 acc_val: 0.7140 time: 0.0332s\n",
      "valid current auc-roc score: 0.906355, current macro_F score: 0.695382\n",
      "Epoch: 00338 loss_train: 0.2353 acc_train: 0.9192 loss_val: 1.7636 acc_val: 0.7066 time: 0.0221s\n",
      "valid current auc-roc score: 0.907579, current macro_F score: 0.677140\n",
      "Epoch: 00339 loss_train: 0.2075 acc_train: 0.9263 loss_val: 1.7407 acc_val: 0.7122 time: 0.0199s\n",
      "valid current auc-roc score: 0.907461, current macro_F score: 0.690272\n",
      "Epoch: 00340 loss_train: 0.2097 acc_train: 0.9299 loss_val: 1.6387 acc_val: 0.7085 time: 0.0227s\n",
      "valid current auc-roc score: 0.912778, current macro_F score: 0.685973\n",
      "Epoch: 00341 loss_train: 0.2044 acc_train: 0.9378 loss_val: 1.6824 acc_val: 0.7269 time: 0.0219s\n",
      "valid current auc-roc score: 0.916742, current macro_F score: 0.700274\n",
      "Test set results: loss= 1.6399 accuracy= 728.1033\n",
      "test current auc-roc score: 0.918283, current macro_F score: 0.706848\n",
      "Epoch: 00342 loss_train: 0.2076 acc_train: 0.9421 loss_val: 1.5710 acc_val: 0.7214 time: 0.0179s\n",
      "valid current auc-roc score: 0.913850, current macro_F score: 0.699976\n",
      "Epoch: 00343 loss_train: 0.1960 acc_train: 0.9328 loss_val: 1.5276 acc_val: 0.7159 time: 0.0192s\n",
      "valid current auc-roc score: 0.922972, current macro_F score: 0.691689\n",
      "Epoch: 00344 loss_train: 0.2103 acc_train: 0.9292 loss_val: 1.5280 acc_val: 0.7269 time: 0.0254s\n",
      "valid current auc-roc score: 0.924560, current macro_F score: 0.707462\n",
      "Epoch: 00345 loss_train: 0.2349 acc_train: 0.9156 loss_val: 1.6760 acc_val: 0.6993 time: 0.0215s\n",
      "valid current auc-roc score: 0.916804, current macro_F score: 0.677131\n",
      "Epoch: 00346 loss_train: 0.2480 acc_train: 0.9142 loss_val: 1.5642 acc_val: 0.7232 time: 0.0208s\n",
      "valid current auc-roc score: 0.917726, current macro_F score: 0.698076\n",
      "Epoch: 00347 loss_train: 0.2115 acc_train: 0.9285 loss_val: 1.7328 acc_val: 0.7103 time: 0.0212s\n",
      "valid current auc-roc score: 0.924640, current macro_F score: 0.681393\n",
      "Epoch: 00348 loss_train: 0.1870 acc_train: 0.9371 loss_val: 1.4721 acc_val: 0.7232 time: 0.0265s\n",
      "valid current auc-roc score: 0.928778, current macro_F score: 0.716306\n",
      "Epoch: 00349 loss_train: 0.2462 acc_train: 0.9113 loss_val: 1.6419 acc_val: 0.7122 time: 0.0205s\n",
      "valid current auc-roc score: 0.919908, current macro_F score: 0.680645\n",
      "Epoch: 00350 loss_train: 0.2196 acc_train: 0.9256 loss_val: 1.7963 acc_val: 0.7066 time: 0.0221s\n",
      "valid current auc-roc score: 0.918705, current macro_F score: 0.679553\n",
      "Epoch: 00351 loss_train: 0.2094 acc_train: 0.9320 loss_val: 1.7278 acc_val: 0.7380 time: 0.0223s\n",
      "valid current auc-roc score: 0.917158, current macro_F score: 0.717710\n",
      "Test set results: loss= 1.7768 accuracy= 750.6790\n",
      "test current auc-roc score: 0.915810, current macro_F score: 0.693490\n",
      "Epoch: 00352 loss_train: 0.2390 acc_train: 0.9185 loss_val: 1.6788 acc_val: 0.7251 time: 0.0194s\n",
      "valid current auc-roc score: 0.920311, current macro_F score: 0.709437\n",
      "Epoch: 00353 loss_train: 0.2165 acc_train: 0.9192 loss_val: 1.6777 acc_val: 0.7288 time: 0.0200s\n",
      "valid current auc-roc score: 0.918450, current macro_F score: 0.705511\n",
      "Epoch: 00354 loss_train: 0.2214 acc_train: 0.9242 loss_val: 1.5071 acc_val: 0.7269 time: 0.0191s\n",
      "valid current auc-roc score: 0.925665, current macro_F score: 0.706209\n",
      "Epoch: 00355 loss_train: 0.2213 acc_train: 0.9213 loss_val: 1.5214 acc_val: 0.7159 time: 0.0271s\n",
      "valid current auc-roc score: 0.921715, current macro_F score: 0.696809\n",
      "Epoch: 00356 loss_train: 0.2391 acc_train: 0.9170 loss_val: 1.5161 acc_val: 0.7325 time: 0.0271s\n",
      "valid current auc-roc score: 0.927229, current macro_F score: 0.702562\n",
      "Epoch: 00357 loss_train: 0.1960 acc_train: 0.9363 loss_val: 1.5547 acc_val: 0.7011 time: 0.0180s\n",
      "valid current auc-roc score: 0.921601, current macro_F score: 0.680451\n",
      "Epoch: 00358 loss_train: 0.2131 acc_train: 0.9270 loss_val: 1.6533 acc_val: 0.7159 time: 0.0192s\n",
      "valid current auc-roc score: 0.919017, current macro_F score: 0.688527\n",
      "Epoch: 00359 loss_train: 0.2346 acc_train: 0.9242 loss_val: 1.4793 acc_val: 0.7362 time: 0.0214s\n",
      "valid current auc-roc score: 0.932725, current macro_F score: 0.727952\n",
      "Epoch: 00360 loss_train: 0.2651 acc_train: 0.9270 loss_val: 1.4902 acc_val: 0.7362 time: 0.0210s\n",
      "valid current auc-roc score: 0.926362, current macro_F score: 0.717889\n",
      "Epoch: 00361 loss_train: 0.2307 acc_train: 0.9220 loss_val: 1.4549 acc_val: 0.7343 time: 0.0275s\n",
      "valid current auc-roc score: 0.925340, current macro_F score: 0.710318\n",
      "Test set results: loss= 1.5284 accuracy= 729.5111\n",
      "test current auc-roc score: 0.923387, current macro_F score: 0.716667\n",
      "Epoch: 00362 loss_train: 0.2065 acc_train: 0.9320 loss_val: 1.5040 acc_val: 0.7362 time: 0.0235s\n",
      "valid current auc-roc score: 0.930671, current macro_F score: 0.714571\n",
      "Epoch: 00363 loss_train: 0.2143 acc_train: 0.9220 loss_val: 1.2728 acc_val: 0.7214 time: 0.0217s\n",
      "valid current auc-roc score: 0.924612, current macro_F score: 0.696668\n",
      "Epoch: 00364 loss_train: 0.2186 acc_train: 0.9213 loss_val: 1.4627 acc_val: 0.7509 time: 0.0232s\n",
      "valid current auc-roc score: 0.932013, current macro_F score: 0.724162\n",
      "Epoch: 00365 loss_train: 0.2002 acc_train: 0.9335 loss_val: 1.3082 acc_val: 0.7122 time: 0.0239s\n",
      "valid current auc-roc score: 0.931837, current macro_F score: 0.682215\n",
      "Epoch: 00366 loss_train: 0.2220 acc_train: 0.9199 loss_val: 1.5156 acc_val: 0.7085 time: 0.0191s\n",
      "valid current auc-roc score: 0.915965, current macro_F score: 0.676225\n",
      "Epoch: 00367 loss_train: 0.2252 acc_train: 0.9235 loss_val: 1.4980 acc_val: 0.7103 time: 0.0190s\n",
      "valid current auc-roc score: 0.925410, current macro_F score: 0.691868\n",
      "Epoch: 00368 loss_train: 0.2095 acc_train: 0.9285 loss_val: 1.4522 acc_val: 0.7343 time: 0.0228s\n",
      "valid current auc-roc score: 0.927730, current macro_F score: 0.715407\n",
      "Epoch: 00369 loss_train: 0.2092 acc_train: 0.9285 loss_val: 1.7392 acc_val: 0.7362 time: 0.0278s\n",
      "valid current auc-roc score: 0.916648, current macro_F score: 0.718938\n",
      "Epoch: 00370 loss_train: 0.2234 acc_train: 0.9242 loss_val: 1.6150 acc_val: 0.7343 time: 0.0233s\n",
      "valid current auc-roc score: 0.918773, current macro_F score: 0.707602\n",
      "Epoch: 00371 loss_train: 0.2244 acc_train: 0.9278 loss_val: 1.8172 acc_val: 0.7232 time: 0.0250s\n",
      "valid current auc-roc score: 0.917080, current macro_F score: 0.703505\n",
      "Test set results: loss= 1.8072 accuracy= 743.4723\n",
      "test current auc-roc score: 0.920055, current macro_F score: 0.708636\n",
      "Epoch: 00372 loss_train: 0.2153 acc_train: 0.9263 loss_val: 1.9326 acc_val: 0.7306 time: 0.0214s\n",
      "valid current auc-roc score: 0.917507, current macro_F score: 0.699576\n",
      "Epoch: 00373 loss_train: 0.2105 acc_train: 0.9306 loss_val: 1.8885 acc_val: 0.7343 time: 0.0240s\n",
      "valid current auc-roc score: 0.920068, current macro_F score: 0.706168\n",
      "Epoch: 00374 loss_train: 0.2093 acc_train: 0.9220 loss_val: 1.4968 acc_val: 0.7269 time: 0.0243s\n",
      "valid current auc-roc score: 0.923502, current macro_F score: 0.703373\n",
      "Epoch: 00375 loss_train: 0.1932 acc_train: 0.9399 loss_val: 1.8358 acc_val: 0.7362 time: 0.0211s\n",
      "valid current auc-roc score: 0.924328, current macro_F score: 0.723567\n",
      "Epoch: 00376 loss_train: 0.2123 acc_train: 0.9256 loss_val: 1.6433 acc_val: 0.7177 time: 0.0210s\n",
      "valid current auc-roc score: 0.928560, current macro_F score: 0.697984\n",
      "Epoch: 00377 loss_train: 0.2066 acc_train: 0.9256 loss_val: 1.6282 acc_val: 0.7159 time: 0.0277s\n",
      "valid current auc-roc score: 0.925605, current macro_F score: 0.695622\n",
      "Epoch: 00378 loss_train: 0.2074 acc_train: 0.9292 loss_val: 1.8007 acc_val: 0.7269 time: 0.0226s\n",
      "valid current auc-roc score: 0.919015, current macro_F score: 0.703247\n",
      "Epoch: 00379 loss_train: 0.2050 acc_train: 0.9335 loss_val: 1.4942 acc_val: 0.7306 time: 0.0219s\n",
      "valid current auc-roc score: 0.925427, current macro_F score: 0.709026\n",
      "Epoch: 00380 loss_train: 0.1970 acc_train: 0.9371 loss_val: 1.4112 acc_val: 0.7417 time: 0.0223s\n",
      "valid current auc-roc score: 0.930543, current macro_F score: 0.723377\n",
      "Epoch: 00381 loss_train: 0.2385 acc_train: 0.9192 loss_val: 1.5051 acc_val: 0.7122 time: 0.0219s\n",
      "valid current auc-roc score: 0.926486, current macro_F score: 0.700266\n",
      "Test set results: loss= 1.5970 accuracy= 736.1365\n",
      "test current auc-roc score: 0.923635, current macro_F score: 0.704941\n",
      "Epoch: 00382 loss_train: 0.2204 acc_train: 0.9206 loss_val: 1.5035 acc_val: 0.7269 time: 0.0205s\n",
      "valid current auc-roc score: 0.924776, current macro_F score: 0.714165\n",
      "Epoch: 00383 loss_train: 0.2172 acc_train: 0.9242 loss_val: 1.4934 acc_val: 0.7214 time: 0.0216s\n",
      "valid current auc-roc score: 0.923387, current macro_F score: 0.696889\n",
      "Epoch: 00384 loss_train: 0.2336 acc_train: 0.9235 loss_val: 1.4119 acc_val: 0.7214 time: 0.0226s\n",
      "valid current auc-roc score: 0.926977, current macro_F score: 0.702862\n",
      "Epoch: 00385 loss_train: 0.2319 acc_train: 0.9177 loss_val: 1.6600 acc_val: 0.7066 time: 0.0264s\n",
      "valid current auc-roc score: 0.919204, current macro_F score: 0.685086\n",
      "Epoch: 00386 loss_train: 0.2186 acc_train: 0.9270 loss_val: 1.6496 acc_val: 0.7048 time: 0.0269s\n",
      "valid current auc-roc score: 0.914991, current macro_F score: 0.683615\n",
      "Epoch: 00387 loss_train: 0.2404 acc_train: 0.9278 loss_val: 1.6212 acc_val: 0.7232 time: 0.0211s\n",
      "valid current auc-roc score: 0.923076, current macro_F score: 0.700174\n",
      "Epoch: 00388 loss_train: 0.2235 acc_train: 0.9263 loss_val: 1.5451 acc_val: 0.6993 time: 0.0179s\n",
      "valid current auc-roc score: 0.918572, current macro_F score: 0.678102\n",
      "Epoch: 00389 loss_train: 0.2269 acc_train: 0.9185 loss_val: 1.4395 acc_val: 0.7269 time: 0.0180s\n",
      "valid current auc-roc score: 0.923999, current macro_F score: 0.712105\n",
      "Epoch: 00390 loss_train: 0.2414 acc_train: 0.9127 loss_val: 1.5972 acc_val: 0.6863 time: 0.0190s\n",
      "valid current auc-roc score: 0.914145, current macro_F score: 0.664059\n",
      "Epoch: 00391 loss_train: 0.2145 acc_train: 0.9227 loss_val: 1.6643 acc_val: 0.7159 time: 0.0220s\n",
      "valid current auc-roc score: 0.919231, current macro_F score: 0.692050\n",
      "Test set results: loss= 1.7379 accuracy= 731.9649\n",
      "test current auc-roc score: 0.920035, current macro_F score: 0.704117\n",
      "Epoch: 00392 loss_train: 0.2720 acc_train: 0.9099 loss_val: 1.7640 acc_val: 0.7103 time: 0.0227s\n",
      "valid current auc-roc score: 0.918141, current macro_F score: 0.695057\n",
      "Epoch: 00393 loss_train: 0.1905 acc_train: 0.9378 loss_val: 1.7219 acc_val: 0.7251 time: 0.0237s\n",
      "valid current auc-roc score: 0.923619, current macro_F score: 0.711858\n",
      "Epoch: 00394 loss_train: 0.2364 acc_train: 0.9263 loss_val: 1.6949 acc_val: 0.7177 time: 0.0219s\n",
      "valid current auc-roc score: 0.919004, current macro_F score: 0.693795\n",
      "Epoch: 00395 loss_train: 0.2307 acc_train: 0.9213 loss_val: 1.7498 acc_val: 0.7103 time: 0.0214s\n",
      "valid current auc-roc score: 0.921102, current macro_F score: 0.680437\n",
      "Epoch: 00396 loss_train: 0.2390 acc_train: 0.9270 loss_val: 1.7699 acc_val: 0.7140 time: 0.0245s\n",
      "valid current auc-roc score: 0.918529, current macro_F score: 0.690870\n",
      "Epoch: 00397 loss_train: 0.2044 acc_train: 0.9342 loss_val: 1.6715 acc_val: 0.7085 time: 0.0209s\n",
      "valid current auc-roc score: 0.923041, current macro_F score: 0.687430\n",
      "Epoch: 00398 loss_train: 0.2147 acc_train: 0.9299 loss_val: 1.9045 acc_val: 0.7177 time: 0.0199s\n",
      "valid current auc-roc score: 0.917518, current macro_F score: 0.698852\n",
      "Epoch: 00399 loss_train: 0.2046 acc_train: 0.9328 loss_val: 1.7337 acc_val: 0.7343 time: 0.0218s\n",
      "valid current auc-roc score: 0.919463, current macro_F score: 0.714304\n",
      "Epoch: 00400 loss_train: 0.2585 acc_train: 0.9127 loss_val: 1.5533 acc_val: 0.7140 time: 0.0203s\n",
      "valid current auc-roc score: 0.922059, current macro_F score: 0.691665\n",
      "Epoch: 00401 loss_train: 0.2197 acc_train: 0.9199 loss_val: 1.7527 acc_val: 0.7232 time: 0.0218s\n",
      "valid current auc-roc score: 0.916514, current macro_F score: 0.713813\n",
      "Test set results: loss= 1.7405 accuracy= 742.9945\n",
      "test current auc-roc score: 0.920584, current macro_F score: 0.707455\n",
      "Epoch: 00402 loss_train: 0.2573 acc_train: 0.9170 loss_val: 1.7156 acc_val: 0.7011 time: 0.0211s\n",
      "valid current auc-roc score: 0.913608, current macro_F score: 0.683923\n",
      "Epoch: 00403 loss_train: 0.2010 acc_train: 0.9313 loss_val: 1.6134 acc_val: 0.7122 time: 0.0241s\n",
      "valid current auc-roc score: 0.918557, current macro_F score: 0.692920\n",
      "Epoch: 00404 loss_train: 0.2212 acc_train: 0.9213 loss_val: 1.4333 acc_val: 0.7435 time: 0.0266s\n",
      "valid current auc-roc score: 0.933040, current macro_F score: 0.721021\n",
      "Epoch: 00405 loss_train: 0.2844 acc_train: 0.9106 loss_val: 1.5141 acc_val: 0.7159 time: 0.0209s\n",
      "valid current auc-roc score: 0.922983, current macro_F score: 0.693664\n",
      "Epoch: 00406 loss_train: 0.2278 acc_train: 0.9235 loss_val: 1.7921 acc_val: 0.7325 time: 0.0214s\n",
      "valid current auc-roc score: 0.916379, current macro_F score: 0.711678\n",
      "Epoch: 00407 loss_train: 0.2064 acc_train: 0.9306 loss_val: 1.5651 acc_val: 0.7435 time: 0.0212s\n",
      "valid current auc-roc score: 0.921342, current macro_F score: 0.717117\n",
      "Epoch: 00408 loss_train: 0.2034 acc_train: 0.9342 loss_val: 1.7613 acc_val: 0.7177 time: 0.0267s\n",
      "valid current auc-roc score: 0.920183, current macro_F score: 0.710590\n",
      "Epoch: 00409 loss_train: 0.2337 acc_train: 0.9199 loss_val: 1.6935 acc_val: 0.6956 time: 0.0210s\n",
      "valid current auc-roc score: 0.915474, current macro_F score: 0.657524\n",
      "Epoch: 00410 loss_train: 0.2452 acc_train: 0.9163 loss_val: 1.7362 acc_val: 0.7196 time: 0.0253s\n",
      "valid current auc-roc score: 0.915174, current macro_F score: 0.694096\n",
      "Epoch: 00411 loss_train: 0.2100 acc_train: 0.9199 loss_val: 1.8680 acc_val: 0.7122 time: 0.0197s\n",
      "valid current auc-roc score: 0.921351, current macro_F score: 0.687040\n",
      "Test set results: loss= 1.7397 accuracy= 741.0830\n",
      "test current auc-roc score: 0.921095, current macro_F score: 0.710544\n",
      "Epoch: 00412 loss_train: 0.2013 acc_train: 0.9371 loss_val: 1.8539 acc_val: 0.7159 time: 0.0230s\n",
      "valid current auc-roc score: 0.918971, current macro_F score: 0.686938\n",
      "Epoch: 00413 loss_train: 0.2153 acc_train: 0.9292 loss_val: 1.7689 acc_val: 0.7196 time: 0.0227s\n",
      "valid current auc-roc score: 0.920914, current macro_F score: 0.703611\n",
      "Epoch: 00414 loss_train: 0.2088 acc_train: 0.9285 loss_val: 1.6626 acc_val: 0.7048 time: 0.0213s\n",
      "valid current auc-roc score: 0.917616, current macro_F score: 0.672388\n",
      "Epoch: 00415 loss_train: 0.2202 acc_train: 0.9285 loss_val: 1.6818 acc_val: 0.7325 time: 0.0265s\n",
      "valid current auc-roc score: 0.920732, current macro_F score: 0.702714\n",
      "Epoch: 00416 loss_train: 0.2260 acc_train: 0.9292 loss_val: 1.5205 acc_val: 0.7159 time: 0.0226s\n",
      "valid current auc-roc score: 0.915845, current macro_F score: 0.689638\n",
      "Epoch: 00417 loss_train: 0.2346 acc_train: 0.9185 loss_val: 1.8516 acc_val: 0.7159 time: 0.0207s\n",
      "valid current auc-roc score: 0.917498, current macro_F score: 0.695767\n",
      "Epoch: 00418 loss_train: 0.2563 acc_train: 0.9113 loss_val: 1.6107 acc_val: 0.7103 time: 0.0195s\n",
      "valid current auc-roc score: 0.912448, current macro_F score: 0.688952\n",
      "Epoch: 00419 loss_train: 0.2024 acc_train: 0.9235 loss_val: 1.8021 acc_val: 0.7196 time: 0.0208s\n",
      "valid current auc-roc score: 0.904686, current macro_F score: 0.699729\n",
      "Epoch: 00420 loss_train: 0.1987 acc_train: 0.9292 loss_val: 1.5351 acc_val: 0.7288 time: 0.0334s\n",
      "valid current auc-roc score: 0.916992, current macro_F score: 0.701443\n",
      "Epoch: 00421 loss_train: 0.1971 acc_train: 0.9363 loss_val: 1.6003 acc_val: 0.7362 time: 0.0205s\n",
      "valid current auc-roc score: 0.921542, current macro_F score: 0.724277\n",
      "Test set results: loss= 1.5785 accuracy= 734.6513\n",
      "test current auc-roc score: 0.925627, current macro_F score: 0.704893\n",
      "Epoch: 00422 loss_train: 0.2413 acc_train: 0.9177 loss_val: 1.4900 acc_val: 0.7140 time: 0.0182s\n",
      "valid current auc-roc score: 0.925020, current macro_F score: 0.694938\n",
      "Epoch: 00423 loss_train: 0.2037 acc_train: 0.9328 loss_val: 1.6580 acc_val: 0.7177 time: 0.0178s\n",
      "valid current auc-roc score: 0.917788, current macro_F score: 0.698721\n",
      "Epoch: 00424 loss_train: 0.2035 acc_train: 0.9378 loss_val: 1.8099 acc_val: 0.7103 time: 0.0220s\n",
      "valid current auc-roc score: 0.909280, current macro_F score: 0.689579\n",
      "Epoch: 00425 loss_train: 0.2245 acc_train: 0.9285 loss_val: 1.8995 acc_val: 0.7232 time: 0.0235s\n",
      "valid current auc-roc score: 0.920210, current macro_F score: 0.693143\n",
      "Epoch: 00426 loss_train: 0.2078 acc_train: 0.9220 loss_val: 1.7441 acc_val: 0.7251 time: 0.0277s\n",
      "valid current auc-roc score: 0.921163, current macro_F score: 0.697209\n",
      "Epoch: 00427 loss_train: 0.2148 acc_train: 0.9285 loss_val: 1.4607 acc_val: 0.7343 time: 0.0224s\n",
      "valid current auc-roc score: 0.931727, current macro_F score: 0.716012\n",
      "Epoch: 00428 loss_train: 0.2329 acc_train: 0.9177 loss_val: 2.0218 acc_val: 0.7196 time: 0.0194s\n",
      "valid current auc-roc score: 0.909550, current macro_F score: 0.699103\n",
      "Epoch: 00429 loss_train: 0.2357 acc_train: 0.9192 loss_val: 1.7185 acc_val: 0.7159 time: 0.0216s\n",
      "valid current auc-roc score: 0.913700, current macro_F score: 0.696104\n",
      "Epoch: 00430 loss_train: 0.2147 acc_train: 0.9285 loss_val: 1.7480 acc_val: 0.7269 time: 0.0235s\n",
      "valid current auc-roc score: 0.917953, current macro_F score: 0.706288\n",
      "Epoch: 00431 loss_train: 0.2542 acc_train: 0.9163 loss_val: 1.7616 acc_val: 0.7399 time: 0.0235s\n",
      "valid current auc-roc score: 0.921561, current macro_F score: 0.715464\n",
      "Test set results: loss= 1.6888 accuracy= 714.9299\n",
      "test current auc-roc score: 0.923418, current macro_F score: 0.719965\n",
      "Epoch: 00432 loss_train: 0.2091 acc_train: 0.9335 loss_val: 1.9804 acc_val: 0.7232 time: 0.0185s\n",
      "valid current auc-roc score: 0.916600, current macro_F score: 0.699640\n",
      "Epoch: 00433 loss_train: 0.2037 acc_train: 0.9320 loss_val: 1.8447 acc_val: 0.6974 time: 0.0214s\n",
      "valid current auc-roc score: 0.922345, current macro_F score: 0.673258\n",
      "Epoch: 00434 loss_train: 0.2357 acc_train: 0.9177 loss_val: 1.6839 acc_val: 0.7048 time: 0.0260s\n",
      "valid current auc-roc score: 0.917706, current macro_F score: 0.670393\n",
      "Epoch: 00435 loss_train: 0.1893 acc_train: 0.9270 loss_val: 1.6412 acc_val: 0.7454 time: 0.0247s\n",
      "valid current auc-roc score: 0.931846, current macro_F score: 0.725085\n",
      "Epoch: 00436 loss_train: 0.1933 acc_train: 0.9313 loss_val: 1.8285 acc_val: 0.7177 time: 0.0221s\n",
      "valid current auc-roc score: 0.914979, current macro_F score: 0.691716\n",
      "Epoch: 00437 loss_train: 0.2002 acc_train: 0.9328 loss_val: 1.9582 acc_val: 0.7140 time: 0.0218s\n",
      "valid current auc-roc score: 0.919659, current macro_F score: 0.694356\n",
      "Epoch: 00438 loss_train: 0.2181 acc_train: 0.9249 loss_val: 1.4036 acc_val: 0.7417 time: 0.0187s\n",
      "valid current auc-roc score: 0.932140, current macro_F score: 0.720805\n",
      "Epoch: 00439 loss_train: 0.2127 acc_train: 0.9270 loss_val: 1.5015 acc_val: 0.7362 time: 0.0197s\n",
      "valid current auc-roc score: 0.921034, current macro_F score: 0.714550\n",
      "Epoch: 00440 loss_train: 0.2011 acc_train: 0.9235 loss_val: 1.6058 acc_val: 0.7362 time: 0.0188s\n",
      "valid current auc-roc score: 0.914179, current macro_F score: 0.718932\n",
      "Epoch: 00441 loss_train: 0.1975 acc_train: 0.9342 loss_val: 1.7279 acc_val: 0.7417 time: 0.0214s\n",
      "valid current auc-roc score: 0.927406, current macro_F score: 0.729692\n",
      "Test set results: loss= 1.6190 accuracy= 734.0443\n",
      "test current auc-roc score: 0.924940, current macro_F score: 0.712182\n",
      "Epoch: 00442 loss_train: 0.2011 acc_train: 0.9335 loss_val: 2.0618 acc_val: 0.6974 time: 0.0202s\n",
      "valid current auc-roc score: 0.914972, current macro_F score: 0.672723\n",
      "Epoch: 00443 loss_train: 0.1953 acc_train: 0.9306 loss_val: 1.7812 acc_val: 0.7159 time: 0.0210s\n",
      "valid current auc-roc score: 0.917840, current macro_F score: 0.682038\n",
      "Epoch: 00444 loss_train: 0.2092 acc_train: 0.9320 loss_val: 1.6792 acc_val: 0.6919 time: 0.0201s\n",
      "valid current auc-roc score: 0.911707, current macro_F score: 0.661597\n",
      "Epoch: 00445 loss_train: 0.2029 acc_train: 0.9270 loss_val: 1.7711 acc_val: 0.7196 time: 0.0215s\n",
      "valid current auc-roc score: 0.919093, current macro_F score: 0.705748\n",
      "Epoch: 00446 loss_train: 0.2043 acc_train: 0.9320 loss_val: 2.0733 acc_val: 0.7122 time: 0.0211s\n",
      "valid current auc-roc score: 0.908858, current macro_F score: 0.689950\n",
      "Epoch: 00447 loss_train: 0.2392 acc_train: 0.9127 loss_val: 1.7767 acc_val: 0.7066 time: 0.0216s\n",
      "valid current auc-roc score: 0.925959, current macro_F score: 0.685905\n",
      "Epoch: 00448 loss_train: 0.2535 acc_train: 0.9113 loss_val: 2.1357 acc_val: 0.7214 time: 0.0228s\n",
      "valid current auc-roc score: 0.918801, current macro_F score: 0.692813\n",
      "Epoch: 00449 loss_train: 0.1929 acc_train: 0.9392 loss_val: 1.8042 acc_val: 0.7251 time: 0.0269s\n",
      "valid current auc-roc score: 0.916480, current macro_F score: 0.706491\n",
      "Epoch: 00450 loss_train: 0.2161 acc_train: 0.9249 loss_val: 1.8661 acc_val: 0.7177 time: 0.0259s\n",
      "valid current auc-roc score: 0.918882, current macro_F score: 0.699232\n",
      "Epoch: 00451 loss_train: 0.1712 acc_train: 0.9456 loss_val: 1.5999 acc_val: 0.7196 time: 0.0228s\n",
      "valid current auc-roc score: 0.911592, current macro_F score: 0.701469\n",
      "Test set results: loss= 1.5434 accuracy= 724.3192\n",
      "test current auc-roc score: 0.927110, current macro_F score: 0.716380\n",
      "Epoch: 00452 loss_train: 0.2306 acc_train: 0.9256 loss_val: 1.6689 acc_val: 0.7288 time: 0.0201s\n",
      "valid current auc-roc score: 0.920233, current macro_F score: 0.712328\n",
      "Epoch: 00453 loss_train: 0.2010 acc_train: 0.9299 loss_val: 1.7130 acc_val: 0.7159 time: 0.0208s\n",
      "valid current auc-roc score: 0.915317, current macro_F score: 0.687840\n",
      "Epoch: 00454 loss_train: 0.2214 acc_train: 0.9163 loss_val: 1.5629 acc_val: 0.7214 time: 0.0246s\n",
      "valid current auc-roc score: 0.928953, current macro_F score: 0.693846\n",
      "Epoch: 00455 loss_train: 0.2143 acc_train: 0.9292 loss_val: 1.5859 acc_val: 0.7030 time: 0.0205s\n",
      "valid current auc-roc score: 0.919355, current macro_F score: 0.671967\n",
      "Epoch: 00456 loss_train: 0.2106 acc_train: 0.9263 loss_val: 1.5883 acc_val: 0.7251 time: 0.0204s\n",
      "valid current auc-roc score: 0.921299, current macro_F score: 0.705659\n",
      "Epoch: 00457 loss_train: 0.2461 acc_train: 0.9285 loss_val: 1.5828 acc_val: 0.7085 time: 0.0216s\n",
      "valid current auc-roc score: 0.915191, current macro_F score: 0.679147\n",
      "Epoch: 00458 loss_train: 0.2340 acc_train: 0.9235 loss_val: 1.9598 acc_val: 0.7140 time: 0.0202s\n",
      "valid current auc-roc score: 0.911616, current macro_F score: 0.681541\n",
      "Epoch: 00459 loss_train: 0.2611 acc_train: 0.9027 loss_val: 1.6993 acc_val: 0.7159 time: 0.0379s\n",
      "valid current auc-roc score: 0.919110, current macro_F score: 0.687417\n",
      "Epoch: 00460 loss_train: 0.2317 acc_train: 0.9263 loss_val: 1.7428 acc_val: 0.6993 time: 0.0224s\n",
      "valid current auc-roc score: 0.914997, current macro_F score: 0.678632\n",
      "Epoch: 00461 loss_train: 0.1949 acc_train: 0.9349 loss_val: 1.9578 acc_val: 0.7066 time: 0.0289s\n",
      "valid current auc-roc score: 0.908535, current macro_F score: 0.685279\n",
      "Test set results: loss= 1.5999 accuracy= 730.5185\n",
      "test current auc-roc score: 0.924402, current macro_F score: 0.713634\n",
      "Epoch: 00462 loss_train: 0.2085 acc_train: 0.9320 loss_val: 1.7069 acc_val: 0.7232 time: 0.0194s\n",
      "valid current auc-roc score: 0.922485, current macro_F score: 0.703454\n",
      "Epoch: 00463 loss_train: 0.1958 acc_train: 0.9349 loss_val: 1.6404 acc_val: 0.7159 time: 0.0208s\n",
      "valid current auc-roc score: 0.918026, current macro_F score: 0.696097\n",
      "Epoch: 00464 loss_train: 0.1992 acc_train: 0.9349 loss_val: 1.8094 acc_val: 0.7103 time: 0.0335s\n",
      "valid current auc-roc score: 0.915557, current macro_F score: 0.687465\n",
      "Epoch: 00465 loss_train: 0.2495 acc_train: 0.9256 loss_val: 2.0427 acc_val: 0.7011 time: 0.0232s\n",
      "valid current auc-roc score: 0.909736, current macro_F score: 0.680607\n",
      "Epoch: 00466 loss_train: 0.2223 acc_train: 0.9278 loss_val: 1.5913 acc_val: 0.6974 time: 0.0291s\n",
      "valid current auc-roc score: 0.913921, current macro_F score: 0.676890\n",
      "Epoch: 00467 loss_train: 0.2198 acc_train: 0.9285 loss_val: 1.9376 acc_val: 0.7214 time: 0.0291s\n",
      "valid current auc-roc score: 0.919366, current macro_F score: 0.698030\n",
      "Epoch: 00468 loss_train: 0.1987 acc_train: 0.9371 loss_val: 1.8143 acc_val: 0.6882 time: 0.0286s\n",
      "valid current auc-roc score: 0.916114, current macro_F score: 0.657863\n",
      "Epoch: 00469 loss_train: 0.2199 acc_train: 0.9363 loss_val: 2.0912 acc_val: 0.6956 time: 0.0203s\n",
      "valid current auc-roc score: 0.910026, current macro_F score: 0.665171\n",
      "Epoch: 00470 loss_train: 0.2022 acc_train: 0.9335 loss_val: 1.8520 acc_val: 0.7103 time: 0.0187s\n",
      "valid current auc-roc score: 0.919567, current macro_F score: 0.677713\n",
      "Epoch: 00471 loss_train: 0.2315 acc_train: 0.9227 loss_val: 1.8096 acc_val: 0.7214 time: 0.0191s\n",
      "valid current auc-roc score: 0.912735, current macro_F score: 0.698242\n",
      "Test set results: loss= 1.7562 accuracy= 745.6937\n",
      "test current auc-roc score: 0.919972, current macro_F score: 0.707003\n",
      "Epoch: 00472 loss_train: 0.1861 acc_train: 0.9385 loss_val: 1.8317 acc_val: 0.6993 time: 0.0270s\n",
      "valid current auc-roc score: 0.916715, current macro_F score: 0.672487\n",
      "Epoch: 00473 loss_train: 0.1962 acc_train: 0.9378 loss_val: 1.9493 acc_val: 0.7140 time: 0.0208s\n",
      "valid current auc-roc score: 0.921141, current macro_F score: 0.697240\n",
      "Epoch: 00474 loss_train: 0.2051 acc_train: 0.9328 loss_val: 1.8094 acc_val: 0.7196 time: 0.0208s\n",
      "valid current auc-roc score: 0.913637, current macro_F score: 0.698057\n",
      "Epoch: 00475 loss_train: 0.1893 acc_train: 0.9406 loss_val: 1.9030 acc_val: 0.7214 time: 0.0217s\n",
      "valid current auc-roc score: 0.913571, current macro_F score: 0.695415\n",
      "Epoch: 00476 loss_train: 0.2162 acc_train: 0.9270 loss_val: 2.0113 acc_val: 0.7214 time: 0.0229s\n",
      "valid current auc-roc score: 0.917731, current macro_F score: 0.708949\n",
      "Epoch: 00477 loss_train: 0.2047 acc_train: 0.9428 loss_val: 1.6809 acc_val: 0.7491 time: 0.0193s\n",
      "valid current auc-roc score: 0.930017, current macro_F score: 0.719934\n",
      "Epoch: 00478 loss_train: 0.1909 acc_train: 0.9349 loss_val: 1.6177 acc_val: 0.7196 time: 0.0175s\n",
      "valid current auc-roc score: 0.919967, current macro_F score: 0.687626\n",
      "Epoch: 00479 loss_train: 0.2102 acc_train: 0.9263 loss_val: 1.6328 acc_val: 0.7232 time: 0.0211s\n",
      "valid current auc-roc score: 0.930799, current macro_F score: 0.719722\n",
      "Epoch: 00480 loss_train: 0.2040 acc_train: 0.9278 loss_val: 1.6638 acc_val: 0.7196 time: 0.0239s\n",
      "valid current auc-roc score: 0.926023, current macro_F score: 0.693235\n",
      "Epoch: 00481 loss_train: 0.2026 acc_train: 0.9349 loss_val: 1.9160 acc_val: 0.7232 time: 0.0206s\n",
      "valid current auc-roc score: 0.919395, current macro_F score: 0.701113\n",
      "Test set results: loss= 1.6173 accuracy= 730.7251\n",
      "test current auc-roc score: 0.924848, current macro_F score: 0.727261\n",
      "Epoch: 00482 loss_train: 0.1880 acc_train: 0.9356 loss_val: 1.7065 acc_val: 0.7196 time: 0.0250s\n",
      "valid current auc-roc score: 0.918763, current macro_F score: 0.699652\n",
      "Epoch: 00483 loss_train: 0.2043 acc_train: 0.9270 loss_val: 1.5729 acc_val: 0.7306 time: 0.0189s\n",
      "valid current auc-roc score: 0.932232, current macro_F score: 0.708961\n",
      "Epoch: 00484 loss_train: 0.2209 acc_train: 0.9185 loss_val: 2.1330 acc_val: 0.7159 time: 0.0196s\n",
      "valid current auc-roc score: 0.916408, current macro_F score: 0.684317\n",
      "Epoch: 00485 loss_train: 0.1949 acc_train: 0.9320 loss_val: 1.6348 acc_val: 0.7214 time: 0.0224s\n",
      "valid current auc-roc score: 0.923702, current macro_F score: 0.700886\n",
      "Epoch: 00486 loss_train: 0.2085 acc_train: 0.9320 loss_val: 1.7962 acc_val: 0.7325 time: 0.0215s\n",
      "valid current auc-roc score: 0.926455, current macro_F score: 0.710144\n",
      "Epoch: 00487 loss_train: 0.2159 acc_train: 0.9213 loss_val: 1.6632 acc_val: 0.7472 time: 0.0218s\n",
      "valid current auc-roc score: 0.923028, current macro_F score: 0.721884\n",
      "Epoch: 00488 loss_train: 0.2257 acc_train: 0.9256 loss_val: 1.8590 acc_val: 0.7343 time: 0.0214s\n",
      "valid current auc-roc score: 0.923983, current macro_F score: 0.715639\n",
      "Epoch: 00489 loss_train: 0.1991 acc_train: 0.9342 loss_val: 1.8328 acc_val: 0.7380 time: 0.0210s\n",
      "valid current auc-roc score: 0.922460, current macro_F score: 0.713334\n",
      "Epoch: 00490 loss_train: 0.2220 acc_train: 0.9213 loss_val: 1.8131 acc_val: 0.7103 time: 0.0216s\n",
      "valid current auc-roc score: 0.922778, current macro_F score: 0.684809\n",
      "Epoch: 00491 loss_train: 0.2030 acc_train: 0.9242 loss_val: 1.8090 acc_val: 0.7140 time: 0.0178s\n",
      "valid current auc-roc score: 0.917192, current macro_F score: 0.691710\n",
      "Test set results: loss= 1.6373 accuracy= 712.5018\n",
      "test current auc-roc score: 0.925101, current macro_F score: 0.717274\n",
      "Epoch: 00492 loss_train: 0.2167 acc_train: 0.9213 loss_val: 1.5402 acc_val: 0.7214 time: 0.0266s\n",
      "valid current auc-roc score: 0.928107, current macro_F score: 0.702570\n",
      "Epoch: 00493 loss_train: 0.2262 acc_train: 0.9270 loss_val: 1.5262 acc_val: 0.6993 time: 0.0223s\n",
      "valid current auc-roc score: 0.922298, current macro_F score: 0.670540\n",
      "Epoch: 00494 loss_train: 0.1976 acc_train: 0.9320 loss_val: 1.7597 acc_val: 0.7159 time: 0.0198s\n",
      "valid current auc-roc score: 0.914857, current macro_F score: 0.683976\n",
      "Epoch: 00495 loss_train: 0.1841 acc_train: 0.9371 loss_val: 1.8983 acc_val: 0.7085 time: 0.0212s\n",
      "valid current auc-roc score: 0.916696, current macro_F score: 0.693321\n",
      "Epoch: 00496 loss_train: 0.2048 acc_train: 0.9313 loss_val: 1.7534 acc_val: 0.7140 time: 0.0193s\n",
      "valid current auc-roc score: 0.919102, current macro_F score: 0.687096\n",
      "Epoch: 00497 loss_train: 0.2087 acc_train: 0.9278 loss_val: 1.6988 acc_val: 0.7343 time: 0.0198s\n",
      "valid current auc-roc score: 0.917582, current macro_F score: 0.711101\n",
      "Epoch: 00498 loss_train: 0.2113 acc_train: 0.9320 loss_val: 1.5782 acc_val: 0.7306 time: 0.0224s\n",
      "valid current auc-roc score: 0.922214, current macro_F score: 0.708560\n",
      "Epoch: 00499 loss_train: 0.2010 acc_train: 0.9292 loss_val: 1.5560 acc_val: 0.7343 time: 0.0227s\n",
      "valid current auc-roc score: 0.920401, current macro_F score: 0.723339\n",
      "Epoch: 00500 loss_train: 0.2060 acc_train: 0.9328 loss_val: 1.8417 acc_val: 0.7399 time: 0.0193s\n",
      "valid current auc-roc score: 0.924886, current macro_F score: 0.723168\n",
      "Epoch: 00501 loss_train: 0.2152 acc_train: 0.9335 loss_val: 1.7151 acc_val: 0.7435 time: 0.0191s\n",
      "valid current auc-roc score: 0.922628, current macro_F score: 0.717010\n",
      "Test set results: loss= 1.6067 accuracy= 730.0664\n",
      "test current auc-roc score: 0.923757, current macro_F score: 0.721288\n",
      "Epoch: 00502 loss_train: 0.2088 acc_train: 0.9249 loss_val: 1.7189 acc_val: 0.7140 time: 0.0203s\n",
      "valid current auc-roc score: 0.927343, current macro_F score: 0.693435\n",
      "Epoch: 00503 loss_train: 0.2133 acc_train: 0.9406 loss_val: 1.6528 acc_val: 0.7362 time: 0.0194s\n",
      "valid current auc-roc score: 0.918652, current macro_F score: 0.710957\n",
      "Epoch: 00504 loss_train: 0.2011 acc_train: 0.9335 loss_val: 1.7063 acc_val: 0.7196 time: 0.0185s\n",
      "valid current auc-roc score: 0.922822, current macro_F score: 0.697269\n",
      "Epoch: 00505 loss_train: 0.2301 acc_train: 0.9256 loss_val: 1.5399 acc_val: 0.7269 time: 0.0176s\n",
      "valid current auc-roc score: 0.929253, current macro_F score: 0.707837\n",
      "Epoch: 00506 loss_train: 0.1917 acc_train: 0.9356 loss_val: 1.7017 acc_val: 0.7232 time: 0.0216s\n",
      "valid current auc-roc score: 0.924848, current macro_F score: 0.706592\n",
      "Epoch: 00507 loss_train: 0.2089 acc_train: 0.9328 loss_val: 2.0316 acc_val: 0.7122 time: 0.0198s\n",
      "valid current auc-roc score: 0.915617, current macro_F score: 0.691127\n",
      "Epoch: 00508 loss_train: 0.2076 acc_train: 0.9349 loss_val: 1.9211 acc_val: 0.7122 time: 0.0208s\n",
      "valid current auc-roc score: 0.916941, current macro_F score: 0.683930\n",
      "Epoch: 00509 loss_train: 0.2011 acc_train: 0.9299 loss_val: 1.7715 acc_val: 0.7288 time: 0.0227s\n",
      "valid current auc-roc score: 0.911217, current macro_F score: 0.710761\n",
      "Epoch: 00510 loss_train: 0.1977 acc_train: 0.9356 loss_val: 1.9546 acc_val: 0.7214 time: 0.0180s\n",
      "valid current auc-roc score: 0.918419, current macro_F score: 0.693245\n",
      "Epoch: 00511 loss_train: 0.2118 acc_train: 0.9249 loss_val: 2.2291 acc_val: 0.7140 time: 0.0245s\n",
      "valid current auc-roc score: 0.914300, current macro_F score: 0.692804\n",
      "Test set results: loss= 1.7666 accuracy= 732.7011\n",
      "test current auc-roc score: 0.920227, current macro_F score: 0.706970\n",
      "Epoch: 00512 loss_train: 0.1910 acc_train: 0.9306 loss_val: 1.9621 acc_val: 0.7177 time: 0.0197s\n",
      "valid current auc-roc score: 0.911462, current macro_F score: 0.690293\n",
      "Epoch: 00513 loss_train: 0.1955 acc_train: 0.9363 loss_val: 1.6060 acc_val: 0.7177 time: 0.0209s\n",
      "valid current auc-roc score: 0.916746, current macro_F score: 0.690525\n",
      "Epoch: 00514 loss_train: 0.2162 acc_train: 0.9278 loss_val: 1.6760 acc_val: 0.7030 time: 0.0231s\n",
      "valid current auc-roc score: 0.915068, current macro_F score: 0.672381\n",
      "Epoch: 00515 loss_train: 0.2140 acc_train: 0.9249 loss_val: 1.5073 acc_val: 0.7159 time: 0.0212s\n",
      "valid current auc-roc score: 0.922099, current macro_F score: 0.699602\n",
      "Epoch: 00516 loss_train: 0.2134 acc_train: 0.9242 loss_val: 1.7184 acc_val: 0.7269 time: 0.0186s\n",
      "valid current auc-roc score: 0.918258, current macro_F score: 0.701467\n",
      "Epoch: 00517 loss_train: 0.2033 acc_train: 0.9256 loss_val: 1.6301 acc_val: 0.7325 time: 0.0182s\n",
      "valid current auc-roc score: 0.918132, current macro_F score: 0.709388\n",
      "Epoch: 00518 loss_train: 0.2249 acc_train: 0.9242 loss_val: 1.7814 acc_val: 0.7159 time: 0.0204s\n",
      "valid current auc-roc score: 0.912046, current macro_F score: 0.689742\n",
      "Epoch: 00519 loss_train: 0.2538 acc_train: 0.9163 loss_val: 1.6936 acc_val: 0.7103 time: 0.0212s\n",
      "valid current auc-roc score: 0.907858, current macro_F score: 0.691090\n",
      "Epoch: 00520 loss_train: 0.2134 acc_train: 0.9342 loss_val: 1.8870 acc_val: 0.7251 time: 0.0203s\n",
      "valid current auc-roc score: 0.908731, current macro_F score: 0.708464\n",
      "Epoch: 00521 loss_train: 0.2028 acc_train: 0.9306 loss_val: 2.0069 acc_val: 0.7214 time: 0.0227s\n",
      "valid current auc-roc score: 0.907511, current macro_F score: 0.704106\n",
      "Test set results: loss= 1.7061 accuracy= 740.1015\n",
      "test current auc-roc score: 0.921147, current macro_F score: 0.683713\n",
      "Epoch: 00522 loss_train: 0.1978 acc_train: 0.9313 loss_val: 2.1365 acc_val: 0.7103 time: 0.0194s\n",
      "valid current auc-roc score: 0.909301, current macro_F score: 0.693289\n",
      "Epoch: 00523 loss_train: 0.2063 acc_train: 0.9349 loss_val: 1.9085 acc_val: 0.6937 time: 0.0235s\n",
      "valid current auc-roc score: 0.909886, current macro_F score: 0.666465\n",
      "Epoch: 00524 loss_train: 0.2200 acc_train: 0.9320 loss_val: 1.9178 acc_val: 0.7066 time: 0.0238s\n",
      "valid current auc-roc score: 0.904753, current macro_F score: 0.667637\n",
      "Epoch: 00525 loss_train: 0.1985 acc_train: 0.9349 loss_val: 1.6841 acc_val: 0.7159 time: 0.0285s\n",
      "valid current auc-roc score: 0.911143, current macro_F score: 0.693998\n",
      "Epoch: 00526 loss_train: 0.2262 acc_train: 0.9199 loss_val: 1.5916 acc_val: 0.7214 time: 0.0189s\n",
      "valid current auc-roc score: 0.920966, current macro_F score: 0.694823\n",
      "Epoch: 00527 loss_train: 0.2418 acc_train: 0.9156 loss_val: 1.6857 acc_val: 0.7122 time: 0.0225s\n",
      "valid current auc-roc score: 0.919508, current macro_F score: 0.680668\n",
      "Epoch: 00528 loss_train: 0.1973 acc_train: 0.9371 loss_val: 2.1373 acc_val: 0.7140 time: 0.0286s\n",
      "valid current auc-roc score: 0.920350, current macro_F score: 0.699916\n",
      "Epoch: 00529 loss_train: 0.2006 acc_train: 0.9263 loss_val: 1.4773 acc_val: 0.7306 time: 0.0201s\n",
      "valid current auc-roc score: 0.923467, current macro_F score: 0.714453\n",
      "Epoch: 00530 loss_train: 0.2354 acc_train: 0.9177 loss_val: 1.8294 acc_val: 0.6919 time: 0.0232s\n",
      "valid current auc-roc score: 0.915299, current macro_F score: 0.668588\n",
      "Epoch: 00531 loss_train: 0.2191 acc_train: 0.9320 loss_val: 1.7882 acc_val: 0.7306 time: 0.0209s\n",
      "valid current auc-roc score: 0.920087, current macro_F score: 0.714004\n",
      "Test set results: loss= 1.6388 accuracy= 731.2546\n",
      "test current auc-roc score: 0.923060, current macro_F score: 0.703918\n",
      "Epoch: 00532 loss_train: 0.1941 acc_train: 0.9328 loss_val: 1.6900 acc_val: 0.7103 time: 0.0223s\n",
      "valid current auc-roc score: 0.918201, current macro_F score: 0.686883\n",
      "Epoch: 00533 loss_train: 0.2191 acc_train: 0.9371 loss_val: 1.7013 acc_val: 0.6956 time: 0.0209s\n",
      "valid current auc-roc score: 0.914232, current macro_F score: 0.685873\n",
      "Epoch: 00534 loss_train: 0.2112 acc_train: 0.9313 loss_val: 1.8111 acc_val: 0.7030 time: 0.0224s\n",
      "valid current auc-roc score: 0.918049, current macro_F score: 0.681944\n",
      "Epoch: 00535 loss_train: 0.2003 acc_train: 0.9349 loss_val: 2.0103 acc_val: 0.7103 time: 0.0237s\n",
      "valid current auc-roc score: 0.911889, current macro_F score: 0.685686\n",
      "Epoch: 00536 loss_train: 0.1892 acc_train: 0.9371 loss_val: 1.6565 acc_val: 0.7343 time: 0.0195s\n",
      "valid current auc-roc score: 0.928710, current macro_F score: 0.720196\n",
      "Epoch: 00537 loss_train: 0.2101 acc_train: 0.9185 loss_val: 1.6025 acc_val: 0.7417 time: 0.0200s\n",
      "valid current auc-roc score: 0.926425, current macro_F score: 0.723115\n",
      "Epoch: 00538 loss_train: 0.1646 acc_train: 0.9442 loss_val: 1.7026 acc_val: 0.7066 time: 0.0211s\n",
      "valid current auc-roc score: 0.915763, current macro_F score: 0.687392\n",
      "Epoch: 00539 loss_train: 0.2153 acc_train: 0.9206 loss_val: 2.0608 acc_val: 0.7103 time: 0.0204s\n",
      "valid current auc-roc score: 0.911980, current macro_F score: 0.680587\n",
      "Epoch: 00540 loss_train: 0.2142 acc_train: 0.9220 loss_val: 1.6063 acc_val: 0.7177 time: 0.0253s\n",
      "valid current auc-roc score: 0.921103, current macro_F score: 0.695648\n",
      "Epoch: 00541 loss_train: 0.1820 acc_train: 0.9306 loss_val: 1.8899 acc_val: 0.7159 time: 0.0226s\n",
      "valid current auc-roc score: 0.916700, current macro_F score: 0.692712\n",
      "Test set results: loss= 1.8116 accuracy= 730.5185\n",
      "test current auc-roc score: 0.918357, current macro_F score: 0.702255\n",
      "Epoch: 00542 loss_train: 0.1947 acc_train: 0.9306 loss_val: 1.7495 acc_val: 0.7103 time: 0.0220s\n",
      "valid current auc-roc score: 0.916244, current macro_F score: 0.690772\n",
      "Epoch: 00543 loss_train: 0.2317 acc_train: 0.9306 loss_val: 2.0928 acc_val: 0.7122 time: 0.0231s\n",
      "valid current auc-roc score: 0.917455, current macro_F score: 0.692354\n",
      "Epoch: 00544 loss_train: 0.2229 acc_train: 0.9235 loss_val: 2.0554 acc_val: 0.7140 time: 0.0243s\n",
      "valid current auc-roc score: 0.919254, current macro_F score: 0.694647\n",
      "Epoch: 00545 loss_train: 0.1831 acc_train: 0.9363 loss_val: 1.6429 acc_val: 0.7251 time: 0.0206s\n",
      "valid current auc-roc score: 0.925685, current macro_F score: 0.705096\n",
      "Epoch: 00546 loss_train: 0.1882 acc_train: 0.9349 loss_val: 2.0318 acc_val: 0.7196 time: 0.0233s\n",
      "valid current auc-roc score: 0.909689, current macro_F score: 0.699532\n",
      "Epoch: 00547 loss_train: 0.1939 acc_train: 0.9335 loss_val: 1.8782 acc_val: 0.7177 time: 0.0286s\n",
      "valid current auc-roc score: 0.914145, current macro_F score: 0.693454\n",
      "Epoch: 00548 loss_train: 0.2080 acc_train: 0.9242 loss_val: 1.8458 acc_val: 0.7122 time: 0.0243s\n",
      "valid current auc-roc score: 0.914870, current macro_F score: 0.689674\n",
      "Epoch: 00549 loss_train: 0.1868 acc_train: 0.9371 loss_val: 1.9588 acc_val: 0.7306 time: 0.0198s\n",
      "valid current auc-roc score: 0.916888, current macro_F score: 0.712354\n",
      "Epoch: 00550 loss_train: 0.1947 acc_train: 0.9285 loss_val: 1.5266 acc_val: 0.7306 time: 0.0229s\n",
      "valid current auc-roc score: 0.917543, current macro_F score: 0.714757\n",
      "Epoch: 00551 loss_train: 0.2034 acc_train: 0.9349 loss_val: 1.7825 acc_val: 0.7048 time: 0.0239s\n",
      "valid current auc-roc score: 0.909840, current macro_F score: 0.676820\n",
      "Test set results: loss= 1.7055 accuracy= 734.8579\n",
      "test current auc-roc score: 0.916234, current macro_F score: 0.704561\n",
      "Epoch: 00552 loss_train: 0.1933 acc_train: 0.9320 loss_val: 1.7457 acc_val: 0.7288 time: 0.0197s\n",
      "valid current auc-roc score: 0.914108, current macro_F score: 0.703723\n",
      "Epoch: 00553 loss_train: 0.2016 acc_train: 0.9399 loss_val: 1.6991 acc_val: 0.7214 time: 0.0199s\n",
      "valid current auc-roc score: 0.907766, current macro_F score: 0.702394\n",
      "Epoch: 00554 loss_train: 0.2150 acc_train: 0.9306 loss_val: 1.8714 acc_val: 0.7177 time: 0.0240s\n",
      "valid current auc-roc score: 0.913025, current macro_F score: 0.690353\n",
      "Epoch: 00555 loss_train: 0.2238 acc_train: 0.9242 loss_val: 1.4586 acc_val: 0.7288 time: 0.0230s\n",
      "valid current auc-roc score: 0.927000, current macro_F score: 0.708129\n",
      "Epoch: 00556 loss_train: 0.1812 acc_train: 0.9413 loss_val: 1.9539 acc_val: 0.7140 time: 0.0201s\n",
      "valid current auc-roc score: 0.909162, current macro_F score: 0.695703\n",
      "Epoch: 00557 loss_train: 0.2126 acc_train: 0.9363 loss_val: 2.1482 acc_val: 0.6974 time: 0.0243s\n",
      "valid current auc-roc score: 0.911671, current macro_F score: 0.667745\n",
      "Epoch: 00558 loss_train: 0.1933 acc_train: 0.9263 loss_val: 2.0786 acc_val: 0.7066 time: 0.0199s\n",
      "valid current auc-roc score: 0.913001, current macro_F score: 0.682697\n",
      "Epoch: 00559 loss_train: 0.2019 acc_train: 0.9320 loss_val: 1.8344 acc_val: 0.7362 time: 0.0216s\n",
      "valid current auc-roc score: 0.922708, current macro_F score: 0.716289\n",
      "Epoch: 00560 loss_train: 0.2019 acc_train: 0.9349 loss_val: 2.0882 acc_val: 0.7011 time: 0.0202s\n",
      "valid current auc-roc score: 0.909350, current macro_F score: 0.680291\n",
      "Epoch: 00561 loss_train: 0.1856 acc_train: 0.9378 loss_val: 1.6892 acc_val: 0.7140 time: 0.0231s\n",
      "valid current auc-roc score: 0.922372, current macro_F score: 0.693567\n",
      "Test set results: loss= 1.7285 accuracy= 744.6476\n",
      "test current auc-roc score: 0.914291, current macro_F score: 0.682352\n",
      "Epoch: 00562 loss_train: 0.1965 acc_train: 0.9256 loss_val: 1.8464 acc_val: 0.7306 time: 0.0220s\n",
      "valid current auc-roc score: 0.923976, current macro_F score: 0.713909\n",
      "Epoch: 00563 loss_train: 0.2136 acc_train: 0.9328 loss_val: 1.8232 acc_val: 0.7122 time: 0.0265s\n",
      "valid current auc-roc score: 0.922299, current macro_F score: 0.692736\n",
      "Epoch: 00564 loss_train: 0.2222 acc_train: 0.9256 loss_val: 1.9341 acc_val: 0.7454 time: 0.0213s\n",
      "valid current auc-roc score: 0.924428, current macro_F score: 0.720089\n",
      "Epoch: 00565 loss_train: 0.2031 acc_train: 0.9363 loss_val: 1.6809 acc_val: 0.7269 time: 0.0224s\n",
      "valid current auc-roc score: 0.923030, current macro_F score: 0.703984\n",
      "Epoch: 00566 loss_train: 0.2090 acc_train: 0.9342 loss_val: 1.8187 acc_val: 0.6937 time: 0.0203s\n",
      "valid current auc-roc score: 0.918648, current macro_F score: 0.668758\n",
      "Epoch: 00567 loss_train: 0.1852 acc_train: 0.9356 loss_val: 1.7734 acc_val: 0.7159 time: 0.0213s\n",
      "valid current auc-roc score: 0.908178, current macro_F score: 0.696473\n",
      "Epoch: 00568 loss_train: 0.2063 acc_train: 0.9263 loss_val: 1.6805 acc_val: 0.7472 time: 0.0212s\n",
      "valid current auc-roc score: 0.923076, current macro_F score: 0.722563\n",
      "Epoch: 00569 loss_train: 0.2037 acc_train: 0.9313 loss_val: 1.7075 acc_val: 0.7491 time: 0.0218s\n",
      "valid current auc-roc score: 0.925503, current macro_F score: 0.732883\n",
      "Epoch: 00570 loss_train: 0.1958 acc_train: 0.9335 loss_val: 1.8795 acc_val: 0.7362 time: 0.0234s\n",
      "valid current auc-roc score: 0.916673, current macro_F score: 0.713798\n",
      "Epoch: 00571 loss_train: 0.2062 acc_train: 0.9270 loss_val: 1.6206 acc_val: 0.7362 time: 0.0198s\n",
      "valid current auc-roc score: 0.925205, current macro_F score: 0.719530\n",
      "Test set results: loss= 1.6545 accuracy= 744.3118\n",
      "test current auc-roc score: 0.917485, current macro_F score: 0.703098\n",
      "Epoch: 00572 loss_train: 0.2110 acc_train: 0.9227 loss_val: 1.7326 acc_val: 0.7380 time: 0.0246s\n",
      "valid current auc-roc score: 0.925237, current macro_F score: 0.714098\n",
      "Epoch: 00573 loss_train: 0.1705 acc_train: 0.9392 loss_val: 1.6614 acc_val: 0.7399 time: 0.0244s\n",
      "valid current auc-roc score: 0.928384, current macro_F score: 0.718835\n",
      "Epoch: 00574 loss_train: 0.1962 acc_train: 0.9328 loss_val: 2.0821 acc_val: 0.7325 time: 0.0225s\n",
      "valid current auc-roc score: 0.911695, current macro_F score: 0.712418\n",
      "Epoch: 00575 loss_train: 0.2038 acc_train: 0.9378 loss_val: 1.8972 acc_val: 0.7565 time: 0.0197s\n",
      "valid current auc-roc score: 0.923517, current macro_F score: 0.738723\n",
      "Epoch: 00576 loss_train: 0.1872 acc_train: 0.9320 loss_val: 1.9806 acc_val: 0.7251 time: 0.0191s\n",
      "valid current auc-roc score: 0.921788, current macro_F score: 0.701506\n",
      "Epoch: 00577 loss_train: 0.1984 acc_train: 0.9278 loss_val: 2.2228 acc_val: 0.7214 time: 0.0188s\n",
      "valid current auc-roc score: 0.908574, current macro_F score: 0.698447\n",
      "Epoch: 00578 loss_train: 0.1940 acc_train: 0.9392 loss_val: 1.7991 acc_val: 0.6974 time: 0.0277s\n",
      "valid current auc-roc score: 0.907848, current macro_F score: 0.669329\n",
      "Epoch: 00579 loss_train: 0.2198 acc_train: 0.9299 loss_val: 1.7480 acc_val: 0.7214 time: 0.0293s\n",
      "valid current auc-roc score: 0.919201, current macro_F score: 0.699297\n",
      "Epoch: 00580 loss_train: 0.2027 acc_train: 0.9299 loss_val: 1.9499 acc_val: 0.7066 time: 0.0191s\n",
      "valid current auc-roc score: 0.923563, current macro_F score: 0.684884\n",
      "Epoch: 00581 loss_train: 0.1818 acc_train: 0.9399 loss_val: 1.9505 acc_val: 0.6974 time: 0.0272s\n",
      "valid current auc-roc score: 0.914147, current macro_F score: 0.679472\n",
      "Test set results: loss= 1.9045 accuracy= 737.0277\n",
      "test current auc-roc score: 0.908561, current macro_F score: 0.684545\n",
      "Epoch: 00582 loss_train: 0.2029 acc_train: 0.9356 loss_val: 2.0716 acc_val: 0.6993 time: 0.0205s\n",
      "valid current auc-roc score: 0.906873, current macro_F score: 0.668333\n",
      "Epoch: 00583 loss_train: 0.1907 acc_train: 0.9413 loss_val: 1.8319 acc_val: 0.7048 time: 0.0227s\n",
      "valid current auc-roc score: 0.914294, current macro_F score: 0.682373\n",
      "Epoch: 00584 loss_train: 0.1921 acc_train: 0.9392 loss_val: 1.9456 acc_val: 0.7177 time: 0.0221s\n",
      "valid current auc-roc score: 0.905959, current macro_F score: 0.687578\n",
      "Epoch: 00585 loss_train: 0.2000 acc_train: 0.9270 loss_val: 1.7588 acc_val: 0.7140 time: 0.0225s\n",
      "valid current auc-roc score: 0.916226, current macro_F score: 0.688051\n",
      "Epoch: 00586 loss_train: 0.1874 acc_train: 0.9406 loss_val: 2.0762 acc_val: 0.7196 time: 0.0203s\n",
      "valid current auc-roc score: 0.915205, current macro_F score: 0.701043\n",
      "Epoch: 00587 loss_train: 0.1991 acc_train: 0.9292 loss_val: 1.7088 acc_val: 0.7122 time: 0.0270s\n",
      "valid current auc-roc score: 0.919071, current macro_F score: 0.682094\n",
      "Epoch: 00588 loss_train: 0.2068 acc_train: 0.9278 loss_val: 1.6052 acc_val: 0.7435 time: 0.0266s\n",
      "valid current auc-roc score: 0.926730, current macro_F score: 0.729083\n",
      "Epoch: 00589 loss_train: 0.1819 acc_train: 0.9349 loss_val: 1.6434 acc_val: 0.7085 time: 0.0206s\n",
      "valid current auc-roc score: 0.916470, current macro_F score: 0.692079\n",
      "Epoch: 00590 loss_train: 0.1845 acc_train: 0.9306 loss_val: 1.7263 acc_val: 0.7177 time: 0.0268s\n",
      "valid current auc-roc score: 0.916438, current macro_F score: 0.696412\n",
      "Epoch: 00591 loss_train: 0.2149 acc_train: 0.9313 loss_val: 1.5250 acc_val: 0.7343 time: 0.0252s\n",
      "valid current auc-roc score: 0.929781, current macro_F score: 0.711883\n",
      "Test set results: loss= 1.7651 accuracy= 733.5793\n",
      "test current auc-roc score: 0.918630, current macro_F score: 0.699647\n",
      "Epoch: 00592 loss_train: 0.1859 acc_train: 0.9349 loss_val: 1.9435 acc_val: 0.7066 time: 0.0211s\n",
      "valid current auc-roc score: 0.909376, current macro_F score: 0.678582\n",
      "Epoch: 00593 loss_train: 0.1804 acc_train: 0.9378 loss_val: 1.8054 acc_val: 0.7306 time: 0.0248s\n",
      "valid current auc-roc score: 0.923279, current macro_F score: 0.709806\n",
      "Epoch: 00594 loss_train: 0.1801 acc_train: 0.9449 loss_val: 1.9048 acc_val: 0.7122 time: 0.0205s\n",
      "valid current auc-roc score: 0.916207, current macro_F score: 0.686935\n",
      "Epoch: 00595 loss_train: 0.2230 acc_train: 0.9299 loss_val: 2.0477 acc_val: 0.7159 time: 0.0206s\n",
      "valid current auc-roc score: 0.916835, current macro_F score: 0.699110\n",
      "Epoch: 00596 loss_train: 0.1865 acc_train: 0.9371 loss_val: 2.1615 acc_val: 0.6974 time: 0.0219s\n",
      "valid current auc-roc score: 0.906847, current macro_F score: 0.674851\n",
      "Epoch: 00597 loss_train: 0.2203 acc_train: 0.9363 loss_val: 1.9244 acc_val: 0.6863 time: 0.0210s\n",
      "valid current auc-roc score: 0.902581, current macro_F score: 0.652079\n",
      "Epoch: 00598 loss_train: 0.2734 acc_train: 0.9113 loss_val: 1.9988 acc_val: 0.6993 time: 0.0217s\n",
      "valid current auc-roc score: 0.904168, current macro_F score: 0.663202\n",
      "Epoch: 00599 loss_train: 0.2077 acc_train: 0.9242 loss_val: 1.8337 acc_val: 0.7232 time: 0.0228s\n",
      "valid current auc-roc score: 0.913791, current macro_F score: 0.710428\n",
      "Epoch: 00600 loss_train: 0.2091 acc_train: 0.9313 loss_val: 1.6915 acc_val: 0.7103 time: 0.0232s\n",
      "valid current auc-roc score: 0.921274, current macro_F score: 0.677542\n",
      "Epoch: 00601 loss_train: 0.2349 acc_train: 0.9177 loss_val: 1.9093 acc_val: 0.7103 time: 0.0328s\n",
      "valid current auc-roc score: 0.907617, current macro_F score: 0.683018\n",
      "Test set results: loss= 1.7253 accuracy= 735.5812\n",
      "test current auc-roc score: 0.914576, current macro_F score: 0.689291\n",
      "Epoch: 00602 loss_train: 0.1966 acc_train: 0.9313 loss_val: 1.8246 acc_val: 0.7122 time: 0.0209s\n",
      "valid current auc-roc score: 0.914912, current macro_F score: 0.689984\n",
      "Epoch: 00603 loss_train: 0.2051 acc_train: 0.9278 loss_val: 1.6370 acc_val: 0.6974 time: 0.0224s\n",
      "valid current auc-roc score: 0.911410, current macro_F score: 0.674069\n",
      "Epoch: 00604 loss_train: 0.2205 acc_train: 0.9177 loss_val: 1.9502 acc_val: 0.6974 time: 0.0211s\n",
      "valid current auc-roc score: 0.904298, current macro_F score: 0.670221\n",
      "Epoch: 00605 loss_train: 0.1969 acc_train: 0.9306 loss_val: 1.8117 acc_val: 0.7048 time: 0.0247s\n",
      "valid current auc-roc score: 0.906962, current macro_F score: 0.678086\n",
      "Epoch: 00606 loss_train: 0.1951 acc_train: 0.9342 loss_val: 1.7922 acc_val: 0.7251 time: 0.0255s\n",
      "valid current auc-roc score: 0.919815, current macro_F score: 0.703837\n",
      "Epoch: 00607 loss_train: 0.2408 acc_train: 0.9163 loss_val: 1.6142 acc_val: 0.7177 time: 0.0202s\n",
      "valid current auc-roc score: 0.911618, current macro_F score: 0.698251\n",
      "Epoch: 00608 loss_train: 0.2048 acc_train: 0.9378 loss_val: 2.1253 acc_val: 0.7214 time: 0.0219s\n",
      "valid current auc-roc score: 0.911718, current macro_F score: 0.695463\n",
      "Epoch: 00609 loss_train: 0.1872 acc_train: 0.9406 loss_val: 1.8356 acc_val: 0.7343 time: 0.0214s\n",
      "valid current auc-roc score: 0.918715, current macro_F score: 0.724622\n",
      "Epoch: 00610 loss_train: 0.1866 acc_train: 0.9356 loss_val: 2.0237 acc_val: 0.7343 time: 0.0242s\n",
      "valid current auc-roc score: 0.916104, current macro_F score: 0.716032\n",
      "Epoch: 00611 loss_train: 0.2037 acc_train: 0.9342 loss_val: 1.8457 acc_val: 0.7159 time: 0.0187s\n",
      "valid current auc-roc score: 0.913739, current macro_F score: 0.692165\n",
      "Test set results: loss= 1.5147 accuracy= 725.8173\n",
      "test current auc-roc score: 0.924402, current macro_F score: 0.712140\n",
      "Epoch: 00612 loss_train: 0.1926 acc_train: 0.9328 loss_val: 1.5807 acc_val: 0.7380 time: 0.0200s\n",
      "valid current auc-roc score: 0.925984, current macro_F score: 0.719023\n",
      "Epoch: 00613 loss_train: 0.1916 acc_train: 0.9392 loss_val: 1.8096 acc_val: 0.7085 time: 0.0194s\n",
      "valid current auc-roc score: 0.923114, current macro_F score: 0.689804\n",
      "Epoch: 00614 loss_train: 0.2213 acc_train: 0.9306 loss_val: 1.8214 acc_val: 0.7159 time: 0.0214s\n",
      "valid current auc-roc score: 0.920273, current macro_F score: 0.694911\n",
      "Epoch: 00615 loss_train: 0.1830 acc_train: 0.9342 loss_val: 1.5622 acc_val: 0.7325 time: 0.0219s\n",
      "valid current auc-roc score: 0.921315, current macro_F score: 0.714502\n",
      "Epoch: 00616 loss_train: 0.2476 acc_train: 0.9120 loss_val: 1.5413 acc_val: 0.7362 time: 0.0199s\n",
      "valid current auc-roc score: 0.925134, current macro_F score: 0.722093\n",
      "Epoch: 00617 loss_train: 0.1896 acc_train: 0.9356 loss_val: 1.9281 acc_val: 0.7011 time: 0.0298s\n",
      "valid current auc-roc score: 0.912481, current macro_F score: 0.676692\n",
      "Epoch: 00618 loss_train: 0.2096 acc_train: 0.9220 loss_val: 2.4281 acc_val: 0.7066 time: 0.0215s\n",
      "valid current auc-roc score: 0.896154, current macro_F score: 0.691397\n",
      "Epoch: 00619 loss_train: 0.2129 acc_train: 0.9263 loss_val: 1.8108 acc_val: 0.7343 time: 0.0228s\n",
      "valid current auc-roc score: 0.919356, current macro_F score: 0.722160\n",
      "Epoch: 00620 loss_train: 0.2031 acc_train: 0.9292 loss_val: 1.7164 acc_val: 0.7343 time: 0.0259s\n",
      "valid current auc-roc score: 0.924200, current macro_F score: 0.721237\n",
      "Epoch: 00621 loss_train: 0.1884 acc_train: 0.9356 loss_val: 1.7137 acc_val: 0.7177 time: 0.0185s\n",
      "valid current auc-roc score: 0.918973, current macro_F score: 0.697042\n",
      "Test set results: loss= 1.7082 accuracy= 734.9871\n",
      "test current auc-roc score: 0.919691, current macro_F score: 0.716788\n",
      "Epoch: 00622 loss_train: 0.2052 acc_train: 0.9299 loss_val: 1.7730 acc_val: 0.7232 time: 0.0227s\n",
      "valid current auc-roc score: 0.914799, current macro_F score: 0.700221\n",
      "Epoch: 00623 loss_train: 0.2097 acc_train: 0.9320 loss_val: 1.6268 acc_val: 0.7232 time: 0.0289s\n",
      "valid current auc-roc score: 0.920106, current macro_F score: 0.698654\n",
      "Epoch: 00624 loss_train: 0.2044 acc_train: 0.9256 loss_val: 1.7528 acc_val: 0.7288 time: 0.0244s\n",
      "valid current auc-roc score: 0.922162, current macro_F score: 0.711480\n",
      "Epoch: 00625 loss_train: 0.2280 acc_train: 0.9270 loss_val: 1.4934 acc_val: 0.7196 time: 0.0283s\n",
      "valid current auc-roc score: 0.921071, current macro_F score: 0.700090\n",
      "Epoch: 00626 loss_train: 0.2151 acc_train: 0.9292 loss_val: 1.4807 acc_val: 0.7066 time: 0.0229s\n",
      "valid current auc-roc score: 0.920820, current macro_F score: 0.685311\n",
      "Epoch: 00627 loss_train: 0.2185 acc_train: 0.9235 loss_val: 1.4837 acc_val: 0.7232 time: 0.0220s\n",
      "valid current auc-roc score: 0.923033, current macro_F score: 0.702580\n",
      "Epoch: 00628 loss_train: 0.1887 acc_train: 0.9385 loss_val: 1.6270 acc_val: 0.7196 time: 0.0278s\n",
      "valid current auc-roc score: 0.922389, current macro_F score: 0.694230\n",
      "Epoch: 00629 loss_train: 0.2219 acc_train: 0.9270 loss_val: 1.6466 acc_val: 0.7325 time: 0.0232s\n",
      "valid current auc-roc score: 0.924818, current macro_F score: 0.708062\n",
      "Epoch: 00630 loss_train: 0.1974 acc_train: 0.9328 loss_val: 1.4342 acc_val: 0.7196 time: 0.0241s\n",
      "valid current auc-roc score: 0.923230, current macro_F score: 0.702757\n",
      "Epoch: 00631 loss_train: 0.2379 acc_train: 0.9185 loss_val: 2.0374 acc_val: 0.7085 time: 0.0208s\n",
      "valid current auc-roc score: 0.914274, current macro_F score: 0.685631\n",
      "Test set results: loss= 1.6232 accuracy= 745.1384\n",
      "test current auc-roc score: 0.923654, current macro_F score: 0.703051\n",
      "Epoch: 00632 loss_train: 0.1871 acc_train: 0.9371 loss_val: 1.6956 acc_val: 0.7214 time: 0.0225s\n",
      "valid current auc-roc score: 0.923750, current macro_F score: 0.697637\n",
      "Epoch: 00633 loss_train: 0.2064 acc_train: 0.9285 loss_val: 1.8444 acc_val: 0.7269 time: 0.0242s\n",
      "valid current auc-roc score: 0.924790, current macro_F score: 0.705605\n",
      "Epoch: 00634 loss_train: 0.1890 acc_train: 0.9363 loss_val: 1.5427 acc_val: 0.7362 time: 0.0225s\n",
      "valid current auc-roc score: 0.927066, current macro_F score: 0.712953\n",
      "Epoch: 00635 loss_train: 0.1968 acc_train: 0.9392 loss_val: 1.5850 acc_val: 0.7306 time: 0.0303s\n",
      "valid current auc-roc score: 0.924378, current macro_F score: 0.699040\n",
      "Epoch: 00636 loss_train: 0.2089 acc_train: 0.9349 loss_val: 1.5252 acc_val: 0.7343 time: 0.0222s\n",
      "valid current auc-roc score: 0.923664, current macro_F score: 0.706724\n",
      "Epoch: 00637 loss_train: 0.2072 acc_train: 0.9299 loss_val: 1.5782 acc_val: 0.7159 time: 0.0242s\n",
      "valid current auc-roc score: 0.923586, current macro_F score: 0.698760\n",
      "Epoch: 00638 loss_train: 0.2615 acc_train: 0.9134 loss_val: 2.0745 acc_val: 0.6919 time: 0.0221s\n",
      "valid current auc-roc score: 0.910566, current macro_F score: 0.666803\n",
      "Epoch: 00639 loss_train: 0.2067 acc_train: 0.9220 loss_val: 1.7887 acc_val: 0.7251 time: 0.0210s\n",
      "valid current auc-roc score: 0.924359, current macro_F score: 0.706819\n",
      "Epoch: 00640 loss_train: 0.2222 acc_train: 0.9242 loss_val: 1.7471 acc_val: 0.7048 time: 0.0195s\n",
      "valid current auc-roc score: 0.922552, current macro_F score: 0.685704\n",
      "Epoch: 00641 loss_train: 0.2204 acc_train: 0.9356 loss_val: 2.0651 acc_val: 0.7030 time: 0.0215s\n",
      "valid current auc-roc score: 0.909140, current macro_F score: 0.688499\n",
      "Test set results: loss= 1.9534 accuracy= 759.0351\n",
      "test current auc-roc score: 0.907540, current macro_F score: 0.675217\n",
      "Epoch: 00642 loss_train: 0.1865 acc_train: 0.9320 loss_val: 1.8937 acc_val: 0.7030 time: 0.0180s\n",
      "valid current auc-roc score: 0.916160, current macro_F score: 0.679366\n",
      "Epoch: 00643 loss_train: 0.2064 acc_train: 0.9213 loss_val: 1.9848 acc_val: 0.7288 time: 0.0184s\n",
      "valid current auc-roc score: 0.912646, current macro_F score: 0.704377\n",
      "Epoch: 00644 loss_train: 0.1950 acc_train: 0.9356 loss_val: 1.7736 acc_val: 0.7140 time: 0.0212s\n",
      "valid current auc-roc score: 0.919447, current macro_F score: 0.692938\n",
      "Epoch: 00645 loss_train: 0.1975 acc_train: 0.9328 loss_val: 1.8345 acc_val: 0.7085 time: 0.0211s\n",
      "valid current auc-roc score: 0.911272, current macro_F score: 0.687712\n",
      "Epoch: 00646 loss_train: 0.2086 acc_train: 0.9349 loss_val: 1.5454 acc_val: 0.7066 time: 0.0335s\n",
      "valid current auc-roc score: 0.915430, current macro_F score: 0.677689\n",
      "Epoch: 00647 loss_train: 0.2186 acc_train: 0.9320 loss_val: 1.7104 acc_val: 0.7232 time: 0.0239s\n",
      "valid current auc-roc score: 0.916978, current macro_F score: 0.707833\n",
      "Epoch: 00648 loss_train: 0.2425 acc_train: 0.9220 loss_val: 1.5406 acc_val: 0.7140 time: 0.0249s\n",
      "valid current auc-roc score: 0.924818, current macro_F score: 0.690746\n",
      "Epoch: 00649 loss_train: 0.2411 acc_train: 0.9170 loss_val: 1.5700 acc_val: 0.6900 time: 0.0288s\n",
      "valid current auc-roc score: 0.917953, current macro_F score: 0.669231\n",
      "Epoch: 00650 loss_train: 0.2705 acc_train: 0.9192 loss_val: 1.6857 acc_val: 0.6974 time: 0.0215s\n",
      "valid current auc-roc score: 0.910375, current macro_F score: 0.684663\n",
      "Epoch: 00651 loss_train: 0.2186 acc_train: 0.9363 loss_val: 1.5922 acc_val: 0.7251 time: 0.0244s\n",
      "valid current auc-roc score: 0.916842, current macro_F score: 0.713722\n",
      "Test set results: loss= 1.6500 accuracy= 732.8948\n",
      "test current auc-roc score: 0.915163, current macro_F score: 0.708618\n",
      "Epoch: 00652 loss_train: 0.2115 acc_train: 0.9292 loss_val: 1.7287 acc_val: 0.7085 time: 0.0193s\n",
      "valid current auc-roc score: 0.906470, current macro_F score: 0.695762\n",
      "Epoch: 00653 loss_train: 0.2566 acc_train: 0.9106 loss_val: 1.6727 acc_val: 0.6771 time: 0.0211s\n",
      "valid current auc-roc score: 0.906776, current macro_F score: 0.659776\n",
      "Epoch: 00654 loss_train: 0.2750 acc_train: 0.9020 loss_val: 1.8262 acc_val: 0.6937 time: 0.0214s\n",
      "valid current auc-roc score: 0.915786, current macro_F score: 0.667949\n",
      "Epoch: 00655 loss_train: 0.3166 acc_train: 0.9020 loss_val: 1.5532 acc_val: 0.6974 time: 0.0219s\n",
      "valid current auc-roc score: 0.918922, current macro_F score: 0.676507\n",
      "Epoch: 00656 loss_train: 0.2677 acc_train: 0.9142 loss_val: 1.5712 acc_val: 0.7140 time: 0.0293s\n",
      "valid current auc-roc score: 0.915177, current macro_F score: 0.690509\n",
      "Epoch: 00657 loss_train: 0.2323 acc_train: 0.9256 loss_val: 1.6846 acc_val: 0.7196 time: 0.0354s\n",
      "valid current auc-roc score: 0.921255, current macro_F score: 0.696080\n",
      "Epoch: 00658 loss_train: 0.2255 acc_train: 0.9292 loss_val: 1.7303 acc_val: 0.7103 time: 0.0194s\n",
      "valid current auc-roc score: 0.920165, current macro_F score: 0.691923\n",
      "Epoch: 00659 loss_train: 0.2690 acc_train: 0.9127 loss_val: 2.0066 acc_val: 0.7103 time: 0.0218s\n",
      "valid current auc-roc score: 0.908801, current macro_F score: 0.697738\n",
      "Epoch: 00660 loss_train: 0.2614 acc_train: 0.9220 loss_val: 1.9311 acc_val: 0.7214 time: 0.0230s\n",
      "valid current auc-roc score: 0.916635, current macro_F score: 0.703999\n",
      "Epoch: 00661 loss_train: 0.3019 acc_train: 0.9034 loss_val: 1.9722 acc_val: 0.7066 time: 0.0217s\n",
      "valid current auc-roc score: 0.903434, current macro_F score: 0.685065\n",
      "Test set results: loss= 1.5725 accuracy= 713.8192\n",
      "test current auc-roc score: 0.925031, current macro_F score: 0.713093\n",
      "Epoch: 00662 loss_train: 0.2975 acc_train: 0.8991 loss_val: 2.0017 acc_val: 0.7030 time: 0.0227s\n",
      "valid current auc-roc score: 0.911105, current macro_F score: 0.687314\n",
      "Epoch: 00663 loss_train: 0.2437 acc_train: 0.9149 loss_val: 1.9013 acc_val: 0.6993 time: 0.0312s\n",
      "valid current auc-roc score: 0.915947, current macro_F score: 0.674516\n",
      "Epoch: 00664 loss_train: 0.2754 acc_train: 0.9034 loss_val: 1.5084 acc_val: 0.6790 time: 0.0299s\n",
      "valid current auc-roc score: 0.921164, current macro_F score: 0.649809\n",
      "Epoch: 00665 loss_train: 0.2608 acc_train: 0.9127 loss_val: 1.8144 acc_val: 0.7140 time: 0.0270s\n",
      "valid current auc-roc score: 0.915829, current macro_F score: 0.694558\n",
      "Epoch: 00666 loss_train: 0.2478 acc_train: 0.9185 loss_val: 1.4359 acc_val: 0.7232 time: 0.0214s\n",
      "valid current auc-roc score: 0.921267, current macro_F score: 0.702722\n",
      "Epoch: 00667 loss_train: 0.2424 acc_train: 0.9220 loss_val: 1.8380 acc_val: 0.7214 time: 0.0196s\n",
      "valid current auc-roc score: 0.922044, current macro_F score: 0.698309\n",
      "Epoch: 00668 loss_train: 0.2171 acc_train: 0.9299 loss_val: 1.8155 acc_val: 0.7122 time: 0.0184s\n",
      "valid current auc-roc score: 0.917954, current macro_F score: 0.683850\n",
      "Epoch: 00669 loss_train: 0.3007 acc_train: 0.9063 loss_val: 1.8317 acc_val: 0.7251 time: 0.0201s\n",
      "valid current auc-roc score: 0.918314, current macro_F score: 0.707393\n",
      "Epoch: 00670 loss_train: 0.2287 acc_train: 0.9227 loss_val: 1.4463 acc_val: 0.7343 time: 0.0247s\n",
      "valid current auc-roc score: 0.928776, current macro_F score: 0.711074\n",
      "Epoch: 00671 loss_train: 0.2335 acc_train: 0.9371 loss_val: 1.5051 acc_val: 0.7362 time: 0.0214s\n",
      "valid current auc-roc score: 0.926557, current macro_F score: 0.716610\n",
      "Test set results: loss= 1.5617 accuracy= 720.7159\n",
      "test current auc-roc score: 0.926314, current macro_F score: 0.716774\n",
      "Epoch: 00672 loss_train: 0.2517 acc_train: 0.9099 loss_val: 1.5517 acc_val: 0.7380 time: 0.0178s\n",
      "valid current auc-roc score: 0.925691, current macro_F score: 0.716749\n",
      "Epoch: 00673 loss_train: 0.2310 acc_train: 0.9263 loss_val: 1.7725 acc_val: 0.6900 time: 0.0210s\n",
      "valid current auc-roc score: 0.912595, current macro_F score: 0.661569\n",
      "Epoch: 00674 loss_train: 0.2644 acc_train: 0.9163 loss_val: 1.8823 acc_val: 0.7103 time: 0.0239s\n",
      "valid current auc-roc score: 0.914328, current macro_F score: 0.693859\n",
      "Epoch: 00675 loss_train: 0.2587 acc_train: 0.9285 loss_val: 2.0712 acc_val: 0.6919 time: 0.0198s\n",
      "valid current auc-roc score: 0.910806, current macro_F score: 0.677297\n",
      "Epoch: 00676 loss_train: 0.2775 acc_train: 0.9127 loss_val: 1.7589 acc_val: 0.7030 time: 0.0247s\n",
      "valid current auc-roc score: 0.906014, current macro_F score: 0.679563\n",
      "Epoch: 00677 loss_train: 0.2207 acc_train: 0.9199 loss_val: 2.0375 acc_val: 0.7030 time: 0.0251s\n",
      "valid current auc-roc score: 0.905095, current macro_F score: 0.672540\n",
      "Epoch: 00678 loss_train: 0.2328 acc_train: 0.9328 loss_val: 1.8910 acc_val: 0.7048 time: 0.0223s\n",
      "valid current auc-roc score: 0.914136, current macro_F score: 0.674131\n",
      "Epoch: 00679 loss_train: 0.2523 acc_train: 0.9185 loss_val: 1.7591 acc_val: 0.6956 time: 0.0208s\n",
      "valid current auc-roc score: 0.914000, current macro_F score: 0.664095\n",
      "Epoch: 00680 loss_train: 0.2552 acc_train: 0.9213 loss_val: 2.0008 acc_val: 0.6900 time: 0.0223s\n",
      "valid current auc-roc score: 0.904841, current macro_F score: 0.667560\n",
      "Epoch: 00681 loss_train: 0.2383 acc_train: 0.9242 loss_val: 1.7923 acc_val: 0.7159 time: 0.0214s\n",
      "valid current auc-roc score: 0.918198, current macro_F score: 0.683632\n",
      "Test set results: loss= 1.6193 accuracy= 740.9539\n",
      "test current auc-roc score: 0.919209, current macro_F score: 0.684768\n",
      "Epoch: 00682 loss_train: 0.2203 acc_train: 0.9220 loss_val: 1.7462 acc_val: 0.7030 time: 0.0185s\n",
      "valid current auc-roc score: 0.912067, current macro_F score: 0.680122\n",
      "Epoch: 00683 loss_train: 0.2407 acc_train: 0.9134 loss_val: 1.8292 acc_val: 0.7030 time: 0.0205s\n",
      "valid current auc-roc score: 0.909125, current macro_F score: 0.669234\n",
      "Epoch: 00684 loss_train: 0.2313 acc_train: 0.9242 loss_val: 1.8015 acc_val: 0.7196 time: 0.0183s\n",
      "valid current auc-roc score: 0.918026, current macro_F score: 0.691788\n",
      "Epoch: 00685 loss_train: 0.2537 acc_train: 0.9149 loss_val: 2.2527 acc_val: 0.6900 time: 0.0212s\n",
      "valid current auc-roc score: 0.906146, current macro_F score: 0.663504\n",
      "Epoch: 00686 loss_train: 0.2333 acc_train: 0.9199 loss_val: 1.5414 acc_val: 0.7232 time: 0.0212s\n",
      "valid current auc-roc score: 0.915510, current macro_F score: 0.699979\n",
      "Epoch: 00687 loss_train: 0.2291 acc_train: 0.9220 loss_val: 1.8877 acc_val: 0.7288 time: 0.0248s\n",
      "valid current auc-roc score: 0.910540, current macro_F score: 0.707133\n",
      "Epoch: 00688 loss_train: 0.2399 acc_train: 0.9113 loss_val: 1.7904 acc_val: 0.7103 time: 0.0268s\n",
      "valid current auc-roc score: 0.915297, current macro_F score: 0.690742\n",
      "Epoch: 00689 loss_train: 0.2535 acc_train: 0.9227 loss_val: 1.9292 acc_val: 0.7325 time: 0.0297s\n",
      "valid current auc-roc score: 0.914221, current macro_F score: 0.721033\n",
      "Epoch: 00690 loss_train: 0.2040 acc_train: 0.9270 loss_val: 1.8228 acc_val: 0.7066 time: 0.0214s\n",
      "valid current auc-roc score: 0.915102, current macro_F score: 0.691905\n",
      "Epoch: 00691 loss_train: 0.2258 acc_train: 0.9263 loss_val: 1.8001 acc_val: 0.7288 time: 0.0207s\n",
      "valid current auc-roc score: 0.913700, current macro_F score: 0.714731\n",
      "Test set results: loss= 1.6809 accuracy= 748.5092\n",
      "test current auc-roc score: 0.917262, current macro_F score: 0.690369\n",
      "Epoch: 00692 loss_train: 0.2111 acc_train: 0.9278 loss_val: 1.7137 acc_val: 0.7196 time: 0.0187s\n",
      "valid current auc-roc score: 0.915680, current macro_F score: 0.702625\n",
      "Epoch: 00693 loss_train: 0.2265 acc_train: 0.9256 loss_val: 1.9124 acc_val: 0.7417 time: 0.0211s\n",
      "valid current auc-roc score: 0.915281, current macro_F score: 0.721803\n",
      "Epoch: 00694 loss_train: 0.2375 acc_train: 0.9199 loss_val: 1.8600 acc_val: 0.7343 time: 0.0218s\n",
      "valid current auc-roc score: 0.919757, current macro_F score: 0.721065\n",
      "Epoch: 00695 loss_train: 0.2555 acc_train: 0.9163 loss_val: 1.7190 acc_val: 0.7140 time: 0.0237s\n",
      "valid current auc-roc score: 0.916362, current macro_F score: 0.680228\n",
      "Epoch: 00696 loss_train: 0.2205 acc_train: 0.9192 loss_val: 1.4508 acc_val: 0.7048 time: 0.0213s\n",
      "valid current auc-roc score: 0.927050, current macro_F score: 0.690925\n",
      "Epoch: 00697 loss_train: 0.2293 acc_train: 0.9256 loss_val: 1.5237 acc_val: 0.7085 time: 0.0225s\n",
      "valid current auc-roc score: 0.917965, current macro_F score: 0.673946\n",
      "Epoch: 00698 loss_train: 0.2157 acc_train: 0.9206 loss_val: 1.7233 acc_val: 0.7103 time: 0.0180s\n",
      "valid current auc-roc score: 0.917529, current macro_F score: 0.683294\n",
      "Epoch: 00699 loss_train: 0.2231 acc_train: 0.9127 loss_val: 1.7166 acc_val: 0.6974 time: 0.0194s\n",
      "valid current auc-roc score: 0.925170, current macro_F score: 0.670434\n",
      "Epoch: 00700 loss_train: 0.2207 acc_train: 0.9299 loss_val: 1.6234 acc_val: 0.7196 time: 0.0215s\n",
      "valid current auc-roc score: 0.930361, current macro_F score: 0.705491\n",
      "Epoch: 00701 loss_train: 0.2154 acc_train: 0.9299 loss_val: 2.0748 acc_val: 0.7103 time: 0.0186s\n",
      "valid current auc-roc score: 0.908571, current macro_F score: 0.696236\n",
      "Test set results: loss= 1.6437 accuracy= 734.9742\n",
      "test current auc-roc score: 0.922458, current macro_F score: 0.705299\n",
      "Epoch: 00702 loss_train: 0.2430 acc_train: 0.9199 loss_val: 2.0091 acc_val: 0.6974 time: 0.0222s\n",
      "valid current auc-roc score: 0.919591, current macro_F score: 0.674624\n",
      "Epoch: 00703 loss_train: 0.2294 acc_train: 0.9185 loss_val: 1.4860 acc_val: 0.7288 time: 0.0237s\n",
      "valid current auc-roc score: 0.922581, current macro_F score: 0.701103\n",
      "Epoch: 00704 loss_train: 0.2278 acc_train: 0.9263 loss_val: 1.7625 acc_val: 0.6974 time: 0.0194s\n",
      "valid current auc-roc score: 0.911574, current macro_F score: 0.664002\n",
      "Epoch: 00705 loss_train: 0.2447 acc_train: 0.9242 loss_val: 1.6389 acc_val: 0.7343 time: 0.0203s\n",
      "valid current auc-roc score: 0.924312, current macro_F score: 0.718252\n",
      "Epoch: 00706 loss_train: 0.1836 acc_train: 0.9371 loss_val: 1.8378 acc_val: 0.7159 time: 0.0248s\n",
      "valid current auc-roc score: 0.915391, current macro_F score: 0.701297\n",
      "Epoch: 00707 loss_train: 0.2136 acc_train: 0.9342 loss_val: 1.6132 acc_val: 0.7251 time: 0.0224s\n",
      "valid current auc-roc score: 0.922728, current macro_F score: 0.699123\n",
      "Epoch: 00708 loss_train: 0.2090 acc_train: 0.9285 loss_val: 1.5299 acc_val: 0.7232 time: 0.0256s\n",
      "valid current auc-roc score: 0.926578, current macro_F score: 0.708648\n",
      "Epoch: 00709 loss_train: 0.2129 acc_train: 0.9328 loss_val: 1.6237 acc_val: 0.7288 time: 0.0253s\n",
      "valid current auc-roc score: 0.921502, current macro_F score: 0.715620\n",
      "Epoch: 00710 loss_train: 0.2121 acc_train: 0.9320 loss_val: 1.6204 acc_val: 0.7306 time: 0.0308s\n",
      "valid current auc-roc score: 0.924656, current macro_F score: 0.715049\n",
      "Epoch: 00711 loss_train: 0.2300 acc_train: 0.9299 loss_val: 1.6357 acc_val: 0.7085 time: 0.0317s\n",
      "valid current auc-roc score: 0.916210, current macro_F score: 0.684855\n",
      "Test set results: loss= 1.5357 accuracy= 733.0886\n",
      "test current auc-roc score: 0.921444, current macro_F score: 0.695330\n",
      "Epoch: 00712 loss_train: 0.2102 acc_train: 0.9270 loss_val: 1.7172 acc_val: 0.7232 time: 0.0180s\n",
      "valid current auc-roc score: 0.916328, current macro_F score: 0.712325\n",
      "Epoch: 00713 loss_train: 0.2161 acc_train: 0.9270 loss_val: 1.8404 acc_val: 0.6974 time: 0.0173s\n",
      "valid current auc-roc score: 0.914903, current macro_F score: 0.679018\n",
      "Epoch: 00714 loss_train: 0.2357 acc_train: 0.9263 loss_val: 1.7378 acc_val: 0.7066 time: 0.0194s\n",
      "valid current auc-roc score: 0.917892, current macro_F score: 0.684553\n",
      "Epoch: 00715 loss_train: 0.2261 acc_train: 0.9278 loss_val: 1.5694 acc_val: 0.7011 time: 0.0249s\n",
      "valid current auc-roc score: 0.915676, current macro_F score: 0.683106\n",
      "Epoch: 00716 loss_train: 0.2433 acc_train: 0.9185 loss_val: 1.7348 acc_val: 0.7159 time: 0.0206s\n",
      "valid current auc-roc score: 0.925047, current macro_F score: 0.693776\n",
      "Epoch: 00717 loss_train: 0.2255 acc_train: 0.9285 loss_val: 1.5891 acc_val: 0.7122 time: 0.0197s\n",
      "valid current auc-roc score: 0.917330, current macro_F score: 0.693398\n",
      "Epoch: 00718 loss_train: 0.2364 acc_train: 0.9220 loss_val: 1.6213 acc_val: 0.6993 time: 0.0206s\n",
      "valid current auc-roc score: 0.912652, current macro_F score: 0.670688\n",
      "Epoch: 00719 loss_train: 0.2007 acc_train: 0.9306 loss_val: 1.6085 acc_val: 0.7343 time: 0.0372s\n",
      "valid current auc-roc score: 0.916918, current macro_F score: 0.713585\n",
      "Epoch: 00720 loss_train: 0.2251 acc_train: 0.9306 loss_val: 1.9532 acc_val: 0.7177 time: 0.0203s\n",
      "valid current auc-roc score: 0.912832, current macro_F score: 0.692870\n",
      "Epoch: 00721 loss_train: 0.2119 acc_train: 0.9320 loss_val: 1.6452 acc_val: 0.7196 time: 0.0203s\n",
      "valid current auc-roc score: 0.913723, current macro_F score: 0.704728\n",
      "Test set results: loss= 1.6898 accuracy= 743.1624\n",
      "test current auc-roc score: 0.917273, current macro_F score: 0.715503\n",
      "Epoch: 00722 loss_train: 0.2401 acc_train: 0.9270 loss_val: 1.8438 acc_val: 0.7214 time: 0.0271s\n",
      "valid current auc-roc score: 0.915897, current macro_F score: 0.702151\n",
      "Epoch: 00723 loss_train: 0.2583 acc_train: 0.9177 loss_val: 2.1147 acc_val: 0.6956 time: 0.0271s\n",
      "valid current auc-roc score: 0.903443, current macro_F score: 0.674041\n",
      "Epoch: 00724 loss_train: 0.1910 acc_train: 0.9328 loss_val: 1.5480 acc_val: 0.7140 time: 0.0187s\n",
      "valid current auc-roc score: 0.917776, current macro_F score: 0.685108\n",
      "Epoch: 00725 loss_train: 0.2000 acc_train: 0.9335 loss_val: 1.5488 acc_val: 0.7214 time: 0.0201s\n",
      "valid current auc-roc score: 0.915653, current macro_F score: 0.702572\n",
      "Epoch: 00726 loss_train: 0.2123 acc_train: 0.9199 loss_val: 1.3593 acc_val: 0.7417 time: 0.0231s\n",
      "valid current auc-roc score: 0.928503, current macro_F score: 0.719385\n",
      "Epoch: 00727 loss_train: 0.2293 acc_train: 0.9142 loss_val: 1.5035 acc_val: 0.7362 time: 0.0201s\n",
      "valid current auc-roc score: 0.920118, current macro_F score: 0.727395\n",
      "Epoch: 00728 loss_train: 0.2104 acc_train: 0.9227 loss_val: 1.5591 acc_val: 0.7306 time: 0.0180s\n",
      "valid current auc-roc score: 0.931051, current macro_F score: 0.721304\n",
      "Epoch: 00729 loss_train: 0.1898 acc_train: 0.9320 loss_val: 1.6487 acc_val: 0.7048 time: 0.0173s\n",
      "valid current auc-roc score: 0.919914, current macro_F score: 0.683769\n",
      "Epoch: 00730 loss_train: 0.1929 acc_train: 0.9406 loss_val: 1.8908 acc_val: 0.7232 time: 0.0185s\n",
      "valid current auc-roc score: 0.913496, current macro_F score: 0.700118\n",
      "Epoch: 00731 loss_train: 0.1988 acc_train: 0.9299 loss_val: 1.5595 acc_val: 0.7122 time: 0.0243s\n",
      "valid current auc-roc score: 0.917144, current macro_F score: 0.695882\n",
      "Test set results: loss= 1.6643 accuracy= 727.0701\n",
      "test current auc-roc score: 0.914804, current macro_F score: 0.697621\n",
      "Epoch: 00732 loss_train: 0.2267 acc_train: 0.9227 loss_val: 1.5402 acc_val: 0.7288 time: 0.0225s\n",
      "valid current auc-roc score: 0.932354, current macro_F score: 0.708499\n",
      "Epoch: 00733 loss_train: 0.1883 acc_train: 0.9363 loss_val: 1.6417 acc_val: 0.6993 time: 0.0224s\n",
      "valid current auc-roc score: 0.914253, current macro_F score: 0.675138\n",
      "Epoch: 00734 loss_train: 0.1814 acc_train: 0.9349 loss_val: 1.7096 acc_val: 0.7509 time: 0.0243s\n",
      "valid current auc-roc score: 0.924380, current macro_F score: 0.731579\n",
      "Epoch: 00735 loss_train: 0.1858 acc_train: 0.9356 loss_val: 1.8062 acc_val: 0.7159 time: 0.0220s\n",
      "valid current auc-roc score: 0.923032, current macro_F score: 0.685886\n",
      "Epoch: 00736 loss_train: 0.1976 acc_train: 0.9356 loss_val: 1.7395 acc_val: 0.7232 time: 0.0197s\n",
      "valid current auc-roc score: 0.909406, current macro_F score: 0.705178\n",
      "Epoch: 00737 loss_train: 0.2116 acc_train: 0.9292 loss_val: 1.6378 acc_val: 0.7196 time: 0.0214s\n",
      "valid current auc-roc score: 0.908710, current macro_F score: 0.690332\n",
      "Epoch: 00738 loss_train: 0.1740 acc_train: 0.9435 loss_val: 2.2091 acc_val: 0.7399 time: 0.0180s\n",
      "valid current auc-roc score: 0.923806, current macro_F score: 0.719290\n",
      "Epoch: 00739 loss_train: 0.1880 acc_train: 0.9392 loss_val: 1.7923 acc_val: 0.7232 time: 0.0182s\n",
      "valid current auc-roc score: 0.907969, current macro_F score: 0.702905\n",
      "Epoch: 00740 loss_train: 0.2122 acc_train: 0.9306 loss_val: 1.7011 acc_val: 0.7306 time: 0.0208s\n",
      "valid current auc-roc score: 0.924844, current macro_F score: 0.698647\n",
      "Epoch: 00741 loss_train: 0.1949 acc_train: 0.9399 loss_val: 1.9381 acc_val: 0.7159 time: 0.0258s\n",
      "valid current auc-roc score: 0.907794, current macro_F score: 0.693401\n",
      "Test set results: loss= 1.7667 accuracy= 745.4225\n",
      "test current auc-roc score: 0.915503, current macro_F score: 0.692244\n",
      "Epoch: 00742 loss_train: 0.1818 acc_train: 0.9413 loss_val: 1.6599 acc_val: 0.7306 time: 0.0180s\n",
      "valid current auc-roc score: 0.916898, current macro_F score: 0.716387\n",
      "Epoch: 00743 loss_train: 0.1956 acc_train: 0.9313 loss_val: 1.5800 acc_val: 0.7085 time: 0.0186s\n",
      "valid current auc-roc score: 0.920696, current macro_F score: 0.690499\n",
      "Epoch: 00744 loss_train: 0.1894 acc_train: 0.9320 loss_val: 1.8915 acc_val: 0.7159 time: 0.0182s\n",
      "valid current auc-roc score: 0.911389, current macro_F score: 0.688624\n",
      "Epoch: 00745 loss_train: 0.1974 acc_train: 0.9285 loss_val: 1.4930 acc_val: 0.7306 time: 0.0225s\n",
      "valid current auc-roc score: 0.928241, current macro_F score: 0.709839\n",
      "Epoch: 00746 loss_train: 0.1917 acc_train: 0.9385 loss_val: 1.8709 acc_val: 0.7140 time: 0.0188s\n",
      "valid current auc-roc score: 0.922183, current macro_F score: 0.684893\n",
      "Epoch: 00747 loss_train: 0.1780 acc_train: 0.9385 loss_val: 1.7309 acc_val: 0.7214 time: 0.0211s\n",
      "valid current auc-roc score: 0.923882, current macro_F score: 0.702823\n",
      "Epoch: 00748 loss_train: 0.2057 acc_train: 0.9263 loss_val: 1.6796 acc_val: 0.7159 time: 0.0245s\n",
      "valid current auc-roc score: 0.920396, current macro_F score: 0.698482\n",
      "Epoch: 00749 loss_train: 0.2130 acc_train: 0.9320 loss_val: 1.5989 acc_val: 0.7103 time: 0.0205s\n",
      "valid current auc-roc score: 0.919554, current macro_F score: 0.689882\n",
      "Epoch: 00750 loss_train: 0.2056 acc_train: 0.9285 loss_val: 1.7859 acc_val: 0.7122 time: 0.0234s\n",
      "valid current auc-roc score: 0.914323, current macro_F score: 0.680689\n",
      "Epoch: 00751 loss_train: 0.2185 acc_train: 0.9278 loss_val: 1.7915 acc_val: 0.7288 time: 0.0218s\n",
      "valid current auc-roc score: 0.921020, current macro_F score: 0.710961\n",
      "Test set results: loss= 1.7599 accuracy= 733.9539\n",
      "test current auc-roc score: 0.916499, current macro_F score: 0.694655\n",
      "Epoch: 00752 loss_train: 0.1862 acc_train: 0.9299 loss_val: 1.7221 acc_val: 0.7269 time: 0.0228s\n",
      "valid current auc-roc score: 0.912856, current macro_F score: 0.704919\n",
      "Epoch: 00753 loss_train: 0.1875 acc_train: 0.9349 loss_val: 1.7684 acc_val: 0.7140 time: 0.0235s\n",
      "valid current auc-roc score: 0.919509, current macro_F score: 0.691171\n",
      "Epoch: 00754 loss_train: 0.2311 acc_train: 0.9249 loss_val: 1.8462 acc_val: 0.7122 time: 0.0219s\n",
      "valid current auc-roc score: 0.917994, current macro_F score: 0.689152\n",
      "Epoch: 00755 loss_train: 0.2070 acc_train: 0.9299 loss_val: 1.6527 acc_val: 0.7288 time: 0.0221s\n",
      "valid current auc-roc score: 0.931929, current macro_F score: 0.715062\n",
      "Epoch: 00756 loss_train: 0.1963 acc_train: 0.9335 loss_val: 1.6283 acc_val: 0.7362 time: 0.0282s\n",
      "valid current auc-roc score: 0.923365, current macro_F score: 0.721826\n",
      "Epoch: 00757 loss_train: 0.2220 acc_train: 0.9263 loss_val: 1.6891 acc_val: 0.7177 time: 0.0181s\n",
      "valid current auc-roc score: 0.927919, current macro_F score: 0.698658\n",
      "Epoch: 00758 loss_train: 0.2034 acc_train: 0.9392 loss_val: 1.9636 acc_val: 0.7177 time: 0.0229s\n",
      "valid current auc-roc score: 0.927482, current macro_F score: 0.703418\n",
      "Epoch: 00759 loss_train: 0.2308 acc_train: 0.9256 loss_val: 1.6778 acc_val: 0.7528 time: 0.0190s\n",
      "valid current auc-roc score: 0.922564, current macro_F score: 0.732319\n",
      "Epoch: 00760 loss_train: 0.1953 acc_train: 0.9278 loss_val: 1.7904 acc_val: 0.7140 time: 0.0237s\n",
      "valid current auc-roc score: 0.915455, current macro_F score: 0.685034\n",
      "Epoch: 00761 loss_train: 0.2124 acc_train: 0.9249 loss_val: 1.8412 acc_val: 0.7085 time: 0.0203s\n",
      "valid current auc-roc score: 0.925069, current macro_F score: 0.687216\n",
      "Test set results: loss= 1.6378 accuracy= 720.3284\n",
      "test current auc-roc score: 0.924176, current macro_F score: 0.705588\n",
      "Epoch: 00762 loss_train: 0.2313 acc_train: 0.9192 loss_val: 1.6261 acc_val: 0.7159 time: 0.0207s\n",
      "valid current auc-roc score: 0.921758, current macro_F score: 0.704434\n",
      "Epoch: 00763 loss_train: 0.2206 acc_train: 0.9213 loss_val: 1.7478 acc_val: 0.7251 time: 0.0232s\n",
      "valid current auc-roc score: 0.924124, current macro_F score: 0.708051\n",
      "Epoch: 00764 loss_train: 0.2201 acc_train: 0.9313 loss_val: 2.2393 acc_val: 0.6919 time: 0.0205s\n",
      "valid current auc-roc score: 0.906937, current macro_F score: 0.664340\n",
      "Epoch: 00765 loss_train: 0.1990 acc_train: 0.9313 loss_val: 2.0337 acc_val: 0.7269 time: 0.0203s\n",
      "valid current auc-roc score: 0.919937, current macro_F score: 0.707576\n",
      "Epoch: 00766 loss_train: 0.1998 acc_train: 0.9371 loss_val: 1.6465 acc_val: 0.7177 time: 0.0201s\n",
      "valid current auc-roc score: 0.919282, current macro_F score: 0.692955\n",
      "Epoch: 00767 loss_train: 0.2291 acc_train: 0.9220 loss_val: 1.9980 acc_val: 0.7011 time: 0.0217s\n",
      "valid current auc-roc score: 0.914987, current macro_F score: 0.680467\n",
      "Epoch: 00768 loss_train: 0.2222 acc_train: 0.9220 loss_val: 1.5117 acc_val: 0.7288 time: 0.0233s\n",
      "valid current auc-roc score: 0.926773, current macro_F score: 0.705697\n",
      "Epoch: 00769 loss_train: 0.1681 acc_train: 0.9413 loss_val: 1.4606 acc_val: 0.7362 time: 0.0307s\n",
      "valid current auc-roc score: 0.929580, current macro_F score: 0.715815\n",
      "Epoch: 00770 loss_train: 0.2006 acc_train: 0.9378 loss_val: 1.6857 acc_val: 0.7085 time: 0.0234s\n",
      "valid current auc-roc score: 0.921596, current macro_F score: 0.689095\n",
      "Epoch: 00771 loss_train: 0.2265 acc_train: 0.9263 loss_val: 1.5907 acc_val: 0.7122 time: 0.0220s\n",
      "valid current auc-roc score: 0.917607, current macro_F score: 0.681336\n",
      "Test set results: loss= 1.5593 accuracy= 710.9779\n",
      "test current auc-roc score: 0.924818, current macro_F score: 0.704266\n",
      "Epoch: 00772 loss_train: 0.2032 acc_train: 0.9371 loss_val: 1.8029 acc_val: 0.7343 time: 0.0183s\n",
      "valid current auc-roc score: 0.918605, current macro_F score: 0.709480\n",
      "Epoch: 00773 loss_train: 0.2027 acc_train: 0.9249 loss_val: 1.3026 acc_val: 0.7325 time: 0.0199s\n",
      "valid current auc-roc score: 0.923718, current macro_F score: 0.707406\n",
      "Epoch: 00774 loss_train: 0.1906 acc_train: 0.9385 loss_val: 1.8001 acc_val: 0.7177 time: 0.0225s\n",
      "valid current auc-roc score: 0.924344, current macro_F score: 0.706508\n",
      "Epoch: 00775 loss_train: 0.2290 acc_train: 0.9242 loss_val: 1.6883 acc_val: 0.6974 time: 0.0275s\n",
      "valid current auc-roc score: 0.915496, current macro_F score: 0.676953\n",
      "Epoch: 00776 loss_train: 0.1812 acc_train: 0.9421 loss_val: 1.6758 acc_val: 0.7232 time: 0.0328s\n",
      "valid current auc-roc score: 0.922422, current macro_F score: 0.702202\n",
      "Epoch: 00777 loss_train: 0.2080 acc_train: 0.9292 loss_val: 1.5727 acc_val: 0.7085 time: 0.0206s\n",
      "valid current auc-roc score: 0.918114, current macro_F score: 0.690070\n",
      "Epoch: 00778 loss_train: 0.2049 acc_train: 0.9471 loss_val: 1.4713 acc_val: 0.7048 time: 0.0195s\n",
      "valid current auc-roc score: 0.921780, current macro_F score: 0.677163\n",
      "Epoch: 00779 loss_train: 0.1876 acc_train: 0.9299 loss_val: 1.7974 acc_val: 0.7269 time: 0.0171s\n",
      "valid current auc-roc score: 0.915778, current macro_F score: 0.705295\n",
      "Epoch: 00780 loss_train: 0.2051 acc_train: 0.9378 loss_val: 1.4900 acc_val: 0.7048 time: 0.0182s\n",
      "valid current auc-roc score: 0.920265, current macro_F score: 0.681631\n",
      "Epoch: 00781 loss_train: 0.1993 acc_train: 0.9249 loss_val: 1.4956 acc_val: 0.7232 time: 0.0287s\n",
      "valid current auc-roc score: 0.922012, current macro_F score: 0.697738\n",
      "Test set results: loss= 1.6490 accuracy= 733.1402\n",
      "test current auc-roc score: 0.920525, current macro_F score: 0.690379\n",
      "Epoch: 00782 loss_train: 0.2109 acc_train: 0.9328 loss_val: 1.4807 acc_val: 0.7066 time: 0.0224s\n",
      "valid current auc-roc score: 0.926858, current macro_F score: 0.678128\n",
      "Epoch: 00783 loss_train: 0.1772 acc_train: 0.9456 loss_val: 1.4713 acc_val: 0.7399 time: 0.0218s\n",
      "valid current auc-roc score: 0.928069, current macro_F score: 0.720882\n",
      "Epoch: 00784 loss_train: 0.1940 acc_train: 0.9306 loss_val: 2.0918 acc_val: 0.7140 time: 0.0199s\n",
      "valid current auc-roc score: 0.910751, current macro_F score: 0.697905\n",
      "Epoch: 00785 loss_train: 0.1907 acc_train: 0.9342 loss_val: 2.1679 acc_val: 0.6956 time: 0.0197s\n",
      "valid current auc-roc score: 0.910658, current macro_F score: 0.670968\n",
      "Epoch: 00786 loss_train: 0.2503 acc_train: 0.9306 loss_val: 1.7452 acc_val: 0.7140 time: 0.0249s\n",
      "valid current auc-roc score: 0.920444, current macro_F score: 0.697472\n",
      "Epoch: 00787 loss_train: 0.2153 acc_train: 0.9421 loss_val: 1.9020 acc_val: 0.7214 time: 0.0224s\n",
      "valid current auc-roc score: 0.916174, current macro_F score: 0.703442\n",
      "Epoch: 00788 loss_train: 0.2044 acc_train: 0.9356 loss_val: 1.7081 acc_val: 0.7251 time: 0.0196s\n",
      "valid current auc-roc score: 0.924060, current macro_F score: 0.702742\n",
      "Epoch: 00789 loss_train: 0.1967 acc_train: 0.9342 loss_val: 1.5303 acc_val: 0.7269 time: 0.0281s\n",
      "valid current auc-roc score: 0.930290, current macro_F score: 0.704767\n",
      "Epoch: 00790 loss_train: 0.1992 acc_train: 0.9335 loss_val: 1.7268 acc_val: 0.7030 time: 0.0289s\n",
      "valid current auc-roc score: 0.915549, current macro_F score: 0.675188\n",
      "Epoch: 00791 loss_train: 0.2010 acc_train: 0.9235 loss_val: 1.5715 acc_val: 0.7214 time: 0.0179s\n",
      "valid current auc-roc score: 0.916677, current macro_F score: 0.695487\n",
      "Test set results: loss= 1.6863 accuracy= 732.0554\n",
      "test current auc-roc score: 0.916843, current macro_F score: 0.712831\n",
      "Epoch: 00792 loss_train: 0.2117 acc_train: 0.9313 loss_val: 1.8960 acc_val: 0.7030 time: 0.0165s\n",
      "valid current auc-roc score: 0.909200, current macro_F score: 0.679719\n",
      "Epoch: 00793 loss_train: 0.2322 acc_train: 0.9227 loss_val: 1.7738 acc_val: 0.7159 time: 0.0191s\n",
      "valid current auc-roc score: 0.911764, current macro_F score: 0.685006\n",
      "Epoch: 00794 loss_train: 0.2132 acc_train: 0.9206 loss_val: 2.0235 acc_val: 0.7325 time: 0.0186s\n",
      "valid current auc-roc score: 0.910523, current macro_F score: 0.713454\n",
      "Epoch: 00795 loss_train: 0.1997 acc_train: 0.9320 loss_val: 1.4994 acc_val: 0.7380 time: 0.0198s\n",
      "valid current auc-roc score: 0.928907, current macro_F score: 0.729873\n",
      "Epoch: 00796 loss_train: 0.1933 acc_train: 0.9413 loss_val: 1.8155 acc_val: 0.6993 time: 0.0206s\n",
      "valid current auc-roc score: 0.914930, current macro_F score: 0.674577\n",
      "Epoch: 00797 loss_train: 0.2040 acc_train: 0.9206 loss_val: 1.9330 acc_val: 0.7491 time: 0.0222s\n",
      "valid current auc-roc score: 0.919918, current macro_F score: 0.734471\n",
      "Epoch: 00798 loss_train: 0.2239 acc_train: 0.9249 loss_val: 1.8691 acc_val: 0.7362 time: 0.0205s\n",
      "valid current auc-roc score: 0.920566, current macro_F score: 0.710219\n",
      "Epoch: 00799 loss_train: 0.1901 acc_train: 0.9371 loss_val: 1.6149 acc_val: 0.7011 time: 0.0246s\n",
      "valid current auc-roc score: 0.920076, current macro_F score: 0.679214\n",
      "Epoch: 00800 loss_train: 0.1939 acc_train: 0.9356 loss_val: 1.8765 acc_val: 0.7454 time: 0.0190s\n",
      "valid current auc-roc score: 0.915454, current macro_F score: 0.723593\n",
      "Epoch: 00801 loss_train: 0.1936 acc_train: 0.9349 loss_val: 1.9901 acc_val: 0.6993 time: 0.0177s\n",
      "valid current auc-roc score: 0.912843, current macro_F score: 0.671301\n",
      "Test set results: loss= 1.8228 accuracy= 733.9797\n",
      "test current auc-roc score: 0.909561, current macro_F score: 0.687860\n",
      "Epoch: 00802 loss_train: 0.2434 acc_train: 0.9242 loss_val: 1.9678 acc_val: 0.7066 time: 0.0190s\n",
      "valid current auc-roc score: 0.910403, current macro_F score: 0.688041\n",
      "Epoch: 00803 loss_train: 0.1913 acc_train: 0.9421 loss_val: 2.0460 acc_val: 0.7066 time: 0.0197s\n",
      "valid current auc-roc score: 0.912503, current macro_F score: 0.682522\n",
      "Epoch: 00804 loss_train: 0.2117 acc_train: 0.9242 loss_val: 2.0148 acc_val: 0.7048 time: 0.0212s\n",
      "valid current auc-roc score: 0.912348, current macro_F score: 0.679850\n",
      "Epoch: 00805 loss_train: 0.2124 acc_train: 0.9270 loss_val: 1.5748 acc_val: 0.7030 time: 0.0192s\n",
      "valid current auc-roc score: 0.921084, current macro_F score: 0.676944\n",
      "Epoch: 00806 loss_train: 0.1946 acc_train: 0.9428 loss_val: 2.2433 acc_val: 0.6863 time: 0.0193s\n",
      "valid current auc-roc score: 0.906564, current macro_F score: 0.655242\n",
      "Epoch: 00807 loss_train: 0.1652 acc_train: 0.9392 loss_val: 1.8895 acc_val: 0.7085 time: 0.0197s\n",
      "valid current auc-roc score: 0.919565, current macro_F score: 0.688397\n",
      "Epoch: 00808 loss_train: 0.1820 acc_train: 0.9392 loss_val: 1.6973 acc_val: 0.7196 time: 0.0223s\n",
      "valid current auc-roc score: 0.917672, current macro_F score: 0.701994\n",
      "Epoch: 00809 loss_train: 0.2053 acc_train: 0.9285 loss_val: 2.0344 acc_val: 0.7140 time: 0.0227s\n",
      "valid current auc-roc score: 0.915802, current macro_F score: 0.694090\n",
      "Epoch: 00810 loss_train: 0.1934 acc_train: 0.9378 loss_val: 1.9037 acc_val: 0.7066 time: 0.0194s\n",
      "valid current auc-roc score: 0.916634, current macro_F score: 0.679042\n",
      "Epoch: 00811 loss_train: 0.1981 acc_train: 0.9335 loss_val: 1.8267 acc_val: 0.7140 time: 0.0209s\n",
      "valid current auc-roc score: 0.915035, current macro_F score: 0.694358\n",
      "Test set results: loss= 1.7529 accuracy= 734.0959\n",
      "test current auc-roc score: 0.916409, current macro_F score: 0.703394\n",
      "Epoch: 00812 loss_train: 0.1871 acc_train: 0.9342 loss_val: 1.6555 acc_val: 0.7435 time: 0.0198s\n",
      "valid current auc-roc score: 0.926988, current macro_F score: 0.729871\n",
      "Epoch: 00813 loss_train: 0.2276 acc_train: 0.9270 loss_val: 1.6930 acc_val: 0.7196 time: 0.0179s\n",
      "valid current auc-roc score: 0.924185, current macro_F score: 0.703370\n",
      "Epoch: 00814 loss_train: 0.1897 acc_train: 0.9385 loss_val: 1.5516 acc_val: 0.7196 time: 0.0229s\n",
      "valid current auc-roc score: 0.924055, current macro_F score: 0.692571\n",
      "Epoch: 00815 loss_train: 0.1770 acc_train: 0.9385 loss_val: 1.7050 acc_val: 0.7177 time: 0.0203s\n",
      "valid current auc-roc score: 0.920426, current macro_F score: 0.694143\n",
      "Epoch: 00816 loss_train: 0.1905 acc_train: 0.9363 loss_val: 1.6246 acc_val: 0.7196 time: 0.0178s\n",
      "valid current auc-roc score: 0.921905, current macro_F score: 0.698863\n",
      "Epoch: 00817 loss_train: 0.1973 acc_train: 0.9335 loss_val: 1.6305 acc_val: 0.7030 time: 0.0179s\n",
      "valid current auc-roc score: 0.923487, current macro_F score: 0.673493\n",
      "Epoch: 00818 loss_train: 0.1697 acc_train: 0.9356 loss_val: 1.5650 acc_val: 0.7362 time: 0.0212s\n",
      "valid current auc-roc score: 0.929422, current macro_F score: 0.721860\n",
      "Epoch: 00819 loss_train: 0.2078 acc_train: 0.9249 loss_val: 1.8456 acc_val: 0.7232 time: 0.0182s\n",
      "valid current auc-roc score: 0.915129, current macro_F score: 0.700286\n",
      "Epoch: 00820 loss_train: 0.1847 acc_train: 0.9442 loss_val: 1.8361 acc_val: 0.7177 time: 0.0212s\n",
      "valid current auc-roc score: 0.919463, current macro_F score: 0.690823\n",
      "Epoch: 00821 loss_train: 0.1974 acc_train: 0.9392 loss_val: 2.0435 acc_val: 0.7140 time: 0.0208s\n",
      "valid current auc-roc score: 0.914774, current macro_F score: 0.688817\n",
      "Test set results: loss= 1.6880 accuracy= 738.3967\n",
      "test current auc-roc score: 0.922166, current macro_F score: 0.686308\n",
      "Epoch: 00822 loss_train: 0.1894 acc_train: 0.9292 loss_val: 1.7194 acc_val: 0.6993 time: 0.0297s\n",
      "valid current auc-roc score: 0.913028, current macro_F score: 0.678664\n",
      "Epoch: 00823 loss_train: 0.1769 acc_train: 0.9356 loss_val: 1.7182 acc_val: 0.7122 time: 0.0203s\n",
      "valid current auc-roc score: 0.922630, current macro_F score: 0.694612\n",
      "Epoch: 00824 loss_train: 0.2137 acc_train: 0.9356 loss_val: 1.9611 acc_val: 0.7066 time: 0.0233s\n",
      "valid current auc-roc score: 0.920317, current macro_F score: 0.686896\n",
      "Epoch: 00825 loss_train: 0.1765 acc_train: 0.9349 loss_val: 1.6603 acc_val: 0.7103 time: 0.0209s\n",
      "valid current auc-roc score: 0.916043, current macro_F score: 0.684927\n",
      "Epoch: 00826 loss_train: 0.1950 acc_train: 0.9399 loss_val: 1.7924 acc_val: 0.6993 time: 0.0203s\n",
      "valid current auc-roc score: 0.923791, current macro_F score: 0.673646\n",
      "Epoch: 00827 loss_train: 0.1902 acc_train: 0.9399 loss_val: 1.6411 acc_val: 0.7362 time: 0.0229s\n",
      "valid current auc-roc score: 0.925703, current macro_F score: 0.708689\n",
      "Epoch: 00828 loss_train: 0.1949 acc_train: 0.9342 loss_val: 1.9407 acc_val: 0.7103 time: 0.0276s\n",
      "valid current auc-roc score: 0.915429, current macro_F score: 0.681277\n",
      "Epoch: 00829 loss_train: 0.1927 acc_train: 0.9335 loss_val: 1.6831 acc_val: 0.7066 time: 0.0236s\n",
      "valid current auc-roc score: 0.914175, current macro_F score: 0.685599\n",
      "Epoch: 00830 loss_train: 0.1914 acc_train: 0.9328 loss_val: 1.7680 acc_val: 0.7030 time: 0.0250s\n",
      "valid current auc-roc score: 0.917187, current macro_F score: 0.678203\n",
      "Epoch: 00831 loss_train: 0.1983 acc_train: 0.9328 loss_val: 1.8079 acc_val: 0.7030 time: 0.0288s\n",
      "valid current auc-roc score: 0.911145, current macro_F score: 0.676930\n",
      "Test set results: loss= 1.6862 accuracy= 742.2454\n",
      "test current auc-roc score: 0.918670, current macro_F score: 0.688979\n",
      "Epoch: 00832 loss_train: 0.1969 acc_train: 0.9363 loss_val: 1.9056 acc_val: 0.6956 time: 0.0201s\n",
      "valid current auc-roc score: 0.910661, current macro_F score: 0.677035\n",
      "Epoch: 00833 loss_train: 0.2055 acc_train: 0.9313 loss_val: 1.7984 acc_val: 0.7122 time: 0.0264s\n",
      "valid current auc-roc score: 0.915864, current macro_F score: 0.688493\n",
      "Epoch: 00834 loss_train: 0.2073 acc_train: 0.9292 loss_val: 1.6898 acc_val: 0.7214 time: 0.0225s\n",
      "valid current auc-roc score: 0.919522, current macro_F score: 0.707818\n",
      "Epoch: 00835 loss_train: 0.2044 acc_train: 0.9313 loss_val: 1.7918 acc_val: 0.6956 time: 0.0208s\n",
      "valid current auc-roc score: 0.913000, current macro_F score: 0.680574\n",
      "Epoch: 00836 loss_train: 0.1867 acc_train: 0.9328 loss_val: 1.9223 acc_val: 0.7435 time: 0.0411s\n",
      "valid current auc-roc score: 0.923528, current macro_F score: 0.730842\n",
      "Epoch: 00837 loss_train: 0.2064 acc_train: 0.9313 loss_val: 1.6066 acc_val: 0.7435 time: 0.0231s\n",
      "valid current auc-roc score: 0.923389, current macro_F score: 0.724534\n",
      "Epoch: 00838 loss_train: 0.2067 acc_train: 0.9335 loss_val: 1.8780 acc_val: 0.7066 time: 0.0192s\n",
      "valid current auc-roc score: 0.917452, current macro_F score: 0.680574\n",
      "Epoch: 00839 loss_train: 0.1841 acc_train: 0.9421 loss_val: 1.7901 acc_val: 0.7122 time: 0.0205s\n",
      "valid current auc-roc score: 0.925949, current macro_F score: 0.688818\n",
      "Epoch: 00840 loss_train: 0.1763 acc_train: 0.9392 loss_val: 1.8357 acc_val: 0.7196 time: 0.0205s\n",
      "valid current auc-roc score: 0.913872, current macro_F score: 0.695773\n",
      "Epoch: 00841 loss_train: 0.1902 acc_train: 0.9371 loss_val: 1.6304 acc_val: 0.7343 time: 0.0187s\n",
      "valid current auc-roc score: 0.925992, current macro_F score: 0.708944\n",
      "Test set results: loss= 1.8015 accuracy= 736.1236\n",
      "test current auc-roc score: 0.916374, current macro_F score: 0.690563\n",
      "Epoch: 00842 loss_train: 0.2129 acc_train: 0.9320 loss_val: 1.7538 acc_val: 0.7103 time: 0.0177s\n",
      "valid current auc-roc score: 0.915337, current macro_F score: 0.689108\n",
      "Epoch: 00843 loss_train: 0.1936 acc_train: 0.9342 loss_val: 1.5987 acc_val: 0.7159 time: 0.0189s\n",
      "valid current auc-roc score: 0.922544, current macro_F score: 0.690668\n",
      "Epoch: 00844 loss_train: 0.1862 acc_train: 0.9435 loss_val: 2.2939 acc_val: 0.7085 time: 0.0218s\n",
      "valid current auc-roc score: 0.924212, current macro_F score: 0.686009\n",
      "Epoch: 00845 loss_train: 0.2105 acc_train: 0.9270 loss_val: 1.7631 acc_val: 0.7140 time: 0.0254s\n",
      "valid current auc-roc score: 0.921560, current macro_F score: 0.678597\n",
      "Epoch: 00846 loss_train: 0.1824 acc_train: 0.9356 loss_val: 2.1784 acc_val: 0.7232 time: 0.0238s\n",
      "valid current auc-roc score: 0.919616, current macro_F score: 0.700402\n",
      "Epoch: 00847 loss_train: 0.1738 acc_train: 0.9392 loss_val: 1.5167 acc_val: 0.7251 time: 0.0208s\n",
      "valid current auc-roc score: 0.925140, current macro_F score: 0.695720\n",
      "Epoch: 00848 loss_train: 0.1926 acc_train: 0.9292 loss_val: 1.6905 acc_val: 0.7177 time: 0.0222s\n",
      "valid current auc-roc score: 0.923278, current macro_F score: 0.696778\n",
      "Epoch: 00849 loss_train: 0.1980 acc_train: 0.9342 loss_val: 2.1985 acc_val: 0.7306 time: 0.0236s\n",
      "valid current auc-roc score: 0.921156, current macro_F score: 0.707659\n",
      "Epoch: 00850 loss_train: 0.2101 acc_train: 0.9292 loss_val: 1.6799 acc_val: 0.7232 time: 0.0227s\n",
      "valid current auc-roc score: 0.920274, current macro_F score: 0.687723\n",
      "Epoch: 00851 loss_train: 0.1865 acc_train: 0.9385 loss_val: 1.7440 acc_val: 0.7103 time: 0.0214s\n",
      "valid current auc-roc score: 0.917781, current macro_F score: 0.685173\n",
      "Test set results: loss= 1.5305 accuracy= 714.3487\n",
      "test current auc-roc score: 0.924525, current macro_F score: 0.702708\n",
      "Epoch: 00852 loss_train: 0.1741 acc_train: 0.9435 loss_val: 1.6322 acc_val: 0.7048 time: 0.0170s\n",
      "valid current auc-roc score: 0.918690, current macro_F score: 0.677398\n",
      "Epoch: 00853 loss_train: 0.2102 acc_train: 0.9328 loss_val: 1.8262 acc_val: 0.7325 time: 0.0228s\n",
      "valid current auc-roc score: 0.923781, current macro_F score: 0.726056\n",
      "Epoch: 00854 loss_train: 0.1981 acc_train: 0.9313 loss_val: 1.5267 acc_val: 0.7399 time: 0.0223s\n",
      "valid current auc-roc score: 0.931259, current macro_F score: 0.720091\n",
      "Epoch: 00855 loss_train: 0.1779 acc_train: 0.9385 loss_val: 1.5389 acc_val: 0.7122 time: 0.0203s\n",
      "valid current auc-roc score: 0.922771, current macro_F score: 0.684353\n",
      "Epoch: 00856 loss_train: 0.1887 acc_train: 0.9299 loss_val: 1.4358 acc_val: 0.7122 time: 0.0220s\n",
      "valid current auc-roc score: 0.926914, current macro_F score: 0.693439\n",
      "Epoch: 00857 loss_train: 0.2005 acc_train: 0.9299 loss_val: 1.6187 acc_val: 0.6956 time: 0.0300s\n",
      "valid current auc-roc score: 0.909948, current macro_F score: 0.670199\n",
      "Epoch: 00858 loss_train: 0.1760 acc_train: 0.9421 loss_val: 1.7453 acc_val: 0.7066 time: 0.0237s\n",
      "valid current auc-roc score: 0.919293, current macro_F score: 0.679073\n",
      "Epoch: 00859 loss_train: 0.1812 acc_train: 0.9371 loss_val: 1.5792 acc_val: 0.7103 time: 0.0265s\n",
      "valid current auc-roc score: 0.913949, current macro_F score: 0.677688\n",
      "Epoch: 00860 loss_train: 0.2281 acc_train: 0.9292 loss_val: 1.7973 acc_val: 0.7177 time: 0.0195s\n",
      "valid current auc-roc score: 0.920135, current macro_F score: 0.689638\n",
      "Epoch: 00861 loss_train: 0.1700 acc_train: 0.9435 loss_val: 1.7112 acc_val: 0.7103 time: 0.0217s\n",
      "valid current auc-roc score: 0.922551, current macro_F score: 0.684339\n",
      "Test set results: loss= 1.7542 accuracy= 749.6458\n",
      "test current auc-roc score: 0.918786, current macro_F score: 0.706245\n",
      "Epoch: 00862 loss_train: 0.2237 acc_train: 0.9192 loss_val: 1.8955 acc_val: 0.7196 time: 0.0187s\n",
      "valid current auc-roc score: 0.914083, current macro_F score: 0.696271\n",
      "Epoch: 00863 loss_train: 0.2517 acc_train: 0.9235 loss_val: 2.1002 acc_val: 0.7269 time: 0.0195s\n",
      "valid current auc-roc score: 0.910817, current macro_F score: 0.708959\n",
      "Epoch: 00864 loss_train: 0.2010 acc_train: 0.9235 loss_val: 1.6184 acc_val: 0.7343 time: 0.0207s\n",
      "valid current auc-roc score: 0.920031, current macro_F score: 0.709873\n",
      "Epoch: 00865 loss_train: 0.1829 acc_train: 0.9349 loss_val: 1.4507 acc_val: 0.7306 time: 0.0190s\n",
      "valid current auc-roc score: 0.927328, current macro_F score: 0.707825\n",
      "Epoch: 00866 loss_train: 0.2091 acc_train: 0.9328 loss_val: 1.7639 acc_val: 0.7140 time: 0.0224s\n",
      "valid current auc-roc score: 0.918741, current macro_F score: 0.697366\n",
      "Epoch: 00867 loss_train: 0.1817 acc_train: 0.9378 loss_val: 1.8539 acc_val: 0.7066 time: 0.0185s\n",
      "valid current auc-roc score: 0.917374, current macro_F score: 0.674630\n",
      "Epoch: 00868 loss_train: 0.1746 acc_train: 0.9385 loss_val: 1.7633 acc_val: 0.7140 time: 0.0204s\n",
      "valid current auc-roc score: 0.917768, current macro_F score: 0.698762\n",
      "Epoch: 00869 loss_train: 0.1687 acc_train: 0.9428 loss_val: 1.6126 acc_val: 0.7103 time: 0.0256s\n",
      "valid current auc-roc score: 0.917184, current macro_F score: 0.687899\n",
      "Epoch: 00870 loss_train: 0.2207 acc_train: 0.9235 loss_val: 1.8978 acc_val: 0.6974 time: 0.0214s\n",
      "valid current auc-roc score: 0.905902, current macro_F score: 0.665358\n",
      "Epoch: 00871 loss_train: 0.1684 acc_train: 0.9442 loss_val: 1.6661 acc_val: 0.7103 time: 0.0219s\n",
      "valid current auc-roc score: 0.921965, current macro_F score: 0.688696\n",
      "Test set results: loss= 1.6367 accuracy= 714.9041\n",
      "test current auc-roc score: 0.918602, current macro_F score: 0.695324\n",
      "Epoch: 00872 loss_train: 0.1727 acc_train: 0.9421 loss_val: 1.6291 acc_val: 0.7435 time: 0.0204s\n",
      "valid current auc-roc score: 0.922442, current macro_F score: 0.721183\n",
      "Epoch: 00873 loss_train: 0.1945 acc_train: 0.9371 loss_val: 1.8561 acc_val: 0.7103 time: 0.0269s\n",
      "valid current auc-roc score: 0.913577, current macro_F score: 0.681966\n",
      "Epoch: 00874 loss_train: 0.1995 acc_train: 0.9299 loss_val: 1.7591 acc_val: 0.7048 time: 0.0217s\n",
      "valid current auc-roc score: 0.923263, current macro_F score: 0.677128\n",
      "Epoch: 00875 loss_train: 0.1789 acc_train: 0.9421 loss_val: 1.7739 acc_val: 0.7214 time: 0.0221s\n",
      "valid current auc-roc score: 0.918376, current macro_F score: 0.694194\n",
      "Epoch: 00876 loss_train: 0.1894 acc_train: 0.9306 loss_val: 1.6446 acc_val: 0.7306 time: 0.0203s\n",
      "valid current auc-roc score: 0.922823, current macro_F score: 0.696101\n",
      "Epoch: 00877 loss_train: 0.2009 acc_train: 0.9306 loss_val: 2.1976 acc_val: 0.6993 time: 0.0212s\n",
      "valid current auc-roc score: 0.903672, current macro_F score: 0.667130\n",
      "Epoch: 00878 loss_train: 0.2660 acc_train: 0.9249 loss_val: 2.1175 acc_val: 0.7122 time: 0.0208s\n",
      "valid current auc-roc score: 0.909623, current macro_F score: 0.691840\n",
      "Epoch: 00879 loss_train: 0.2030 acc_train: 0.9371 loss_val: 1.9165 acc_val: 0.7103 time: 0.0184s\n",
      "valid current auc-roc score: 0.914412, current macro_F score: 0.693827\n",
      "Epoch: 00880 loss_train: 0.1997 acc_train: 0.9378 loss_val: 1.5804 acc_val: 0.7140 time: 0.0194s\n",
      "valid current auc-roc score: 0.921627, current macro_F score: 0.688827\n",
      "Epoch: 00881 loss_train: 0.1939 acc_train: 0.9328 loss_val: 1.5118 acc_val: 0.7140 time: 0.0188s\n",
      "valid current auc-roc score: 0.921992, current macro_F score: 0.684026\n",
      "Test set results: loss= 1.4489 accuracy= 712.3081\n",
      "test current auc-roc score: 0.925223, current macro_F score: 0.689780\n",
      "Epoch: 00882 loss_train: 0.2034 acc_train: 0.9356 loss_val: 1.4926 acc_val: 0.7251 time: 0.0192s\n",
      "valid current auc-roc score: 0.920497, current macro_F score: 0.700952\n",
      "Epoch: 00883 loss_train: 0.2496 acc_train: 0.9185 loss_val: 1.3731 acc_val: 0.7196 time: 0.0186s\n",
      "valid current auc-roc score: 0.926831, current macro_F score: 0.697754\n",
      "Epoch: 00884 loss_train: 0.2192 acc_train: 0.9220 loss_val: 1.3528 acc_val: 0.7214 time: 0.0219s\n",
      "valid current auc-roc score: 0.925465, current macro_F score: 0.692377\n",
      "Epoch: 00885 loss_train: 0.2073 acc_train: 0.9349 loss_val: 1.5508 acc_val: 0.7066 time: 0.0204s\n",
      "valid current auc-roc score: 0.918314, current macro_F score: 0.693257\n",
      "Epoch: 00886 loss_train: 0.2217 acc_train: 0.9270 loss_val: 1.5503 acc_val: 0.7011 time: 0.0233s\n",
      "valid current auc-roc score: 0.911944, current macro_F score: 0.676968\n",
      "Epoch: 00887 loss_train: 0.1983 acc_train: 0.9349 loss_val: 1.3651 acc_val: 0.7288 time: 0.0194s\n",
      "valid current auc-roc score: 0.923109, current macro_F score: 0.711204\n",
      "Epoch: 00888 loss_train: 0.2107 acc_train: 0.9299 loss_val: 1.5844 acc_val: 0.7048 time: 0.0194s\n",
      "valid current auc-roc score: 0.911504, current macro_F score: 0.686657\n",
      "Epoch: 00889 loss_train: 0.2281 acc_train: 0.9263 loss_val: 1.4596 acc_val: 0.7269 time: 0.0226s\n",
      "valid current auc-roc score: 0.925607, current macro_F score: 0.701533\n",
      "Epoch: 00890 loss_train: 0.2047 acc_train: 0.9363 loss_val: 1.4825 acc_val: 0.7269 time: 0.0238s\n",
      "valid current auc-roc score: 0.925149, current macro_F score: 0.713535\n",
      "Epoch: 00891 loss_train: 0.2202 acc_train: 0.9256 loss_val: 1.7100 acc_val: 0.6882 time: 0.0260s\n",
      "valid current auc-roc score: 0.907533, current macro_F score: 0.663096\n",
      "Test set results: loss= 1.7026 accuracy= 736.0074\n",
      "test current auc-roc score: 0.914452, current macro_F score: 0.691239\n",
      "Epoch: 00892 loss_train: 0.2365 acc_train: 0.9149 loss_val: 1.6091 acc_val: 0.6771 time: 0.0169s\n",
      "valid current auc-roc score: 0.908877, current macro_F score: 0.653906\n",
      "Epoch: 00893 loss_train: 0.1883 acc_train: 0.9363 loss_val: 1.5147 acc_val: 0.7103 time: 0.0184s\n",
      "valid current auc-roc score: 0.918064, current macro_F score: 0.685370\n",
      "Epoch: 00894 loss_train: 0.2176 acc_train: 0.9285 loss_val: 1.8915 acc_val: 0.6661 time: 0.0185s\n",
      "valid current auc-roc score: 0.900165, current macro_F score: 0.644685\n",
      "Epoch: 00895 loss_train: 0.2221 acc_train: 0.9256 loss_val: 1.7025 acc_val: 0.7103 time: 0.0208s\n",
      "valid current auc-roc score: 0.913410, current macro_F score: 0.683598\n",
      "Epoch: 00896 loss_train: 0.1835 acc_train: 0.9378 loss_val: 1.7387 acc_val: 0.6790 time: 0.0185s\n",
      "valid current auc-roc score: 0.908974, current macro_F score: 0.654818\n",
      "Epoch: 00897 loss_train: 0.2083 acc_train: 0.9256 loss_val: 1.8031 acc_val: 0.7066 time: 0.0194s\n",
      "valid current auc-roc score: 0.907494, current macro_F score: 0.677005\n",
      "Epoch: 00898 loss_train: 0.1898 acc_train: 0.9363 loss_val: 1.8288 acc_val: 0.7122 time: 0.0226s\n",
      "valid current auc-roc score: 0.919938, current macro_F score: 0.691071\n",
      "Epoch: 00899 loss_train: 0.2153 acc_train: 0.9263 loss_val: 1.6725 acc_val: 0.7085 time: 0.0244s\n",
      "valid current auc-roc score: 0.916814, current macro_F score: 0.688808\n",
      "Epoch: 00900 loss_train: 0.1732 acc_train: 0.9371 loss_val: 1.8053 acc_val: 0.7103 time: 0.0221s\n",
      "valid current auc-roc score: 0.923003, current macro_F score: 0.680411\n",
      "Epoch: 00901 loss_train: 0.1842 acc_train: 0.9320 loss_val: 1.8231 acc_val: 0.6790 time: 0.0241s\n",
      "valid current auc-roc score: 0.911288, current macro_F score: 0.646878\n",
      "Test set results: loss= 1.7942 accuracy= 738.9262\n",
      "test current auc-roc score: 0.913785, current macro_F score: 0.705670\n",
      "Epoch: 00902 loss_train: 0.1718 acc_train: 0.9399 loss_val: 1.6573 acc_val: 0.7232 time: 0.0185s\n",
      "valid current auc-roc score: 0.917324, current macro_F score: 0.693815\n",
      "Epoch: 00903 loss_train: 0.1914 acc_train: 0.9270 loss_val: 1.9277 acc_val: 0.7066 time: 0.0181s\n",
      "valid current auc-roc score: 0.912404, current macro_F score: 0.682256\n",
      "Epoch: 00904 loss_train: 0.2025 acc_train: 0.9378 loss_val: 1.9215 acc_val: 0.6993 time: 0.0209s\n",
      "valid current auc-roc score: 0.917195, current macro_F score: 0.674842\n",
      "Epoch: 00905 loss_train: 0.2499 acc_train: 0.9242 loss_val: 1.6149 acc_val: 0.7085 time: 0.0207s\n",
      "valid current auc-roc score: 0.918505, current macro_F score: 0.687650\n",
      "Epoch: 00906 loss_train: 0.1909 acc_train: 0.9356 loss_val: 2.0329 acc_val: 0.6845 time: 0.0214s\n",
      "valid current auc-roc score: 0.904133, current macro_F score: 0.658695\n",
      "Epoch: 00907 loss_train: 0.1890 acc_train: 0.9385 loss_val: 1.6645 acc_val: 0.7269 time: 0.0221s\n",
      "valid current auc-roc score: 0.930162, current macro_F score: 0.722629\n",
      "Epoch: 00908 loss_train: 0.2076 acc_train: 0.9270 loss_val: 1.7913 acc_val: 0.7159 time: 0.0233s\n",
      "valid current auc-roc score: 0.919708, current macro_F score: 0.698338\n",
      "Epoch: 00909 loss_train: 0.1946 acc_train: 0.9385 loss_val: 1.9239 acc_val: 0.7085 time: 0.0236s\n",
      "valid current auc-roc score: 0.915262, current macro_F score: 0.693879\n",
      "Epoch: 00910 loss_train: 0.2120 acc_train: 0.9270 loss_val: 1.9727 acc_val: 0.7306 time: 0.0281s\n",
      "valid current auc-roc score: 0.907985, current macro_F score: 0.713097\n",
      "Epoch: 00911 loss_train: 0.2066 acc_train: 0.9270 loss_val: 2.1633 acc_val: 0.7399 time: 0.0234s\n",
      "valid current auc-roc score: 0.915269, current macro_F score: 0.726896\n",
      "Test set results: loss= 1.8142 accuracy= 753.6365\n",
      "test current auc-roc score: 0.909888, current macro_F score: 0.694598\n",
      "Epoch: 00912 loss_train: 0.2191 acc_train: 0.9235 loss_val: 2.1213 acc_val: 0.6753 time: 0.0182s\n",
      "valid current auc-roc score: 0.893415, current macro_F score: 0.649979\n",
      "Epoch: 00913 loss_train: 0.2291 acc_train: 0.9220 loss_val: 1.8626 acc_val: 0.7196 time: 0.0227s\n",
      "valid current auc-roc score: 0.916196, current macro_F score: 0.711602\n",
      "Epoch: 00914 loss_train: 0.2032 acc_train: 0.9270 loss_val: 1.6334 acc_val: 0.7232 time: 0.0197s\n",
      "valid current auc-roc score: 0.917136, current macro_F score: 0.710783\n",
      "Epoch: 00915 loss_train: 0.2008 acc_train: 0.9292 loss_val: 1.6977 acc_val: 0.6956 time: 0.0191s\n",
      "valid current auc-roc score: 0.913980, current macro_F score: 0.667704\n",
      "Epoch: 00916 loss_train: 0.2015 acc_train: 0.9313 loss_val: 1.8184 acc_val: 0.7085 time: 0.0192s\n",
      "valid current auc-roc score: 0.917924, current macro_F score: 0.683453\n",
      "Epoch: 00917 loss_train: 0.2272 acc_train: 0.9270 loss_val: 1.4884 acc_val: 0.6993 time: 0.0226s\n",
      "valid current auc-roc score: 0.922425, current macro_F score: 0.673526\n",
      "Epoch: 00918 loss_train: 0.1995 acc_train: 0.9335 loss_val: 1.6325 acc_val: 0.7066 time: 0.0191s\n",
      "valid current auc-roc score: 0.920847, current macro_F score: 0.694580\n",
      "Epoch: 00919 loss_train: 0.1975 acc_train: 0.9306 loss_val: 1.8440 acc_val: 0.7030 time: 0.0205s\n",
      "valid current auc-roc score: 0.915932, current macro_F score: 0.667320\n",
      "Epoch: 00920 loss_train: 0.1947 acc_train: 0.9335 loss_val: 1.7648 acc_val: 0.7103 time: 0.0253s\n",
      "valid current auc-roc score: 0.910900, current macro_F score: 0.688286\n",
      "Epoch: 00921 loss_train: 0.1748 acc_train: 0.9471 loss_val: 1.5821 acc_val: 0.7325 time: 0.0226s\n",
      "valid current auc-roc score: 0.925048, current macro_F score: 0.714840\n",
      "Test set results: loss= 1.7592 accuracy= 745.6292\n",
      "test current auc-roc score: 0.915382, current macro_F score: 0.717245\n",
      "Epoch: 00922 loss_train: 0.2074 acc_train: 0.9313 loss_val: 1.9350 acc_val: 0.7288 time: 0.0181s\n",
      "valid current auc-roc score: 0.917846, current macro_F score: 0.712360\n",
      "Epoch: 00923 loss_train: 0.1979 acc_train: 0.9328 loss_val: 1.9948 acc_val: 0.7140 time: 0.0234s\n",
      "valid current auc-roc score: 0.908716, current macro_F score: 0.703922\n",
      "Epoch: 00924 loss_train: 0.2079 acc_train: 0.9278 loss_val: 2.0737 acc_val: 0.7232 time: 0.0185s\n",
      "valid current auc-roc score: 0.915308, current macro_F score: 0.709839\n",
      "Epoch: 00925 loss_train: 0.1968 acc_train: 0.9306 loss_val: 1.8341 acc_val: 0.7177 time: 0.0230s\n",
      "valid current auc-roc score: 0.912944, current macro_F score: 0.689682\n",
      "Epoch: 00926 loss_train: 0.1912 acc_train: 0.9328 loss_val: 2.0440 acc_val: 0.7030 time: 0.0211s\n",
      "valid current auc-roc score: 0.915172, current macro_F score: 0.676233\n",
      "Epoch: 00927 loss_train: 0.1847 acc_train: 0.9349 loss_val: 2.1956 acc_val: 0.6993 time: 0.0209s\n",
      "valid current auc-roc score: 0.915343, current macro_F score: 0.664673\n",
      "Epoch: 00928 loss_train: 0.1869 acc_train: 0.9392 loss_val: 2.1988 acc_val: 0.7066 time: 0.0296s\n",
      "valid current auc-roc score: 0.912850, current macro_F score: 0.691954\n",
      "Epoch: 00929 loss_train: 0.1909 acc_train: 0.9435 loss_val: 2.1495 acc_val: 0.6808 time: 0.0250s\n",
      "valid current auc-roc score: 0.903002, current macro_F score: 0.646876\n",
      "Epoch: 00930 loss_train: 0.2103 acc_train: 0.9263 loss_val: 1.9630 acc_val: 0.6993 time: 0.0219s\n",
      "valid current auc-roc score: 0.912998, current macro_F score: 0.677020\n",
      "Epoch: 00931 loss_train: 0.2207 acc_train: 0.9285 loss_val: 1.5785 acc_val: 0.7085 time: 0.0209s\n",
      "valid current auc-roc score: 0.921554, current macro_F score: 0.678203\n",
      "Test set results: loss= 1.8694 accuracy= 732.3007\n",
      "test current auc-roc score: 0.912569, current macro_F score: 0.710413\n",
      "Epoch: 00932 loss_train: 0.2029 acc_train: 0.9320 loss_val: 2.0339 acc_val: 0.7122 time: 0.0285s\n",
      "valid current auc-roc score: 0.915674, current macro_F score: 0.681034\n",
      "Epoch: 00933 loss_train: 0.2000 acc_train: 0.9371 loss_val: 1.9017 acc_val: 0.7177 time: 0.0247s\n",
      "valid current auc-roc score: 0.918079, current macro_F score: 0.692396\n",
      "Epoch: 00934 loss_train: 0.1685 acc_train: 0.9406 loss_val: 2.2194 acc_val: 0.6974 time: 0.0253s\n",
      "valid current auc-roc score: 0.910402, current macro_F score: 0.665630\n",
      "Epoch: 00935 loss_train: 0.1949 acc_train: 0.9278 loss_val: 2.1784 acc_val: 0.6827 time: 0.0200s\n",
      "valid current auc-roc score: 0.906499, current macro_F score: 0.645634\n",
      "Epoch: 00936 loss_train: 0.1821 acc_train: 0.9413 loss_val: 1.6939 acc_val: 0.7288 time: 0.0205s\n",
      "valid current auc-roc score: 0.920805, current macro_F score: 0.699006\n",
      "Epoch: 00937 loss_train: 0.1843 acc_train: 0.9320 loss_val: 1.9982 acc_val: 0.7103 time: 0.0217s\n",
      "valid current auc-roc score: 0.917819, current macro_F score: 0.685491\n",
      "Epoch: 00938 loss_train: 0.1880 acc_train: 0.9371 loss_val: 1.7901 acc_val: 0.7306 time: 0.0201s\n",
      "valid current auc-roc score: 0.915717, current macro_F score: 0.709517\n",
      "Epoch: 00939 loss_train: 0.2012 acc_train: 0.9285 loss_val: 1.3728 acc_val: 0.7472 time: 0.0196s\n",
      "valid current auc-roc score: 0.934298, current macro_F score: 0.726685\n",
      "Epoch: 00940 loss_train: 0.1935 acc_train: 0.9385 loss_val: 1.6897 acc_val: 0.7417 time: 0.0215s\n",
      "valid current auc-roc score: 0.930448, current macro_F score: 0.721409\n",
      "Epoch: 00941 loss_train: 0.2250 acc_train: 0.9256 loss_val: 2.0252 acc_val: 0.7269 time: 0.0269s\n",
      "valid current auc-roc score: 0.916265, current macro_F score: 0.696808\n",
      "Test set results: loss= 1.6434 accuracy= 709.3376\n",
      "test current auc-roc score: 0.921197, current macro_F score: 0.712584\n",
      "Epoch: 00942 loss_train: 0.2041 acc_train: 0.9320 loss_val: 1.8818 acc_val: 0.7380 time: 0.0188s\n",
      "valid current auc-roc score: 0.927105, current macro_F score: 0.721715\n",
      "Epoch: 00943 loss_train: 0.1964 acc_train: 0.9299 loss_val: 1.6121 acc_val: 0.7343 time: 0.0496s\n",
      "valid current auc-roc score: 0.930789, current macro_F score: 0.712032\n",
      "Epoch: 00944 loss_train: 0.1998 acc_train: 0.9278 loss_val: 1.7913 acc_val: 0.7103 time: 0.0223s\n",
      "valid current auc-roc score: 0.929561, current macro_F score: 0.683811\n",
      "Epoch: 00945 loss_train: 0.1979 acc_train: 0.9313 loss_val: 1.6854 acc_val: 0.7177 time: 0.0204s\n",
      "valid current auc-roc score: 0.921595, current macro_F score: 0.700329\n",
      "Epoch: 00946 loss_train: 0.2065 acc_train: 0.9306 loss_val: 1.8103 acc_val: 0.6919 time: 0.0202s\n",
      "valid current auc-roc score: 0.906049, current macro_F score: 0.669730\n",
      "Epoch: 00947 loss_train: 0.1946 acc_train: 0.9313 loss_val: 2.0348 acc_val: 0.7103 time: 0.0222s\n",
      "valid current auc-roc score: 0.916893, current macro_F score: 0.679043\n",
      "Epoch: 00948 loss_train: 0.2000 acc_train: 0.9335 loss_val: 1.9010 acc_val: 0.7103 time: 0.0212s\n",
      "valid current auc-roc score: 0.917632, current macro_F score: 0.684793\n",
      "Epoch: 00949 loss_train: 0.2037 acc_train: 0.9263 loss_val: 1.6345 acc_val: 0.7232 time: 0.0221s\n",
      "valid current auc-roc score: 0.910620, current macro_F score: 0.689967\n",
      "Epoch: 00950 loss_train: 0.2069 acc_train: 0.9242 loss_val: 1.7657 acc_val: 0.7232 time: 0.0239s\n",
      "valid current auc-roc score: 0.911941, current macro_F score: 0.702043\n",
      "Epoch: 00951 loss_train: 0.1680 acc_train: 0.9478 loss_val: 1.6097 acc_val: 0.7325 time: 0.0194s\n",
      "valid current auc-roc score: 0.914664, current macro_F score: 0.704148\n",
      "Test set results: loss= 1.6601 accuracy= 740.1919\n",
      "test current auc-roc score: 0.917307, current macro_F score: 0.708384\n",
      "Epoch: 00952 loss_train: 0.2149 acc_train: 0.9199 loss_val: 1.6449 acc_val: 0.7269 time: 0.0211s\n",
      "valid current auc-roc score: 0.922389, current macro_F score: 0.701002\n",
      "Epoch: 00953 loss_train: 0.1914 acc_train: 0.9392 loss_val: 1.6329 acc_val: 0.7325 time: 0.0183s\n",
      "valid current auc-roc score: 0.926510, current macro_F score: 0.715855\n",
      "Epoch: 00954 loss_train: 0.1848 acc_train: 0.9335 loss_val: 1.7342 acc_val: 0.7380 time: 0.0181s\n",
      "valid current auc-roc score: 0.924178, current macro_F score: 0.709159\n",
      "Epoch: 00955 loss_train: 0.1904 acc_train: 0.9349 loss_val: 1.8322 acc_val: 0.7159 time: 0.0183s\n",
      "valid current auc-roc score: 0.915483, current macro_F score: 0.691176\n",
      "Epoch: 00956 loss_train: 0.1777 acc_train: 0.9335 loss_val: 1.6416 acc_val: 0.7325 time: 0.0194s\n",
      "valid current auc-roc score: 0.927172, current macro_F score: 0.710436\n",
      "Epoch: 00957 loss_train: 0.2097 acc_train: 0.9363 loss_val: 2.1419 acc_val: 0.7399 time: 0.0222s\n",
      "valid current auc-roc score: 0.925953, current macro_F score: 0.718610\n",
      "Epoch: 00958 loss_train: 0.1863 acc_train: 0.9363 loss_val: 1.5955 acc_val: 0.7306 time: 0.0245s\n",
      "valid current auc-roc score: 0.927188, current macro_F score: 0.702843\n",
      "Epoch: 00959 loss_train: 0.2063 acc_train: 0.9349 loss_val: 2.0553 acc_val: 0.7362 time: 0.0222s\n",
      "valid current auc-roc score: 0.923827, current macro_F score: 0.729478\n",
      "Epoch: 00960 loss_train: 0.2072 acc_train: 0.9320 loss_val: 1.6555 acc_val: 0.7380 time: 0.0211s\n",
      "valid current auc-roc score: 0.920756, current macro_F score: 0.721047\n",
      "Epoch: 00961 loss_train: 0.1856 acc_train: 0.9378 loss_val: 1.7963 acc_val: 0.7140 time: 0.0201s\n",
      "valid current auc-roc score: 0.917286, current macro_F score: 0.683172\n",
      "Test set results: loss= 1.7567 accuracy= 742.6328\n",
      "test current auc-roc score: 0.916149, current macro_F score: 0.697049\n",
      "Epoch: 00962 loss_train: 0.1844 acc_train: 0.9363 loss_val: 1.7670 acc_val: 0.7085 time: 0.0181s\n",
      "valid current auc-roc score: 0.922171, current macro_F score: 0.690205\n",
      "Epoch: 00963 loss_train: 0.1864 acc_train: 0.9392 loss_val: 1.9623 acc_val: 0.7159 time: 0.0201s\n",
      "valid current auc-roc score: 0.927051, current macro_F score: 0.690477\n",
      "Epoch: 00964 loss_train: 0.1927 acc_train: 0.9471 loss_val: 1.6592 acc_val: 0.7085 time: 0.0206s\n",
      "valid current auc-roc score: 0.919207, current macro_F score: 0.680972\n",
      "Epoch: 00965 loss_train: 0.1769 acc_train: 0.9371 loss_val: 1.7913 acc_val: 0.7288 time: 0.0190s\n",
      "valid current auc-roc score: 0.926896, current macro_F score: 0.718203\n",
      "Epoch: 00966 loss_train: 0.1677 acc_train: 0.9413 loss_val: 2.0124 acc_val: 0.7214 time: 0.0175s\n",
      "valid current auc-roc score: 0.924519, current macro_F score: 0.690792\n",
      "Epoch: 00967 loss_train: 0.2020 acc_train: 0.9306 loss_val: 1.9564 acc_val: 0.7380 time: 0.0183s\n",
      "valid current auc-roc score: 0.924843, current macro_F score: 0.731739\n",
      "Epoch: 00968 loss_train: 0.1961 acc_train: 0.9328 loss_val: 1.8369 acc_val: 0.7288 time: 0.0200s\n",
      "valid current auc-roc score: 0.928054, current macro_F score: 0.713530\n",
      "Epoch: 00969 loss_train: 0.2238 acc_train: 0.9313 loss_val: 1.8954 acc_val: 0.7177 time: 0.0196s\n",
      "valid current auc-roc score: 0.921326, current macro_F score: 0.700628\n",
      "Epoch: 00970 loss_train: 0.1730 acc_train: 0.9456 loss_val: 1.7568 acc_val: 0.7177 time: 0.0196s\n",
      "valid current auc-roc score: 0.918529, current macro_F score: 0.689445\n",
      "Epoch: 00971 loss_train: 0.1711 acc_train: 0.9406 loss_val: 1.9756 acc_val: 0.7306 time: 0.0180s\n",
      "valid current auc-roc score: 0.917344, current macro_F score: 0.711335\n",
      "Test set results: loss= 1.7512 accuracy= 733.1273\n",
      "test current auc-roc score: 0.917873, current macro_F score: 0.695128\n",
      "Epoch: 00972 loss_train: 0.1820 acc_train: 0.9342 loss_val: 1.6792 acc_val: 0.7159 time: 0.0193s\n",
      "valid current auc-roc score: 0.924395, current macro_F score: 0.692057\n",
      "Epoch: 00973 loss_train: 0.1751 acc_train: 0.9428 loss_val: 1.7802 acc_val: 0.7030 time: 0.0192s\n",
      "valid current auc-roc score: 0.913994, current macro_F score: 0.680399\n",
      "Epoch: 00974 loss_train: 0.1604 acc_train: 0.9442 loss_val: 2.0467 acc_val: 0.7288 time: 0.0191s\n",
      "valid current auc-roc score: 0.923374, current macro_F score: 0.717351\n",
      "Epoch: 00975 loss_train: 0.1830 acc_train: 0.9442 loss_val: 1.8769 acc_val: 0.7232 time: 0.0190s\n",
      "valid current auc-roc score: 0.920698, current macro_F score: 0.701224\n",
      "Epoch: 00976 loss_train: 0.1760 acc_train: 0.9385 loss_val: 1.6299 acc_val: 0.7435 time: 0.0181s\n",
      "valid current auc-roc score: 0.927020, current macro_F score: 0.720077\n",
      "Epoch: 00977 loss_train: 0.1857 acc_train: 0.9435 loss_val: 1.7938 acc_val: 0.7196 time: 0.0177s\n",
      "valid current auc-roc score: 0.917496, current macro_F score: 0.690499\n",
      "Epoch: 00978 loss_train: 0.1701 acc_train: 0.9406 loss_val: 1.6891 acc_val: 0.7251 time: 0.0189s\n",
      "valid current auc-roc score: 0.924468, current macro_F score: 0.700982\n",
      "Epoch: 00979 loss_train: 0.1824 acc_train: 0.9363 loss_val: 1.7220 acc_val: 0.7362 time: 0.0256s\n",
      "valid current auc-roc score: 0.926626, current macro_F score: 0.724310\n",
      "Epoch: 00980 loss_train: 0.1799 acc_train: 0.9392 loss_val: 1.7785 acc_val: 0.7122 time: 0.0236s\n",
      "valid current auc-roc score: 0.918192, current macro_F score: 0.686660\n",
      "Epoch: 00981 loss_train: 0.1836 acc_train: 0.9385 loss_val: 1.7511 acc_val: 0.7214 time: 0.0234s\n",
      "valid current auc-roc score: 0.918835, current macro_F score: 0.694136\n",
      "Test set results: loss= 1.8437 accuracy= 724.1642\n",
      "test current auc-roc score: 0.916694, current macro_F score: 0.703995\n",
      "Epoch: 00982 loss_train: 0.1997 acc_train: 0.9306 loss_val: 1.8343 acc_val: 0.7306 time: 0.0188s\n",
      "valid current auc-roc score: 0.918572, current macro_F score: 0.708757\n",
      "Epoch: 00983 loss_train: 0.1886 acc_train: 0.9335 loss_val: 1.8647 acc_val: 0.7140 time: 0.0200s\n",
      "valid current auc-roc score: 0.919848, current macro_F score: 0.694345\n",
      "Epoch: 00984 loss_train: 0.1860 acc_train: 0.9378 loss_val: 1.7099 acc_val: 0.7140 time: 0.0220s\n",
      "valid current auc-roc score: 0.923536, current macro_F score: 0.697265\n",
      "Epoch: 00985 loss_train: 0.2036 acc_train: 0.9278 loss_val: 2.1290 acc_val: 0.6919 time: 0.0263s\n",
      "valid current auc-roc score: 0.912615, current macro_F score: 0.662891\n",
      "Epoch: 00986 loss_train: 0.2100 acc_train: 0.9270 loss_val: 2.0364 acc_val: 0.6900 time: 0.0231s\n",
      "valid current auc-roc score: 0.911952, current macro_F score: 0.660140\n",
      "Epoch: 00987 loss_train: 0.2007 acc_train: 0.9306 loss_val: 1.8753 acc_val: 0.6863 time: 0.0201s\n",
      "valid current auc-roc score: 0.910567, current macro_F score: 0.655791\n",
      "Epoch: 00988 loss_train: 0.1990 acc_train: 0.9249 loss_val: 1.8053 acc_val: 0.7103 time: 0.0185s\n",
      "valid current auc-roc score: 0.926155, current macro_F score: 0.683343\n",
      "Epoch: 00989 loss_train: 0.1788 acc_train: 0.9399 loss_val: 1.5971 acc_val: 0.7399 time: 0.0195s\n",
      "valid current auc-roc score: 0.921096, current macro_F score: 0.710618\n",
      "Epoch: 00990 loss_train: 0.1897 acc_train: 0.9299 loss_val: 1.9260 acc_val: 0.7048 time: 0.0189s\n",
      "valid current auc-roc score: 0.920494, current macro_F score: 0.673168\n",
      "Epoch: 00991 loss_train: 0.1808 acc_train: 0.9428 loss_val: 1.9013 acc_val: 0.7159 time: 0.0203s\n",
      "valid current auc-roc score: 0.921824, current macro_F score: 0.692891\n",
      "Test set results: loss= 1.7971 accuracy= 739.0037\n",
      "test current auc-roc score: 0.918387, current macro_F score: 0.713897\n",
      "Epoch: 00992 loss_train: 0.2163 acc_train: 0.9335 loss_val: 2.0083 acc_val: 0.7454 time: 0.0208s\n",
      "valid current auc-roc score: 0.919168, current macro_F score: 0.725050\n",
      "Epoch: 00993 loss_train: 0.1798 acc_train: 0.9342 loss_val: 1.8235 acc_val: 0.7399 time: 0.0223s\n",
      "valid current auc-roc score: 0.922047, current macro_F score: 0.721728\n",
      "Epoch: 00994 loss_train: 0.2018 acc_train: 0.9349 loss_val: 1.6313 acc_val: 0.7380 time: 0.0206s\n",
      "valid current auc-roc score: 0.928752, current macro_F score: 0.713562\n",
      "Epoch: 00995 loss_train: 0.1978 acc_train: 0.9349 loss_val: 1.6241 acc_val: 0.7362 time: 0.0185s\n",
      "valid current auc-roc score: 0.921293, current macro_F score: 0.728085\n",
      "Epoch: 00996 loss_train: 0.1976 acc_train: 0.9378 loss_val: 1.5662 acc_val: 0.7399 time: 0.0254s\n",
      "valid current auc-roc score: 0.924807, current macro_F score: 0.722611\n",
      "Epoch: 00997 loss_train: 0.2175 acc_train: 0.9242 loss_val: 1.9429 acc_val: 0.7085 time: 0.0273s\n",
      "valid current auc-roc score: 0.907526, current macro_F score: 0.682787\n",
      "Epoch: 00998 loss_train: 0.1942 acc_train: 0.9342 loss_val: 1.7081 acc_val: 0.7251 time: 0.0350s\n",
      "valid current auc-roc score: 0.913287, current macro_F score: 0.699770\n",
      "Epoch: 00999 loss_train: 0.1874 acc_train: 0.9378 loss_val: 1.8282 acc_val: 0.7030 time: 0.0258s\n",
      "valid current auc-roc score: 0.915883, current macro_F score: 0.681070\n",
      "Epoch: 01000 loss_train: 0.1702 acc_train: 0.9435 loss_val: 1.8214 acc_val: 0.6993 time: 0.0420s\n",
      "valid current auc-roc score: 0.907863, current macro_F score: 0.673350\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc_trains = []\n",
    "acc_vals = []\n",
    "loss_trains = []\n",
    "loss_vals = []\n",
    "loss_test = []\n",
    "test_acc = []\n",
    "loss_tests = []\n",
    "test_accs = []\n",
    "outputs = None\n",
    "embed = None\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "        acc_train, acc_val, loss_train, loss_val = train(epoch)\n",
    "        acc_trains.append(acc_train)\n",
    "        acc_vals.append(acc_val)\n",
    "        loss_trains.append(loss_train)\n",
    "        loss_vals.append(loss_val)\n",
    "        if epoch % 10 == 0:\n",
    "                loss_test, test_acc, outputs, embed = test(epoch)\n",
    "                loss_tests.append(loss_test)\n",
    "                test_accs.append(test_acc)\n",
    "confusion_matrix_vis(outputs[test_idx], labels[test_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2708, 64])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save / Load Dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_dic(path, dictionary):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(dictionary, f)\n",
    "\n",
    "def load_dic(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        dic = pickle.load(f)\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {\n",
    "    \"acc_trains\": acc_trains,\n",
    "    \"acc_vals\": acc_vals,\n",
    "    \"loss_trains\": loss_trains,\n",
    "    \"loss_vals\": loss_vals,\n",
    "    \"loss_test\": loss_test,\n",
    "    \"test_acc\": test_acc,\n",
    "    \"loss_tests\": loss_tests,\n",
    "    \"test_accs\": test_accs\n",
    "}\n",
    "save_dic('result.pkl', result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the trained 2 layer classifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model():\n",
    "    saved_content = {}\n",
    "    saved_content['encoder'] = encoder_n.state_dict()\n",
    "    saved_content['classifier'] = classifier_n.state_dict()\n",
    "    torch.save(saved_content, 'checkpoint/{}/Normal_opt{}_m{}_act{}_init{}_ir{}_res{}_l{}_h{}.pth'.format(args.dataset, \n",
    "    args.optimizer_alg, \n",
    "    args.momentum, \n",
    "    args.activation_func, \n",
    "    args.initalization,\n",
    "    args.imbalance_ratio,\n",
    "    args.res_connection,\n",
    "    len(n_hidden),\n",
    "    n_hidden[-1]))\n",
    "    return\n",
    "save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GraphSMOTE's trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "encoder_s = GCN_Encoder_s(nfeat = features.shape[1],\n",
    "        nhid = args.n_hidden,\n",
    "        nembed = args.n_hidden,\n",
    "        dropout = args.dropout, init = args.initalization)\n",
    "classifier_s = GCN_Classifier_s(nembed=args.n_hidden, \n",
    "        nhid = args.n_hidden, \n",
    "        nclass = labels.max().item() + 1, \n",
    "        dropout = args.dropout, device = device, init = args.initalization)\n",
    "decoder_s = Decoder_s(nembed = args.n_hidden,\n",
    "        dropout = args.dropout, init = args.initalization)\n",
    "# optimizer_en = optim.Adam(encoder_s.parameters(),\n",
    "#                        lr=args.learning_rate, weight_decay=args.weight_decay)\n",
    "# optimizer_cls = optim.Adam(classifier_s.parameters(),\n",
    "#                        lr=args.learning_rate, weight_decay=args.weight_decay)\n",
    "# optimizer_de = optim.Adam(decoder_s.parameters(),\n",
    "#                        lr=args.learning_rate, weight_decay=args.weight_decay)\n",
    "if args.optimizer_alg == \"ADAM\":\n",
    "        optimizer_en = optim.Adam(encoder_n.parameters(),\n",
    "                        lr = args.learning_rate, weight_decay = args.weight_decay)\n",
    "        optimizer_cls = optim.Adam(classifier_n.parameters(),\n",
    "                        lr = args.learning_rate, weight_decay = args.weight_decay)\n",
    "        optimizer_de = optim.Adam(decoder_s.parameters(),\n",
    "                       lr = args.learning_rate, weight_decay = args.weight_decay)\n",
    "elif args.optimizer_alg == \"Momentum\":\n",
    "        optimizer_en = optim.SGD(encoder_n.parameters(),\n",
    "                        lr = args.learning_rate, momentum = args.momentum)\n",
    "        optimizer_cls = optim.SGD(classifier_n.parameters(),\n",
    "                        lr = args.learning_rate, momentum = args.momentum)\n",
    "        optimizer_de = optim.SGD(decoder_s.parameters(),\n",
    "                        lr = args.learning_rate, momentum = args.momentum)\n",
    "elif args.optimizer_alg == \"RMSProp\":\n",
    "        optimizer_en = optim.RMSprop(encoder_n.parameters(),\n",
    "                        lr = args.learning_rate, weight_decay = args.weight_decay)\n",
    "        optimizer_cls = optim.RMSprop(classifier_n.parameters(),\n",
    "                        lr = args.learning_rate, weight_decay = args.weight_decay)\n",
    "        optimizer_de = optim.RMSprop(decoder_s.parameters(),\n",
    "                        lr = args.learning_rate, weight_decay = args.weight_decay)\n",
    "else:\n",
    "        optimizer_en = optim.Adam(encoder_n.parameters(),\n",
    "                        lr = args.learning_rate, weight_decay = args.weight_decay)\n",
    "        optimizer_cls = optim.Adam(classifier_n.parameters(),\n",
    "                        lr = args.learning_rate, weight_decay = args.weight_decay)\n",
    "        optimizer_de = optim.Adam(decoder_s.parameters(),\n",
    "                        lr = args.learning_rate, weight_decay = args.weight_decay)\n",
    "def train(epoch):\n",
    "    t = time.time()\n",
    "    encoder_s.train()\n",
    "    classifier_s.train()\n",
    "    decoder_s.train()\n",
    "    optimizer_en.zero_grad()\n",
    "    optimizer_cls.zero_grad()\n",
    "    optimizer_de.zero_grad()\n",
    "\n",
    "    embed = encoder_s(features, adj_mtx)\n",
    "\n",
    "    if args.setting == 'recon_newG' or args.setting == 'recon' or args.setting == 'newG_cls':\n",
    "        ori_num = labels.shape[0]\n",
    "        embed, labels_new, idx_train_new, adj_up = utils.recon_upsample(embed, labels, train_idx, adj = adj_mtx.detach().to_dense(), portion = args.up_scale, im_class_num = args.im_class_num)\n",
    "        generated_G = decoder_s(embed)\n",
    "\n",
    "        loss_rec = utils.adj_mse_loss(generated_G[: ori_num, :][:, : ori_num], adj_mtx.detach().to_dense())\n",
    "        \n",
    "        #ipdb.set_trace()\n",
    "\n",
    "\n",
    "        if not args.opt_new_G:\n",
    "            adj_new = copy.deepcopy(generated_G.detach())\n",
    "            threshold = 0.5\n",
    "            adj_new[adj_new < threshold] = 0.0\n",
    "            adj_new[adj_new >= threshold] = 1.0\n",
    "\n",
    "            #ipdb.set_trace()\n",
    "            edge_ac = adj_new[: ori_num, : ori_num].eq(adj_mtx.to_dense()).double().sum()/(ori_num**2)\n",
    "        else:\n",
    "            adj_new = generated_G\n",
    "            edge_ac = F.l1_loss(adj_new[: ori_num, : ori_num], adj_mtx.to_dense(), reduction = 'mean')\n",
    "\n",
    "\n",
    "        #calculate generation information\n",
    "        exist_edge_prob = adj_new[:ori_num, :ori_num].mean() #edge prob for existing nodes\n",
    "        generated_edge_prob = adj_new[ori_num:, :ori_num].mean() #edge prob for generated nodes\n",
    "        print(\"edge acc: {:.4f}, exist_edge_prob: {:.4f}, generated_edge_prob: {:.4f}\".format(edge_ac.item(), exist_edge_prob.item(), generated_edge_prob.item()))\n",
    "\n",
    "\n",
    "        adj_new = torch.mul(adj_up, adj_new)\n",
    "\n",
    "        exist_edge_prob = adj_new[:ori_num, :ori_num].mean() #edge prob for existing nodes\n",
    "        generated_edge_prob = adj_new[ori_num:, :ori_num].mean() #edge prob for generated nodes\n",
    "        print(\"after filtering, edge acc: {:.4f}, exist_edge_prob: {:.4f}, generated_edge_prob: {:.4f}\".format(edge_ac.item(), exist_edge_prob.item(), generated_edge_prob.item()))\n",
    "\n",
    "\n",
    "        adj_new[:ori_num, :][:, :ori_num] = adj_mtx.detach().to_dense()\n",
    "        #adj_new = adj_new.to_sparse()\n",
    "        #ipdb.set_trace()\n",
    "\n",
    "        if not args.opt_new_G:\n",
    "            adj_new = adj_new.detach()\n",
    "\n",
    "        if args.setting == 'newG_cls':\n",
    "            idx_train_new = train_idx\n",
    "\n",
    "    elif args.setting == 'embed_up':\n",
    "        #perform SMOTE in embedding space\n",
    "        embed, labels_new, idx_train_new = utils.recon_upsample(embed, labels, train_idx, portion=args.up_scale, im_class_num = args.im_class_num)\n",
    "        adj_new = adj_mtx\n",
    "    else:\n",
    "        labels_new = labels\n",
    "        idx_train_new = train_idx\n",
    "        adj_new = adj_mtx\n",
    "\n",
    "    #ipdb.set_trace()\n",
    "    output = classifier_s(embed, adj_new)\n",
    "\n",
    "\n",
    "\n",
    "    if args.setting == 'reweight':\n",
    "        weight = features.new((labels.max().item() + 1)).fill_(1)\n",
    "        weight[-args.im_class_num:] = 1 + args.up_scale\n",
    "        loss_train = F.cross_entropy(output[idx_train_new], labels_new[idx_train_new].reshape(-1), weight=weight)\n",
    "    else:\n",
    "        loss_train = F.cross_entropy(output[idx_train_new], labels_new[idx_train_new].reshape(-1))\n",
    "\n",
    "    acc_train = accuracy(output[train_idx], labels_new[train_idx].reshape(-1))\n",
    "    if args.setting == 'recon_newG':\n",
    "        loss = loss_train + loss_rec * args.rec_weight\n",
    "    elif args.setting == 'recon':\n",
    "        loss = loss_rec + 0 * loss_train\n",
    "    else:\n",
    "        loss = loss_train\n",
    "        loss_rec = loss_train\n",
    "\n",
    "    loss.backward()\n",
    "    if args.setting == 'newG_cls':\n",
    "        optimizer_en.zero_grad()\n",
    "        optimizer_de.zero_grad()\n",
    "    else:\n",
    "        optimizer_en.step()\n",
    "\n",
    "    optimizer_cls.step()\n",
    "\n",
    "    if args.setting == 'recon_newG' or args.setting == 'recon':\n",
    "        optimizer_de.step()\n",
    "\n",
    "    loss_val = F.cross_entropy(output[val_idx], labels[val_idx].reshape(-1))\n",
    "    acc_val = accuracy(output[val_idx], labels[val_idx].reshape(-1))\n",
    "\n",
    "    print('Epoch: {:05d}'.format(epoch + 1),\n",
    "          'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "          'loss_rec: {:.4f}'.format(loss_rec.item()),\n",
    "          'acc_train: {:.4f}'.format(acc_train.item()),\n",
    "          'loss_val: {:.4f}'.format(loss_val.item()),\n",
    "          'acc_val: {:.4f}'.format(acc_val.item()),\n",
    "          'time: {:.4f}s'.format(time.time() - t))\n",
    "    return acc_train.item(), acc_val.item(), loss_train.item(), loss_val.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GraphSOMTE's test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch = 0):\n",
    "    encoder_s.eval()\n",
    "    classifier_s.eval()\n",
    "#     outputs = encoder(features, adj_mtx)\n",
    "    embed = encoder_s(features, adj_mtx)\n",
    "    outputs = classifier_s(embed, adj_mtx)\n",
    "    loss_test = F.cross_entropy(outputs[test_idx], labels[test_idx])\n",
    "    acc_test = accuracy(outputs[test_idx], labels[test_idx])\n",
    "    print(\"Test set results:\",\n",
    "          \"loss= {:.4f}\".format(loss_test.item()),\n",
    "          \"accuracy= {:.4f}\".format(acc_test.item()))\n",
    "    print_class_acc(outputs[test_idx], labels[test_idx], pre='test')\n",
    "    return loss_test.item(), acc_test.item(), outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GraphSOMTE's training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_trains = []\n",
    "acc_vals = []\n",
    "loss_trains = []\n",
    "loss_vals = []\n",
    "loss_test = []\n",
    "test_acc = []\n",
    "loss_tests = []\n",
    "test_accs = []\n",
    "\n",
    "for epoch in tqdm(range(args.epochs)):\n",
    "        acc_train, acc_val, loss_train, loss_val = train(epoch, features, labels)\n",
    "        acc_trains.append(acc_train)\n",
    "        acc_vals.append(acc_val)\n",
    "        loss_trains.append(loss_train)\n",
    "        loss_vals.append(loss_val)\n",
    "        if epoch % 10 == 0:\n",
    "                test(epoch)\n",
    "                loss_test, test_acc, outputs = test(epoch)\n",
    "                loss_tests.append(loss_test)\n",
    "                test_accs.append(test_acc)\n",
    "confusion_matrix_vis(outputs[test_idx], labels[test_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the trained GraphSMOTE's model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model():\n",
    "    saved_content = {}\n",
    "    saved_content['encoder'] = encoder_s.state_dict()\n",
    "    saved_content['classifier'] = classifier_s.state_dict()\n",
    "    saved_content['decoder'] = decoder_s.state_dict()\n",
    "    torch.save(saved_content, 'checkpoint/{}/GraphSMOTE_opt{}_m{}_act{}_init{}_ir{}_res{}_l{}_h{}.pth'.format(args.dataset, \n",
    "        args.optimizer_alg, \n",
    "        args.momentum, \n",
    "        args.activation_func, \n",
    "        args.initalization,\n",
    "        args.imbalance_ratio,\n",
    "        args.res_connection,\n",
    "        len(n_hidden),\n",
    "        n_hidden[-1]))\n",
    "        return\n",
    "save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reweight model's train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.GraphConvolution import GCN_Encoder3, GCN_Classifier, GCN_Encoder_w\n",
    "import time\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from utils.evaluation import accuracy, print_class_acc\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torchvision import datasets,transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import copy\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "from torch import autograd\n",
    "import higher\n",
    "import itertools\n",
    "from utils.reweight import next, next2\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "np.seterr(all=\"ignore\")\n",
    "\n",
    "\n",
    "# encoder = GCN_Encoder3(nfeat=n_features,\n",
    "#         nhid=n_hidden,\n",
    "#         nembed=n_hidden[-1],\n",
    "#         dropout=args.dropout,\n",
    "#         nclass=args.n_classes,\n",
    "#         order=1)\n",
    "# classifier = GCN_Classifier(nembed=n_hidden[-1], \n",
    "#         nhid=n_hidden[-1], \n",
    "#         nclass=int(labels.max().item()) + 1, \n",
    "#         dropout=args.dropout, device=device)\n",
    "encoder = GCN_Encoder_w(nfeat = n_features, \n",
    "        nembed = n_hidden[-1], \n",
    "        nhid = n_hidden[-1], \n",
    "        nclass = int(labels.max().item()) + 1, \n",
    "        dropout = args.dropout, \n",
    "        device = device, init = args.initalization)\n",
    "# optimizer = optim.Adam(encoder.parameters(),\n",
    "#                        lr = args.learning_rate, weight_decay = args.weight_decay)\n",
    "if args.optimizer_alg == \"ADAM\":\n",
    "        optimizer = optim.Adam(encoder_n.parameters(),\n",
    "                        lr = args.learning_rate, weight_decay = args.weight_decay)\n",
    "elif args.optimizer_alg == \"Momentum\":\n",
    "        optimizer = optim.SGD(encoder_n.parameters(),\n",
    "                        lr = args.learning_rate, momentum = args.momentum)\n",
    "elif args.optimizer_alg == \"RMSProp\":\n",
    "        optimizer = optim.SGD(encoder_n.parameters(),\n",
    "                        lr = args.learning_rate, weight_decay = args.weight_decay)\n",
    "else:\n",
    "        optimizer = optim.Adam(encoder_n.parameters(),\n",
    "                        lr = args.learning_rate, weight_decay = args.weight_decay)\n",
    "# criterion = nn.BCEWithLogitsLoss().to(device)\n",
    "def train(epoch, features, labels):\n",
    "        encoder.train()\n",
    "        # classifier.train()\n",
    "        t = time.time()\n",
    "        optimizer.zero_grad()\n",
    "        with higher.innerloop_ctx(encoder, optimizer) as (meta_model, meta_opt):\n",
    "                meta_train_outputs = meta_model(features, adj_mtx)\n",
    "                # criterion.reduction = 'none'\n",
    "                # new_labels = F.one_hot(labels, num_classes=int(labels.max().item()) + 1).double()\n",
    "                meta_train_loss = F.cross_entropy(meta_train_outputs[train_idx], labels[train_idx])\n",
    "                # meta_train_loss = criterion(meta_train_outputs[train_idx], new_labels[train_idx])\n",
    "                eps = torch.zeros(meta_train_loss.size(), requires_grad=True, device=device)\n",
    "                meta_train_loss = torch.sum(eps * meta_train_loss)\n",
    "                meta_opt.step(meta_train_loss)\n",
    "                sampled_val_idx, new_adj_mtx, new_features, new_labels = next(args, features, labels, val_idx, adj_mtx)\n",
    "                # meta_inputs, meta_labels = next(args, features, labels, val_idx, adj_mtx)\n",
    "                meta_val_idx, meta_adj_mtx, meta_features, meta_labels = sampled_val_idx.to(device=device, non_blocking=True), \\\n",
    "                        new_adj_mtx.to(device=device, non_blocking=True), \\\n",
    "                        new_features.to(device=device, non_blocking=True), \\\n",
    "                        new_labels.to(device=device, non_blocking=True)\n",
    "                meta_val_outputs = meta_model(meta_features, meta_adj_mtx.double())\n",
    "                # criterion.reduction = 'mean'\n",
    "                # new_meta_labels = F.one_hot(meta_labels, num_classes=int(labels.max().item()) + 1).double()\n",
    "                meta_train_loss = F.cross_entropy(meta_val_outputs, meta_labels)\n",
    "                # meta_val_loss = criterion(meta_val_outputs, new_meta_labels)\n",
    "                eps_grads = torch.autograd.grad(meta_train_loss, eps)[0].detach()\n",
    "        w_tilde = torch.clamp(-eps_grads, min=0)\n",
    "        l1_norm = torch.sum(w_tilde)\n",
    "        if l1_norm != 0:\n",
    "                w = w_tilde / l1_norm\n",
    "        else:\n",
    "                w = w_tilde\n",
    "        outputs = encoder(features, adj_mtx.double())\n",
    "        # criterion.reduction = 'none'\n",
    "        # new_main_labels = F.one_hot(labels, num_classes=int(labels.max().item()) + 1).double()\n",
    "        loss = F.cross_entropy(outputs[train_idx], labels[train_idx])\n",
    "        # loss = criterion(outputs[train_idx], new_main_labels[train_idx])\n",
    "        loss = torch.sum(w * loss)\n",
    "\n",
    "        loss_train = F.cross_entropy(outputs[train_idx], labels[train_idx].reshape(-1))\n",
    "        acc_train = accuracy(outputs[train_idx], labels[train_idx].reshape(-1))\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_val = F.cross_entropy(outputs[val_idx], labels[val_idx].reshape(-1))\n",
    "        acc_val = accuracy(outputs[val_idx], labels[val_idx].reshape(-1))\n",
    "\n",
    "        print('Epoch: {:05d}'.format(epoch + 1),\n",
    "                'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "                'acc_train: {:.4f}'.format(acc_train.item()),\n",
    "                'loss_val: {:.4f}'.format(loss_val.item()),\n",
    "                'acc_val: {:.4f}'.format(acc_val.item()),\n",
    "                'time: {:.4f}s'.format(time.time() - t))\n",
    "        return acc_train.item(), acc_val.item(), loss_train.item(), loss_val.item()\n",
    "\n",
    "        # keep track of epoch loss/accuracy\n",
    "        # train_loss += loss.item() * outputs.shape[0]\n",
    "\n",
    "                # out = output[train_idx]\n",
    "                # gt = labels[train_idx].reshape(-1)\n",
    "                # if args.setting == 'reweight':\n",
    "                #         weight = \"STH\"\n",
    "                #         loss_train = F.cross_entropy(out, gt, weight = weight)\n",
    "                # else:\n",
    "                #         loss_train = F.cross_entropy(out, gt)\n",
    "                # acc_train = accuracy(out, gt)\n",
    "                # loss_train.backward()\n",
    "                # optimizer_en.step()\n",
    "                # optimizer_cls.step()\n",
    "                # gt_v = labels[test_idx].reshape(-1)\n",
    "                # out_v = output[test_idx]\n",
    "                # loss_val = F.cross_entropy(out_v, gt_v)\n",
    "                # acc_val = accuracy(out_v, gt_v)\n",
    "                # # print_class_acc(out_v, gt_v)\n",
    "                # print('Epoch: {:05d}'.format(epoch+ 1),\n",
    "                # 'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "                # 'acc_train: {:.4f}'.format(acc_train.item()),\n",
    "                # 'loss_val: {:.4f}'.format(loss_val.item()),\n",
    "                # 'acc_val: {:.4f}'.format(acc_val.item()),\n",
    "                # 'time: {:.4f}s'.format(time.time() - t))\n",
    "                \n",
    "        # return acc_train.item(), acc_val.item(), loss_train.item(), loss_val.item()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reweight model's test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch = 0):\n",
    "    encoder.eval()\n",
    "    outputs = encoder(features, adj_mtx)\n",
    "    loss_test = F.cross_entropy(outputs[test_idx], labels[test_idx])\n",
    "    acc_test = accuracy(outputs[test_idx], labels[test_idx])\n",
    "    print(\"Test set results:\",\n",
    "          \"loss= {:.4f}\".format(loss_test.item()),\n",
    "          \"accuracy= {:.4f}\".format(acc_test.item()))\n",
    "\n",
    "    print_class_acc(outputs[test_idx], labels[test_idx], pre='test')\n",
    "    return loss_test.item(), acc_test.item(), outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reweight model's train and testing process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_trains = []\n",
    "acc_vals = []\n",
    "loss_trains = []\n",
    "loss_vals = []\n",
    "loss_test = []\n",
    "test_acc = []\n",
    "loss_tests = []\n",
    "test_accs = []\n",
    "for epoch in tqdm(range(args.epochs)):\n",
    "        acc_train, acc_val, loss_train, loss_val = train(epoch, features, labels)\n",
    "        acc_trains.append(acc_train)\n",
    "        acc_vals.append(acc_val)\n",
    "        loss_trains.append(loss_train)\n",
    "        loss_vals.append(loss_val)\n",
    "        if epoch % 10 == 0:\n",
    "                loss_test, test_acc, outputs = test(epoch)\n",
    "                loss_tests.append(loss_test)\n",
    "                test_accs.append(test_acc)\n",
    "confusion_matrix_vis(outputs[test_idx], labels[test_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the reweight model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model():\n",
    "    saved_content = {}\n",
    "    saved_content['encoder'] = encoder.state_dict()\n",
    "    torch.save(saved_content, 'checkpoint/{}/Reweight_opt{}_m{}_act{}_init{}_ir{}_res{}_l{}_h{}.pth'.format(args.dataset, \n",
    "        args.optimizer_alg, \n",
    "        args.momentum, \n",
    "        args.activation_func, \n",
    "        args.initalization,\n",
    "        args.imbalance_ratio,\n",
    "        args.res_connection,\n",
    "        len(n_hidden),\n",
    "        n_hidden[-1]))\n",
    "    return\n",
    "save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# %matplotlib notebook\n",
    "# %matplotlib inline\n",
    "\n",
    "plt.plot(loss_vals)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Label 8')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "# Load the MNIST data\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True, as_frame=False)\n",
    " \n",
    "# Randomly select 1000 samples for performance reasons\n",
    "np.random.seed(100)\n",
    "subsample_idc = np.random.choice(X.shape[0], 1000, replace=False)\n",
    "X = X[subsample_idc,:]\n",
    "y = y[subsample_idc]\n",
    " \n",
    "# Show two example images\n",
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].imshow(X[11,:].reshape(28,28), 'Greys')\n",
    "ax[1].imshow(X[15,:].reshape(28,28), 'Greys')\n",
    "ax[0].set_title(\"Label 3\")\n",
    "ax[1].set_title(\"Label 8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 7.6822e-02, -7.1310e-03, -7.3054e-03, -4.3642e-03, -6.8385e-03,\n",
       "        -3.0414e-03,  9.7736e-01,  1.1751e+00,  1.2688e+00, -1.6855e-03,\n",
       "         1.1703e+00,  1.2958e+00, -4.0162e-04, -1.1210e-02, -9.3044e-03,\n",
       "         4.0033e-01, -5.3877e-03, -8.9215e-03, -2.9110e-02,  7.4358e-01,\n",
       "        -3.3134e-03, -2.9392e-03, -4.1255e-03,  1.5071e-01, -7.6853e-03,\n",
       "         2.5594e-01, -9.8877e-03, -1.1375e-02, -2.2427e-03,  7.0393e-02,\n",
       "        -1.2150e-02,  1.2418e+00,  4.9066e-01, -1.3234e-03, -2.8120e-03,\n",
       "        -1.9271e-02,  3.2047e-02, -8.5873e-03, -4.5847e-03, -5.6326e-03,\n",
       "        -9.3875e-04, -1.6507e-02, -1.0231e-02,  7.8923e-01, -5.9627e-03,\n",
       "        -4.1853e-04, -1.7628e-02, -5.0738e-03,  9.9925e-01,  2.0283e-02,\n",
       "        -5.2995e-03, -4.4723e-03, -1.1188e-03, -4.3558e-02, -7.2224e-03,\n",
       "         5.0062e-01, -4.7456e-03,  8.7793e-01, -2.0701e-02, -2.2587e-02,\n",
       "        -1.3794e-02, -2.5667e-02, -6.6246e-03, -1.0123e-02],\n",
       "       dtype=torch.float64, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape\n",
    "# (1000, 784)\n",
    "# 1000 Samples with 784 features\n",
    "y.shape\n",
    "# (1000,)\n",
    "# 1000 labels\n",
    "np.unique(y)\n",
    "# array(['0', '1', '2', '3', '4', '5', '6', '7', '8', '9'], dtype=object)\n",
    "# The 10 classes of the images\n",
    "X[0]\n",
    "embed[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mahdi/anaconda3/envs/practice/lib/python3.10/site-packages/sklearn/manifold/_t_sne.py:800: FutureWarning: The default initialization in TSNE will change from 'random' to 'pca' in 1.2.\n",
      "  warnings.warn(\n",
      "/home/mahdi/anaconda3/envs/practice/lib/python3.10/site-packages/sklearn/manifold/_t_sne.py:810: FutureWarning: The default learning rate in TSNE will change from 200.0 to 'auto' in 1.2.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1000, 784)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    " \n",
    "# We want to get TSNE embedding with 2 dimensions\n",
    "n_components = 3\n",
    "tsne = TSNE(n_components)\n",
    "tsne_result = tsne.fit_transform(X)\n",
    "tsne_result.shape\n",
    "# (1000, 2)\n",
    "# Two dimensions for each of our images\n",
    " \n",
    "# Plot the result of our TSNE with the label color coded\n",
    "# A lot of the stuff here is about making the plot look pretty and not TSNE\n",
    "# tsne_result_df = pd.DataFrame({'tsne_1': tsne_result[:,0], 'tsne_2': tsne_result[:,1], 'label': y})\n",
    "# fig, ax = plt.subplots(1)\n",
    "# sns.scatterplot(x='tsne_1', y='tsne_2', hue='label', data=tsne_result_df, ax=ax,s=120)\n",
    "# lim = (tsne_result.min()-5, tsne_result.max()+5)\n",
    "# ax.set_xlim(lim)\n",
    "# ax.set_ylim(lim)\n",
    "# ax.set_aspect('equal')\n",
    "# ax.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('arc_selection-master')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "04f122987ad9a59b0c863ec73977cb4833edd644652b774e5b01a9e2fe636c23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
