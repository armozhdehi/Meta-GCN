{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.GraphConvolution import GraphConvolution\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils.GraphConvolution import GraphConvolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    weight_decay = 5e-4\n",
    "    epochs = 300\n",
    "    learning_rate = 0.01\n",
    "    learning_rate_W = 0.01\n",
    "    dropout = 0.5\n",
    "    dropout_W = 0.5\n",
    "    gamma = 1\n",
    "    no_cuda = False\n",
    "    train_ratio=0.6\n",
    "    test_ratio=0.1\n",
    "    n_classes = 2\n",
    "    seed = 12345\n",
    "    torch.manual_seed(seed)\n",
    "    dataset = \"diabetes\"\n",
    "    # dataset = \"haberman\"\n",
    "    order = 4\n",
    "    n_features = 0\n",
    "    w_val_size = 10\n",
    "    imbalance_ratio = None\n",
    "    n_hidden = 0\n",
    "    setting = None\n",
    "\n",
    "args = Args()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset specific variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_loader import data_loader_diabetes, data_loader_haberman\n",
    "\n",
    "diabetes_adj_mtx, diabetes_labels_df, diabetes_features_df, \\\n",
    "        diabetes_train_idx, diabetes_val_idx, diabetes_test_idx, diabetes_n_features = data_loader_diabetes(args)\n",
    "\n",
    "haberman_adj_mtx, haberman_labels_df, haberman_features_df, \\\n",
    "        haberman_train_idx, haberman_val_idx, haberman_test_idx, haberman_n_features = data_loader_haberman(args)\n",
    "\n",
    "if args.dataset == \"diabetes\":\n",
    "    adj_mtx = diabetes_adj_mtx\n",
    "    n_hidden = [64, 64, 64, 64]\n",
    "    n_features = diabetes_n_features\n",
    "    features = diabetes_features_df\n",
    "    labels = diabetes_labels_df\n",
    "    # train_X = diabetes_train_X_df\n",
    "    # train_Y = diabetes_train_Y_df\n",
    "    # val_X = diabetes_val_X_df\n",
    "    # val_Y = diabetes_val_Y_df\n",
    "    # test_X = diabetes_test_X_df\n",
    "    # test_Y = diabetes_test_Y_df\n",
    "    train_idx = diabetes_train_idx\n",
    "    val_idx = diabetes_val_idx\n",
    "    test_idx = diabetes_test_idx\n",
    "elif args.dataset == \"haberman\":\n",
    "    adj_mtx = haberman_adj_mtx\n",
    "    n_hidden = [64]\n",
    "    n_features = haberman_n_features\n",
    "    features = haberman_features_df\n",
    "    labels = haberman_labels_df\n",
    "    # train_X = haberman_train_X_df\n",
    "    # train_Y = haberman_train_Y_df\n",
    "    # val_X = haberman_val_X_df\n",
    "    # val_Y = haberman_val_Y_df\n",
    "    # test_X = haberman_test_X_df\n",
    "    # test_Y = haberman_test_Y_df\n",
    "    train_idx = haberman_train_idx\n",
    "    val_idx = haberman_val_idx\n",
    "    test_idx = haberman_test_idx\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(train_Y, columns=['labels']).labels.unique()\n",
    "# .groupby('Team')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert len(pd.DataFrame(val_Y, columns=['labels']).labels.unique()) == len(pd.DataFrame(train_Y, columns=['labels']).labels.unique()) == len(pd.DataFrame(test_Y, columns=['labels']).labels.unique()), \\\n",
    "#     \"There are some classes missing in one the 3 partitiones of the dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if False else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe to Tensor transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = torch.from_numpy(np.concatenate((train_X, val_X, test_X), axis=0)).to(device)\n",
    "# labels = torch.from_numpy(np.int64(np.concatenate((train_Y, val_Y, test_Y), axis=0))).to(device)\n",
    "train_idx = torch.from_numpy(np.array(train_idx, dtype=np.int64)).to(device)\n",
    "val_idx = torch.from_numpy(np.array(val_idx, dtype=np.int64)).to(device)\n",
    "test_idx = torch.from_numpy(np.array(test_idx, dtype=np.int64)).to(device)\n",
    "features = torch.from_numpy(np.array(features, dtype=np.float64)).to(device)\n",
    "labels = torch.from_numpy(np.array(labels, dtype=np.int64)).to(device)\n",
    "adj_mtx = torch.from_numpy(np.array(adj_mtx, dtype=np.float64)).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.GraphConvolution import GCN_Encoder3, GCN_Classifier\n",
    "import time\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from utils.evaluation import accuracy, print_class_acc\n",
    "\n",
    "encoder = GCN_Encoder3(nfeat=n_features,\n",
    "        nhid=n_hidden,\n",
    "        nembed=n_hidden[-1],\n",
    "        dropout=args.dropout,\n",
    "        nclass=args.n_classes,\n",
    "        order=1)\n",
    "classifier = GCN_Classifier(nembed=n_hidden[-1], \n",
    "        nhid=n_hidden[-1], \n",
    "        nclass=int(labels.max().item()) + 1, \n",
    "        dropout=args.dropout, device=device)\n",
    "optimizer_en = optim.Adam(encoder.parameters(),\n",
    "                       lr=args.learning_rate, weight_decay=args.weight_decay)\n",
    "optimizer_cls = optim.Adam(classifier.parameters(),\n",
    "                       lr=args.learning_rate, weight_decay=args.weight_decay)\n",
    "def train(epoch):\n",
    "        t = time.time()\n",
    "        encoder.train()\n",
    "        classifier.train()\n",
    "        optimizer_en.zero_grad()\n",
    "        optimizer_cls.zero_grad()\n",
    "        embed = encoder(features, adj_mtx)\n",
    "        output = classifier(embed, adj_mtx)\n",
    "        out = output[train_idx]\n",
    "        gt = labels[train_idx].reshape(-1)\n",
    "        if args.setting == 'reweight':\n",
    "                weight = \"STH\"\n",
    "                loss_train = F.cross_entropy(out, gt, weight=weight)\n",
    "        else:\n",
    "                loss_train = F.cross_entropy(out, gt)\n",
    "        acc_train = accuracy(out, gt)\n",
    "        loss_train.backward()\n",
    "        optimizer_en.step()\n",
    "        optimizer_cls.step()\n",
    "        gt_v = labels[test_idx].reshape(-1)\n",
    "        out_v = output[test_idx]\n",
    "        loss_val = F.cross_entropy(out_v, gt_v)\n",
    "        acc_val = accuracy(out_v, gt_v)\n",
    "        print_class_acc(out_v, gt_v)\n",
    "        print('Epoch: {:05d}'.format(epoch+ 1),\n",
    "          'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "          'acc_train: {:.4f}'.format(acc_train.item()),\n",
    "          'loss_val: {:.4f}'.format(loss_val.item()),\n",
    "          'acc_val: {:.4f}'.format(acc_val.item()),\n",
    "          'time: {:.4f}s'.format(time.time() - t))\n",
    "        \n",
    "        return acc_train.item(), acc_val.item(), loss_train.item(), loss_val.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid current auc-roc score: 0.467407, current macro_F score: 0.416327\n",
      "Epoch: 00001 loss_train: 79643.0313 acc_train: 0.5783 loss_val: 143108.6244 acc_val: 0.4935 time: 0.0345s\n",
      "valid current auc-roc score: 0.622222, current macro_F score: 0.583639\n",
      "Epoch: 00002 loss_train: 91211.1294 acc_train: 0.4935 loss_val: 81699.9482 acc_val: 0.5974 time: 0.0217s\n",
      "valid current auc-roc score: 0.554815, current macro_F score: 0.432540\n",
      "Epoch: 00003 loss_train: 165744.5774 acc_train: 0.6522 loss_val: 142274.7153 acc_val: 0.6623 time: 0.0231s\n",
      "valid current auc-roc score: 0.631111, current macro_F score: 0.536455\n",
      "Epoch: 00004 loss_train: 36527.6863 acc_train: 0.5870 loss_val: 34851.2615 acc_val: 0.6494 time: 0.0226s\n",
      "valid current auc-roc score: 0.410370, current macro_F score: 0.326300\n",
      "Epoch: 00005 loss_train: 105474.2743 acc_train: 0.4174 loss_val: 108384.8422 acc_val: 0.3377 time: 0.0246s\n",
      "valid current auc-roc score: 0.426667, current macro_F score: 0.381802\n",
      "Epoch: 00006 loss_train: 35913.8981 acc_train: 0.5435 loss_val: 47833.5731 acc_val: 0.4156 time: 0.0436s\n",
      "valid current auc-roc score: 0.620741, current macro_F score: 0.454760\n",
      "Epoch: 00007 loss_train: 22071.8002 acc_train: 0.6522 loss_val: 16293.2872 acc_val: 0.6494 time: 0.0752s\n",
      "valid current auc-roc score: 0.745556, current macro_F score: 0.495148\n",
      "Epoch: 00008 loss_train: 7420.2171 acc_train: 0.6370 loss_val: 4622.0594 acc_val: 0.6753 time: 0.0412s\n",
      "valid current auc-roc score: 0.474074, current macro_F score: 0.416358\n",
      "Epoch: 00009 loss_train: 2194.6065 acc_train: 0.5391 loss_val: 1734.1905 acc_val: 0.4416 time: 0.0302s\n",
      "valid current auc-roc score: 0.716667, current macro_F score: 0.495148\n",
      "Epoch: 00010 loss_train: 1032.4989 acc_train: 0.6587 loss_val: 779.6075 acc_val: 0.6753 time: 0.0321s\n",
      "valid current auc-roc score: 0.428889, current macro_F score: 0.390152\n",
      "Epoch: 00011 loss_train: 1040.6832 acc_train: 0.4804 loss_val: 1275.4487 acc_val: 0.4026 time: 0.0428s\n",
      "valid current auc-roc score: 0.728148, current macro_F score: 0.432540\n",
      "Epoch: 00012 loss_train: 836.6053 acc_train: 0.6130 loss_val: 788.3392 acc_val: 0.6623 time: 0.0353s\n",
      "valid current auc-roc score: 0.690370, current macro_F score: 0.500840\n",
      "Epoch: 00013 loss_train: 492.2971 acc_train: 0.6348 loss_val: 403.9860 acc_val: 0.6494 time: 0.0624s\n",
      "valid current auc-roc score: 0.569259, current macro_F score: 0.545593\n",
      "Epoch: 00014 loss_train: 400.1486 acc_train: 0.5696 loss_val: 476.2726 acc_val: 0.5974 time: 0.0372s\n",
      "valid current auc-roc score: 0.653704, current macro_F score: 0.519751\n",
      "Epoch: 00015 loss_train: 341.9719 acc_train: 0.6174 loss_val: 316.7537 acc_val: 0.6494 time: 0.0391s\n",
      "valid current auc-roc score: 0.471111, current macro_F score: 0.450000\n",
      "Epoch: 00016 loss_train: 173.1636 acc_train: 0.4304 loss_val: 152.5862 acc_val: 0.4545 time: 0.0461s\n",
      "valid current auc-roc score: 0.414815, current macro_F score: 0.441181\n",
      "Epoch: 00017 loss_train: 142.3137 acc_train: 0.4457 loss_val: 153.0518 acc_val: 0.4416 time: 0.0473s\n",
      "valid current auc-roc score: 0.561111, current macro_F score: 0.512570\n",
      "Epoch: 00018 loss_train: 66.3753 acc_train: 0.5783 loss_val: 74.1179 acc_val: 0.5455 time: 0.0557s\n",
      "valid current auc-roc score: 0.519259, current macro_F score: 0.505051\n",
      "Epoch: 00019 loss_train: 75.8142 acc_train: 0.5239 loss_val: 81.1040 acc_val: 0.5455 time: 0.0635s\n",
      "valid current auc-roc score: 0.612963, current macro_F score: 0.576258\n",
      "Epoch: 00020 loss_train: 26.3898 acc_train: 0.5891 loss_val: 20.0296 acc_val: 0.6364 time: 0.0541s\n",
      "valid current auc-roc score: 0.463704, current macro_F score: 0.446259\n",
      "Epoch: 00021 loss_train: 5.6708 acc_train: 0.4957 loss_val: 7.5931 acc_val: 0.5195 time: 0.0414s\n",
      "valid current auc-roc score: 0.523333, current macro_F score: 0.453901\n",
      "Epoch: 00022 loss_train: 3.4391 acc_train: 0.5304 loss_val: 1.4583 acc_val: 0.4805 time: 0.0356s\n",
      "valid current auc-roc score: 0.585926, current macro_F score: 0.545593\n",
      "Epoch: 00023 loss_train: 2.5242 acc_train: 0.6152 loss_val: 0.9162 acc_val: 0.5974 time: 0.0525s\n",
      "valid current auc-roc score: 0.514074, current macro_F score: 0.554545\n",
      "Epoch: 00024 loss_train: 0.7104 acc_train: 0.6130 loss_val: 0.7157 acc_val: 0.6364 time: 0.0388s\n",
      "valid current auc-roc score: 0.498519, current macro_F score: 0.459091\n",
      "Epoch: 00025 loss_train: 0.6597 acc_train: 0.6261 loss_val: 0.6875 acc_val: 0.5584 time: 0.0475s\n",
      "valid current auc-roc score: 0.709630, current macro_F score: 0.560965\n",
      "Epoch: 00026 loss_train: 0.8884 acc_train: 0.6348 loss_val: 0.7265 acc_val: 0.6623 time: 0.0372s\n",
      "valid current auc-roc score: 0.673333, current macro_F score: 0.574790\n",
      "Epoch: 00027 loss_train: 0.9916 acc_train: 0.6217 loss_val: 0.7136 acc_val: 0.7013 time: 0.0440s\n",
      "valid current auc-roc score: 0.640000, current macro_F score: 0.560965\n",
      "Epoch: 00028 loss_train: 0.6255 acc_train: 0.6565 loss_val: 0.6388 acc_val: 0.6623 time: 0.0419s\n",
      "valid current auc-roc score: 0.640000, current macro_F score: 0.500840\n",
      "Epoch: 00029 loss_train: 0.6602 acc_train: 0.6304 loss_val: 0.6243 acc_val: 0.6494 time: 0.0420s\n",
      "valid current auc-roc score: 0.657778, current macro_F score: 0.440771\n",
      "Epoch: 00030 loss_train: 0.6643 acc_train: 0.6348 loss_val: 0.6148 acc_val: 0.6234 time: 0.0421s\n",
      "valid current auc-roc score: 0.717778, current macro_F score: 0.484176\n",
      "Epoch: 00031 loss_train: 0.6441 acc_train: 0.6283 loss_val: 0.5770 acc_val: 0.6234 time: 0.0349s\n",
      "valid current auc-roc score: 0.688889, current macro_F score: 0.426891\n",
      "Epoch: 00032 loss_train: 0.6497 acc_train: 0.6326 loss_val: 0.5827 acc_val: 0.5974 time: 0.0373s\n",
      "valid current auc-roc score: 0.702963, current macro_F score: 0.596690\n",
      "Epoch: 00033 loss_train: 0.6260 acc_train: 0.6326 loss_val: 0.5892 acc_val: 0.6753 time: 0.0403s\n",
      "valid current auc-roc score: 0.613333, current macro_F score: 0.484176\n",
      "Epoch: 00034 loss_train: 0.6188 acc_train: 0.6457 loss_val: 0.6326 acc_val: 0.6234 time: 0.0394s\n",
      "valid current auc-roc score: 0.567407, current macro_F score: 0.467630\n",
      "Epoch: 00035 loss_train: 0.6348 acc_train: 0.6130 loss_val: 0.6590 acc_val: 0.5714 time: 0.0427s\n",
      "valid current auc-roc score: 0.716296, current macro_F score: 0.493421\n",
      "Epoch: 00036 loss_train: 0.6340 acc_train: 0.6413 loss_val: 0.5766 acc_val: 0.6104 time: 0.0391s\n",
      "valid current auc-roc score: 0.585926, current macro_F score: 0.435366\n",
      "Epoch: 00037 loss_train: 0.6434 acc_train: 0.6370 loss_val: 0.6521 acc_val: 0.5455 time: 0.0357s\n",
      "valid current auc-roc score: 0.623704, current macro_F score: 0.403101\n",
      "Epoch: 00038 loss_train: 0.6478 acc_train: 0.6304 loss_val: 0.6199 acc_val: 0.5195 time: 0.0420s\n",
      "valid current auc-roc score: 0.655926, current macro_F score: 0.492467\n",
      "Epoch: 00039 loss_train: 0.6636 acc_train: 0.6261 loss_val: 0.6283 acc_val: 0.6364 time: 0.0373s\n",
      "valid current auc-roc score: 0.616667, current macro_F score: 0.463866\n",
      "Epoch: 00040 loss_train: 0.6410 acc_train: 0.6500 loss_val: 0.6717 acc_val: 0.6234 time: 0.0393s\n",
      "valid current auc-roc score: 0.559259, current macro_F score: 0.518023\n",
      "Epoch: 00041 loss_train: 1.1796 acc_train: 0.6304 loss_val: 1.0802 acc_val: 0.6234 time: 0.0494s\n",
      "valid current auc-roc score: 0.645185, current macro_F score: 0.456215\n",
      "Epoch: 00042 loss_train: 0.6484 acc_train: 0.6152 loss_val: 0.6117 acc_val: 0.6104 time: 0.0373s\n",
      "valid current auc-roc score: 0.560741, current macro_F score: 0.499895\n",
      "Epoch: 00043 loss_train: 0.6734 acc_train: 0.6326 loss_val: 0.6945 acc_val: 0.5974 time: 0.0393s\n",
      "valid current auc-roc score: 0.643704, current macro_F score: 0.560965\n",
      "Epoch: 00044 loss_train: 0.6641 acc_train: 0.6326 loss_val: 0.6179 acc_val: 0.6623 time: 0.0350s\n",
      "valid current auc-roc score: 0.593333, current macro_F score: 0.515723\n",
      "Epoch: 00045 loss_train: 0.6571 acc_train: 0.6109 loss_val: 0.6133 acc_val: 0.5844 time: 0.0406s\n",
      "valid current auc-roc score: 0.596296, current macro_F score: 0.535024\n",
      "Epoch: 00046 loss_train: 0.6675 acc_train: 0.5848 loss_val: 0.6401 acc_val: 0.6104 time: 0.0404s\n",
      "valid current auc-roc score: 0.640741, current macro_F score: 0.644615\n",
      "Epoch: 00047 loss_train: 0.6466 acc_train: 0.6196 loss_val: 0.6363 acc_val: 0.6883 time: 0.0420s\n",
      "valid current auc-roc score: 0.562963, current macro_F score: 0.486667\n",
      "Epoch: 00048 loss_train: 0.6555 acc_train: 0.5935 loss_val: 0.6315 acc_val: 0.5325 time: 0.0436s\n",
      "valid current auc-roc score: 0.564444, current macro_F score: 0.499895\n",
      "Epoch: 00049 loss_train: 0.6432 acc_train: 0.6413 loss_val: 0.6574 acc_val: 0.5974 time: 0.0443s\n",
      "valid current auc-roc score: 0.400000, current macro_F score: 0.372241\n",
      "Epoch: 00050 loss_train: 0.6649 acc_train: 0.5935 loss_val: 0.7019 acc_val: 0.4675 time: 0.0481s\n",
      "valid current auc-roc score: 0.597778, current macro_F score: 0.555975\n",
      "Epoch: 00051 loss_train: 0.6495 acc_train: 0.6087 loss_val: 0.6428 acc_val: 0.6234 time: 0.0499s\n",
      "valid current auc-roc score: 0.706667, current macro_F score: 0.574405\n",
      "Epoch: 00052 loss_train: 0.6438 acc_train: 0.6413 loss_val: 0.5984 acc_val: 0.6623 time: 0.0396s\n",
      "valid current auc-roc score: 0.602222, current macro_F score: 0.522727\n",
      "Epoch: 00053 loss_train: 0.6448 acc_train: 0.6435 loss_val: 0.6248 acc_val: 0.6104 time: 0.0421s\n",
      "valid current auc-roc score: 0.680000, current macro_F score: 0.519751\n",
      "Epoch: 00054 loss_train: 0.6559 acc_train: 0.6217 loss_val: 0.6037 acc_val: 0.6494 time: 0.0393s\n",
      "valid current auc-roc score: 0.666667, current macro_F score: 0.545826\n",
      "Epoch: 00055 loss_train: 0.6408 acc_train: 0.5848 loss_val: 0.6145 acc_val: 0.6623 time: 0.0433s\n",
      "valid current auc-roc score: 0.702222, current macro_F score: 0.532160\n",
      "Epoch: 00056 loss_train: 0.6556 acc_train: 0.6043 loss_val: 0.5871 acc_val: 0.6234 time: 0.0394s\n",
      "valid current auc-roc score: 0.655556, current macro_F score: 0.586364\n",
      "Epoch: 00057 loss_train: 0.6495 acc_train: 0.6217 loss_val: 0.6218 acc_val: 0.6623 time: 0.0373s\n",
      "valid current auc-roc score: 0.766667, current macro_F score: 0.537815\n",
      "Epoch: 00058 loss_train: 0.6474 acc_train: 0.5957 loss_val: 0.5771 acc_val: 0.6753 time: 0.0389s\n",
      "valid current auc-roc score: 0.652963, current macro_F score: 0.502118\n",
      "Epoch: 00059 loss_train: 0.6582 acc_train: 0.5891 loss_val: 0.6127 acc_val: 0.6234 time: 0.0386s\n",
      "valid current auc-roc score: 0.558519, current macro_F score: 0.393701\n",
      "Epoch: 00060 loss_train: 0.6435 acc_train: 0.6500 loss_val: 0.6555 acc_val: 0.6494 time: 0.0382s\n",
      "valid current auc-roc score: 0.683333, current macro_F score: 0.393701\n",
      "Epoch: 00061 loss_train: 107.0575 acc_train: 0.6478 loss_val: 109.0682 acc_val: 0.6494 time: 0.0393s\n",
      "valid current auc-roc score: 0.641481, current macro_F score: 0.393701\n",
      "Epoch: 00062 loss_train: 0.6368 acc_train: 0.6522 loss_val: 0.6203 acc_val: 0.6494 time: 0.0386s\n",
      "valid current auc-roc score: 0.687407, current macro_F score: 0.393701\n",
      "Epoch: 00063 loss_train: 0.6381 acc_train: 0.6522 loss_val: 0.6149 acc_val: 0.6494 time: 0.0385s\n",
      "valid current auc-roc score: 0.682222, current macro_F score: 0.393701\n",
      "Epoch: 00064 loss_train: 0.6498 acc_train: 0.6522 loss_val: 0.6198 acc_val: 0.6494 time: 0.0367s\n",
      "valid current auc-roc score: 0.529630, current macro_F score: 0.384000\n",
      "Epoch: 00065 loss_train: 0.6497 acc_train: 0.6413 loss_val: 0.6572 acc_val: 0.6234 time: 0.0415s\n",
      "valid current auc-roc score: 0.627407, current macro_F score: 0.393701\n",
      "Epoch: 00066 loss_train: 0.6554 acc_train: 0.6522 loss_val: 0.6364 acc_val: 0.6494 time: 0.0492s\n",
      "valid current auc-roc score: 0.561111, current macro_F score: 0.393701\n",
      "Epoch: 00067 loss_train: 0.6465 acc_train: 0.6522 loss_val: 0.6509 acc_val: 0.6494 time: 0.0457s\n",
      "valid current auc-roc score: 0.672222, current macro_F score: 0.393701\n",
      "Epoch: 00068 loss_train: 0.6477 acc_train: 0.6478 loss_val: 0.6260 acc_val: 0.6494 time: 0.0398s\n",
      "valid current auc-roc score: 0.574074, current macro_F score: 0.393701\n",
      "Epoch: 00069 loss_train: 0.6546 acc_train: 0.6522 loss_val: 0.6498 acc_val: 0.6494 time: 0.0426s\n",
      "valid current auc-roc score: 0.559259, current macro_F score: 0.393701\n",
      "Epoch: 00070 loss_train: 0.6408 acc_train: 0.6522 loss_val: 0.6490 acc_val: 0.6494 time: 0.0348s\n",
      "valid current auc-roc score: 0.640741, current macro_F score: 0.393701\n",
      "Epoch: 00071 loss_train: 0.6367 acc_train: 0.6522 loss_val: 0.6279 acc_val: 0.6494 time: 0.0442s\n",
      "valid current auc-roc score: 0.642222, current macro_F score: 0.393701\n",
      "Epoch: 00072 loss_train: 0.6468 acc_train: 0.6543 loss_val: 0.6289 acc_val: 0.6494 time: 0.0492s\n",
      "valid current auc-roc score: 0.776296, current macro_F score: 0.393701\n",
      "Epoch: 00073 loss_train: 0.6333 acc_train: 0.6522 loss_val: 0.5826 acc_val: 0.6494 time: 0.0424s\n",
      "valid current auc-roc score: 0.567037, current macro_F score: 0.393701\n",
      "Epoch: 00074 loss_train: 0.6426 acc_train: 0.6522 loss_val: 0.6504 acc_val: 0.6494 time: 0.0403s\n",
      "valid current auc-roc score: 0.682222, current macro_F score: 0.379032\n",
      "Epoch: 00075 loss_train: 6.3901 acc_train: 0.6522 loss_val: 3.5715 acc_val: 0.6104 time: 0.0398s\n",
      "valid current auc-roc score: 0.675185, current macro_F score: 0.393701\n",
      "Epoch: 00076 loss_train: 0.6331 acc_train: 0.6370 loss_val: 0.5833 acc_val: 0.6494 time: 0.0368s\n",
      "valid current auc-roc score: 0.658148, current macro_F score: 0.393701\n",
      "Epoch: 00077 loss_train: 0.6377 acc_train: 0.6522 loss_val: 0.6213 acc_val: 0.6494 time: 0.0398s\n",
      "valid current auc-roc score: 0.660741, current macro_F score: 0.393701\n",
      "Epoch: 00078 loss_train: 0.6456 acc_train: 0.6522 loss_val: 0.6236 acc_val: 0.6494 time: 0.0414s\n",
      "valid current auc-roc score: 0.611481, current macro_F score: 0.393701\n",
      "Epoch: 00079 loss_train: 0.6560 acc_train: 0.6522 loss_val: 0.6389 acc_val: 0.6494 time: 0.0473s\n",
      "valid current auc-roc score: 0.609630, current macro_F score: 0.393701\n",
      "Epoch: 00080 loss_train: 0.6537 acc_train: 0.6522 loss_val: 0.6404 acc_val: 0.6494 time: 0.0363s\n",
      "valid current auc-roc score: 0.583333, current macro_F score: 0.393701\n",
      "Epoch: 00081 loss_train: 0.6401 acc_train: 0.6522 loss_val: 0.6543 acc_val: 0.6494 time: 0.0374s\n",
      "valid current auc-roc score: 0.588889, current macro_F score: 0.393701\n",
      "Epoch: 00082 loss_train: 0.6286 acc_train: 0.6522 loss_val: 0.6433 acc_val: 0.6494 time: 0.0359s\n",
      "valid current auc-roc score: 0.610741, current macro_F score: 0.393701\n",
      "Epoch: 00083 loss_train: 0.6424 acc_train: 0.6522 loss_val: 0.6276 acc_val: 0.6494 time: 0.0374s\n",
      "valid current auc-roc score: 0.627037, current macro_F score: 0.393701\n",
      "Epoch: 00084 loss_train: 0.6643 acc_train: 0.6522 loss_val: 0.6348 acc_val: 0.6494 time: 0.0404s\n",
      "valid current auc-roc score: 0.744444, current macro_F score: 0.393701\n",
      "Epoch: 00085 loss_train: 0.6421 acc_train: 0.6522 loss_val: 0.5962 acc_val: 0.6494 time: 0.0433s\n",
      "valid current auc-roc score: 0.594815, current macro_F score: 0.393701\n",
      "Epoch: 00086 loss_train: 0.6397 acc_train: 0.6522 loss_val: 0.6349 acc_val: 0.6494 time: 0.0372s\n",
      "valid current auc-roc score: 0.591111, current macro_F score: 0.393701\n",
      "Epoch: 00087 loss_train: 0.6304 acc_train: 0.6522 loss_val: 0.6226 acc_val: 0.6494 time: 0.0371s\n",
      "valid current auc-roc score: 0.711852, current macro_F score: 0.393701\n",
      "Epoch: 00088 loss_train: 0.6472 acc_train: 0.6522 loss_val: 0.6083 acc_val: 0.6494 time: 0.0374s\n",
      "valid current auc-roc score: 0.677778, current macro_F score: 0.393701\n",
      "Epoch: 00089 loss_train: 0.6421 acc_train: 0.6522 loss_val: 0.6052 acc_val: 0.6494 time: 0.0424s\n",
      "valid current auc-roc score: 0.552593, current macro_F score: 0.393701\n",
      "Epoch: 00090 loss_train: 0.6349 acc_train: 0.6522 loss_val: 0.6434 acc_val: 0.6494 time: 0.0576s\n",
      "valid current auc-roc score: 0.660000, current macro_F score: 0.393701\n",
      "Epoch: 00091 loss_train: 0.6488 acc_train: 0.6522 loss_val: 0.5979 acc_val: 0.6494 time: 0.0494s\n",
      "valid current auc-roc score: 0.620741, current macro_F score: 0.393701\n",
      "Epoch: 00092 loss_train: 0.6406 acc_train: 0.6522 loss_val: 0.6115 acc_val: 0.6494 time: 0.0490s\n",
      "valid current auc-roc score: 0.608889, current macro_F score: 0.393701\n",
      "Epoch: 00093 loss_train: 0.6407 acc_train: 0.6522 loss_val: 0.6191 acc_val: 0.6494 time: 0.0508s\n",
      "valid current auc-roc score: 0.643704, current macro_F score: 0.393701\n",
      "Epoch: 00094 loss_train: 0.6310 acc_train: 0.6522 loss_val: 0.6249 acc_val: 0.6494 time: 0.0496s\n",
      "valid current auc-roc score: 0.604444, current macro_F score: 0.393701\n",
      "Epoch: 00095 loss_train: 0.6184 acc_train: 0.6522 loss_val: 0.6291 acc_val: 0.6494 time: 0.0578s\n",
      "valid current auc-roc score: 0.588148, current macro_F score: 0.393701\n",
      "Epoch: 00096 loss_train: 0.6317 acc_train: 0.6522 loss_val: 0.6391 acc_val: 0.6494 time: 0.0498s\n",
      "valid current auc-roc score: 0.611852, current macro_F score: 0.393701\n",
      "Epoch: 00097 loss_train: 0.6377 acc_train: 0.6522 loss_val: 0.6233 acc_val: 0.6494 time: 0.0479s\n",
      "valid current auc-roc score: 0.601481, current macro_F score: 0.393701\n",
      "Epoch: 00098 loss_train: 0.6413 acc_train: 0.6522 loss_val: 0.6306 acc_val: 0.6494 time: 0.0408s\n",
      "valid current auc-roc score: 0.562963, current macro_F score: 0.393701\n",
      "Epoch: 00099 loss_train: 0.6318 acc_train: 0.6522 loss_val: 0.6465 acc_val: 0.6494 time: 0.0432s\n",
      "valid current auc-roc score: 0.657778, current macro_F score: 0.393701\n",
      "Epoch: 00100 loss_train: 0.6300 acc_train: 0.6522 loss_val: 0.6142 acc_val: 0.6494 time: 0.0547s\n",
      "valid current auc-roc score: 0.641481, current macro_F score: 0.393701\n",
      "Epoch: 00101 loss_train: 0.6442 acc_train: 0.6522 loss_val: 0.6223 acc_val: 0.6494 time: 0.0475s\n",
      "valid current auc-roc score: 0.642963, current macro_F score: 0.393701\n",
      "Epoch: 00102 loss_train: 0.6273 acc_train: 0.6522 loss_val: 0.6099 acc_val: 0.6494 time: 0.0460s\n",
      "valid current auc-roc score: 0.686667, current macro_F score: 0.393701\n",
      "Epoch: 00103 loss_train: 0.6213 acc_train: 0.6522 loss_val: 0.6054 acc_val: 0.6494 time: 0.0458s\n",
      "valid current auc-roc score: 0.645185, current macro_F score: 0.393701\n",
      "Epoch: 00104 loss_train: 0.6473 acc_train: 0.6522 loss_val: 0.6289 acc_val: 0.6494 time: 0.0495s\n",
      "valid current auc-roc score: 0.616667, current macro_F score: 0.393701\n",
      "Epoch: 00105 loss_train: 0.6301 acc_train: 0.6522 loss_val: 0.6182 acc_val: 0.6494 time: 0.0456s\n",
      "valid current auc-roc score: 0.634815, current macro_F score: 0.393701\n",
      "Epoch: 00106 loss_train: 0.6373 acc_train: 0.6522 loss_val: 0.6195 acc_val: 0.6494 time: 0.0469s\n",
      "valid current auc-roc score: 0.701111, current macro_F score: 0.393701\n",
      "Epoch: 00107 loss_train: 0.6351 acc_train: 0.6522 loss_val: 0.6016 acc_val: 0.6494 time: 0.0430s\n",
      "valid current auc-roc score: 0.720741, current macro_F score: 0.393701\n",
      "Epoch: 00108 loss_train: 0.6408 acc_train: 0.6522 loss_val: 0.5959 acc_val: 0.6494 time: 0.0442s\n",
      "valid current auc-roc score: 0.669259, current macro_F score: 0.393701\n",
      "Epoch: 00109 loss_train: 0.6343 acc_train: 0.6522 loss_val: 0.6122 acc_val: 0.6494 time: 0.0382s\n",
      "valid current auc-roc score: 0.531481, current macro_F score: 0.393701\n",
      "Epoch: 00110 loss_train: 0.6412 acc_train: 0.6522 loss_val: 0.6503 acc_val: 0.6494 time: 0.0427s\n",
      "valid current auc-roc score: 0.650000, current macro_F score: 0.393701\n",
      "Epoch: 00111 loss_train: 0.6286 acc_train: 0.6522 loss_val: 0.6257 acc_val: 0.6494 time: 0.0656s\n",
      "valid current auc-roc score: 0.660000, current macro_F score: 0.393701\n",
      "Epoch: 00112 loss_train: 0.6339 acc_train: 0.6522 loss_val: 0.6113 acc_val: 0.6494 time: 0.0779s\n",
      "valid current auc-roc score: 0.684444, current macro_F score: 0.393701\n",
      "Epoch: 00113 loss_train: 0.6375 acc_train: 0.6522 loss_val: 0.6105 acc_val: 0.6494 time: 0.0498s\n",
      "valid current auc-roc score: 0.639259, current macro_F score: 0.393701\n",
      "Epoch: 00114 loss_train: 0.6374 acc_train: 0.6522 loss_val: 0.6269 acc_val: 0.6494 time: 0.0554s\n",
      "valid current auc-roc score: 0.569630, current macro_F score: 0.393701\n",
      "Epoch: 00115 loss_train: 0.6380 acc_train: 0.6522 loss_val: 0.6378 acc_val: 0.6494 time: 0.0570s\n",
      "valid current auc-roc score: 0.688148, current macro_F score: 0.393701\n",
      "Epoch: 00116 loss_train: 0.6302 acc_train: 0.6522 loss_val: 0.6167 acc_val: 0.6494 time: 0.0481s\n",
      "valid current auc-roc score: 0.663704, current macro_F score: 0.393701\n",
      "Epoch: 00117 loss_train: 0.6390 acc_train: 0.6522 loss_val: 0.6212 acc_val: 0.6494 time: 0.0791s\n",
      "valid current auc-roc score: 0.724815, current macro_F score: 0.393701\n",
      "Epoch: 00118 loss_train: 0.6295 acc_train: 0.6522 loss_val: 0.6016 acc_val: 0.6494 time: 0.0657s\n",
      "valid current auc-roc score: 0.661481, current macro_F score: 0.393701\n",
      "Epoch: 00119 loss_train: 0.6286 acc_train: 0.6522 loss_val: 0.6196 acc_val: 0.6494 time: 0.0548s\n",
      "valid current auc-roc score: 0.694815, current macro_F score: 0.393701\n",
      "Epoch: 00120 loss_train: 0.6353 acc_train: 0.6522 loss_val: 0.6075 acc_val: 0.6494 time: 0.0466s\n",
      "valid current auc-roc score: 0.811111, current macro_F score: 0.393701\n",
      "Epoch: 00121 loss_train: 0.6350 acc_train: 0.6522 loss_val: 0.5893 acc_val: 0.6494 time: 0.0466s\n",
      "valid current auc-roc score: 0.604444, current macro_F score: 0.393701\n",
      "Epoch: 00122 loss_train: 0.6319 acc_train: 0.6522 loss_val: 0.6282 acc_val: 0.6494 time: 0.0478s\n",
      "valid current auc-roc score: 0.565185, current macro_F score: 0.393701\n",
      "Epoch: 00123 loss_train: 0.6221 acc_train: 0.6522 loss_val: 0.6356 acc_val: 0.6494 time: 0.0404s\n",
      "valid current auc-roc score: 0.597407, current macro_F score: 0.393701\n",
      "Epoch: 00124 loss_train: 0.6245 acc_train: 0.6522 loss_val: 0.6383 acc_val: 0.6494 time: 0.0386s\n",
      "valid current auc-roc score: 0.677037, current macro_F score: 0.393701\n",
      "Epoch: 00125 loss_train: 0.6208 acc_train: 0.6522 loss_val: 0.6071 acc_val: 0.6494 time: 0.0373s\n",
      "valid current auc-roc score: 0.681481, current macro_F score: 0.393701\n",
      "Epoch: 00126 loss_train: 0.6296 acc_train: 0.6522 loss_val: 0.6091 acc_val: 0.6494 time: 0.0347s\n",
      "valid current auc-roc score: 0.624444, current macro_F score: 0.393701\n",
      "Epoch: 00127 loss_train: 0.6291 acc_train: 0.6522 loss_val: 0.6382 acc_val: 0.6494 time: 0.0335s\n",
      "valid current auc-roc score: 0.612593, current macro_F score: 0.393701\n",
      "Epoch: 00128 loss_train: 0.6290 acc_train: 0.6522 loss_val: 0.6188 acc_val: 0.6494 time: 0.0392s\n",
      "valid current auc-roc score: 0.642963, current macro_F score: 0.393701\n",
      "Epoch: 00129 loss_train: 0.6326 acc_train: 0.6522 loss_val: 0.6161 acc_val: 0.6494 time: 0.0397s\n",
      "valid current auc-roc score: 0.703704, current macro_F score: 0.393701\n",
      "Epoch: 00130 loss_train: 0.6515 acc_train: 0.6522 loss_val: 0.6037 acc_val: 0.6494 time: 0.0351s\n",
      "valid current auc-roc score: 0.694815, current macro_F score: 0.393701\n",
      "Epoch: 00131 loss_train: 0.6481 acc_train: 0.6522 loss_val: 0.6121 acc_val: 0.6494 time: 0.0392s\n",
      "valid current auc-roc score: 0.635556, current macro_F score: 0.393701\n",
      "Epoch: 00132 loss_train: 0.6435 acc_train: 0.6522 loss_val: 0.6133 acc_val: 0.6494 time: 0.0347s\n",
      "valid current auc-roc score: 0.661481, current macro_F score: 0.393701\n",
      "Epoch: 00133 loss_train: 0.6383 acc_train: 0.6522 loss_val: 0.6167 acc_val: 0.6494 time: 0.0362s\n",
      "valid current auc-roc score: 0.661481, current macro_F score: 0.393701\n",
      "Epoch: 00134 loss_train: 0.6456 acc_train: 0.6522 loss_val: 0.6187 acc_val: 0.6494 time: 0.0390s\n",
      "valid current auc-roc score: 0.591111, current macro_F score: 0.393701\n",
      "Epoch: 00135 loss_train: 0.6434 acc_train: 0.6522 loss_val: 0.6381 acc_val: 0.6494 time: 0.0342s\n",
      "valid current auc-roc score: 0.747778, current macro_F score: 0.393701\n",
      "Epoch: 00136 loss_train: 0.6239 acc_train: 0.6522 loss_val: 0.5962 acc_val: 0.6494 time: 0.0347s\n",
      "valid current auc-roc score: 0.644444, current macro_F score: 0.393701\n",
      "Epoch: 00137 loss_train: 0.6225 acc_train: 0.6522 loss_val: 0.6198 acc_val: 0.6494 time: 0.0329s\n",
      "valid current auc-roc score: 0.632222, current macro_F score: 0.393701\n",
      "Epoch: 00138 loss_train: 0.6266 acc_train: 0.6522 loss_val: 0.6228 acc_val: 0.6494 time: 0.0346s\n",
      "valid current auc-roc score: 0.581852, current macro_F score: 0.393701\n",
      "Epoch: 00139 loss_train: 0.6335 acc_train: 0.6522 loss_val: 0.6356 acc_val: 0.6494 time: 0.0317s\n",
      "valid current auc-roc score: 0.699259, current macro_F score: 0.393701\n",
      "Epoch: 00140 loss_train: 0.6389 acc_train: 0.6522 loss_val: 0.6079 acc_val: 0.6494 time: 0.0350s\n",
      "valid current auc-roc score: 0.723704, current macro_F score: 0.393701\n",
      "Epoch: 00141 loss_train: 0.6366 acc_train: 0.6522 loss_val: 0.6092 acc_val: 0.6494 time: 0.0404s\n",
      "valid current auc-roc score: 0.624444, current macro_F score: 0.393701\n",
      "Epoch: 00142 loss_train: 0.6799 acc_train: 0.6522 loss_val: 0.6131 acc_val: 0.6494 time: 0.0407s\n",
      "valid current auc-roc score: 0.614815, current macro_F score: 0.393701\n",
      "Epoch: 00143 loss_train: 0.6373 acc_train: 0.6522 loss_val: 0.6317 acc_val: 0.6494 time: 0.0384s\n",
      "valid current auc-roc score: 0.672593, current macro_F score: 0.393701\n",
      "Epoch: 00144 loss_train: 0.6371 acc_train: 0.6522 loss_val: 0.6134 acc_val: 0.6494 time: 0.0374s\n",
      "valid current auc-roc score: 0.745926, current macro_F score: 0.393701\n",
      "Epoch: 00145 loss_train: 0.6401 acc_train: 0.6522 loss_val: 0.5995 acc_val: 0.6494 time: 0.0344s\n",
      "valid current auc-roc score: 0.679630, current macro_F score: 0.393701\n",
      "Epoch: 00146 loss_train: 0.6320 acc_train: 0.6522 loss_val: 0.6158 acc_val: 0.6494 time: 0.0350s\n",
      "valid current auc-roc score: 0.563333, current macro_F score: 0.393701\n",
      "Epoch: 00147 loss_train: 0.6280 acc_train: 0.6522 loss_val: 0.6369 acc_val: 0.6494 time: 0.0313s\n",
      "valid current auc-roc score: 0.760741, current macro_F score: 0.393701\n",
      "Epoch: 00148 loss_train: 0.6290 acc_train: 0.6522 loss_val: 0.5843 acc_val: 0.6494 time: 0.1487s\n",
      "valid current auc-roc score: 0.697778, current macro_F score: 0.393701\n",
      "Epoch: 00149 loss_train: 0.6343 acc_train: 0.6522 loss_val: 0.6099 acc_val: 0.6494 time: 0.0435s\n",
      "valid current auc-roc score: 0.658519, current macro_F score: 0.393701\n",
      "Epoch: 00150 loss_train: 0.6385 acc_train: 0.6522 loss_val: 0.6115 acc_val: 0.6494 time: 0.0387s\n",
      "valid current auc-roc score: 0.513704, current macro_F score: 0.393701\n",
      "Epoch: 00151 loss_train: 0.6483 acc_train: 0.6522 loss_val: 0.6459 acc_val: 0.6494 time: 0.0338s\n",
      "valid current auc-roc score: 0.647407, current macro_F score: 0.393701\n",
      "Epoch: 00152 loss_train: 0.6402 acc_train: 0.6522 loss_val: 0.6211 acc_val: 0.6494 time: 0.0336s\n",
      "valid current auc-roc score: 0.683704, current macro_F score: 0.393701\n",
      "Epoch: 00153 loss_train: 0.6320 acc_train: 0.6522 loss_val: 0.6220 acc_val: 0.6494 time: 0.0313s\n",
      "valid current auc-roc score: 0.654815, current macro_F score: 0.393701\n",
      "Epoch: 00154 loss_train: 0.6246 acc_train: 0.6522 loss_val: 0.6296 acc_val: 0.6494 time: 0.0310s\n",
      "valid current auc-roc score: 0.707037, current macro_F score: 0.393701\n",
      "Epoch: 00155 loss_train: 0.6363 acc_train: 0.6522 loss_val: 0.5998 acc_val: 0.6494 time: 0.0314s\n",
      "valid current auc-roc score: 0.745926, current macro_F score: 0.393701\n",
      "Epoch: 00156 loss_train: 0.6458 acc_train: 0.6522 loss_val: 0.5863 acc_val: 0.6494 time: 0.0323s\n",
      "valid current auc-roc score: 0.596296, current macro_F score: 0.393701\n",
      "Epoch: 00157 loss_train: 0.6381 acc_train: 0.6522 loss_val: 0.6343 acc_val: 0.6494 time: 0.0331s\n",
      "valid current auc-roc score: 0.682963, current macro_F score: 0.393701\n",
      "Epoch: 00158 loss_train: 0.6358 acc_train: 0.6522 loss_val: 0.6102 acc_val: 0.6494 time: 0.0319s\n",
      "valid current auc-roc score: 0.628889, current macro_F score: 0.393701\n",
      "Epoch: 00159 loss_train: 0.6282 acc_train: 0.6522 loss_val: 0.6226 acc_val: 0.6494 time: 0.0307s\n",
      "valid current auc-roc score: 0.674815, current macro_F score: 0.393701\n",
      "Epoch: 00160 loss_train: 0.6331 acc_train: 0.6522 loss_val: 0.6176 acc_val: 0.6494 time: 0.0316s\n",
      "valid current auc-roc score: 0.604444, current macro_F score: 0.393701\n",
      "Epoch: 00161 loss_train: 0.6374 acc_train: 0.6522 loss_val: 0.6286 acc_val: 0.6494 time: 0.0306s\n",
      "valid current auc-roc score: 0.684444, current macro_F score: 0.393701\n",
      "Epoch: 00162 loss_train: 0.6301 acc_train: 0.6522 loss_val: 0.6166 acc_val: 0.6494 time: 0.0319s\n",
      "valid current auc-roc score: 0.545185, current macro_F score: 0.393701\n",
      "Epoch: 00163 loss_train: 0.6370 acc_train: 0.6522 loss_val: 0.6384 acc_val: 0.6494 time: 0.0308s\n",
      "valid current auc-roc score: 0.586296, current macro_F score: 0.393701\n",
      "Epoch: 00164 loss_train: 0.6409 acc_train: 0.6522 loss_val: 0.6367 acc_val: 0.6494 time: 0.0297s\n",
      "valid current auc-roc score: 0.722963, current macro_F score: 0.393701\n",
      "Epoch: 00165 loss_train: 0.6359 acc_train: 0.6522 loss_val: 0.6095 acc_val: 0.6494 time: 0.0330s\n",
      "valid current auc-roc score: 0.715556, current macro_F score: 0.393701\n",
      "Epoch: 00166 loss_train: 0.6292 acc_train: 0.6522 loss_val: 0.6020 acc_val: 0.6494 time: 0.0321s\n",
      "valid current auc-roc score: 0.710370, current macro_F score: 0.393701\n",
      "Epoch: 00167 loss_train: 0.6322 acc_train: 0.6522 loss_val: 0.6089 acc_val: 0.6494 time: 0.0305s\n",
      "valid current auc-roc score: 0.597407, current macro_F score: 0.432540\n",
      "Epoch: 00168 loss_train: 0.6371 acc_train: 0.6565 loss_val: 0.6242 acc_val: 0.6623 time: 0.0301s\n",
      "valid current auc-roc score: 0.678519, current macro_F score: 0.393701\n",
      "Epoch: 00169 loss_train: 0.6269 acc_train: 0.6522 loss_val: 0.6091 acc_val: 0.6494 time: 0.0301s\n",
      "valid current auc-roc score: 0.609630, current macro_F score: 0.393701\n",
      "Epoch: 00170 loss_train: 0.6295 acc_train: 0.6522 loss_val: 0.6323 acc_val: 0.6494 time: 0.0315s\n",
      "valid current auc-roc score: 0.711111, current macro_F score: 0.393701\n",
      "Epoch: 00171 loss_train: 0.6346 acc_train: 0.6522 loss_val: 0.6115 acc_val: 0.6494 time: 0.0331s\n",
      "valid current auc-roc score: 0.661481, current macro_F score: 0.393701\n",
      "Epoch: 00172 loss_train: 0.6394 acc_train: 0.6522 loss_val: 0.6183 acc_val: 0.6494 time: 0.0319s\n",
      "valid current auc-roc score: 0.692593, current macro_F score: 0.393701\n",
      "Epoch: 00173 loss_train: 0.6191 acc_train: 0.6522 loss_val: 0.6049 acc_val: 0.6494 time: 0.0314s\n",
      "valid current auc-roc score: 0.576667, current macro_F score: 0.393701\n",
      "Epoch: 00174 loss_train: 0.6253 acc_train: 0.6522 loss_val: 0.6505 acc_val: 0.6494 time: 0.0258s\n",
      "valid current auc-roc score: 0.699259, current macro_F score: 0.393701\n",
      "Epoch: 00175 loss_train: 0.6330 acc_train: 0.6522 loss_val: 0.6039 acc_val: 0.6494 time: 0.0295s\n",
      "valid current auc-roc score: 0.642963, current macro_F score: 0.393701\n",
      "Epoch: 00176 loss_train: 0.6304 acc_train: 0.6522 loss_val: 0.6110 acc_val: 0.6494 time: 0.0295s\n",
      "valid current auc-roc score: 0.628889, current macro_F score: 0.393701\n",
      "Epoch: 00177 loss_train: 0.6329 acc_train: 0.6522 loss_val: 0.6361 acc_val: 0.6494 time: 0.0302s\n",
      "valid current auc-roc score: 0.613333, current macro_F score: 0.393701\n",
      "Epoch: 00178 loss_train: 0.6294 acc_train: 0.6522 loss_val: 0.6304 acc_val: 0.6494 time: 0.0317s\n",
      "valid current auc-roc score: 0.621481, current macro_F score: 0.393701\n",
      "Epoch: 00179 loss_train: 0.6384 acc_train: 0.6522 loss_val: 0.6224 acc_val: 0.6494 time: 0.0322s\n",
      "valid current auc-roc score: 0.663333, current macro_F score: 0.393701\n",
      "Epoch: 00180 loss_train: 0.6325 acc_train: 0.6522 loss_val: 0.6205 acc_val: 0.6494 time: 0.0322s\n",
      "valid current auc-roc score: 0.677778, current macro_F score: 0.393701\n",
      "Epoch: 00181 loss_train: 0.6241 acc_train: 0.6522 loss_val: 0.6068 acc_val: 0.6494 time: 0.0310s\n",
      "valid current auc-roc score: 0.612593, current macro_F score: 0.393701\n",
      "Epoch: 00182 loss_train: 0.6386 acc_train: 0.6522 loss_val: 0.6322 acc_val: 0.6494 time: 0.0294s\n",
      "valid current auc-roc score: 0.645926, current macro_F score: 0.393701\n",
      "Epoch: 00183 loss_train: 0.6363 acc_train: 0.6522 loss_val: 0.6163 acc_val: 0.6494 time: 0.0282s\n",
      "valid current auc-roc score: 0.653333, current macro_F score: 0.393701\n",
      "Epoch: 00184 loss_train: 0.6285 acc_train: 0.6522 loss_val: 0.6144 acc_val: 0.6494 time: 0.0260s\n",
      "valid current auc-roc score: 0.735556, current macro_F score: 0.393701\n",
      "Epoch: 00185 loss_train: 0.6396 acc_train: 0.6522 loss_val: 0.5946 acc_val: 0.6494 time: 0.0284s\n",
      "valid current auc-roc score: 0.615556, current macro_F score: 0.388889\n",
      "Epoch: 00186 loss_train: 0.6332 acc_train: 0.6609 loss_val: 0.6427 acc_val: 0.6364 time: 0.0294s\n",
      "valid current auc-roc score: 0.627778, current macro_F score: 0.393701\n",
      "Epoch: 00187 loss_train: 0.6285 acc_train: 0.6522 loss_val: 0.6277 acc_val: 0.6494 time: 0.0289s\n",
      "valid current auc-roc score: 0.615556, current macro_F score: 0.393701\n",
      "Epoch: 00188 loss_train: 0.6294 acc_train: 0.6522 loss_val: 0.6299 acc_val: 0.6494 time: 0.0296s\n",
      "valid current auc-roc score: 0.707037, current macro_F score: 0.393701\n",
      "Epoch: 00189 loss_train: 0.6353 acc_train: 0.6522 loss_val: 0.6126 acc_val: 0.6494 time: 0.0305s\n",
      "valid current auc-roc score: 0.678519, current macro_F score: 0.393701\n",
      "Epoch: 00190 loss_train: 0.6345 acc_train: 0.6522 loss_val: 0.6073 acc_val: 0.6494 time: 0.0304s\n",
      "valid current auc-roc score: 0.667407, current macro_F score: 0.393701\n",
      "Epoch: 00191 loss_train: 0.6293 acc_train: 0.6522 loss_val: 0.6183 acc_val: 0.6494 time: 0.0283s\n",
      "valid current auc-roc score: 0.602593, current macro_F score: 0.393701\n",
      "Epoch: 00192 loss_train: 0.6331 acc_train: 0.6522 loss_val: 0.6290 acc_val: 0.6494 time: 0.0288s\n",
      "valid current auc-roc score: 0.603704, current macro_F score: 0.420430\n",
      "Epoch: 00193 loss_train: 0.6241 acc_train: 0.6609 loss_val: 0.6374 acc_val: 0.6364 time: 0.0312s\n",
      "valid current auc-roc score: 0.707778, current macro_F score: 0.393701\n",
      "Epoch: 00194 loss_train: 0.6322 acc_train: 0.6522 loss_val: 0.6065 acc_val: 0.6494 time: 0.0334s\n",
      "valid current auc-roc score: 0.597037, current macro_F score: 0.393701\n",
      "Epoch: 00195 loss_train: 0.6408 acc_train: 0.6522 loss_val: 0.6324 acc_val: 0.6494 time: 0.0304s\n",
      "valid current auc-roc score: 0.723333, current macro_F score: 0.393701\n",
      "Epoch: 00196 loss_train: 0.6254 acc_train: 0.6522 loss_val: 0.5985 acc_val: 0.6494 time: 0.0290s\n",
      "valid current auc-roc score: 0.650000, current macro_F score: 0.393701\n",
      "Epoch: 00197 loss_train: 0.6343 acc_train: 0.6522 loss_val: 0.6243 acc_val: 0.6494 time: 0.0221s\n",
      "valid current auc-roc score: 0.655556, current macro_F score: 0.393701\n",
      "Epoch: 00198 loss_train: 0.6282 acc_train: 0.6522 loss_val: 0.6153 acc_val: 0.6494 time: 0.0275s\n",
      "valid current auc-roc score: 0.686667, current macro_F score: 0.393701\n",
      "Epoch: 00199 loss_train: 0.6340 acc_train: 0.6522 loss_val: 0.6026 acc_val: 0.6494 time: 0.0250s\n",
      "valid current auc-roc score: 0.607407, current macro_F score: 0.393701\n",
      "Epoch: 00200 loss_train: 0.6282 acc_train: 0.6522 loss_val: 0.6299 acc_val: 0.6494 time: 0.0277s\n",
      "valid current auc-roc score: 0.580000, current macro_F score: 0.393701\n",
      "Epoch: 00201 loss_train: 0.6350 acc_train: 0.6522 loss_val: 0.6449 acc_val: 0.6494 time: 0.0302s\n",
      "valid current auc-roc score: 0.740741, current macro_F score: 0.393701\n",
      "Epoch: 00202 loss_train: 0.6256 acc_train: 0.6522 loss_val: 0.6016 acc_val: 0.6494 time: 0.0303s\n",
      "valid current auc-roc score: 0.625926, current macro_F score: 0.393701\n",
      "Epoch: 00203 loss_train: 0.6701 acc_train: 0.6522 loss_val: 0.6455 acc_val: 0.6494 time: 0.0347s\n",
      "valid current auc-roc score: 0.661481, current macro_F score: 0.393701\n",
      "Epoch: 00204 loss_train: 0.6331 acc_train: 0.6522 loss_val: 0.6112 acc_val: 0.6494 time: 0.0411s\n",
      "valid current auc-roc score: 0.632593, current macro_F score: 0.393701\n",
      "Epoch: 00205 loss_train: 0.6327 acc_train: 0.6522 loss_val: 0.6295 acc_val: 0.6494 time: 0.0366s\n",
      "valid current auc-roc score: 0.691852, current macro_F score: 0.393701\n",
      "Epoch: 00206 loss_train: 0.6327 acc_train: 0.6522 loss_val: 0.6120 acc_val: 0.6494 time: 0.0335s\n",
      "valid current auc-roc score: 0.584815, current macro_F score: 0.393701\n",
      "Epoch: 00207 loss_train: 0.6250 acc_train: 0.6522 loss_val: 0.6433 acc_val: 0.6494 time: 0.0273s\n",
      "valid current auc-roc score: 0.762963, current macro_F score: 0.393701\n",
      "Epoch: 00208 loss_train: 0.6284 acc_train: 0.6522 loss_val: 0.5909 acc_val: 0.6494 time: 0.0323s\n",
      "valid current auc-roc score: 0.734074, current macro_F score: 0.468966\n",
      "Epoch: 00209 loss_train: 0.6345 acc_train: 0.6543 loss_val: 0.5957 acc_val: 0.6753 time: 0.0317s\n",
      "valid current auc-roc score: 0.546667, current macro_F score: 0.393701\n",
      "Epoch: 00210 loss_train: 0.6318 acc_train: 0.6522 loss_val: 0.6479 acc_val: 0.6494 time: 0.0306s\n",
      "valid current auc-roc score: 0.739259, current macro_F score: 0.393701\n",
      "Epoch: 00211 loss_train: 0.6293 acc_train: 0.6522 loss_val: 0.5982 acc_val: 0.6494 time: 0.0276s\n",
      "valid current auc-roc score: 0.588148, current macro_F score: 0.393701\n",
      "Epoch: 00212 loss_train: 0.6273 acc_train: 0.6522 loss_val: 0.6340 acc_val: 0.6494 time: 0.0349s\n",
      "valid current auc-roc score: 0.724444, current macro_F score: 0.393701\n",
      "Epoch: 00213 loss_train: 0.6407 acc_train: 0.6522 loss_val: 0.5953 acc_val: 0.6494 time: 0.0353s\n",
      "valid current auc-roc score: 0.663704, current macro_F score: 0.393701\n",
      "Epoch: 00214 loss_train: 0.6374 acc_train: 0.6522 loss_val: 0.6230 acc_val: 0.6494 time: 0.0334s\n",
      "valid current auc-roc score: 0.688889, current macro_F score: 0.393701\n",
      "Epoch: 00215 loss_train: 0.6276 acc_train: 0.6522 loss_val: 0.6134 acc_val: 0.6494 time: 0.0319s\n",
      "valid current auc-roc score: 0.588889, current macro_F score: 0.393701\n",
      "Epoch: 00216 loss_train: 0.6464 acc_train: 0.6522 loss_val: 0.6307 acc_val: 0.6494 time: 0.0397s\n",
      "valid current auc-roc score: 0.597778, current macro_F score: 0.393701\n",
      "Epoch: 00217 loss_train: 0.6307 acc_train: 0.6522 loss_val: 0.6388 acc_val: 0.6494 time: 0.0331s\n",
      "valid current auc-roc score: 0.697778, current macro_F score: 0.384000\n",
      "Epoch: 00218 loss_train: 150.8720 acc_train: 0.6391 loss_val: 147.8774 acc_val: 0.6234 time: 0.0376s\n",
      "valid current auc-roc score: 0.650370, current macro_F score: 0.393701\n",
      "Epoch: 00219 loss_train: 0.6348 acc_train: 0.6522 loss_val: 0.6240 acc_val: 0.6494 time: 0.0407s\n",
      "valid current auc-roc score: 0.603333, current macro_F score: 0.393701\n",
      "Epoch: 00220 loss_train: 0.6330 acc_train: 0.6522 loss_val: 0.6328 acc_val: 0.6494 time: 0.0409s\n",
      "valid current auc-roc score: 0.700000, current macro_F score: 0.393701\n",
      "Epoch: 00221 loss_train: 0.6275 acc_train: 0.6522 loss_val: 0.6084 acc_val: 0.6494 time: 0.0478s\n",
      "valid current auc-roc score: 0.581481, current macro_F score: 0.393701\n",
      "Epoch: 00222 loss_train: 0.6373 acc_train: 0.6522 loss_val: 0.6431 acc_val: 0.6494 time: 0.0401s\n",
      "valid current auc-roc score: 0.583704, current macro_F score: 0.426483\n",
      "Epoch: 00223 loss_train: 0.6382 acc_train: 0.6543 loss_val: 0.6390 acc_val: 0.6494 time: 0.0383s\n",
      "valid current auc-roc score: 0.661852, current macro_F score: 0.420430\n",
      "Epoch: 00224 loss_train: 0.6480 acc_train: 0.6435 loss_val: 0.6403 acc_val: 0.6364 time: 0.0370s\n",
      "valid current auc-roc score: 0.701481, current macro_F score: 0.393701\n",
      "Epoch: 00225 loss_train: 0.6370 acc_train: 0.6543 loss_val: 0.6119 acc_val: 0.6494 time: 0.0367s\n",
      "valid current auc-roc score: 0.615926, current macro_F score: 0.393701\n",
      "Epoch: 00226 loss_train: 0.6393 acc_train: 0.6522 loss_val: 0.6182 acc_val: 0.6494 time: 0.0356s\n",
      "valid current auc-roc score: 0.635556, current macro_F score: 0.393701\n",
      "Epoch: 00227 loss_train: 0.6456 acc_train: 0.6522 loss_val: 0.6151 acc_val: 0.6494 time: 0.0552s\n",
      "valid current auc-roc score: 0.689259, current macro_F score: 0.393701\n",
      "Epoch: 00228 loss_train: 0.6345 acc_train: 0.6522 loss_val: 0.6059 acc_val: 0.6494 time: 0.0489s\n",
      "valid current auc-roc score: 0.640000, current macro_F score: 0.393701\n",
      "Epoch: 00229 loss_train: 0.6405 acc_train: 0.6522 loss_val: 0.6164 acc_val: 0.6494 time: 0.0430s\n",
      "valid current auc-roc score: 0.616296, current macro_F score: 0.495148\n",
      "Epoch: 00230 loss_train: 0.6392 acc_train: 0.6587 loss_val: 0.6283 acc_val: 0.6753 time: 0.0456s\n",
      "valid current auc-roc score: 0.597778, current macro_F score: 0.388889\n",
      "Epoch: 00231 loss_train: 0.6293 acc_train: 0.6478 loss_val: 0.6289 acc_val: 0.6364 time: 0.0648s\n",
      "valid current auc-roc score: 0.629630, current macro_F score: 0.393701\n",
      "Epoch: 00232 loss_train: 0.6934 acc_train: 0.6522 loss_val: 0.6889 acc_val: 0.6494 time: 0.0522s\n",
      "valid current auc-roc score: 0.597778, current macro_F score: 0.393701\n",
      "Epoch: 00233 loss_train: 0.6405 acc_train: 0.6522 loss_val: 0.6335 acc_val: 0.6494 time: 0.0497s\n",
      "valid current auc-roc score: 0.671852, current macro_F score: 0.393701\n",
      "Epoch: 00234 loss_train: 0.6386 acc_train: 0.6522 loss_val: 0.6104 acc_val: 0.6494 time: 0.0394s\n",
      "valid current auc-roc score: 0.744444, current macro_F score: 0.432540\n",
      "Epoch: 00235 loss_train: 0.6282 acc_train: 0.6587 loss_val: 0.5838 acc_val: 0.6623 time: 0.0436s\n",
      "valid current auc-roc score: 0.600000, current macro_F score: 0.393701\n",
      "Epoch: 00236 loss_train: 0.6278 acc_train: 0.6522 loss_val: 0.6252 acc_val: 0.6494 time: 0.0428s\n",
      "valid current auc-roc score: 0.651852, current macro_F score: 0.393701\n",
      "Epoch: 00237 loss_train: 0.6367 acc_train: 0.6522 loss_val: 0.6392 acc_val: 0.6494 time: 0.0345s\n",
      "valid current auc-roc score: 0.643333, current macro_F score: 0.393701\n",
      "Epoch: 00238 loss_train: 0.6467 acc_train: 0.6522 loss_val: 0.6326 acc_val: 0.6494 time: 0.0348s\n",
      "valid current auc-roc score: 0.651852, current macro_F score: 0.393701\n",
      "Epoch: 00239 loss_train: 0.6280 acc_train: 0.6522 loss_val: 0.6170 acc_val: 0.6494 time: 0.0317s\n",
      "valid current auc-roc score: 0.527407, current macro_F score: 0.393701\n",
      "Epoch: 00240 loss_train: 0.6376 acc_train: 0.6522 loss_val: 0.6526 acc_val: 0.6494 time: 0.0359s\n",
      "valid current auc-roc score: 0.623333, current macro_F score: 0.461828\n",
      "Epoch: 00241 loss_train: 0.6295 acc_train: 0.6630 loss_val: 0.6177 acc_val: 0.6623 time: 0.0476s\n",
      "valid current auc-roc score: 0.704074, current macro_F score: 0.393701\n",
      "Epoch: 00242 loss_train: 0.6325 acc_train: 0.6522 loss_val: 0.6206 acc_val: 0.6494 time: 0.0384s\n",
      "valid current auc-roc score: 0.714815, current macro_F score: 0.393701\n",
      "Epoch: 00243 loss_train: 0.6352 acc_train: 0.6522 loss_val: 0.6032 acc_val: 0.6494 time: 0.0488s\n",
      "valid current auc-roc score: 0.704815, current macro_F score: 0.393701\n",
      "Epoch: 00244 loss_train: 0.6334 acc_train: 0.6522 loss_val: 0.6126 acc_val: 0.6494 time: 0.0761s\n",
      "valid current auc-roc score: 0.657037, current macro_F score: 0.393701\n",
      "Epoch: 00245 loss_train: 0.6393 acc_train: 0.6522 loss_val: 0.6239 acc_val: 0.6494 time: 0.0674s\n",
      "valid current auc-roc score: 0.733333, current macro_F score: 0.393701\n",
      "Epoch: 00246 loss_train: 0.6348 acc_train: 0.6522 loss_val: 0.5952 acc_val: 0.6494 time: 0.0406s\n",
      "valid current auc-roc score: 0.611481, current macro_F score: 0.432540\n",
      "Epoch: 00247 loss_train: 0.6451 acc_train: 0.6543 loss_val: 0.6277 acc_val: 0.6623 time: 0.0431s\n",
      "valid current auc-roc score: 0.529630, current macro_F score: 0.393701\n",
      "Epoch: 00248 loss_train: 0.6338 acc_train: 0.6522 loss_val: 0.6412 acc_val: 0.6494 time: 0.0401s\n",
      "valid current auc-roc score: 0.563333, current macro_F score: 0.393701\n",
      "Epoch: 00249 loss_train: 0.6416 acc_train: 0.6522 loss_val: 0.6329 acc_val: 0.6494 time: 0.0371s\n",
      "valid current auc-roc score: 0.621111, current macro_F score: 0.393701\n",
      "Epoch: 00250 loss_train: 0.6390 acc_train: 0.6522 loss_val: 0.6302 acc_val: 0.6494 time: 0.0347s\n",
      "valid current auc-roc score: 0.658519, current macro_F score: 0.393701\n",
      "Epoch: 00251 loss_train: 0.6257 acc_train: 0.6522 loss_val: 0.6184 acc_val: 0.6494 time: 0.0366s\n",
      "valid current auc-roc score: 0.632593, current macro_F score: 0.393701\n",
      "Epoch: 00252 loss_train: 0.6356 acc_train: 0.6522 loss_val: 0.6242 acc_val: 0.6494 time: 0.0465s\n",
      "valid current auc-roc score: 0.624444, current macro_F score: 0.393701\n",
      "Epoch: 00253 loss_train: 0.6380 acc_train: 0.6522 loss_val: 0.6246 acc_val: 0.6494 time: 0.0458s\n",
      "valid current auc-roc score: 0.762963, current macro_F score: 0.393701\n",
      "Epoch: 00254 loss_train: 0.6384 acc_train: 0.6522 loss_val: 0.5918 acc_val: 0.6494 time: 0.0508s\n",
      "valid current auc-roc score: 0.585556, current macro_F score: 0.432540\n",
      "Epoch: 00255 loss_train: 0.6276 acc_train: 0.6587 loss_val: 0.6320 acc_val: 0.6623 time: 0.0409s\n",
      "valid current auc-roc score: 0.595556, current macro_F score: 0.503226\n",
      "Epoch: 00256 loss_train: 0.6333 acc_train: 0.6609 loss_val: 0.6218 acc_val: 0.6883 time: 0.0408s\n",
      "valid current auc-roc score: 0.662963, current macro_F score: 0.495148\n",
      "Epoch: 00257 loss_train: 0.6212 acc_train: 0.6717 loss_val: 0.6151 acc_val: 0.6753 time: 0.0459s\n",
      "valid current auc-roc score: 0.539259, current macro_F score: 0.393701\n",
      "Epoch: 00258 loss_train: 0.6339 acc_train: 0.6522 loss_val: 0.6462 acc_val: 0.6494 time: 0.0402s\n",
      "valid current auc-roc score: 0.626667, current macro_F score: 0.393701\n",
      "Epoch: 00259 loss_train: 0.6393 acc_train: 0.6587 loss_val: 0.6185 acc_val: 0.6494 time: 0.0450s\n",
      "valid current auc-roc score: 0.659259, current macro_F score: 0.393701\n",
      "Epoch: 00260 loss_train: 0.6311 acc_train: 0.6522 loss_val: 0.6130 acc_val: 0.6494 time: 0.0366s\n",
      "valid current auc-roc score: 0.660741, current macro_F score: 0.393701\n",
      "Epoch: 00261 loss_train: 0.6161 acc_train: 0.6522 loss_val: 0.6073 acc_val: 0.6494 time: 0.0311s\n",
      "valid current auc-roc score: 0.632222, current macro_F score: 0.468966\n",
      "Epoch: 00262 loss_train: 0.6301 acc_train: 0.6500 loss_val: 0.6219 acc_val: 0.6753 time: 0.0363s\n",
      "valid current auc-roc score: 0.640370, current macro_F score: 0.393701\n",
      "Epoch: 00263 loss_train: 0.6416 acc_train: 0.6522 loss_val: 0.6139 acc_val: 0.6494 time: 0.0359s\n",
      "valid current auc-roc score: 0.694444, current macro_F score: 0.393701\n",
      "Epoch: 00264 loss_train: 0.6309 acc_train: 0.6522 loss_val: 0.6124 acc_val: 0.6494 time: 0.0347s\n",
      "valid current auc-roc score: 0.655556, current macro_F score: 0.432540\n",
      "Epoch: 00265 loss_train: 0.6297 acc_train: 0.6630 loss_val: 0.6049 acc_val: 0.6623 time: 0.0469s\n",
      "valid current auc-roc score: 0.615185, current macro_F score: 0.393701\n",
      "Epoch: 00266 loss_train: 0.6380 acc_train: 0.6522 loss_val: 0.6242 acc_val: 0.6494 time: 0.0389s\n",
      "valid current auc-roc score: 0.668148, current macro_F score: 0.566086\n",
      "Epoch: 00267 loss_train: 0.6274 acc_train: 0.6717 loss_val: 0.5996 acc_val: 0.7143 time: 0.0393s\n",
      "valid current auc-roc score: 0.651111, current macro_F score: 0.420430\n",
      "Epoch: 00268 loss_train: 0.7810 acc_train: 0.6587 loss_val: 0.7795 acc_val: 0.6364 time: 0.0670s\n",
      "valid current auc-roc score: 0.589630, current macro_F score: 0.393701\n",
      "Epoch: 00269 loss_train: 0.6330 acc_train: 0.6522 loss_val: 0.6417 acc_val: 0.6494 time: 0.1049s\n",
      "valid current auc-roc score: 0.592593, current macro_F score: 0.454760\n",
      "Epoch: 00270 loss_train: 0.6578 acc_train: 0.6587 loss_val: 0.6433 acc_val: 0.6494 time: 0.0526s\n",
      "valid current auc-roc score: 0.613333, current macro_F score: 0.503226\n",
      "Epoch: 00271 loss_train: 0.6284 acc_train: 0.6652 loss_val: 0.6023 acc_val: 0.6883 time: 0.0399s\n",
      "valid current auc-roc score: 0.622222, current macro_F score: 0.393701\n",
      "Epoch: 00272 loss_train: 0.6392 acc_train: 0.6522 loss_val: 0.6356 acc_val: 0.6494 time: 0.0347s\n",
      "valid current auc-roc score: 0.612593, current macro_F score: 0.393701\n",
      "Epoch: 00273 loss_train: 0.6454 acc_train: 0.6522 loss_val: 0.6282 acc_val: 0.6494 time: 0.0381s\n",
      "valid current auc-roc score: 0.725926, current macro_F score: 0.393701\n",
      "Epoch: 00274 loss_train: 0.6516 acc_train: 0.6522 loss_val: 0.6007 acc_val: 0.6494 time: 0.0347s\n",
      "valid current auc-roc score: 0.579259, current macro_F score: 0.393701\n",
      "Epoch: 00275 loss_train: 0.6520 acc_train: 0.6522 loss_val: 0.6529 acc_val: 0.6494 time: 0.0439s\n",
      "valid current auc-roc score: 0.643704, current macro_F score: 0.393701\n",
      "Epoch: 00276 loss_train: 0.6465 acc_train: 0.6522 loss_val: 0.6201 acc_val: 0.6494 time: 0.0382s\n",
      "valid current auc-roc score: 0.665556, current macro_F score: 0.432540\n",
      "Epoch: 00277 loss_train: 0.6220 acc_train: 0.6609 loss_val: 0.6086 acc_val: 0.6623 time: 0.0357s\n",
      "valid current auc-roc score: 0.618519, current macro_F score: 0.393701\n",
      "Epoch: 00278 loss_train: 0.6339 acc_train: 0.6522 loss_val: 0.6347 acc_val: 0.6494 time: 0.0356s\n",
      "valid current auc-roc score: 0.553333, current macro_F score: 0.393701\n",
      "Epoch: 00279 loss_train: 0.6286 acc_train: 0.6522 loss_val: 0.6449 acc_val: 0.6494 time: 0.0345s\n",
      "valid current auc-roc score: 0.686667, current macro_F score: 0.393701\n",
      "Epoch: 00280 loss_train: 0.6362 acc_train: 0.6522 loss_val: 0.6129 acc_val: 0.6494 time: 0.0373s\n",
      "valid current auc-roc score: 0.752593, current macro_F score: 0.393701\n",
      "Epoch: 00281 loss_train: 0.6288 acc_train: 0.6522 loss_val: 0.6012 acc_val: 0.6494 time: 0.0339s\n",
      "valid current auc-roc score: 0.654815, current macro_F score: 0.393701\n",
      "Epoch: 00282 loss_train: 0.6310 acc_train: 0.6522 loss_val: 0.6172 acc_val: 0.6494 time: 0.0365s\n",
      "valid current auc-roc score: 0.709630, current macro_F score: 0.393701\n",
      "Epoch: 00283 loss_train: 0.6434 acc_train: 0.6522 loss_val: 0.6053 acc_val: 0.6494 time: 0.0359s\n",
      "valid current auc-roc score: 0.704444, current macro_F score: 0.393701\n",
      "Epoch: 00284 loss_train: 0.6251 acc_train: 0.6522 loss_val: 0.6013 acc_val: 0.6494 time: 0.0311s\n",
      "valid current auc-roc score: 0.656296, current macro_F score: 0.393701\n",
      "Epoch: 00285 loss_train: 0.6361 acc_train: 0.6522 loss_val: 0.6137 acc_val: 0.6494 time: 0.0340s\n",
      "valid current auc-roc score: 0.659259, current macro_F score: 0.393701\n",
      "Epoch: 00286 loss_train: 0.6332 acc_train: 0.6522 loss_val: 0.6210 acc_val: 0.6494 time: 0.0316s\n",
      "valid current auc-roc score: 0.720370, current macro_F score: 0.393701\n",
      "Epoch: 00287 loss_train: 0.6421 acc_train: 0.6522 loss_val: 0.6106 acc_val: 0.6494 time: 0.0316s\n",
      "valid current auc-roc score: 0.700000, current macro_F score: 0.393701\n",
      "Epoch: 00288 loss_train: 0.6428 acc_train: 0.6522 loss_val: 0.5966 acc_val: 0.6494 time: 0.0368s\n",
      "valid current auc-roc score: 0.622222, current macro_F score: 0.393701\n",
      "Epoch: 00289 loss_train: 0.6288 acc_train: 0.6522 loss_val: 0.6264 acc_val: 0.6494 time: 0.0352s\n",
      "valid current auc-roc score: 0.703704, current macro_F score: 0.393701\n",
      "Epoch: 00290 loss_train: 0.6338 acc_train: 0.6522 loss_val: 0.6131 acc_val: 0.6494 time: 0.0375s\n",
      "valid current auc-roc score: 0.677407, current macro_F score: 0.393701\n",
      "Epoch: 00291 loss_train: 0.6368 acc_train: 0.6522 loss_val: 0.6222 acc_val: 0.6494 time: 0.0328s\n",
      "valid current auc-roc score: 0.673704, current macro_F score: 0.393701\n",
      "Epoch: 00292 loss_train: 0.6325 acc_train: 0.6522 loss_val: 0.6178 acc_val: 0.6494 time: 0.0335s\n",
      "valid current auc-roc score: 0.614815, current macro_F score: 0.393701\n",
      "Epoch: 00293 loss_train: 0.6330 acc_train: 0.6522 loss_val: 0.6324 acc_val: 0.6494 time: 0.0317s\n",
      "valid current auc-roc score: 0.659259, current macro_F score: 0.393701\n",
      "Epoch: 00294 loss_train: 0.6279 acc_train: 0.6522 loss_val: 0.6184 acc_val: 0.6494 time: 0.0317s\n",
      "valid current auc-roc score: 0.694815, current macro_F score: 0.393701\n",
      "Epoch: 00295 loss_train: 0.6284 acc_train: 0.6522 loss_val: 0.6049 acc_val: 0.6494 time: 0.0334s\n",
      "valid current auc-roc score: 0.625926, current macro_F score: 0.393701\n",
      "Epoch: 00296 loss_train: 0.6335 acc_train: 0.6522 loss_val: 0.6259 acc_val: 0.6494 time: 0.0339s\n",
      "valid current auc-roc score: 0.610370, current macro_F score: 0.393701\n",
      "Epoch: 00297 loss_train: 0.6392 acc_train: 0.6522 loss_val: 0.6416 acc_val: 0.6494 time: 0.0331s\n",
      "valid current auc-roc score: 0.682963, current macro_F score: 0.393701\n",
      "Epoch: 00298 loss_train: 0.6520 acc_train: 0.6522 loss_val: 0.6076 acc_val: 0.6494 time: 0.0324s\n",
      "valid current auc-roc score: 0.574815, current macro_F score: 0.426483\n",
      "Epoch: 00299 loss_train: 0.6225 acc_train: 0.6587 loss_val: 0.6396 acc_val: 0.6494 time: 0.0317s\n",
      "valid current auc-roc score: 0.671481, current macro_F score: 0.393701\n",
      "Epoch: 00300 loss_train: 0.6396 acc_train: 0.6522 loss_val: 0.6189 acc_val: 0.6494 time: 0.0325s\n"
     ]
    }
   ],
   "source": [
    "acc_trains = []\n",
    "acc_vals = []\n",
    "loss_trains = []\n",
    "loss_vals = []\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "        acc_train, acc_val, loss_train, loss_val = train(epoch)\n",
    "        acc_trains.append(acc_train)\n",
    "        acc_vals.append(acc_val)\n",
    "        loss_trains.append(loss_train)\n",
    "        loss_vals.append(loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# %matplotlib notebook\n",
    "# %matplotlib inline\n",
    "\n",
    "plt.plot(loss_vals)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GraphSMOTE's implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recon_upsample(embed, labels, idx_train, adj=None, portion=1.0, im_class_num=3):\n",
    "    c_largest = labels.max().item()\n",
    "    avg_number = int(idx_train.shape[0]/(c_largest+1))\n",
    "    adj_new = None\n",
    "    for i in range(im_class_num):\n",
    "        chosen = idx_train[(labels==(c_largest-i))[idx_train]]\n",
    "        num = int(chosen.shape[0]*portion)\n",
    "        if portion == 0:\n",
    "            c_portion = int(avg_number/chosen.shape[0])\n",
    "            num = chosen.shape[0]\n",
    "        else:\n",
    "            c_portion = 1\n",
    "\n",
    "        for j in range(c_portion):\n",
    "            chosen = chosen[:num]\n",
    "\n",
    "            chosen_embed = embed[chosen,:]\n",
    "            distance = squareform(pdist(chosen_embed.cpu().detach()))\n",
    "            np.fill_diagonal(distance,distance.max()+100)\n",
    "\n",
    "            idx_neighbor = distance.argmin(axis=-1)\n",
    "            \n",
    "            interp_place = random.random()\n",
    "            new_embed = embed[chosen,:] + (chosen_embed[idx_neighbor,:]-embed[chosen,:])*interp_place\n",
    "\n",
    "\n",
    "            new_labels = labels.new(torch.Size((chosen.shape[0],1))).reshape(-1).fill_(c_largest-i)\n",
    "            idx_new = np.arange(embed.shape[0], embed.shape[0]+chosen.shape[0])\n",
    "            idx_train_append = idx_train.new(idx_new)\n",
    "\n",
    "            embed = torch.cat((embed,new_embed), 0)\n",
    "            labels = torch.cat((labels,new_labels), 0)\n",
    "            idx_train = torch.cat((idx_train,idx_train_append), 0)\n",
    "\n",
    "            if adj is not None:\n",
    "                if adj_new is None:\n",
    "                    adj_new = adj.new(torch.clamp_(adj[chosen,:] + adj[idx_neighbor,:], min=0.0, max = 1.0))\n",
    "                else:\n",
    "                    temp = adj.new(torch.clamp_(adj[chosen,:] + adj[idx_neighbor,:], min=0.0, max = 1.0))\n",
    "                    adj_new = torch.cat((adj_new, temp), 0)\n",
    "\n",
    "    if adj is not None:\n",
    "        add_num = adj_new.shape[0]\n",
    "        new_adj = adj.new(torch.Size((adj.shape[0]+add_num, adj.shape[0]+add_num))).fill_(0.0)\n",
    "        new_adj[:adj.shape[0], :adj.shape[0]] = adj[:,:]\n",
    "        new_adj[adj.shape[0]:, :adj.shape[0]] = adj_new[:,:]\n",
    "        new_adj[:adj.shape[0], adj.shape[0]:] = torch.transpose(adj_new, 0, 1)[:,:]\n",
    "\n",
    "        return embed, labels, idx_train, new_adj.detach()\n",
    "\n",
    "    else:\n",
    "        return embed, labels, idx_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train & eval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import networkx as nx\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "import pickle\n",
    "\n",
    "\n",
    "def encode_onehot_torch(labels):\n",
    "    num_classes = int(labels.max() + 1)\n",
    "    y = torch.eye(num_classes)\n",
    "    return y[labels]\n",
    "\n",
    "\n",
    "def encode_onehot(labels):\n",
    "    classes = set(labels)\n",
    "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in\n",
    "                    enumerate(classes)}\n",
    "    labels_onehot = np.array(list(map(classes_dict.get, labels)),\n",
    "                             dtype=np.int32)\n",
    "    return labels_onehot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('arc_selection-master')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "04f122987ad9a59b0c863ec73977cb4833edd644652b774e5b01a9e2fe636c23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
