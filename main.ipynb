{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils.GraphConvolution import GCN_Encoder_s, GCN_Classifier_s, Decoder_s\n",
    "from utils.GraphConvolution import GraphConvolution, GCN_Encoder3\n",
    "import argparse\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "import torch\n",
    "import ipdb\n",
    "from scipy.io import loadmat\n",
    "import utils\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    weight_decay = 5e-4\n",
    "    epochs = 300\n",
    "    learning_rate = 0.01\n",
    "    learning_rate_W = 0.01\n",
    "    dropout = 0.5\n",
    "    dropout_W = 0.5\n",
    "    gamma = 1\n",
    "    no_cuda = False\n",
    "    train_ratio=0.6\n",
    "    test_ratio=0.1\n",
    "    n_classes = 2\n",
    "    seed = 12345\n",
    "    torch.manual_seed(seed)\n",
    "    dataset = \"cora\"\n",
    "    # dataset = \"haberman\"\n",
    "    order = 4\n",
    "    n_features = 0\n",
    "    w_val_size = 10\n",
    "    imbalance_ratio = None\n",
    "    n_hidden = 64\n",
    "    setting = None\n",
    "    im_class_num = 3\n",
    "    setting = \"upsampling\"\n",
    "    opt_new_G = False\n",
    "    up_scale = 1\n",
    "    im_ratio = 0.5\n",
    "args = Args()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset specific variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_loader import data_loader_diabetes, data_loader_haberman, data_loader_cora\n",
    "\n",
    "cora_adj_mtx, cora_labels_df, cora_features_df, \\\n",
    "        cora_train_idx, cora_val_idx, cora_test_idx, cora_n_features = data_loader_cora(args)\n",
    "        \n",
    "diabetes_adj_mtx, diabetes_labels_df, diabetes_features_df, \\\n",
    "        diabetes_train_idx, diabetes_val_idx, diabetes_test_idx, diabetes_n_features = data_loader_diabetes(args)\n",
    "\n",
    "haberman_adj_mtx, haberman_labels_df, haberman_features_df, \\\n",
    "        haberman_train_idx, haberman_val_idx, haberman_test_idx, haberman_n_features = data_loader_haberman(args)\n",
    "\n",
    "if args.dataset == \"diabetes\":\n",
    "    adj_mtx = diabetes_adj_mtx\n",
    "    n_hidden = [64, 64, 64]\n",
    "    n_features = diabetes_n_features\n",
    "    features = diabetes_features_df\n",
    "    labels = diabetes_labels_df\n",
    "    # train_X = diabetes_train_X_df\n",
    "    # train_Y = diabetes_train_Y_df\n",
    "    # val_X = diabetes_val_X_df\n",
    "    # val_Y = diabetes_val_Y_df\n",
    "    # test_X = diabetes_test_X_df\n",
    "    # test_Y = diabetes_test_Y_df\n",
    "    train_idx = diabetes_train_idx\n",
    "    val_idx = diabetes_val_idx\n",
    "    test_idx = diabetes_test_idx\n",
    "elif args.dataset == \"cora\":\n",
    "    adj_mtx = cora_adj_mtx\n",
    "    n_hidden = [64, 64, 64]\n",
    "    n_features = cora_n_features\n",
    "    features = cora_features_df\n",
    "    labels = cora_labels_df\n",
    "    # train_X = diabetes_train_X_df\n",
    "    # train_Y = diabetes_train_Y_df\n",
    "    # val_X = diabetes_val_X_df\n",
    "    # val_Y = diabetes_val_Y_df\n",
    "    # test_X = diabetes_test_X_df\n",
    "    # test_Y = diabetes_test_Y_df\n",
    "    train_idx = cora_train_idx\n",
    "    val_idx = cora_val_idx\n",
    "    test_idx = cora_test_idx\n",
    "elif args.dataset == \"haberman\":\n",
    "    adj_mtx = haberman_adj_mtx\n",
    "    n_hidden = [64]\n",
    "    n_features = haberman_n_features\n",
    "    features = haberman_features_df\n",
    "    labels = haberman_labels_df\n",
    "    # train_X = haberman_train_X_df\n",
    "    # train_Y = haberman_train_Y_df\n",
    "    # val_X = haberman_val_X_df\n",
    "    # val_Y = haberman_val_Y_df\n",
    "    # test_X = haberman_test_X_df\n",
    "    # test_Y = haberman_test_Y_df\n",
    "    train_idx = haberman_train_idx\n",
    "    val_idx = haberman_val_idx\n",
    "    test_idx = haberman_test_idx\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# assert len(pd.DataFrame(val_Y, columns=['labels']).labels.unique()) == len(pd.DataFrame(train_Y, columns=['labels']).labels.unique()) == len(pd.DataFrame(test_Y, columns=['labels']).labels.unique()), \\\n",
    "#     \"There are some classes missing in one the 3 partitiones of the dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if False else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataframe to Tensor transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features = torch.from_numpy(np.concatenate((train_X, val_X, test_X), axis=0)).to(device)\n",
    "# labels = torch.from_numpy(np.int64(np.concatenate((train_Y, val_Y, test_Y), axis=0))).to(device)\n",
    "train_idx = torch.from_numpy(np.array(train_idx, dtype = np.int64)).to(device)\n",
    "val_idx = torch.from_numpy(np.array(val_idx, dtype = np.int64)).to(device)\n",
    "test_idx = torch.from_numpy(np.array(test_idx, dtype = np.int64)).to(device)\n",
    "features = torch.from_numpy(np.array(features, dtype = np.float64)).to(device)\n",
    "labels = torch.from_numpy(np.array(labels, dtype = np.int64)).to(device)\n",
    "try:\n",
    "    adj_mtx = torch.from_numpy(np.array(adj_mtx, dtype = np.float64)).to(device)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.GraphConvolution import GCN_Encoder3, GCN_Classifier\n",
    "import time\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from utils.evaluation import accuracy, print_class_acc\n",
    "\n",
    "# encoder = GCN_Encoder3(nfeat=n_features,\n",
    "#         nhid=n_hidden,\n",
    "#         nembed=n_hidden[-1],\n",
    "#         dropout=args.dropout,\n",
    "#         nclass=args.n_classes,\n",
    "#         order=1)\n",
    "# classifier = GCN_Classifier(nembed=n_hidden[-1], \n",
    "#         nhid=n_hidden[-1], \n",
    "#         nclass=int(labels.max().item()) + 1, \n",
    "#         dropout=args.dropout, device=device)\n",
    "encoder = GCN_Encoder_s(nfeat = n_features, nhid = n_hidden[-1], nembed = n_hidden[-1], dropout = args.dropout)\n",
    "classifier = GCN_Classifier_s(nembed = n_hidden[-1], nhid = n_hidden[-1], nclass = int(labels.max().item()) + 1, dropout = args.dropout, device = device)\n",
    "optimizer_en = optim.Adam(encoder.parameters(),\n",
    "                       lr = args.learning_rate, weight_decay = args.weight_decay)\n",
    "optimizer_cls = optim.Adam(classifier.parameters(),\n",
    "                       lr = args.learning_rate, weight_decay = args.weight_decay)\n",
    "encoder.train()\n",
    "classifier.train()\n",
    "def train(epoch):\n",
    "        t = time.time()\n",
    "        optimizer_en.zero_grad()\n",
    "        optimizer_cls.zero_grad()\n",
    "        embed = encoder(features, adj_mtx)\n",
    "        output = classifier(embed, adj_mtx)\n",
    "        out = output[train_idx]\n",
    "        gt = labels[train_idx].reshape(-1)\n",
    "        if args.setting == 'reweight':\n",
    "                weight = \"STH\"\n",
    "                loss_train = F.cross_entropy(out, gt, weight = weight)\n",
    "        else:\n",
    "                loss_train = F.cross_entropy(out, gt)\n",
    "        acc_train = accuracy(out, gt)\n",
    "        loss_train.backward()\n",
    "        optimizer_en.step()\n",
    "        optimizer_cls.step()\n",
    "        gt_v = labels[test_idx].reshape(-1)\n",
    "        out_v = output[test_idx]\n",
    "        loss_val = F.cross_entropy(out_v, gt_v)\n",
    "        acc_val = accuracy(out_v, gt_v)\n",
    "        print_class_acc(out_v, gt_v)\n",
    "        print('Epoch: {:05d}'.format(epoch+ 1),\n",
    "          'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "          'acc_train: {:.4f}'.format(acc_train.item()),\n",
    "          'loss_val: {:.4f}'.format(loss_val.item()),\n",
    "          'acc_val: {:.4f}'.format(acc_val.item()),\n",
    "          'time: {:.4f}s'.format(time.time() - t))\n",
    "        \n",
    "        return acc_train.item(), acc_val.item(), loss_train.item(), loss_val.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "valid current auc-roc score: 0.499357, current macro_F score: 0.068612\n",
      "Epoch: 00001 loss_train: 1.9485 acc_train: 0.1139 loss_val: 1.9538 acc_val: 0.1144 time: 0.3523s\n",
      "valid current auc-roc score: 0.611719, current macro_F score: 0.098924\n",
      "Epoch: 00002 loss_train: 1.8380 acc_train: 0.2457 loss_val: 1.8797 acc_val: 0.1661 time: 0.2315s\n",
      "valid current auc-roc score: 0.618204, current macro_F score: 0.147298\n",
      "Epoch: 00003 loss_train: 1.7594 acc_train: 0.3147 loss_val: 1.8200 acc_val: 0.2768 time: 0.1902s\n",
      "valid current auc-roc score: 0.669604, current macro_F score: 0.201065\n",
      "Epoch: 00004 loss_train: 1.6423 acc_train: 0.3953 loss_val: 1.7625 acc_val: 0.3542 time: 0.1916s\n",
      "valid current auc-roc score: 0.716914, current macro_F score: 0.226615\n",
      "Epoch: 00005 loss_train: 1.5177 acc_train: 0.4452 loss_val: 1.7011 acc_val: 0.3653 time: 0.2029s\n",
      "valid current auc-roc score: 0.743671, current macro_F score: 0.315708\n",
      "Epoch: 00006 loss_train: 1.4178 acc_train: 0.5006 loss_val: 1.6388 acc_val: 0.3985 time: 0.1902s\n",
      "valid current auc-roc score: 0.758973, current macro_F score: 0.367331\n",
      "Epoch: 00007 loss_train: 1.3551 acc_train: 0.5486 loss_val: 1.6527 acc_val: 0.4539 time: 0.1905s\n",
      "valid current auc-roc score: 0.805754, current macro_F score: 0.425830\n",
      "Epoch: 00008 loss_train: 1.2633 acc_train: 0.6305 loss_val: 1.5665 acc_val: 0.5055 time: 0.3310s\n",
      "valid current auc-roc score: 0.816369, current macro_F score: 0.457093\n",
      "Epoch: 00009 loss_train: 1.2127 acc_train: 0.6539 loss_val: 1.5465 acc_val: 0.5277 time: 0.1710s\n",
      "valid current auc-roc score: 0.826342, current macro_F score: 0.476484\n",
      "Epoch: 00010 loss_train: 1.1218 acc_train: 0.6958 loss_val: 1.5339 acc_val: 0.5646 time: 0.1641s\n",
      "valid current auc-roc score: 0.841516, current macro_F score: 0.493754\n",
      "Epoch: 00011 loss_train: 1.1347 acc_train: 0.6940 loss_val: 1.4914 acc_val: 0.5720 time: 0.1645s\n",
      "valid current auc-roc score: 0.848487, current macro_F score: 0.505450\n",
      "Epoch: 00012 loss_train: 1.0707 acc_train: 0.7057 loss_val: 1.4489 acc_val: 0.6125 time: 0.1927s\n",
      "valid current auc-roc score: 0.876422, current macro_F score: 0.519720\n",
      "Epoch: 00013 loss_train: 0.9718 acc_train: 0.7229 loss_val: 1.3559 acc_val: 0.6236 time: 0.1757s\n",
      "valid current auc-roc score: 0.855463, current macro_F score: 0.508602\n",
      "Epoch: 00014 loss_train: 0.9895 acc_train: 0.7100 loss_val: 1.4386 acc_val: 0.5904 time: 0.1449s\n",
      "valid current auc-roc score: 0.885521, current macro_F score: 0.570421\n",
      "Epoch: 00015 loss_train: 0.9470 acc_train: 0.7555 loss_val: 1.2733 acc_val: 0.6568 time: 0.1645s\n",
      "valid current auc-roc score: 0.894163, current macro_F score: 0.600868\n",
      "Epoch: 00016 loss_train: 0.8844 acc_train: 0.7617 loss_val: 1.2802 acc_val: 0.6642 time: 0.1588s\n",
      "valid current auc-roc score: 0.897427, current macro_F score: 0.590352\n",
      "Epoch: 00017 loss_train: 0.8133 acc_train: 0.7709 loss_val: 1.2090 acc_val: 0.6605 time: 0.1451s\n",
      "valid current auc-roc score: 0.912619, current macro_F score: 0.621479\n",
      "Epoch: 00018 loss_train: 0.8003 acc_train: 0.7802 loss_val: 1.1364 acc_val: 0.6716 time: 0.1620s\n",
      "valid current auc-roc score: 0.898970, current macro_F score: 0.590303\n",
      "Epoch: 00019 loss_train: 0.7371 acc_train: 0.7833 loss_val: 1.0696 acc_val: 0.6642 time: 0.1712s\n",
      "valid current auc-roc score: 0.915800, current macro_F score: 0.593117\n",
      "Epoch: 00020 loss_train: 0.7417 acc_train: 0.7814 loss_val: 1.0894 acc_val: 0.6642 time: 0.1509s\n",
      "valid current auc-roc score: 0.907435, current macro_F score: 0.582463\n",
      "Epoch: 00021 loss_train: 0.7129 acc_train: 0.7906 loss_val: 1.0467 acc_val: 0.6310 time: 0.1602s\n",
      "valid current auc-roc score: 0.908298, current macro_F score: 0.555136\n",
      "Epoch: 00022 loss_train: 0.6889 acc_train: 0.7851 loss_val: 1.0547 acc_val: 0.6199 time: 0.1616s\n",
      "valid current auc-roc score: 0.903514, current macro_F score: 0.583694\n",
      "Epoch: 00023 loss_train: 0.6569 acc_train: 0.7993 loss_val: 1.0662 acc_val: 0.6494 time: 0.1734s\n",
      "valid current auc-roc score: 0.906719, current macro_F score: 0.632904\n",
      "Epoch: 00024 loss_train: 0.6242 acc_train: 0.8147 loss_val: 1.0210 acc_val: 0.6827 time: 0.1537s\n",
      "valid current auc-roc score: 0.918871, current macro_F score: 0.672145\n",
      "Epoch: 00025 loss_train: 0.6061 acc_train: 0.8282 loss_val: 0.9544 acc_val: 0.7196 time: 0.2428s\n",
      "valid current auc-roc score: 0.934042, current macro_F score: 0.653264\n",
      "Epoch: 00026 loss_train: 0.6073 acc_train: 0.8220 loss_val: 0.8989 acc_val: 0.6937 time: 0.1714s\n",
      "valid current auc-roc score: 0.928653, current macro_F score: 0.646941\n",
      "Epoch: 00027 loss_train: 0.5577 acc_train: 0.8399 loss_val: 0.9292 acc_val: 0.6937 time: 0.1181s\n",
      "valid current auc-roc score: 0.913622, current macro_F score: 0.675863\n",
      "Epoch: 00028 loss_train: 0.5595 acc_train: 0.8300 loss_val: 0.9736 acc_val: 0.7085 time: 0.1129s\n",
      "valid current auc-roc score: 0.921593, current macro_F score: 0.656262\n",
      "Epoch: 00029 loss_train: 0.5171 acc_train: 0.8399 loss_val: 0.9486 acc_val: 0.6863 time: 0.1117s\n",
      "valid current auc-roc score: 0.910508, current macro_F score: 0.674296\n",
      "Epoch: 00030 loss_train: 0.5337 acc_train: 0.8424 loss_val: 1.0222 acc_val: 0.7048 time: 0.1441s\n",
      "valid current auc-roc score: 0.925185, current macro_F score: 0.682290\n",
      "Epoch: 00031 loss_train: 0.4981 acc_train: 0.8547 loss_val: 0.8914 acc_val: 0.7159 time: 0.1253s\n",
      "valid current auc-roc score: 0.917555, current macro_F score: 0.695184\n",
      "Epoch: 00032 loss_train: 0.4979 acc_train: 0.8639 loss_val: 0.9476 acc_val: 0.7196 time: 0.1482s\n",
      "valid current auc-roc score: 0.919201, current macro_F score: 0.676853\n",
      "Epoch: 00033 loss_train: 0.4892 acc_train: 0.8547 loss_val: 0.9253 acc_val: 0.7011 time: 0.1734s\n",
      "valid current auc-roc score: 0.919150, current macro_F score: 0.706508\n",
      "Epoch: 00034 loss_train: 0.4873 acc_train: 0.8565 loss_val: 0.9071 acc_val: 0.7343 time: 0.1052s\n",
      "valid current auc-roc score: 0.921700, current macro_F score: 0.695592\n",
      "Epoch: 00035 loss_train: 0.4499 acc_train: 0.8688 loss_val: 0.9014 acc_val: 0.7269 time: 0.1017s\n",
      "valid current auc-roc score: 0.914119, current macro_F score: 0.701015\n",
      "Epoch: 00036 loss_train: 0.4467 acc_train: 0.8725 loss_val: 0.9382 acc_val: 0.7159 time: 0.0960s\n",
      "valid current auc-roc score: 0.906052, current macro_F score: 0.655121\n",
      "Epoch: 00037 loss_train: 0.4286 acc_train: 0.8639 loss_val: 1.0649 acc_val: 0.6827 time: 0.0894s\n",
      "valid current auc-roc score: 0.924915, current macro_F score: 0.716907\n",
      "Epoch: 00038 loss_train: 0.4314 acc_train: 0.8701 loss_val: 0.9216 acc_val: 0.7417 time: 0.1022s\n",
      "valid current auc-roc score: 0.920941, current macro_F score: 0.702810\n",
      "Epoch: 00039 loss_train: 0.4155 acc_train: 0.8830 loss_val: 0.9551 acc_val: 0.7269 time: 0.0884s\n",
      "valid current auc-roc score: 0.923607, current macro_F score: 0.686177\n",
      "Epoch: 00040 loss_train: 0.4114 acc_train: 0.8787 loss_val: 0.9314 acc_val: 0.7085 time: 0.0898s\n",
      "valid current auc-roc score: 0.922896, current macro_F score: 0.674328\n",
      "Epoch: 00041 loss_train: 0.3977 acc_train: 0.8879 loss_val: 0.9518 acc_val: 0.6937 time: 0.0946s\n",
      "valid current auc-roc score: 0.917763, current macro_F score: 0.709754\n",
      "Epoch: 00042 loss_train: 0.3799 acc_train: 0.8892 loss_val: 0.9445 acc_val: 0.7343 time: 0.0914s\n",
      "valid current auc-roc score: 0.921229, current macro_F score: 0.685937\n",
      "Epoch: 00043 loss_train: 0.3812 acc_train: 0.8805 loss_val: 0.9178 acc_val: 0.7122 time: 0.0866s\n",
      "valid current auc-roc score: 0.913284, current macro_F score: 0.632451\n",
      "Epoch: 00044 loss_train: 0.4028 acc_train: 0.8744 loss_val: 0.9506 acc_val: 0.6790 time: 0.0918s\n",
      "valid current auc-roc score: 0.928296, current macro_F score: 0.700452\n",
      "Epoch: 00045 loss_train: 0.3684 acc_train: 0.8978 loss_val: 0.8635 acc_val: 0.7232 time: 0.1112s\n",
      "valid current auc-roc score: 0.920048, current macro_F score: 0.694897\n",
      "Epoch: 00046 loss_train: 0.3633 acc_train: 0.8830 loss_val: 0.9287 acc_val: 0.7306 time: 0.0967s\n",
      "valid current auc-roc score: 0.921223, current macro_F score: 0.685813\n",
      "Epoch: 00047 loss_train: 0.3614 acc_train: 0.8873 loss_val: 0.9410 acc_val: 0.7159 time: 0.1028s\n",
      "valid current auc-roc score: 0.923647, current macro_F score: 0.693828\n",
      "Epoch: 00048 loss_train: 0.3645 acc_train: 0.8904 loss_val: 0.9141 acc_val: 0.7122 time: 0.1128s\n",
      "valid current auc-roc score: 0.924237, current macro_F score: 0.692094\n",
      "Epoch: 00049 loss_train: 0.3332 acc_train: 0.9058 loss_val: 0.9060 acc_val: 0.7122 time: 0.0984s\n",
      "valid current auc-roc score: 0.926073, current macro_F score: 0.675635\n",
      "Epoch: 00050 loss_train: 0.3130 acc_train: 0.8990 loss_val: 0.9370 acc_val: 0.7048 time: 0.0898s\n",
      "valid current auc-roc score: 0.921550, current macro_F score: 0.683255\n",
      "Epoch: 00051 loss_train: 0.3510 acc_train: 0.8904 loss_val: 0.9835 acc_val: 0.7048 time: 0.1021s\n",
      "valid current auc-roc score: 0.907691, current macro_F score: 0.692179\n",
      "Epoch: 00052 loss_train: 0.3144 acc_train: 0.9046 loss_val: 1.0021 acc_val: 0.7122 time: 0.0964s\n",
      "valid current auc-roc score: 0.924109, current macro_F score: 0.691517\n",
      "Epoch: 00053 loss_train: 0.3193 acc_train: 0.9076 loss_val: 0.9272 acc_val: 0.7159 time: 0.0948s\n",
      "valid current auc-roc score: 0.922433, current macro_F score: 0.694084\n",
      "Epoch: 00054 loss_train: 0.3067 acc_train: 0.9101 loss_val: 0.9548 acc_val: 0.7122 time: 0.1046s\n",
      "valid current auc-roc score: 0.912864, current macro_F score: 0.702975\n",
      "Epoch: 00055 loss_train: 0.3142 acc_train: 0.9113 loss_val: 0.9895 acc_val: 0.7196 time: 0.0995s\n",
      "valid current auc-roc score: 0.915706, current macro_F score: 0.681352\n",
      "Epoch: 00056 loss_train: 0.2868 acc_train: 0.9224 loss_val: 1.0038 acc_val: 0.7011 time: 0.0923s\n",
      "valid current auc-roc score: 0.920426, current macro_F score: 0.692348\n",
      "Epoch: 00057 loss_train: 0.2993 acc_train: 0.9200 loss_val: 0.9706 acc_val: 0.7196 time: 0.1063s\n",
      "valid current auc-roc score: 0.929130, current macro_F score: 0.699616\n",
      "Epoch: 00058 loss_train: 0.3149 acc_train: 0.9126 loss_val: 0.9024 acc_val: 0.7196 time: 0.1042s\n",
      "valid current auc-roc score: 0.906591, current macro_F score: 0.644290\n",
      "Epoch: 00059 loss_train: 0.3229 acc_train: 0.9107 loss_val: 1.0798 acc_val: 0.6642 time: 0.0885s\n",
      "valid current auc-roc score: 0.911672, current macro_F score: 0.656374\n",
      "Epoch: 00060 loss_train: 0.3101 acc_train: 0.9002 loss_val: 1.0542 acc_val: 0.6790 time: 0.0995s\n",
      "valid current auc-roc score: 0.910550, current macro_F score: 0.674202\n",
      "Epoch: 00061 loss_train: 0.2763 acc_train: 0.9156 loss_val: 1.0609 acc_val: 0.6827 time: 0.1002s\n",
      "valid current auc-roc score: 0.911798, current macro_F score: 0.672158\n",
      "Epoch: 00062 loss_train: 0.3075 acc_train: 0.9076 loss_val: 1.0093 acc_val: 0.7085 time: 0.0849s\n",
      "valid current auc-roc score: 0.916696, current macro_F score: 0.658491\n",
      "Epoch: 00063 loss_train: 0.2977 acc_train: 0.9150 loss_val: 1.0185 acc_val: 0.6863 time: 0.0955s\n",
      "valid current auc-roc score: 0.921540, current macro_F score: 0.693482\n",
      "Epoch: 00064 loss_train: 0.2767 acc_train: 0.9200 loss_val: 1.0007 acc_val: 0.7122 time: 0.0869s\n",
      "valid current auc-roc score: 0.921448, current macro_F score: 0.657208\n",
      "Epoch: 00065 loss_train: 0.2915 acc_train: 0.9070 loss_val: 0.9908 acc_val: 0.6827 time: 0.0862s\n",
      "valid current auc-roc score: 0.918177, current macro_F score: 0.677315\n",
      "Epoch: 00066 loss_train: 0.2860 acc_train: 0.9132 loss_val: 1.0309 acc_val: 0.7085 time: 0.0912s\n",
      "valid current auc-roc score: 0.919742, current macro_F score: 0.714177\n",
      "Epoch: 00067 loss_train: 0.2732 acc_train: 0.9187 loss_val: 0.9927 acc_val: 0.7232 time: 0.1012s\n",
      "valid current auc-roc score: 0.905920, current macro_F score: 0.714163\n",
      "Epoch: 00068 loss_train: 0.2684 acc_train: 0.9175 loss_val: 1.0864 acc_val: 0.7343 time: 0.0871s\n",
      "valid current auc-roc score: 0.927931, current macro_F score: 0.701220\n",
      "Epoch: 00069 loss_train: 0.2812 acc_train: 0.9150 loss_val: 0.9454 acc_val: 0.7159 time: 0.1029s\n",
      "valid current auc-roc score: 0.901139, current macro_F score: 0.662116\n",
      "Epoch: 00070 loss_train: 0.2602 acc_train: 0.9212 loss_val: 1.1501 acc_val: 0.6827 time: 0.0887s\n",
      "valid current auc-roc score: 0.916405, current macro_F score: 0.675130\n",
      "Epoch: 00071 loss_train: 0.2582 acc_train: 0.9218 loss_val: 1.0497 acc_val: 0.6974 time: 0.0805s\n",
      "valid current auc-roc score: 0.922786, current macro_F score: 0.682755\n",
      "Epoch: 00072 loss_train: 0.2580 acc_train: 0.9200 loss_val: 1.0055 acc_val: 0.7011 time: 0.0841s\n",
      "valid current auc-roc score: 0.913878, current macro_F score: 0.670726\n",
      "Epoch: 00073 loss_train: 0.2746 acc_train: 0.9206 loss_val: 1.0858 acc_val: 0.6937 time: 0.0862s\n",
      "valid current auc-roc score: 0.920920, current macro_F score: 0.691414\n",
      "Epoch: 00074 loss_train: 0.2442 acc_train: 0.9273 loss_val: 1.0126 acc_val: 0.7085 time: 0.0820s\n",
      "valid current auc-roc score: 0.915719, current macro_F score: 0.722430\n",
      "Epoch: 00075 loss_train: 0.2597 acc_train: 0.9163 loss_val: 1.1067 acc_val: 0.7306 time: 0.0824s\n",
      "valid current auc-roc score: 0.925509, current macro_F score: 0.678099\n",
      "Epoch: 00076 loss_train: 0.2494 acc_train: 0.9206 loss_val: 1.0064 acc_val: 0.7011 time: 0.0881s\n",
      "valid current auc-roc score: 0.917502, current macro_F score: 0.681221\n",
      "Epoch: 00077 loss_train: 0.2635 acc_train: 0.9144 loss_val: 1.1047 acc_val: 0.7048 time: 0.0796s\n",
      "valid current auc-roc score: 0.918170, current macro_F score: 0.685097\n",
      "Epoch: 00078 loss_train: 0.2571 acc_train: 0.9267 loss_val: 1.0316 acc_val: 0.7159 time: 0.0832s\n",
      "valid current auc-roc score: 0.910210, current macro_F score: 0.666418\n",
      "Epoch: 00079 loss_train: 0.2380 acc_train: 0.9292 loss_val: 1.0650 acc_val: 0.6863 time: 0.0908s\n",
      "valid current auc-roc score: 0.924704, current macro_F score: 0.674295\n",
      "Epoch: 00080 loss_train: 0.2486 acc_train: 0.9273 loss_val: 0.9701 acc_val: 0.6937 time: 0.0991s\n",
      "valid current auc-roc score: 0.922769, current macro_F score: 0.689972\n",
      "Epoch: 00081 loss_train: 0.2268 acc_train: 0.9329 loss_val: 1.0145 acc_val: 0.7232 time: 0.0969s\n",
      "valid current auc-roc score: 0.916302, current macro_F score: 0.677455\n",
      "Epoch: 00082 loss_train: 0.2402 acc_train: 0.9360 loss_val: 1.0388 acc_val: 0.6900 time: 0.0931s\n",
      "valid current auc-roc score: 0.919424, current macro_F score: 0.698218\n",
      "Epoch: 00083 loss_train: 0.2282 acc_train: 0.9310 loss_val: 1.0537 acc_val: 0.7196 time: 0.0976s\n",
      "valid current auc-roc score: 0.921838, current macro_F score: 0.688148\n",
      "Epoch: 00084 loss_train: 0.2363 acc_train: 0.9341 loss_val: 1.0523 acc_val: 0.7122 time: 0.1035s\n",
      "valid current auc-roc score: 0.920365, current macro_F score: 0.683383\n",
      "Epoch: 00085 loss_train: 0.2210 acc_train: 0.9304 loss_val: 1.0276 acc_val: 0.7048 time: 0.0994s\n",
      "valid current auc-roc score: 0.922974, current macro_F score: 0.682575\n",
      "Epoch: 00086 loss_train: 0.2178 acc_train: 0.9298 loss_val: 1.0647 acc_val: 0.7085 time: 0.0899s\n",
      "valid current auc-roc score: 0.903626, current macro_F score: 0.691172\n",
      "Epoch: 00087 loss_train: 0.2225 acc_train: 0.9360 loss_val: 1.2222 acc_val: 0.7085 time: 0.0991s\n",
      "valid current auc-roc score: 0.913811, current macro_F score: 0.663531\n",
      "Epoch: 00088 loss_train: 0.2356 acc_train: 0.9335 loss_val: 1.0794 acc_val: 0.6863 time: 0.0882s\n",
      "valid current auc-roc score: 0.910417, current macro_F score: 0.679276\n",
      "Epoch: 00089 loss_train: 0.2367 acc_train: 0.9255 loss_val: 1.1819 acc_val: 0.6974 time: 0.0875s\n",
      "valid current auc-roc score: 0.919535, current macro_F score: 0.693012\n",
      "Epoch: 00090 loss_train: 0.2228 acc_train: 0.9329 loss_val: 1.1410 acc_val: 0.7159 time: 0.0944s\n",
      "valid current auc-roc score: 0.913734, current macro_F score: 0.674859\n",
      "Epoch: 00091 loss_train: 0.2250 acc_train: 0.9397 loss_val: 1.1733 acc_val: 0.7011 time: 0.1207s\n",
      "valid current auc-roc score: 0.917869, current macro_F score: 0.668294\n",
      "Epoch: 00092 loss_train: 0.2275 acc_train: 0.9310 loss_val: 1.1546 acc_val: 0.7048 time: 0.1153s\n",
      "valid current auc-roc score: 0.922596, current macro_F score: 0.714370\n",
      "Epoch: 00093 loss_train: 0.2333 acc_train: 0.9329 loss_val: 1.1359 acc_val: 0.7343 time: 0.1257s\n",
      "valid current auc-roc score: 0.915212, current macro_F score: 0.675243\n",
      "Epoch: 00094 loss_train: 0.2571 acc_train: 0.9298 loss_val: 1.1832 acc_val: 0.7048 time: 0.1243s\n",
      "valid current auc-roc score: 0.919922, current macro_F score: 0.697538\n",
      "Epoch: 00095 loss_train: 0.2087 acc_train: 0.9347 loss_val: 1.0529 acc_val: 0.7196 time: 0.1093s\n",
      "valid current auc-roc score: 0.915833, current macro_F score: 0.681799\n",
      "Epoch: 00096 loss_train: 0.2076 acc_train: 0.9317 loss_val: 1.1061 acc_val: 0.7011 time: 0.1206s\n",
      "valid current auc-roc score: 0.913772, current macro_F score: 0.681953\n",
      "Epoch: 00097 loss_train: 0.2303 acc_train: 0.9366 loss_val: 1.1036 acc_val: 0.7085 time: 0.1102s\n",
      "valid current auc-roc score: 0.909841, current macro_F score: 0.694992\n",
      "Epoch: 00098 loss_train: 0.2266 acc_train: 0.9317 loss_val: 1.1855 acc_val: 0.7159 time: 0.1084s\n",
      "valid current auc-roc score: 0.908898, current macro_F score: 0.666337\n",
      "Epoch: 00099 loss_train: 0.2108 acc_train: 0.9390 loss_val: 1.1725 acc_val: 0.6863 time: 0.1245s\n",
      "valid current auc-roc score: 0.902200, current macro_F score: 0.700132\n",
      "Epoch: 00100 loss_train: 0.2140 acc_train: 0.9366 loss_val: 1.1564 acc_val: 0.7196 time: 0.1153s\n",
      "valid current auc-roc score: 0.916870, current macro_F score: 0.663646\n",
      "Epoch: 00101 loss_train: 0.2122 acc_train: 0.9366 loss_val: 1.0768 acc_val: 0.6790 time: 0.1022s\n",
      "valid current auc-roc score: 0.928087, current macro_F score: 0.695215\n",
      "Epoch: 00102 loss_train: 0.2163 acc_train: 0.9433 loss_val: 1.0846 acc_val: 0.7159 time: 0.1050s\n",
      "valid current auc-roc score: 0.913845, current macro_F score: 0.695683\n",
      "Epoch: 00103 loss_train: 0.2150 acc_train: 0.9347 loss_val: 1.1552 acc_val: 0.7159 time: 0.1134s\n",
      "valid current auc-roc score: 0.913838, current macro_F score: 0.670920\n",
      "Epoch: 00104 loss_train: 0.2044 acc_train: 0.9446 loss_val: 1.1673 acc_val: 0.6974 time: 0.0974s\n",
      "valid current auc-roc score: 0.921772, current macro_F score: 0.684503\n",
      "Epoch: 00105 loss_train: 0.2050 acc_train: 0.9384 loss_val: 1.0855 acc_val: 0.7085 time: 0.0909s\n",
      "valid current auc-roc score: 0.913768, current macro_F score: 0.684621\n",
      "Epoch: 00106 loss_train: 0.2098 acc_train: 0.9440 loss_val: 1.0906 acc_val: 0.7085 time: 0.0941s\n",
      "valid current auc-roc score: 0.910191, current macro_F score: 0.690100\n",
      "Epoch: 00107 loss_train: 0.2155 acc_train: 0.9409 loss_val: 1.2498 acc_val: 0.7085 time: 0.0895s\n",
      "valid current auc-roc score: 0.907445, current macro_F score: 0.704049\n",
      "Epoch: 00108 loss_train: 0.2205 acc_train: 0.9341 loss_val: 1.3117 acc_val: 0.7232 time: 0.0915s\n",
      "valid current auc-roc score: 0.906395, current macro_F score: 0.698484\n",
      "Epoch: 00109 loss_train: 0.2064 acc_train: 0.9360 loss_val: 1.3537 acc_val: 0.7122 time: 0.1138s\n",
      "valid current auc-roc score: 0.900272, current macro_F score: 0.661386\n",
      "Epoch: 00110 loss_train: 0.2068 acc_train: 0.9329 loss_val: 1.3897 acc_val: 0.6790 time: 0.1152s\n",
      "valid current auc-roc score: 0.901169, current macro_F score: 0.694003\n",
      "Epoch: 00111 loss_train: 0.2164 acc_train: 0.9347 loss_val: 1.3066 acc_val: 0.7048 time: 0.1085s\n",
      "valid current auc-roc score: 0.916136, current macro_F score: 0.689683\n",
      "Epoch: 00112 loss_train: 0.2009 acc_train: 0.9446 loss_val: 1.2015 acc_val: 0.7085 time: 0.1072s\n",
      "valid current auc-roc score: 0.915743, current macro_F score: 0.691482\n",
      "Epoch: 00113 loss_train: 0.2034 acc_train: 0.9384 loss_val: 1.2132 acc_val: 0.7011 time: 0.1048s\n",
      "valid current auc-roc score: 0.917523, current macro_F score: 0.711264\n",
      "Epoch: 00114 loss_train: 0.2178 acc_train: 0.9433 loss_val: 1.2166 acc_val: 0.7269 time: 0.0974s\n",
      "valid current auc-roc score: 0.922007, current macro_F score: 0.661104\n",
      "Epoch: 00115 loss_train: 0.2032 acc_train: 0.9384 loss_val: 1.1717 acc_val: 0.6790 time: 0.0988s\n",
      "valid current auc-roc score: 0.919074, current macro_F score: 0.657745\n",
      "Epoch: 00116 loss_train: 0.2072 acc_train: 0.9390 loss_val: 1.0970 acc_val: 0.6863 time: 0.1023s\n",
      "valid current auc-roc score: 0.917592, current macro_F score: 0.713183\n",
      "Epoch: 00117 loss_train: 0.1919 acc_train: 0.9446 loss_val: 1.2059 acc_val: 0.7159 time: 0.0989s\n",
      "valid current auc-roc score: 0.905923, current macro_F score: 0.664575\n",
      "Epoch: 00118 loss_train: 0.1916 acc_train: 0.9433 loss_val: 1.2422 acc_val: 0.6827 time: 0.1212s\n",
      "valid current auc-roc score: 0.910819, current macro_F score: 0.677749\n",
      "Epoch: 00119 loss_train: 0.1955 acc_train: 0.9397 loss_val: 1.1316 acc_val: 0.6974 time: 0.1257s\n",
      "valid current auc-roc score: 0.917576, current macro_F score: 0.693526\n",
      "Epoch: 00120 loss_train: 0.1912 acc_train: 0.9470 loss_val: 1.1764 acc_val: 0.7048 time: 0.0981s\n",
      "valid current auc-roc score: 0.914128, current macro_F score: 0.699040\n",
      "Epoch: 00121 loss_train: 0.2187 acc_train: 0.9329 loss_val: 1.2748 acc_val: 0.7232 time: 0.0933s\n",
      "valid current auc-roc score: 0.904680, current macro_F score: 0.697929\n",
      "Epoch: 00122 loss_train: 0.1825 acc_train: 0.9507 loss_val: 1.3119 acc_val: 0.7159 time: 0.0941s\n",
      "valid current auc-roc score: 0.920800, current macro_F score: 0.670791\n",
      "Epoch: 00123 loss_train: 0.1853 acc_train: 0.9446 loss_val: 1.1795 acc_val: 0.7011 time: 0.1024s\n",
      "valid current auc-roc score: 0.896719, current macro_F score: 0.654015\n",
      "Epoch: 00124 loss_train: 0.1792 acc_train: 0.9433 loss_val: 1.3569 acc_val: 0.6863 time: 0.0919s\n",
      "valid current auc-roc score: 0.917673, current macro_F score: 0.678237\n",
      "Epoch: 00125 loss_train: 0.2144 acc_train: 0.9347 loss_val: 1.1320 acc_val: 0.7048 time: 0.0910s\n",
      "valid current auc-roc score: 0.899728, current macro_F score: 0.657155\n",
      "Epoch: 00126 loss_train: 0.1995 acc_train: 0.9378 loss_val: 1.3242 acc_val: 0.6900 time: 0.0874s\n",
      "valid current auc-roc score: 0.909907, current macro_F score: 0.700477\n",
      "Epoch: 00127 loss_train: 0.1859 acc_train: 0.9403 loss_val: 1.2041 acc_val: 0.7232 time: 0.0869s\n",
      "valid current auc-roc score: 0.915773, current macro_F score: 0.702604\n",
      "Epoch: 00128 loss_train: 0.1872 acc_train: 0.9440 loss_val: 1.2268 acc_val: 0.7269 time: 0.0950s\n",
      "valid current auc-roc score: 0.922393, current macro_F score: 0.703513\n",
      "Epoch: 00129 loss_train: 0.1858 acc_train: 0.9403 loss_val: 1.1407 acc_val: 0.7306 time: 0.0999s\n",
      "valid current auc-roc score: 0.912902, current macro_F score: 0.693508\n",
      "Epoch: 00130 loss_train: 0.1847 acc_train: 0.9501 loss_val: 1.2635 acc_val: 0.7122 time: 0.1032s\n",
      "valid current auc-roc score: 0.915325, current macro_F score: 0.692239\n",
      "Epoch: 00131 loss_train: 0.1982 acc_train: 0.9397 loss_val: 1.2365 acc_val: 0.7159 time: 0.0873s\n",
      "valid current auc-roc score: 0.909133, current macro_F score: 0.670553\n",
      "Epoch: 00132 loss_train: 0.2056 acc_train: 0.9409 loss_val: 1.2837 acc_val: 0.6900 time: 0.0933s\n",
      "valid current auc-roc score: 0.912733, current macro_F score: 0.670406\n",
      "Epoch: 00133 loss_train: 0.1843 acc_train: 0.9470 loss_val: 1.1999 acc_val: 0.6900 time: 0.0816s\n",
      "valid current auc-roc score: 0.921853, current macro_F score: 0.701385\n",
      "Epoch: 00134 loss_train: 0.2109 acc_train: 0.9378 loss_val: 1.1680 acc_val: 0.7122 time: 0.0854s\n",
      "valid current auc-roc score: 0.901826, current macro_F score: 0.696880\n",
      "Epoch: 00135 loss_train: 0.1760 acc_train: 0.9483 loss_val: 1.2936 acc_val: 0.7122 time: 0.0935s\n",
      "valid current auc-roc score: 0.915425, current macro_F score: 0.734634\n",
      "Epoch: 00136 loss_train: 0.1859 acc_train: 0.9427 loss_val: 1.1364 acc_val: 0.7528 time: 0.0997s\n",
      "valid current auc-roc score: 0.910532, current macro_F score: 0.652602\n",
      "Epoch: 00137 loss_train: 0.1754 acc_train: 0.9433 loss_val: 1.2511 acc_val: 0.6863 time: 0.0920s\n",
      "valid current auc-roc score: 0.910702, current macro_F score: 0.698092\n",
      "Epoch: 00138 loss_train: 0.1796 acc_train: 0.9464 loss_val: 1.2479 acc_val: 0.7269 time: 0.0853s\n",
      "valid current auc-roc score: 0.920046, current macro_F score: 0.690862\n",
      "Epoch: 00139 loss_train: 0.1638 acc_train: 0.9538 loss_val: 1.1576 acc_val: 0.7159 time: 0.0952s\n",
      "valid current auc-roc score: 0.913354, current macro_F score: 0.707340\n",
      "Epoch: 00140 loss_train: 0.2055 acc_train: 0.9409 loss_val: 1.2001 acc_val: 0.7343 time: 0.0856s\n",
      "valid current auc-roc score: 0.909722, current macro_F score: 0.693719\n",
      "Epoch: 00141 loss_train: 0.1763 acc_train: 0.9477 loss_val: 1.1913 acc_val: 0.7122 time: 0.0999s\n",
      "valid current auc-roc score: 0.913985, current macro_F score: 0.715746\n",
      "Epoch: 00142 loss_train: 0.1832 acc_train: 0.9415 loss_val: 1.1849 acc_val: 0.7306 time: 0.0951s\n",
      "valid current auc-roc score: 0.920831, current macro_F score: 0.739102\n",
      "Epoch: 00143 loss_train: 0.1761 acc_train: 0.9470 loss_val: 1.1531 acc_val: 0.7491 time: 0.0880s\n",
      "valid current auc-roc score: 0.913302, current macro_F score: 0.694079\n",
      "Epoch: 00144 loss_train: 0.1737 acc_train: 0.9526 loss_val: 1.2046 acc_val: 0.7159 time: 0.0823s\n",
      "valid current auc-roc score: 0.913797, current macro_F score: 0.713288\n",
      "Epoch: 00145 loss_train: 0.1599 acc_train: 0.9532 loss_val: 1.2153 acc_val: 0.7232 time: 0.0869s\n",
      "valid current auc-roc score: 0.908758, current macro_F score: 0.700509\n",
      "Epoch: 00146 loss_train: 0.1638 acc_train: 0.9526 loss_val: 1.2483 acc_val: 0.7196 time: 0.0932s\n",
      "valid current auc-roc score: 0.909893, current macro_F score: 0.700226\n",
      "Epoch: 00147 loss_train: 0.1710 acc_train: 0.9458 loss_val: 1.1870 acc_val: 0.7196 time: 0.1088s\n",
      "valid current auc-roc score: 0.914594, current macro_F score: 0.687346\n",
      "Epoch: 00148 loss_train: 0.1634 acc_train: 0.9532 loss_val: 1.2026 acc_val: 0.7048 time: 0.0983s\n",
      "valid current auc-roc score: 0.917465, current macro_F score: 0.671358\n",
      "Epoch: 00149 loss_train: 0.1580 acc_train: 0.9557 loss_val: 1.2054 acc_val: 0.6974 time: 0.0861s\n",
      "valid current auc-roc score: 0.905074, current macro_F score: 0.712626\n",
      "Epoch: 00150 loss_train: 0.1616 acc_train: 0.9470 loss_val: 1.2833 acc_val: 0.7306 time: 0.1070s\n",
      "valid current auc-roc score: 0.909951, current macro_F score: 0.715793\n",
      "Epoch: 00151 loss_train: 0.1690 acc_train: 0.9489 loss_val: 1.2638 acc_val: 0.7306 time: 0.1124s\n",
      "valid current auc-roc score: 0.925571, current macro_F score: 0.691573\n",
      "Epoch: 00152 loss_train: 0.1663 acc_train: 0.9464 loss_val: 1.1643 acc_val: 0.7196 time: 0.1071s\n",
      "valid current auc-roc score: 0.918422, current macro_F score: 0.722119\n",
      "Epoch: 00153 loss_train: 0.1759 acc_train: 0.9495 loss_val: 1.2234 acc_val: 0.7417 time: 0.0970s\n",
      "valid current auc-roc score: 0.916209, current macro_F score: 0.685538\n",
      "Epoch: 00154 loss_train: 0.1516 acc_train: 0.9514 loss_val: 1.2976 acc_val: 0.7011 time: 0.0944s\n",
      "valid current auc-roc score: 0.904246, current macro_F score: 0.690042\n",
      "Epoch: 00155 loss_train: 0.1734 acc_train: 0.9433 loss_val: 1.2802 acc_val: 0.7196 time: 0.0927s\n",
      "valid current auc-roc score: 0.920729, current macro_F score: 0.720839\n",
      "Epoch: 00156 loss_train: 0.1578 acc_train: 0.9489 loss_val: 1.1532 acc_val: 0.7380 time: 0.0948s\n",
      "valid current auc-roc score: 0.913111, current macro_F score: 0.715839\n",
      "Epoch: 00157 loss_train: 0.2273 acc_train: 0.9390 loss_val: 1.2853 acc_val: 0.7343 time: 0.0943s\n",
      "valid current auc-roc score: 0.906921, current macro_F score: 0.713465\n",
      "Epoch: 00158 loss_train: 0.2202 acc_train: 0.9317 loss_val: 1.3443 acc_val: 0.7380 time: 0.0912s\n",
      "valid current auc-roc score: 0.923115, current macro_F score: 0.691887\n",
      "Epoch: 00159 loss_train: 0.1674 acc_train: 0.9483 loss_val: 1.1826 acc_val: 0.7048 time: 0.0949s\n",
      "valid current auc-roc score: 0.909571, current macro_F score: 0.707646\n",
      "Epoch: 00160 loss_train: 0.1786 acc_train: 0.9440 loss_val: 1.3104 acc_val: 0.7343 time: 0.1072s\n",
      "valid current auc-roc score: 0.906773, current macro_F score: 0.667102\n",
      "Epoch: 00161 loss_train: 0.3655 acc_train: 0.9273 loss_val: 1.3469 acc_val: 0.6900 time: 0.0992s\n",
      "valid current auc-roc score: 0.909447, current macro_F score: 0.717086\n",
      "Epoch: 00162 loss_train: 0.2038 acc_train: 0.9390 loss_val: 1.2841 acc_val: 0.7306 time: 0.0947s\n",
      "valid current auc-roc score: 0.916951, current macro_F score: 0.659136\n",
      "Epoch: 00163 loss_train: 0.2254 acc_train: 0.9317 loss_val: 1.2492 acc_val: 0.6790 time: 0.0911s\n",
      "valid current auc-roc score: 0.925721, current macro_F score: 0.657872\n",
      "Epoch: 00164 loss_train: 0.1704 acc_train: 0.9433 loss_val: 1.0910 acc_val: 0.6937 time: 0.0905s\n",
      "valid current auc-roc score: 0.910142, current macro_F score: 0.685790\n",
      "Epoch: 00165 loss_train: 0.2198 acc_train: 0.9298 loss_val: 1.3718 acc_val: 0.7159 time: 0.0881s\n",
      "valid current auc-roc score: 0.915348, current macro_F score: 0.675932\n",
      "Epoch: 00166 loss_train: 0.3063 acc_train: 0.9317 loss_val: 1.3818 acc_val: 0.7048 time: 0.0832s\n",
      "valid current auc-roc score: 0.912987, current macro_F score: 0.687845\n",
      "Epoch: 00167 loss_train: 0.1966 acc_train: 0.9409 loss_val: 1.3229 acc_val: 0.7085 time: 0.0982s\n",
      "valid current auc-roc score: 0.922071, current macro_F score: 0.697488\n",
      "Epoch: 00168 loss_train: 0.1831 acc_train: 0.9452 loss_val: 1.1532 acc_val: 0.7122 time: 0.0921s\n",
      "valid current auc-roc score: 0.917582, current macro_F score: 0.682691\n",
      "Epoch: 00169 loss_train: 0.1791 acc_train: 0.9470 loss_val: 1.1534 acc_val: 0.6937 time: 0.0899s\n",
      "valid current auc-roc score: 0.914746, current macro_F score: 0.707650\n",
      "Epoch: 00170 loss_train: 0.1878 acc_train: 0.9489 loss_val: 1.1506 acc_val: 0.7196 time: 0.0854s\n",
      "valid current auc-roc score: 0.916324, current macro_F score: 0.684200\n",
      "Epoch: 00171 loss_train: 0.2653 acc_train: 0.9403 loss_val: 1.2622 acc_val: 0.7122 time: 0.0951s\n",
      "valid current auc-roc score: 0.912913, current macro_F score: 0.721487\n",
      "Epoch: 00172 loss_train: 0.2510 acc_train: 0.9372 loss_val: 1.2349 acc_val: 0.7380 time: 0.0824s\n",
      "valid current auc-roc score: 0.910279, current macro_F score: 0.689237\n",
      "Epoch: 00173 loss_train: 0.2180 acc_train: 0.9403 loss_val: 1.3123 acc_val: 0.7122 time: 0.0855s\n",
      "valid current auc-roc score: 0.914884, current macro_F score: 0.713469\n",
      "Epoch: 00174 loss_train: 0.2048 acc_train: 0.9433 loss_val: 1.1491 acc_val: 0.7454 time: 0.0814s\n",
      "valid current auc-roc score: 0.920220, current macro_F score: 0.712084\n",
      "Epoch: 00175 loss_train: 0.1871 acc_train: 0.9514 loss_val: 1.1749 acc_val: 0.7343 time: 0.0778s\n",
      "valid current auc-roc score: 0.912994, current macro_F score: 0.696781\n",
      "Epoch: 00176 loss_train: 0.1767 acc_train: 0.9489 loss_val: 1.2069 acc_val: 0.7269 time: 0.0831s\n",
      "valid current auc-roc score: 0.919972, current macro_F score: 0.703953\n",
      "Epoch: 00177 loss_train: 0.1689 acc_train: 0.9526 loss_val: 1.1847 acc_val: 0.7232 time: 0.0866s\n",
      "valid current auc-roc score: 0.919279, current macro_F score: 0.687772\n",
      "Epoch: 00178 loss_train: 0.1857 acc_train: 0.9427 loss_val: 1.1770 acc_val: 0.7048 time: 0.0915s\n",
      "valid current auc-roc score: 0.915324, current macro_F score: 0.688823\n",
      "Epoch: 00179 loss_train: 0.1807 acc_train: 0.9458 loss_val: 1.1903 acc_val: 0.7085 time: 0.0955s\n",
      "valid current auc-roc score: 0.911131, current macro_F score: 0.700608\n",
      "Epoch: 00180 loss_train: 0.1757 acc_train: 0.9421 loss_val: 1.2001 acc_val: 0.7343 time: 0.0893s\n",
      "valid current auc-roc score: 0.912083, current macro_F score: 0.686103\n",
      "Epoch: 00181 loss_train: 0.1714 acc_train: 0.9520 loss_val: 1.2745 acc_val: 0.7159 time: 0.0864s\n",
      "valid current auc-roc score: 0.919037, current macro_F score: 0.698300\n",
      "Epoch: 00182 loss_train: 0.1780 acc_train: 0.9452 loss_val: 1.2385 acc_val: 0.7232 time: 0.0877s\n",
      "valid current auc-roc score: 0.904577, current macro_F score: 0.679043\n",
      "Epoch: 00183 loss_train: 0.1780 acc_train: 0.9458 loss_val: 1.4214 acc_val: 0.7159 time: 0.0877s\n",
      "valid current auc-roc score: 0.904363, current macro_F score: 0.665308\n",
      "Epoch: 00184 loss_train: 0.1691 acc_train: 0.9446 loss_val: 1.4022 acc_val: 0.6937 time: 0.0823s\n",
      "valid current auc-roc score: 0.913389, current macro_F score: 0.699466\n",
      "Epoch: 00185 loss_train: 0.1550 acc_train: 0.9557 loss_val: 1.2727 acc_val: 0.7196 time: 0.0916s\n",
      "valid current auc-roc score: 0.909503, current macro_F score: 0.685436\n",
      "Epoch: 00186 loss_train: 0.1770 acc_train: 0.9489 loss_val: 1.3096 acc_val: 0.7011 time: 0.0859s\n",
      "valid current auc-roc score: 0.915585, current macro_F score: 0.710063\n",
      "Epoch: 00187 loss_train: 0.1574 acc_train: 0.9514 loss_val: 1.2975 acc_val: 0.7269 time: 0.0831s\n",
      "valid current auc-roc score: 0.915201, current macro_F score: 0.689275\n",
      "Epoch: 00188 loss_train: 0.1899 acc_train: 0.9421 loss_val: 1.4164 acc_val: 0.7048 time: 0.0821s\n",
      "valid current auc-roc score: 0.913205, current macro_F score: 0.671089\n",
      "Epoch: 00189 loss_train: 0.1688 acc_train: 0.9501 loss_val: 1.2571 acc_val: 0.7048 time: 0.0854s\n",
      "valid current auc-roc score: 0.909215, current macro_F score: 0.680467\n",
      "Epoch: 00190 loss_train: 0.1680 acc_train: 0.9489 loss_val: 1.3224 acc_val: 0.7085 time: 0.0815s\n",
      "valid current auc-roc score: 0.913045, current macro_F score: 0.678715\n",
      "Epoch: 00191 loss_train: 0.1772 acc_train: 0.9514 loss_val: 1.2213 acc_val: 0.7159 time: 0.0852s\n",
      "valid current auc-roc score: 0.912776, current macro_F score: 0.684152\n",
      "Epoch: 00192 loss_train: 0.1739 acc_train: 0.9452 loss_val: 1.2559 acc_val: 0.7085 time: 0.0861s\n",
      "valid current auc-roc score: 0.898338, current macro_F score: 0.689908\n",
      "Epoch: 00193 loss_train: 0.1806 acc_train: 0.9440 loss_val: 1.4939 acc_val: 0.7122 time: 0.0894s\n",
      "valid current auc-roc score: 0.909972, current macro_F score: 0.731932\n",
      "Epoch: 00194 loss_train: 0.1929 acc_train: 0.9403 loss_val: 1.2842 acc_val: 0.7417 time: 0.1044s\n",
      "valid current auc-roc score: 0.910276, current macro_F score: 0.659327\n",
      "Epoch: 00195 loss_train: 0.1538 acc_train: 0.9594 loss_val: 1.3070 acc_val: 0.6863 time: 0.0932s\n",
      "valid current auc-roc score: 0.905954, current macro_F score: 0.670455\n",
      "Epoch: 00196 loss_train: 0.1752 acc_train: 0.9470 loss_val: 1.4094 acc_val: 0.6900 time: 0.0888s\n",
      "valid current auc-roc score: 0.902571, current macro_F score: 0.670872\n",
      "Epoch: 00197 loss_train: 0.2061 acc_train: 0.9372 loss_val: 1.4034 acc_val: 0.6974 time: 0.0986s\n",
      "valid current auc-roc score: 0.901674, current macro_F score: 0.678763\n",
      "Epoch: 00198 loss_train: 0.1672 acc_train: 0.9544 loss_val: 1.3986 acc_val: 0.6974 time: 0.1012s\n",
      "valid current auc-roc score: 0.914606, current macro_F score: 0.697125\n",
      "Epoch: 00199 loss_train: 0.1472 acc_train: 0.9569 loss_val: 1.2431 acc_val: 0.7159 time: 0.0958s\n",
      "valid current auc-roc score: 0.920080, current macro_F score: 0.698105\n",
      "Epoch: 00200 loss_train: 0.1589 acc_train: 0.9489 loss_val: 1.1385 acc_val: 0.7232 time: 0.1138s\n",
      "valid current auc-roc score: 0.912711, current macro_F score: 0.686946\n",
      "Epoch: 00201 loss_train: 0.1639 acc_train: 0.9452 loss_val: 1.3877 acc_val: 0.7011 time: 0.1068s\n",
      "valid current auc-roc score: 0.917024, current macro_F score: 0.695907\n",
      "Epoch: 00202 loss_train: 0.1770 acc_train: 0.9415 loss_val: 1.3069 acc_val: 0.7159 time: 0.1000s\n",
      "valid current auc-roc score: 0.912710, current macro_F score: 0.683074\n",
      "Epoch: 00203 loss_train: 0.1635 acc_train: 0.9446 loss_val: 1.3321 acc_val: 0.7159 time: 0.0991s\n",
      "valid current auc-roc score: 0.923753, current macro_F score: 0.659126\n",
      "Epoch: 00204 loss_train: 0.1587 acc_train: 0.9483 loss_val: 1.1792 acc_val: 0.6900 time: 0.1127s\n",
      "valid current auc-roc score: 0.902672, current macro_F score: 0.680757\n",
      "Epoch: 00205 loss_train: 0.1744 acc_train: 0.9452 loss_val: 1.3846 acc_val: 0.7011 time: 0.0892s\n",
      "valid current auc-roc score: 0.911119, current macro_F score: 0.685749\n",
      "Epoch: 00206 loss_train: 0.1667 acc_train: 0.9526 loss_val: 1.4262 acc_val: 0.7122 time: 0.0972s\n",
      "valid current auc-roc score: 0.904834, current macro_F score: 0.700775\n",
      "Epoch: 00207 loss_train: 0.1504 acc_train: 0.9470 loss_val: 1.4067 acc_val: 0.7269 time: 0.0854s\n",
      "valid current auc-roc score: 0.902259, current macro_F score: 0.702742\n",
      "Epoch: 00208 loss_train: 0.1504 acc_train: 0.9575 loss_val: 1.4354 acc_val: 0.7232 time: 0.0975s\n",
      "valid current auc-roc score: 0.925296, current macro_F score: 0.707197\n",
      "Epoch: 00209 loss_train: 0.1604 acc_train: 0.9538 loss_val: 1.1580 acc_val: 0.7269 time: 0.0890s\n",
      "valid current auc-roc score: 0.907576, current macro_F score: 0.703308\n",
      "Epoch: 00210 loss_train: 0.1643 acc_train: 0.9477 loss_val: 1.3795 acc_val: 0.7232 time: 0.0905s\n",
      "valid current auc-roc score: 0.916647, current macro_F score: 0.700122\n",
      "Epoch: 00211 loss_train: 0.1498 acc_train: 0.9477 loss_val: 1.2560 acc_val: 0.7269 time: 0.1064s\n",
      "valid current auc-roc score: 0.917162, current macro_F score: 0.727505\n",
      "Epoch: 00212 loss_train: 0.1568 acc_train: 0.9544 loss_val: 1.2943 acc_val: 0.7380 time: 0.0907s\n",
      "valid current auc-roc score: 0.906767, current macro_F score: 0.697290\n",
      "Epoch: 00213 loss_train: 0.1546 acc_train: 0.9550 loss_val: 1.4669 acc_val: 0.7085 time: 0.0808s\n",
      "valid current auc-roc score: 0.915906, current macro_F score: 0.662956\n",
      "Epoch: 00214 loss_train: 0.1470 acc_train: 0.9544 loss_val: 1.2475 acc_val: 0.6937 time: 0.0967s\n",
      "valid current auc-roc score: 0.926095, current macro_F score: 0.726811\n",
      "Epoch: 00215 loss_train: 0.1773 acc_train: 0.9514 loss_val: 1.2201 acc_val: 0.7417 time: 0.1095s\n",
      "valid current auc-roc score: 0.917257, current macro_F score: 0.686918\n",
      "Epoch: 00216 loss_train: 0.1507 acc_train: 0.9507 loss_val: 1.2411 acc_val: 0.7196 time: 0.0823s\n",
      "valid current auc-roc score: 0.908476, current macro_F score: 0.698510\n",
      "Epoch: 00217 loss_train: 0.1539 acc_train: 0.9600 loss_val: 1.3487 acc_val: 0.7196 time: 0.0984s\n",
      "valid current auc-roc score: 0.910881, current macro_F score: 0.690983\n",
      "Epoch: 00218 loss_train: 0.1480 acc_train: 0.9581 loss_val: 1.4018 acc_val: 0.7122 time: 0.0885s\n",
      "valid current auc-roc score: 0.907898, current macro_F score: 0.685187\n",
      "Epoch: 00219 loss_train: 0.1798 acc_train: 0.9477 loss_val: 1.3955 acc_val: 0.7048 time: 0.0820s\n",
      "valid current auc-roc score: 0.904898, current macro_F score: 0.685497\n",
      "Epoch: 00220 loss_train: 0.1553 acc_train: 0.9563 loss_val: 1.4273 acc_val: 0.7085 time: 0.0906s\n",
      "valid current auc-roc score: 0.909121, current macro_F score: 0.700861\n",
      "Epoch: 00221 loss_train: 0.1573 acc_train: 0.9526 loss_val: 1.3575 acc_val: 0.7159 time: 0.0975s\n",
      "valid current auc-roc score: 0.906579, current macro_F score: 0.704787\n",
      "Epoch: 00222 loss_train: 0.1461 acc_train: 0.9612 loss_val: 1.3164 acc_val: 0.7232 time: 0.1152s\n",
      "valid current auc-roc score: 0.902864, current macro_F score: 0.669197\n",
      "Epoch: 00223 loss_train: 0.1701 acc_train: 0.9477 loss_val: 1.3232 acc_val: 0.6937 time: 0.0986s\n",
      "valid current auc-roc score: 0.912572, current macro_F score: 0.732571\n",
      "Epoch: 00224 loss_train: 0.1586 acc_train: 0.9477 loss_val: 1.2211 acc_val: 0.7454 time: 0.0947s\n",
      "valid current auc-roc score: 0.913188, current macro_F score: 0.722359\n",
      "Epoch: 00225 loss_train: 0.1627 acc_train: 0.9514 loss_val: 1.3142 acc_val: 0.7306 time: 0.1138s\n",
      "valid current auc-roc score: 0.912701, current macro_F score: 0.703914\n",
      "Epoch: 00226 loss_train: 0.1741 acc_train: 0.9470 loss_val: 1.3979 acc_val: 0.7269 time: 0.0872s\n",
      "valid current auc-roc score: 0.918867, current macro_F score: 0.698916\n",
      "Epoch: 00227 loss_train: 0.1467 acc_train: 0.9526 loss_val: 1.2569 acc_val: 0.7159 time: 0.0927s\n",
      "valid current auc-roc score: 0.899143, current macro_F score: 0.671816\n",
      "Epoch: 00228 loss_train: 0.1498 acc_train: 0.9495 loss_val: 1.4465 acc_val: 0.6974 time: 0.0887s\n",
      "valid current auc-roc score: 0.911018, current macro_F score: 0.690585\n",
      "Epoch: 00229 loss_train: 0.1823 acc_train: 0.9366 loss_val: 1.2531 acc_val: 0.7085 time: 0.0941s\n",
      "valid current auc-roc score: 0.905359, current macro_F score: 0.667324\n",
      "Epoch: 00230 loss_train: 0.1864 acc_train: 0.9489 loss_val: 1.3331 acc_val: 0.6900 time: 0.0860s\n",
      "valid current auc-roc score: 0.920186, current macro_F score: 0.701939\n",
      "Epoch: 00231 loss_train: 0.1944 acc_train: 0.9440 loss_val: 1.2693 acc_val: 0.7196 time: 0.0896s\n",
      "valid current auc-roc score: 0.921306, current macro_F score: 0.702301\n",
      "Epoch: 00232 loss_train: 0.1591 acc_train: 0.9587 loss_val: 1.1635 acc_val: 0.7343 time: 0.0855s\n",
      "valid current auc-roc score: 0.907055, current macro_F score: 0.703997\n",
      "Epoch: 00233 loss_train: 0.1505 acc_train: 0.9532 loss_val: 1.2917 acc_val: 0.7196 time: 0.0853s\n",
      "valid current auc-roc score: 0.914568, current macro_F score: 0.682770\n",
      "Epoch: 00234 loss_train: 0.1695 acc_train: 0.9403 loss_val: 1.3196 acc_val: 0.7122 time: 0.0876s\n",
      "valid current auc-roc score: 0.911943, current macro_F score: 0.701478\n",
      "Epoch: 00235 loss_train: 0.1654 acc_train: 0.9544 loss_val: 1.3364 acc_val: 0.7232 time: 0.0898s\n",
      "valid current auc-roc score: 0.913243, current macro_F score: 0.684203\n",
      "Epoch: 00236 loss_train: 0.1525 acc_train: 0.9526 loss_val: 1.3361 acc_val: 0.7159 time: 0.1100s\n",
      "valid current auc-roc score: 0.914862, current macro_F score: 0.683441\n",
      "Epoch: 00237 loss_train: 0.1587 acc_train: 0.9507 loss_val: 1.2522 acc_val: 0.7159 time: 0.1044s\n",
      "valid current auc-roc score: 0.912955, current macro_F score: 0.710588\n",
      "Epoch: 00238 loss_train: 0.1577 acc_train: 0.9526 loss_val: 1.2608 acc_val: 0.7159 time: 0.0951s\n",
      "valid current auc-roc score: 0.906361, current macro_F score: 0.690196\n",
      "Epoch: 00239 loss_train: 0.1523 acc_train: 0.9594 loss_val: 1.3212 acc_val: 0.7159 time: 0.0842s\n",
      "valid current auc-roc score: 0.922532, current macro_F score: 0.672502\n",
      "Epoch: 00240 loss_train: 0.1986 acc_train: 0.9446 loss_val: 1.1871 acc_val: 0.6974 time: 0.1008s\n",
      "valid current auc-roc score: 0.919729, current macro_F score: 0.705976\n",
      "Epoch: 00241 loss_train: 0.1843 acc_train: 0.9489 loss_val: 1.2091 acc_val: 0.7269 time: 0.1076s\n",
      "valid current auc-roc score: 0.916238, current macro_F score: 0.688891\n",
      "Epoch: 00242 loss_train: 0.1646 acc_train: 0.9489 loss_val: 1.2625 acc_val: 0.7085 time: 0.1085s\n",
      "valid current auc-roc score: 0.911472, current macro_F score: 0.702082\n",
      "Epoch: 00243 loss_train: 0.1964 acc_train: 0.9366 loss_val: 1.3039 acc_val: 0.7122 time: 0.1082s\n",
      "valid current auc-roc score: 0.927645, current macro_F score: 0.712812\n",
      "Epoch: 00244 loss_train: 0.1832 acc_train: 0.9483 loss_val: 1.1469 acc_val: 0.7380 time: 0.0973s\n",
      "valid current auc-roc score: 0.915136, current macro_F score: 0.683731\n",
      "Epoch: 00245 loss_train: 0.1592 acc_train: 0.9520 loss_val: 1.2662 acc_val: 0.7011 time: 0.1093s\n",
      "valid current auc-roc score: 0.907999, current macro_F score: 0.703314\n",
      "Epoch: 00246 loss_train: 0.1465 acc_train: 0.9538 loss_val: 1.3338 acc_val: 0.7269 time: 0.1107s\n",
      "valid current auc-roc score: 0.903939, current macro_F score: 0.702577\n",
      "Epoch: 00247 loss_train: 0.1797 acc_train: 0.9446 loss_val: 1.4618 acc_val: 0.7159 time: 0.0954s\n",
      "valid current auc-roc score: 0.907022, current macro_F score: 0.686222\n",
      "Epoch: 00248 loss_train: 0.1696 acc_train: 0.9526 loss_val: 1.2456 acc_val: 0.7269 time: 0.1134s\n",
      "valid current auc-roc score: 0.922091, current macro_F score: 0.708993\n",
      "Epoch: 00249 loss_train: 0.1677 acc_train: 0.9470 loss_val: 1.2211 acc_val: 0.7306 time: 0.0862s\n",
      "valid current auc-roc score: 0.918136, current macro_F score: 0.681084\n",
      "Epoch: 00250 loss_train: 0.1382 acc_train: 0.9600 loss_val: 1.3369 acc_val: 0.7011 time: 0.0882s\n",
      "valid current auc-roc score: 0.923089, current macro_F score: 0.698926\n",
      "Epoch: 00251 loss_train: 0.1430 acc_train: 0.9544 loss_val: 1.2245 acc_val: 0.7159 time: 0.0892s\n",
      "valid current auc-roc score: 0.930454, current macro_F score: 0.713753\n",
      "Epoch: 00252 loss_train: 0.1612 acc_train: 0.9550 loss_val: 1.1074 acc_val: 0.7306 time: 0.0959s\n",
      "valid current auc-roc score: 0.915485, current macro_F score: 0.685276\n",
      "Epoch: 00253 loss_train: 0.1339 acc_train: 0.9600 loss_val: 1.2683 acc_val: 0.7011 time: 0.0908s\n",
      "valid current auc-roc score: 0.916845, current macro_F score: 0.714911\n",
      "Epoch: 00254 loss_train: 0.1500 acc_train: 0.9532 loss_val: 1.3556 acc_val: 0.7306 time: 0.0912s\n",
      "valid current auc-roc score: 0.902064, current macro_F score: 0.667686\n",
      "Epoch: 00255 loss_train: 0.1416 acc_train: 0.9587 loss_val: 1.5096 acc_val: 0.6937 time: 0.0937s\n",
      "valid current auc-roc score: 0.910565, current macro_F score: 0.692219\n",
      "Epoch: 00256 loss_train: 0.1454 acc_train: 0.9557 loss_val: 1.4298 acc_val: 0.7196 time: 0.1057s\n",
      "valid current auc-roc score: 0.914478, current macro_F score: 0.701915\n",
      "Epoch: 00257 loss_train: 0.1338 acc_train: 0.9618 loss_val: 1.3401 acc_val: 0.7232 time: 0.0997s\n",
      "valid current auc-roc score: 0.924230, current macro_F score: 0.683750\n",
      "Epoch: 00258 loss_train: 0.1430 acc_train: 0.9581 loss_val: 1.1772 acc_val: 0.7122 time: 0.0917s\n",
      "valid current auc-roc score: 0.916804, current macro_F score: 0.697337\n",
      "Epoch: 00259 loss_train: 0.1397 acc_train: 0.9631 loss_val: 1.2924 acc_val: 0.7232 time: 0.0940s\n",
      "valid current auc-roc score: 0.913388, current macro_F score: 0.676579\n",
      "Epoch: 00260 loss_train: 0.1453 acc_train: 0.9557 loss_val: 1.4221 acc_val: 0.6937 time: 0.0959s\n",
      "valid current auc-roc score: 0.907954, current macro_F score: 0.704295\n",
      "Epoch: 00261 loss_train: 0.1501 acc_train: 0.9514 loss_val: 1.4579 acc_val: 0.7232 time: 0.0967s\n",
      "valid current auc-roc score: 0.919482, current macro_F score: 0.699621\n",
      "Epoch: 00262 loss_train: 0.1403 acc_train: 0.9538 loss_val: 1.3028 acc_val: 0.7196 time: 0.0886s\n",
      "valid current auc-roc score: 0.911532, current macro_F score: 0.679602\n",
      "Epoch: 00263 loss_train: 0.1429 acc_train: 0.9550 loss_val: 1.3478 acc_val: 0.7085 time: 0.1108s\n",
      "valid current auc-roc score: 0.909230, current macro_F score: 0.688183\n",
      "Epoch: 00264 loss_train: 0.1414 acc_train: 0.9544 loss_val: 1.5244 acc_val: 0.7085 time: 0.0839s\n",
      "valid current auc-roc score: 0.912083, current macro_F score: 0.660517\n",
      "Epoch: 00265 loss_train: 0.1215 acc_train: 0.9606 loss_val: 1.3989 acc_val: 0.6900 time: 0.0872s\n",
      "valid current auc-roc score: 0.907396, current macro_F score: 0.676590\n",
      "Epoch: 00266 loss_train: 0.1383 acc_train: 0.9618 loss_val: 1.4883 acc_val: 0.7011 time: 0.0895s\n",
      "valid current auc-roc score: 0.910429, current macro_F score: 0.709032\n",
      "Epoch: 00267 loss_train: 0.1202 acc_train: 0.9606 loss_val: 1.4273 acc_val: 0.7269 time: 0.1202s\n",
      "valid current auc-roc score: 0.917861, current macro_F score: 0.718318\n",
      "Epoch: 00268 loss_train: 0.1421 acc_train: 0.9563 loss_val: 1.2958 acc_val: 0.7343 time: 0.1064s\n",
      "valid current auc-roc score: 0.911288, current macro_F score: 0.688335\n",
      "Epoch: 00269 loss_train: 0.1367 acc_train: 0.9569 loss_val: 1.3807 acc_val: 0.7011 time: 0.1131s\n",
      "valid current auc-roc score: 0.919648, current macro_F score: 0.707638\n",
      "Epoch: 00270 loss_train: 0.1448 acc_train: 0.9538 loss_val: 1.2875 acc_val: 0.7306 time: 0.0912s\n",
      "valid current auc-roc score: 0.920707, current macro_F score: 0.707154\n",
      "Epoch: 00271 loss_train: 0.1640 acc_train: 0.9452 loss_val: 1.2691 acc_val: 0.7122 time: 0.0891s\n",
      "valid current auc-roc score: 0.920454, current macro_F score: 0.674192\n",
      "Epoch: 00272 loss_train: 0.1685 acc_train: 0.9440 loss_val: 1.2549 acc_val: 0.6974 time: 0.0959s\n",
      "valid current auc-roc score: 0.908264, current macro_F score: 0.682665\n",
      "Epoch: 00273 loss_train: 0.1506 acc_train: 0.9594 loss_val: 1.3863 acc_val: 0.7048 time: 0.1008s\n",
      "valid current auc-roc score: 0.925627, current macro_F score: 0.711875\n",
      "Epoch: 00274 loss_train: 0.1466 acc_train: 0.9569 loss_val: 1.2263 acc_val: 0.7343 time: 0.1006s\n",
      "valid current auc-roc score: 0.925388, current macro_F score: 0.686937\n",
      "Epoch: 00275 loss_train: 0.1509 acc_train: 0.9569 loss_val: 1.1198 acc_val: 0.7196 time: 0.0935s\n",
      "valid current auc-roc score: 0.918015, current macro_F score: 0.686746\n",
      "Epoch: 00276 loss_train: 0.1528 acc_train: 0.9495 loss_val: 1.3173 acc_val: 0.7048 time: 0.0947s\n",
      "valid current auc-roc score: 0.899833, current macro_F score: 0.688347\n",
      "Epoch: 00277 loss_train: 0.1499 acc_train: 0.9550 loss_val: 1.5168 acc_val: 0.7011 time: 0.0993s\n",
      "valid current auc-roc score: 0.915401, current macro_F score: 0.687704\n",
      "Epoch: 00278 loss_train: 0.1452 acc_train: 0.9637 loss_val: 1.3980 acc_val: 0.7159 time: 0.0952s\n",
      "valid current auc-roc score: 0.908914, current macro_F score: 0.694249\n",
      "Epoch: 00279 loss_train: 0.1363 acc_train: 0.9550 loss_val: 1.5152 acc_val: 0.7232 time: 0.1011s\n",
      "valid current auc-roc score: 0.899418, current macro_F score: 0.700417\n",
      "Epoch: 00280 loss_train: 0.1369 acc_train: 0.9612 loss_val: 1.5085 acc_val: 0.7232 time: 0.1318s\n",
      "valid current auc-roc score: 0.921047, current macro_F score: 0.691807\n",
      "Epoch: 00281 loss_train: 0.1425 acc_train: 0.9581 loss_val: 1.2486 acc_val: 0.7048 time: 0.1131s\n",
      "valid current auc-roc score: 0.905365, current macro_F score: 0.700297\n",
      "Epoch: 00282 loss_train: 0.1323 acc_train: 0.9612 loss_val: 1.4116 acc_val: 0.7232 time: 0.1145s\n",
      "valid current auc-roc score: 0.911379, current macro_F score: 0.683021\n",
      "Epoch: 00283 loss_train: 0.1341 acc_train: 0.9563 loss_val: 1.3817 acc_val: 0.7085 time: 0.1294s\n",
      "valid current auc-roc score: 0.901472, current macro_F score: 0.665585\n",
      "Epoch: 00284 loss_train: 0.1210 acc_train: 0.9637 loss_val: 1.3922 acc_val: 0.6937 time: 0.1260s\n",
      "valid current auc-roc score: 0.921410, current macro_F score: 0.723890\n",
      "Epoch: 00285 loss_train: 0.1381 acc_train: 0.9600 loss_val: 1.2200 acc_val: 0.7380 time: 0.1287s\n",
      "valid current auc-roc score: 0.921858, current macro_F score: 0.715227\n",
      "Epoch: 00286 loss_train: 0.1310 acc_train: 0.9600 loss_val: 1.2273 acc_val: 0.7343 time: 0.1428s\n",
      "valid current auc-roc score: 0.916032, current macro_F score: 0.680885\n",
      "Epoch: 00287 loss_train: 0.1180 acc_train: 0.9655 loss_val: 1.2962 acc_val: 0.7122 time: 0.1424s\n",
      "valid current auc-roc score: 0.912739, current macro_F score: 0.671592\n",
      "Epoch: 00288 loss_train: 0.1360 acc_train: 0.9600 loss_val: 1.3094 acc_val: 0.6900 time: 0.1280s\n",
      "valid current auc-roc score: 0.913631, current macro_F score: 0.681584\n",
      "Epoch: 00289 loss_train: 0.1241 acc_train: 0.9674 loss_val: 1.2847 acc_val: 0.7011 time: 0.1102s\n",
      "valid current auc-roc score: 0.922251, current macro_F score: 0.718398\n",
      "Epoch: 00290 loss_train: 0.1364 acc_train: 0.9575 loss_val: 1.2539 acc_val: 0.7417 time: 0.1317s\n",
      "valid current auc-roc score: 0.913233, current macro_F score: 0.680914\n",
      "Epoch: 00291 loss_train: 0.1324 acc_train: 0.9637 loss_val: 1.3964 acc_val: 0.7011 time: 0.1066s\n",
      "valid current auc-roc score: 0.918027, current macro_F score: 0.695420\n",
      "Epoch: 00292 loss_train: 0.1506 acc_train: 0.9550 loss_val: 1.3439 acc_val: 0.7159 time: 0.0911s\n",
      "valid current auc-roc score: 0.923573, current macro_F score: 0.699610\n",
      "Epoch: 00293 loss_train: 0.1362 acc_train: 0.9581 loss_val: 1.2547 acc_val: 0.7159 time: 0.1107s\n",
      "valid current auc-roc score: 0.902593, current macro_F score: 0.703208\n",
      "Epoch: 00294 loss_train: 0.1358 acc_train: 0.9655 loss_val: 1.4734 acc_val: 0.7306 time: 0.1103s\n",
      "valid current auc-roc score: 0.905688, current macro_F score: 0.691577\n",
      "Epoch: 00295 loss_train: 0.1470 acc_train: 0.9581 loss_val: 1.4975 acc_val: 0.7159 time: 0.0959s\n",
      "valid current auc-roc score: 0.913461, current macro_F score: 0.668810\n",
      "Epoch: 00296 loss_train: 0.1398 acc_train: 0.9575 loss_val: 1.3849 acc_val: 0.6900 time: 0.1001s\n",
      "valid current auc-roc score: 0.912111, current macro_F score: 0.666626\n",
      "Epoch: 00297 loss_train: 0.1511 acc_train: 0.9544 loss_val: 1.4099 acc_val: 0.6900 time: 0.1004s\n",
      "valid current auc-roc score: 0.913215, current macro_F score: 0.702822\n",
      "Epoch: 00298 loss_train: 0.1413 acc_train: 0.9563 loss_val: 1.3391 acc_val: 0.7232 time: 0.0929s\n",
      "valid current auc-roc score: 0.907007, current macro_F score: 0.681908\n",
      "Epoch: 00299 loss_train: 0.1294 acc_train: 0.9612 loss_val: 1.4354 acc_val: 0.7011 time: 0.1042s\n",
      "valid current auc-roc score: 0.913246, current macro_F score: 0.673106\n",
      "Epoch: 00300 loss_train: 0.1359 acc_train: 0.9563 loss_val: 1.3374 acc_val: 0.7085 time: 0.0868s\n"
     ]
    }
   ],
   "source": [
    "acc_trains = []\n",
    "acc_vals = []\n",
    "loss_trains = []\n",
    "loss_vals = []\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "        acc_train, acc_val, loss_train, loss_val = train(epoch)\n",
    "        acc_trains.append(acc_train)\n",
    "        acc_vals.append(acc_val)\n",
    "        loss_trains.append(loss_train)\n",
    "        loss_vals.append(loss_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# %matplotlib notebook\n",
    "# %matplotlib inline\n",
    "\n",
    "plt.plot(loss_vals)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GraphSMOTE's implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 00001 loss_train: 1.9431 loss_rec: 1.9431 acc_train: 0.1589 loss_val: 1.9431 acc_val: 0.1611 time: 0.1057s\n",
      "Epoch: 00002 loss_train: 1.8532 loss_rec: 1.8532 acc_train: 0.3282 loss_val: 1.8851 acc_val: 0.2891 time: 0.1044s\n",
      "Epoch: 00003 loss_train: 1.7596 loss_rec: 1.7596 acc_train: 0.3787 loss_val: 1.8070 acc_val: 0.3432 time: 0.0990s\n",
      "Epoch: 00004 loss_train: 1.6494 loss_rec: 1.6494 acc_train: 0.4181 loss_val: 1.7405 acc_val: 0.3641 time: 0.0863s\n",
      "Epoch: 00005 loss_train: 1.5616 loss_rec: 1.5616 acc_train: 0.4433 loss_val: 1.6536 acc_val: 0.3875 time: 0.1121s\n",
      "Epoch: 00006 loss_train: 1.4922 loss_rec: 1.4922 acc_train: 0.4507 loss_val: 1.6175 acc_val: 0.3838 time: 0.1199s\n",
      "Epoch: 00007 loss_train: 1.3763 loss_rec: 1.3763 acc_train: 0.5425 loss_val: 1.5626 acc_val: 0.4440 time: 0.0888s\n",
      "Epoch: 00008 loss_train: 1.2871 loss_rec: 1.2871 acc_train: 0.6108 loss_val: 1.4611 acc_val: 0.5240 time: 0.0866s\n",
      "Epoch: 00009 loss_train: 1.1963 loss_rec: 1.1963 acc_train: 0.6626 loss_val: 1.4249 acc_val: 0.5572 time: 0.0839s\n",
      "Epoch: 00010 loss_train: 1.1951 loss_rec: 1.1951 acc_train: 0.6601 loss_val: 1.3667 acc_val: 0.5843 time: 0.0787s\n",
      "Epoch: 00011 loss_train: 1.1034 loss_rec: 1.1034 acc_train: 0.6866 loss_val: 1.3053 acc_val: 0.6113 time: 0.0857s\n",
      "Epoch: 00012 loss_train: 1.0619 loss_rec: 1.0619 acc_train: 0.7254 loss_val: 1.3110 acc_val: 0.6298 time: 0.1246s\n",
      "Epoch: 00013 loss_train: 1.0348 loss_rec: 1.0348 acc_train: 0.7137 loss_val: 1.2790 acc_val: 0.6273 time: 0.0985s\n",
      "Epoch: 00014 loss_train: 0.9764 loss_rec: 0.9764 acc_train: 0.7346 loss_val: 1.2244 acc_val: 0.6433 time: 0.0861s\n",
      "Epoch: 00015 loss_train: 0.9526 loss_rec: 0.9526 acc_train: 0.7297 loss_val: 1.1688 acc_val: 0.6519 time: 0.1052s\n",
      "Epoch: 00016 loss_train: 0.8813 loss_rec: 0.8813 acc_train: 0.7241 loss_val: 1.1689 acc_val: 0.6101 time: 0.1155s\n",
      "Epoch: 00017 loss_train: 0.8607 loss_rec: 0.8607 acc_train: 0.7457 loss_val: 1.1153 acc_val: 0.6704 time: 0.1019s\n",
      "Epoch: 00018 loss_train: 0.8280 loss_rec: 0.8280 acc_train: 0.7672 loss_val: 1.0855 acc_val: 0.6691 time: 0.1221s\n",
      "Epoch: 00019 loss_train: 0.7461 loss_rec: 0.7461 acc_train: 0.7802 loss_val: 1.0345 acc_val: 0.6900 time: 0.1151s\n",
      "Epoch: 00020 loss_train: 0.7582 loss_rec: 0.7582 acc_train: 0.7876 loss_val: 1.0254 acc_val: 0.6777 time: 0.1324s\n",
      "Epoch: 00021 loss_train: 0.7133 loss_rec: 0.7133 acc_train: 0.7839 loss_val: 0.9791 acc_val: 0.6986 time: 0.1282s\n",
      "Epoch: 00022 loss_train: 0.7111 loss_rec: 0.7111 acc_train: 0.7722 loss_val: 0.9955 acc_val: 0.6777 time: 0.1359s\n",
      "Epoch: 00023 loss_train: 0.6775 loss_rec: 0.6775 acc_train: 0.7974 loss_val: 0.9733 acc_val: 0.6925 time: 0.1157s\n",
      "Epoch: 00024 loss_train: 0.6329 loss_rec: 0.6329 acc_train: 0.8159 loss_val: 0.9476 acc_val: 0.7294 time: 0.1373s\n",
      "Epoch: 00025 loss_train: 0.6112 loss_rec: 0.6112 acc_train: 0.8190 loss_val: 0.9002 acc_val: 0.7392 time: 0.1099s\n",
      "Epoch: 00026 loss_train: 0.5701 loss_rec: 0.5701 acc_train: 0.8300 loss_val: 0.8854 acc_val: 0.7269 time: 0.1036s\n",
      "Epoch: 00027 loss_train: 0.5699 loss_rec: 0.5699 acc_train: 0.8424 loss_val: 0.8392 acc_val: 0.7540 time: 0.0925s\n",
      "Epoch: 00028 loss_train: 0.5659 loss_rec: 0.5659 acc_train: 0.8430 loss_val: 0.8337 acc_val: 0.7405 time: 0.0994s\n",
      "Epoch: 00029 loss_train: 0.5620 loss_rec: 0.5620 acc_train: 0.8467 loss_val: 0.8298 acc_val: 0.7515 time: 0.1259s\n",
      "Epoch: 00030 loss_train: 0.5068 loss_rec: 0.5068 acc_train: 0.8645 loss_val: 0.8453 acc_val: 0.7454 time: 0.1005s\n",
      "Epoch: 00031 loss_train: 0.5054 loss_rec: 0.5054 acc_train: 0.8498 loss_val: 0.8432 acc_val: 0.7491 time: 0.1113s\n",
      "Epoch: 00032 loss_train: 0.4883 loss_rec: 0.4883 acc_train: 0.8498 loss_val: 0.8072 acc_val: 0.7614 time: 0.1130s\n",
      "Epoch: 00033 loss_train: 0.4700 loss_rec: 0.4700 acc_train: 0.8565 loss_val: 0.7586 acc_val: 0.7749 time: 0.0787s\n",
      "Epoch: 00034 loss_train: 0.4478 loss_rec: 0.4478 acc_train: 0.8621 loss_val: 0.8049 acc_val: 0.7688 time: 0.0764s\n",
      "Epoch: 00035 loss_train: 0.4477 loss_rec: 0.4477 acc_train: 0.8688 loss_val: 0.7624 acc_val: 0.7749 time: 0.0872s\n",
      "Epoch: 00036 loss_train: 0.4364 loss_rec: 0.4364 acc_train: 0.8719 loss_val: 0.7312 acc_val: 0.7761 time: 0.0672s\n",
      "Epoch: 00037 loss_train: 0.4254 loss_rec: 0.4254 acc_train: 0.8799 loss_val: 0.7471 acc_val: 0.7761 time: 0.0712s\n",
      "Epoch: 00038 loss_train: 0.4154 loss_rec: 0.4154 acc_train: 0.8799 loss_val: 0.7635 acc_val: 0.7749 time: 0.0766s\n",
      "Epoch: 00039 loss_train: 0.4136 loss_rec: 0.4136 acc_train: 0.8781 loss_val: 0.8118 acc_val: 0.7921 time: 0.0745s\n",
      "Epoch: 00040 loss_train: 0.3931 loss_rec: 0.3931 acc_train: 0.8812 loss_val: 0.8267 acc_val: 0.7835 time: 0.0892s\n",
      "Epoch: 00041 loss_train: 0.3830 loss_rec: 0.3830 acc_train: 0.8787 loss_val: 0.8150 acc_val: 0.7614 time: 0.0736s\n",
      "Epoch: 00042 loss_train: 0.3736 loss_rec: 0.3736 acc_train: 0.8959 loss_val: 0.7773 acc_val: 0.7884 time: 0.0678s\n",
      "Epoch: 00043 loss_train: 0.3661 loss_rec: 0.3661 acc_train: 0.8867 loss_val: 0.8037 acc_val: 0.7638 time: 0.0734s\n",
      "Epoch: 00044 loss_train: 0.3983 loss_rec: 0.3983 acc_train: 0.8719 loss_val: 0.8068 acc_val: 0.7675 time: 0.0825s\n",
      "Epoch: 00045 loss_train: 0.3540 loss_rec: 0.3540 acc_train: 0.8941 loss_val: 0.7503 acc_val: 0.8020 time: 0.1075s\n",
      "Epoch: 00046 loss_train: 0.3540 loss_rec: 0.3540 acc_train: 0.8892 loss_val: 0.7628 acc_val: 0.7786 time: 0.0994s\n",
      "Epoch: 00047 loss_train: 0.3643 loss_rec: 0.3643 acc_train: 0.8768 loss_val: 0.7670 acc_val: 0.7811 time: 0.0719s\n",
      "Epoch: 00048 loss_train: 0.3659 loss_rec: 0.3659 acc_train: 0.8781 loss_val: 0.7629 acc_val: 0.7749 time: 0.0733s\n",
      "Epoch: 00049 loss_train: 0.3394 loss_rec: 0.3394 acc_train: 0.8916 loss_val: 0.7523 acc_val: 0.7860 time: 0.0695s\n",
      "Epoch: 00050 loss_train: 0.3182 loss_rec: 0.3182 acc_train: 0.9002 loss_val: 0.7630 acc_val: 0.7860 time: 0.0678s\n",
      "Epoch: 00051 loss_train: 0.3244 loss_rec: 0.3244 acc_train: 0.8996 loss_val: 0.7820 acc_val: 0.7798 time: 0.0685s\n",
      "Epoch: 00052 loss_train: 0.3142 loss_rec: 0.3142 acc_train: 0.9064 loss_val: 0.7404 acc_val: 0.7786 time: 0.0640s\n",
      "Epoch: 00053 loss_train: 0.3010 loss_rec: 0.3010 acc_train: 0.9095 loss_val: 0.7568 acc_val: 0.7823 time: 0.0768s\n",
      "Epoch: 00054 loss_train: 0.2955 loss_rec: 0.2955 acc_train: 0.9144 loss_val: 0.7365 acc_val: 0.8007 time: 0.0797s\n",
      "Epoch: 00055 loss_train: 0.2932 loss_rec: 0.2932 acc_train: 0.9070 loss_val: 0.7249 acc_val: 0.7983 time: 0.0705s\n",
      "Epoch: 00056 loss_train: 0.3127 loss_rec: 0.3127 acc_train: 0.9101 loss_val: 0.8103 acc_val: 0.7749 time: 0.0877s\n",
      "Epoch: 00057 loss_train: 0.2938 loss_rec: 0.2938 acc_train: 0.9039 loss_val: 0.7892 acc_val: 0.7847 time: 0.0878s\n",
      "Epoch: 00058 loss_train: 0.2702 loss_rec: 0.2702 acc_train: 0.9175 loss_val: 0.7911 acc_val: 0.7921 time: 0.0712s\n",
      "Epoch: 00059 loss_train: 0.2684 loss_rec: 0.2684 acc_train: 0.9175 loss_val: 0.7583 acc_val: 0.7688 time: 0.0796s\n",
      "Epoch: 00060 loss_train: 0.2895 loss_rec: 0.2895 acc_train: 0.9144 loss_val: 0.8127 acc_val: 0.7761 time: 0.0667s\n",
      "Epoch: 00061 loss_train: 0.2648 loss_rec: 0.2648 acc_train: 0.9200 loss_val: 0.7948 acc_val: 0.7688 time: 0.0706s\n",
      "Epoch: 00062 loss_train: 0.2601 loss_rec: 0.2601 acc_train: 0.9206 loss_val: 0.8000 acc_val: 0.7847 time: 0.0728s\n",
      "Epoch: 00063 loss_train: 0.2770 loss_rec: 0.2770 acc_train: 0.9187 loss_val: 0.8185 acc_val: 0.7786 time: 0.0678s\n",
      "Epoch: 00064 loss_train: 0.2827 loss_rec: 0.2827 acc_train: 0.9150 loss_val: 0.7847 acc_val: 0.7983 time: 0.0767s\n",
      "Epoch: 00065 loss_train: 0.2539 loss_rec: 0.2539 acc_train: 0.9212 loss_val: 0.8376 acc_val: 0.7847 time: 0.0680s\n",
      "Epoch: 00066 loss_train: 0.2648 loss_rec: 0.2648 acc_train: 0.9243 loss_val: 0.8442 acc_val: 0.7786 time: 0.0747s\n",
      "Epoch: 00067 loss_train: 0.2386 loss_rec: 0.2386 acc_train: 0.9292 loss_val: 0.7471 acc_val: 0.7897 time: 0.0775s\n",
      "Epoch: 00068 loss_train: 0.2459 loss_rec: 0.2459 acc_train: 0.9243 loss_val: 0.7942 acc_val: 0.7872 time: 0.0823s\n",
      "Epoch: 00069 loss_train: 0.2669 loss_rec: 0.2669 acc_train: 0.9187 loss_val: 0.8549 acc_val: 0.7675 time: 0.0803s\n",
      "Epoch: 00070 loss_train: 0.2513 loss_rec: 0.2513 acc_train: 0.9292 loss_val: 0.8344 acc_val: 0.7909 time: 0.0857s\n",
      "Epoch: 00071 loss_train: 0.2510 loss_rec: 0.2510 acc_train: 0.9181 loss_val: 0.8239 acc_val: 0.7651 time: 0.0729s\n",
      "Epoch: 00072 loss_train: 0.2674 loss_rec: 0.2674 acc_train: 0.9169 loss_val: 0.8272 acc_val: 0.7724 time: 0.0763s\n",
      "Epoch: 00073 loss_train: 0.2422 loss_rec: 0.2422 acc_train: 0.9310 loss_val: 0.7976 acc_val: 0.7995 time: 0.0775s\n",
      "Epoch: 00074 loss_train: 0.2426 loss_rec: 0.2426 acc_train: 0.9347 loss_val: 0.8631 acc_val: 0.7921 time: 0.0734s\n",
      "Epoch: 00075 loss_train: 0.2401 loss_rec: 0.2401 acc_train: 0.9335 loss_val: 0.8295 acc_val: 0.7601 time: 0.0672s\n",
      "Epoch: 00076 loss_train: 0.2562 loss_rec: 0.2562 acc_train: 0.9212 loss_val: 0.8221 acc_val: 0.7847 time: 0.0728s\n",
      "Epoch: 00077 loss_train: 0.2207 loss_rec: 0.2207 acc_train: 0.9366 loss_val: 0.7759 acc_val: 0.7995 time: 0.0728s\n",
      "Epoch: 00078 loss_train: 0.2448 loss_rec: 0.2448 acc_train: 0.9261 loss_val: 0.8229 acc_val: 0.7860 time: 0.0710s\n",
      "Epoch: 00079 loss_train: 0.2265 loss_rec: 0.2265 acc_train: 0.9298 loss_val: 0.8206 acc_val: 0.7823 time: 0.0689s\n",
      "Epoch: 00080 loss_train: 0.2250 loss_rec: 0.2250 acc_train: 0.9323 loss_val: 0.8298 acc_val: 0.7700 time: 0.0766s\n",
      "Epoch: 00081 loss_train: 0.2322 loss_rec: 0.2322 acc_train: 0.9298 loss_val: 0.8153 acc_val: 0.7749 time: 0.0731s\n",
      "Epoch: 00082 loss_train: 0.2176 loss_rec: 0.2176 acc_train: 0.9341 loss_val: 0.8132 acc_val: 0.7847 time: 0.0645s\n",
      "Epoch: 00083 loss_train: 0.2266 loss_rec: 0.2266 acc_train: 0.9261 loss_val: 0.8169 acc_val: 0.7761 time: 0.0733s\n",
      "Epoch: 00084 loss_train: 0.2448 loss_rec: 0.2448 acc_train: 0.9249 loss_val: 0.8290 acc_val: 0.7835 time: 0.0737s\n",
      "Epoch: 00085 loss_train: 0.2078 loss_rec: 0.2078 acc_train: 0.9372 loss_val: 0.8185 acc_val: 0.7983 time: 0.0842s\n",
      "Epoch: 00086 loss_train: 0.2144 loss_rec: 0.2144 acc_train: 0.9390 loss_val: 0.8241 acc_val: 0.7798 time: 0.0967s\n",
      "Epoch: 00087 loss_train: 0.2082 loss_rec: 0.2082 acc_train: 0.9304 loss_val: 0.8398 acc_val: 0.7860 time: 0.0757s\n",
      "Epoch: 00088 loss_train: 0.2152 loss_rec: 0.2152 acc_train: 0.9329 loss_val: 0.8530 acc_val: 0.7700 time: 0.0636s\n",
      "Epoch: 00089 loss_train: 0.2016 loss_rec: 0.2016 acc_train: 0.9372 loss_val: 0.8614 acc_val: 0.7774 time: 0.0550s\n",
      "Epoch: 00090 loss_train: 0.2164 loss_rec: 0.2164 acc_train: 0.9304 loss_val: 0.8426 acc_val: 0.7823 time: 0.0515s\n",
      "Epoch: 00091 loss_train: 0.2054 loss_rec: 0.2054 acc_train: 0.9390 loss_val: 0.8446 acc_val: 0.7958 time: 0.0562s\n",
      "Epoch: 00092 loss_train: 0.2180 loss_rec: 0.2180 acc_train: 0.9310 loss_val: 0.8391 acc_val: 0.7872 time: 0.0498s\n",
      "Epoch: 00093 loss_train: 0.1976 loss_rec: 0.1976 acc_train: 0.9378 loss_val: 0.8371 acc_val: 0.7835 time: 0.0549s\n",
      "Epoch: 00094 loss_train: 0.2127 loss_rec: 0.2127 acc_train: 0.9415 loss_val: 0.8802 acc_val: 0.7601 time: 0.1149s\n",
      "Epoch: 00095 loss_train: 0.1878 loss_rec: 0.1878 acc_train: 0.9514 loss_val: 0.7854 acc_val: 0.7761 time: 0.1508s\n",
      "Epoch: 00096 loss_train: 0.2050 loss_rec: 0.2050 acc_train: 0.9353 loss_val: 0.8088 acc_val: 0.7712 time: 0.0847s\n",
      "Epoch: 00097 loss_train: 0.1833 loss_rec: 0.1833 acc_train: 0.9452 loss_val: 0.8222 acc_val: 0.7884 time: 0.0731s\n",
      "Epoch: 00098 loss_train: 0.2152 loss_rec: 0.2152 acc_train: 0.9366 loss_val: 0.8498 acc_val: 0.7970 time: 0.0712s\n",
      "Epoch: 00099 loss_train: 0.1841 loss_rec: 0.1841 acc_train: 0.9464 loss_val: 0.9017 acc_val: 0.7761 time: 0.0737s\n",
      "Epoch: 00100 loss_train: 0.2015 loss_rec: 0.2015 acc_train: 0.9421 loss_val: 0.8417 acc_val: 0.7934 time: 0.0578s\n",
      "Epoch: 00101 loss_train: 0.1973 loss_rec: 0.1973 acc_train: 0.9452 loss_val: 0.8223 acc_val: 0.7970 time: 0.0560s\n",
      "Epoch: 00102 loss_train: 0.1839 loss_rec: 0.1839 acc_train: 0.9514 loss_val: 0.8897 acc_val: 0.7737 time: 0.0556s\n",
      "Epoch: 00103 loss_train: 0.1952 loss_rec: 0.1952 acc_train: 0.9458 loss_val: 0.8885 acc_val: 0.7884 time: 0.0628s\n",
      "Epoch: 00104 loss_train: 0.2073 loss_rec: 0.2073 acc_train: 0.9366 loss_val: 0.8973 acc_val: 0.7675 time: 0.0701s\n",
      "Epoch: 00105 loss_train: 0.2005 loss_rec: 0.2005 acc_train: 0.9397 loss_val: 0.8435 acc_val: 0.7737 time: 0.0634s\n",
      "Epoch: 00106 loss_train: 0.2099 loss_rec: 0.2099 acc_train: 0.9372 loss_val: 0.9192 acc_val: 0.7663 time: 0.0637s\n",
      "Epoch: 00107 loss_train: 0.1740 loss_rec: 0.1740 acc_train: 0.9514 loss_val: 0.9008 acc_val: 0.7651 time: 0.0654s\n",
      "Epoch: 00108 loss_train: 0.1962 loss_rec: 0.1962 acc_train: 0.9366 loss_val: 0.9290 acc_val: 0.7749 time: 0.0829s\n",
      "Epoch: 00109 loss_train: 0.1713 loss_rec: 0.1713 acc_train: 0.9477 loss_val: 0.8973 acc_val: 0.7774 time: 0.0642s\n",
      "Epoch: 00110 loss_train: 0.1931 loss_rec: 0.1931 acc_train: 0.9415 loss_val: 0.8969 acc_val: 0.7884 time: 0.0601s\n",
      "Epoch: 00111 loss_train: 0.2027 loss_rec: 0.2027 acc_train: 0.9347 loss_val: 0.8655 acc_val: 0.7835 time: 0.0658s\n",
      "Epoch: 00112 loss_train: 0.1806 loss_rec: 0.1806 acc_train: 0.9446 loss_val: 0.9087 acc_val: 0.7835 time: 0.0720s\n",
      "Epoch: 00113 loss_train: 0.1845 loss_rec: 0.1845 acc_train: 0.9452 loss_val: 0.9550 acc_val: 0.7872 time: 0.0797s\n",
      "Epoch: 00114 loss_train: 0.1840 loss_rec: 0.1840 acc_train: 0.9458 loss_val: 0.9083 acc_val: 0.7823 time: 0.0855s\n",
      "Epoch: 00115 loss_train: 0.1760 loss_rec: 0.1760 acc_train: 0.9526 loss_val: 0.8547 acc_val: 0.7761 time: 0.0726s\n",
      "Epoch: 00116 loss_train: 0.2084 loss_rec: 0.2084 acc_train: 0.9372 loss_val: 0.8972 acc_val: 0.7749 time: 0.0673s\n",
      "Epoch: 00117 loss_train: 0.1727 loss_rec: 0.1727 acc_train: 0.9483 loss_val: 0.8684 acc_val: 0.7860 time: 0.0614s\n",
      "Epoch: 00118 loss_train: 0.1736 loss_rec: 0.1736 acc_train: 0.9520 loss_val: 0.8893 acc_val: 0.7995 time: 0.0686s\n",
      "Epoch: 00119 loss_train: 0.2004 loss_rec: 0.2004 acc_train: 0.9390 loss_val: 0.8828 acc_val: 0.7884 time: 0.0650s\n",
      "Epoch: 00120 loss_train: 0.2023 loss_rec: 0.2023 acc_train: 0.9390 loss_val: 0.9782 acc_val: 0.7761 time: 0.0542s\n",
      "Epoch: 00121 loss_train: 0.1900 loss_rec: 0.1900 acc_train: 0.9397 loss_val: 0.8902 acc_val: 0.7823 time: 0.0617s\n",
      "Epoch: 00122 loss_train: 0.1824 loss_rec: 0.1824 acc_train: 0.9433 loss_val: 0.9145 acc_val: 0.7835 time: 0.0721s\n",
      "Epoch: 00123 loss_train: 0.1814 loss_rec: 0.1814 acc_train: 0.9452 loss_val: 0.8840 acc_val: 0.7737 time: 0.0689s\n",
      "Epoch: 00124 loss_train: 0.1758 loss_rec: 0.1758 acc_train: 0.9507 loss_val: 0.9132 acc_val: 0.7811 time: 0.0790s\n",
      "Epoch: 00125 loss_train: 0.1856 loss_rec: 0.1856 acc_train: 0.9458 loss_val: 0.8809 acc_val: 0.7749 time: 0.0804s\n",
      "Epoch: 00126 loss_train: 0.1789 loss_rec: 0.1789 acc_train: 0.9409 loss_val: 0.9517 acc_val: 0.7786 time: 0.0655s\n",
      "Epoch: 00127 loss_train: 0.1730 loss_rec: 0.1730 acc_train: 0.9421 loss_val: 0.8999 acc_val: 0.7934 time: 0.0660s\n",
      "Epoch: 00128 loss_train: 0.1830 loss_rec: 0.1830 acc_train: 0.9403 loss_val: 0.9030 acc_val: 0.7897 time: 0.0753s\n",
      "Epoch: 00129 loss_train: 0.1751 loss_rec: 0.1751 acc_train: 0.9550 loss_val: 0.9482 acc_val: 0.7872 time: 0.0576s\n",
      "Epoch: 00130 loss_train: 0.1743 loss_rec: 0.1743 acc_train: 0.9520 loss_val: 0.8903 acc_val: 0.7737 time: 0.0568s\n",
      "Epoch: 00131 loss_train: 0.1732 loss_rec: 0.1732 acc_train: 0.9526 loss_val: 0.9136 acc_val: 0.7835 time: 0.0540s\n",
      "Epoch: 00132 loss_train: 0.1677 loss_rec: 0.1677 acc_train: 0.9544 loss_val: 0.9231 acc_val: 0.7798 time: 0.0571s\n",
      "Epoch: 00133 loss_train: 0.1668 loss_rec: 0.1668 acc_train: 0.9507 loss_val: 0.9386 acc_val: 0.7700 time: 0.0561s\n",
      "Epoch: 00134 loss_train: 0.2009 loss_rec: 0.2009 acc_train: 0.9464 loss_val: 0.9831 acc_val: 0.7823 time: 0.0547s\n",
      "Epoch: 00135 loss_train: 0.1885 loss_rec: 0.1885 acc_train: 0.9495 loss_val: 0.8625 acc_val: 0.7897 time: 0.0532s\n",
      "Epoch: 00136 loss_train: 0.1639 loss_rec: 0.1639 acc_train: 0.9446 loss_val: 0.9588 acc_val: 0.7823 time: 0.0547s\n",
      "Epoch: 00137 loss_train: 0.2000 loss_rec: 0.2000 acc_train: 0.9347 loss_val: 0.9177 acc_val: 0.7626 time: 0.0575s\n",
      "Epoch: 00138 loss_train: 0.1839 loss_rec: 0.1839 acc_train: 0.9384 loss_val: 0.9097 acc_val: 0.7860 time: 0.0548s\n",
      "Epoch: 00139 loss_train: 0.1574 loss_rec: 0.1574 acc_train: 0.9501 loss_val: 0.9067 acc_val: 0.7983 time: 0.0528s\n",
      "Epoch: 00140 loss_train: 0.1606 loss_rec: 0.1606 acc_train: 0.9544 loss_val: 0.9180 acc_val: 0.7774 time: 0.0603s\n",
      "Epoch: 00141 loss_train: 0.1724 loss_rec: 0.1724 acc_train: 0.9489 loss_val: 1.0170 acc_val: 0.7601 time: 0.0487s\n",
      "Epoch: 00142 loss_train: 0.1679 loss_rec: 0.1679 acc_train: 0.9501 loss_val: 0.9017 acc_val: 0.7798 time: 0.0510s\n",
      "Epoch: 00143 loss_train: 0.1815 loss_rec: 0.1815 acc_train: 0.9452 loss_val: 1.0134 acc_val: 0.7626 time: 0.0557s\n",
      "Epoch: 00144 loss_train: 0.1697 loss_rec: 0.1697 acc_train: 0.9477 loss_val: 0.9576 acc_val: 0.7884 time: 0.0615s\n",
      "Epoch: 00145 loss_train: 0.1632 loss_rec: 0.1632 acc_train: 0.9446 loss_val: 0.9886 acc_val: 0.7884 time: 0.0654s\n",
      "Epoch: 00146 loss_train: 0.1763 loss_rec: 0.1763 acc_train: 0.9501 loss_val: 0.9709 acc_val: 0.7712 time: 0.0561s\n",
      "Epoch: 00147 loss_train: 0.1484 loss_rec: 0.1484 acc_train: 0.9563 loss_val: 0.9557 acc_val: 0.7761 time: 0.0610s\n",
      "Epoch: 00148 loss_train: 0.1515 loss_rec: 0.1515 acc_train: 0.9520 loss_val: 0.9736 acc_val: 0.7749 time: 0.0595s\n",
      "Epoch: 00149 loss_train: 0.1703 loss_rec: 0.1703 acc_train: 0.9421 loss_val: 0.9792 acc_val: 0.7823 time: 0.0557s\n",
      "Epoch: 00150 loss_train: 0.1779 loss_rec: 0.1779 acc_train: 0.9415 loss_val: 1.0264 acc_val: 0.7663 time: 0.0510s\n",
      "Epoch: 00151 loss_train: 0.2280 loss_rec: 0.2280 acc_train: 0.9446 loss_val: 0.9848 acc_val: 0.7872 time: 0.0587s\n",
      "Epoch: 00152 loss_train: 0.2013 loss_rec: 0.2013 acc_train: 0.9347 loss_val: 0.9743 acc_val: 0.7663 time: 0.0589s\n",
      "Epoch: 00153 loss_train: 0.1838 loss_rec: 0.1838 acc_train: 0.9403 loss_val: 0.9958 acc_val: 0.7774 time: 0.0601s\n",
      "Epoch: 00154 loss_train: 0.1833 loss_rec: 0.1833 acc_train: 0.9483 loss_val: 1.0425 acc_val: 0.7466 time: 0.0556s\n",
      "Epoch: 00155 loss_train: 0.1846 loss_rec: 0.1846 acc_train: 0.9427 loss_val: 0.9215 acc_val: 0.7749 time: 0.0619s\n",
      "Epoch: 00156 loss_train: 0.1740 loss_rec: 0.1740 acc_train: 0.9433 loss_val: 0.8847 acc_val: 0.7823 time: 0.0636s\n",
      "Epoch: 00157 loss_train: 0.1790 loss_rec: 0.1790 acc_train: 0.9489 loss_val: 0.9547 acc_val: 0.7626 time: 0.0546s\n",
      "Epoch: 00158 loss_train: 0.1915 loss_rec: 0.1915 acc_train: 0.9415 loss_val: 0.9817 acc_val: 0.7761 time: 0.0497s\n",
      "Epoch: 00159 loss_train: 0.1723 loss_rec: 0.1723 acc_train: 0.9477 loss_val: 0.9669 acc_val: 0.7651 time: 0.0481s\n",
      "Epoch: 00160 loss_train: 0.1598 loss_rec: 0.1598 acc_train: 0.9495 loss_val: 0.9466 acc_val: 0.7614 time: 0.0522s\n",
      "Epoch: 00161 loss_train: 0.1580 loss_rec: 0.1580 acc_train: 0.9520 loss_val: 0.9848 acc_val: 0.7688 time: 0.0426s\n",
      "Epoch: 00162 loss_train: 0.1696 loss_rec: 0.1696 acc_train: 0.9507 loss_val: 0.9560 acc_val: 0.7798 time: 0.0577s\n",
      "Epoch: 00163 loss_train: 0.1648 loss_rec: 0.1648 acc_train: 0.9446 loss_val: 0.9161 acc_val: 0.7897 time: 0.0506s\n",
      "Epoch: 00164 loss_train: 0.1648 loss_rec: 0.1648 acc_train: 0.9433 loss_val: 0.9623 acc_val: 0.7700 time: 0.0613s\n",
      "Epoch: 00165 loss_train: 0.1622 loss_rec: 0.1622 acc_train: 0.9520 loss_val: 0.9849 acc_val: 0.7860 time: 0.0550s\n",
      "Epoch: 00166 loss_train: 0.1772 loss_rec: 0.1772 acc_train: 0.9433 loss_val: 1.0240 acc_val: 0.7798 time: 0.0547s\n",
      "Epoch: 00167 loss_train: 0.1463 loss_rec: 0.1463 acc_train: 0.9575 loss_val: 1.0174 acc_val: 0.7872 time: 0.0456s\n",
      "Epoch: 00168 loss_train: 0.1495 loss_rec: 0.1495 acc_train: 0.9520 loss_val: 0.9521 acc_val: 0.7860 time: 0.0526s\n",
      "Epoch: 00169 loss_train: 0.1600 loss_rec: 0.1600 acc_train: 0.9514 loss_val: 1.0009 acc_val: 0.7811 time: 0.0536s\n",
      "Epoch: 00170 loss_train: 0.1530 loss_rec: 0.1530 acc_train: 0.9507 loss_val: 0.9056 acc_val: 0.7749 time: 0.0507s\n",
      "Epoch: 00171 loss_train: 0.1598 loss_rec: 0.1598 acc_train: 0.9501 loss_val: 0.9904 acc_val: 0.7626 time: 0.0489s\n",
      "Epoch: 00172 loss_train: 0.1783 loss_rec: 0.1783 acc_train: 0.9489 loss_val: 0.9260 acc_val: 0.7614 time: 0.0487s\n",
      "Epoch: 00173 loss_train: 0.1700 loss_rec: 0.1700 acc_train: 0.9520 loss_val: 1.0243 acc_val: 0.7638 time: 0.0557s\n",
      "Epoch: 00174 loss_train: 0.1530 loss_rec: 0.1530 acc_train: 0.9544 loss_val: 1.0312 acc_val: 0.7700 time: 0.0618s\n",
      "Epoch: 00175 loss_train: 0.1755 loss_rec: 0.1755 acc_train: 0.9452 loss_val: 1.0103 acc_val: 0.7761 time: 0.0508s\n",
      "Epoch: 00176 loss_train: 0.1872 loss_rec: 0.1872 acc_train: 0.9421 loss_val: 0.9450 acc_val: 0.7811 time: 0.0474s\n",
      "Epoch: 00177 loss_train: 0.1982 loss_rec: 0.1982 acc_train: 0.9409 loss_val: 0.9800 acc_val: 0.7774 time: 0.0516s\n",
      "Epoch: 00178 loss_train: 0.1697 loss_rec: 0.1697 acc_train: 0.9366 loss_val: 1.0218 acc_val: 0.7749 time: 0.0553s\n",
      "Epoch: 00179 loss_train: 0.1789 loss_rec: 0.1789 acc_train: 0.9470 loss_val: 0.9447 acc_val: 0.7786 time: 0.0438s\n",
      "Epoch: 00180 loss_train: 0.1913 loss_rec: 0.1913 acc_train: 0.9384 loss_val: 1.0188 acc_val: 0.7601 time: 0.0537s\n",
      "Epoch: 00181 loss_train: 0.1636 loss_rec: 0.1636 acc_train: 0.9477 loss_val: 0.8997 acc_val: 0.7688 time: 0.0508s\n",
      "Epoch: 00182 loss_train: 0.1836 loss_rec: 0.1836 acc_train: 0.9507 loss_val: 0.9673 acc_val: 0.7724 time: 0.0503s\n",
      "Epoch: 00183 loss_train: 0.1676 loss_rec: 0.1676 acc_train: 0.9514 loss_val: 0.9947 acc_val: 0.7774 time: 0.0555s\n",
      "Epoch: 00184 loss_train: 0.2164 loss_rec: 0.2164 acc_train: 0.9477 loss_val: 0.9989 acc_val: 0.7688 time: 0.0500s\n",
      "Epoch: 00185 loss_train: 0.1877 loss_rec: 0.1877 acc_train: 0.9507 loss_val: 0.9936 acc_val: 0.7700 time: 0.0453s\n",
      "Epoch: 00186 loss_train: 0.1801 loss_rec: 0.1801 acc_train: 0.9440 loss_val: 1.0063 acc_val: 0.7663 time: 0.0506s\n",
      "Epoch: 00187 loss_train: 0.1664 loss_rec: 0.1664 acc_train: 0.9470 loss_val: 1.0266 acc_val: 0.7614 time: 0.0478s\n",
      "Epoch: 00188 loss_train: 0.1514 loss_rec: 0.1514 acc_train: 0.9532 loss_val: 0.9350 acc_val: 0.7712 time: 0.0480s\n",
      "Epoch: 00189 loss_train: 0.1455 loss_rec: 0.1455 acc_train: 0.9550 loss_val: 0.9411 acc_val: 0.7675 time: 0.0507s\n",
      "Epoch: 00190 loss_train: 0.1649 loss_rec: 0.1649 acc_train: 0.9507 loss_val: 1.0289 acc_val: 0.7626 time: 0.0498s\n",
      "Epoch: 00191 loss_train: 0.1465 loss_rec: 0.1465 acc_train: 0.9569 loss_val: 0.9550 acc_val: 0.7700 time: 0.0505s\n",
      "Epoch: 00192 loss_train: 0.1943 loss_rec: 0.1943 acc_train: 0.9495 loss_val: 1.0273 acc_val: 0.7700 time: 0.0586s\n",
      "Epoch: 00193 loss_train: 0.1477 loss_rec: 0.1477 acc_train: 0.9557 loss_val: 0.9643 acc_val: 0.7761 time: 0.0699s\n",
      "Epoch: 00194 loss_train: 0.1618 loss_rec: 0.1618 acc_train: 0.9557 loss_val: 1.0253 acc_val: 0.7675 time: 0.0632s\n",
      "Epoch: 00195 loss_train: 0.1477 loss_rec: 0.1477 acc_train: 0.9483 loss_val: 0.9411 acc_val: 0.7626 time: 0.0581s\n",
      "Epoch: 00196 loss_train: 0.1906 loss_rec: 0.1906 acc_train: 0.9378 loss_val: 0.9867 acc_val: 0.7798 time: 0.0572s\n",
      "Epoch: 00197 loss_train: 0.1466 loss_rec: 0.1466 acc_train: 0.9544 loss_val: 1.0176 acc_val: 0.7897 time: 0.0552s\n",
      "Epoch: 00198 loss_train: 0.1576 loss_rec: 0.1576 acc_train: 0.9544 loss_val: 0.9411 acc_val: 0.7823 time: 0.0546s\n",
      "Epoch: 00199 loss_train: 0.1522 loss_rec: 0.1522 acc_train: 0.9618 loss_val: 0.9659 acc_val: 0.7811 time: 0.0478s\n",
      "Epoch: 00200 loss_train: 0.1736 loss_rec: 0.1736 acc_train: 0.9452 loss_val: 1.0082 acc_val: 0.7712 time: 0.0601s\n",
      "Epoch: 00201 loss_train: 0.1636 loss_rec: 0.1636 acc_train: 0.9544 loss_val: 0.8978 acc_val: 0.7823 time: 0.0620s\n",
      "Epoch: 00202 loss_train: 0.1612 loss_rec: 0.1612 acc_train: 0.9514 loss_val: 1.0195 acc_val: 0.7884 time: 0.0570s\n",
      "Epoch: 00203 loss_train: 0.1712 loss_rec: 0.1712 acc_train: 0.9464 loss_val: 0.9144 acc_val: 0.7798 time: 0.0516s\n",
      "Epoch: 00204 loss_train: 0.1820 loss_rec: 0.1820 acc_train: 0.9470 loss_val: 0.9899 acc_val: 0.7946 time: 0.0570s\n",
      "Epoch: 00205 loss_train: 0.1589 loss_rec: 0.1589 acc_train: 0.9507 loss_val: 1.0656 acc_val: 0.7786 time: 0.0538s\n",
      "Epoch: 00206 loss_train: 0.1735 loss_rec: 0.1735 acc_train: 0.9452 loss_val: 1.0434 acc_val: 0.7614 time: 0.0515s\n",
      "Epoch: 00207 loss_train: 0.1549 loss_rec: 0.1549 acc_train: 0.9557 loss_val: 0.9154 acc_val: 0.7749 time: 0.0547s\n",
      "Epoch: 00208 loss_train: 0.1608 loss_rec: 0.1608 acc_train: 0.9520 loss_val: 0.9617 acc_val: 0.7688 time: 0.0599s\n",
      "Epoch: 00209 loss_train: 0.1671 loss_rec: 0.1671 acc_train: 0.9458 loss_val: 1.0247 acc_val: 0.7528 time: 0.0542s\n",
      "Epoch: 00210 loss_train: 0.1581 loss_rec: 0.1581 acc_train: 0.9483 loss_val: 0.9894 acc_val: 0.7798 time: 0.0575s\n",
      "Epoch: 00211 loss_train: 0.1524 loss_rec: 0.1524 acc_train: 0.9612 loss_val: 1.0126 acc_val: 0.7724 time: 0.0589s\n",
      "Epoch: 00212 loss_train: 0.1573 loss_rec: 0.1573 acc_train: 0.9532 loss_val: 0.9857 acc_val: 0.7737 time: 0.0565s\n",
      "Epoch: 00213 loss_train: 0.1623 loss_rec: 0.1623 acc_train: 0.9594 loss_val: 1.0150 acc_val: 0.7528 time: 0.0499s\n",
      "Epoch: 00214 loss_train: 0.1873 loss_rec: 0.1873 acc_train: 0.9409 loss_val: 1.0241 acc_val: 0.7835 time: 0.0536s\n",
      "Epoch: 00215 loss_train: 0.1617 loss_rec: 0.1617 acc_train: 0.9532 loss_val: 0.9153 acc_val: 0.7884 time: 0.0507s\n",
      "Epoch: 00216 loss_train: 0.1552 loss_rec: 0.1552 acc_train: 0.9520 loss_val: 0.9654 acc_val: 0.7823 time: 0.0545s\n",
      "Epoch: 00217 loss_train: 0.1561 loss_rec: 0.1561 acc_train: 0.9520 loss_val: 0.9733 acc_val: 0.7688 time: 0.0479s\n",
      "Epoch: 00218 loss_train: 0.1355 loss_rec: 0.1355 acc_train: 0.9581 loss_val: 0.9076 acc_val: 0.7688 time: 0.0535s\n",
      "Epoch: 00219 loss_train: 0.1623 loss_rec: 0.1623 acc_train: 0.9532 loss_val: 0.9673 acc_val: 0.7811 time: 0.0572s\n",
      "Epoch: 00220 loss_train: 0.1442 loss_rec: 0.1442 acc_train: 0.9563 loss_val: 1.0402 acc_val: 0.7749 time: 0.0574s\n",
      "Epoch: 00221 loss_train: 0.1613 loss_rec: 0.1613 acc_train: 0.9507 loss_val: 0.9089 acc_val: 0.7675 time: 0.0466s\n",
      "Epoch: 00222 loss_train: 0.1467 loss_rec: 0.1467 acc_train: 0.9532 loss_val: 0.9470 acc_val: 0.7983 time: 0.0591s\n",
      "Epoch: 00223 loss_train: 0.1567 loss_rec: 0.1567 acc_train: 0.9544 loss_val: 0.9390 acc_val: 0.7946 time: 0.0544s\n",
      "Epoch: 00224 loss_train: 0.1553 loss_rec: 0.1553 acc_train: 0.9501 loss_val: 1.1101 acc_val: 0.7626 time: 0.0487s\n",
      "Epoch: 00225 loss_train: 0.1533 loss_rec: 0.1533 acc_train: 0.9544 loss_val: 0.9974 acc_val: 0.7601 time: 0.0474s\n",
      "Epoch: 00226 loss_train: 0.1443 loss_rec: 0.1443 acc_train: 0.9606 loss_val: 1.0195 acc_val: 0.7786 time: 0.0549s\n",
      "Epoch: 00227 loss_train: 0.1308 loss_rec: 0.1308 acc_train: 0.9649 loss_val: 0.9922 acc_val: 0.7847 time: 0.0520s\n",
      "Epoch: 00228 loss_train: 0.1556 loss_rec: 0.1556 acc_train: 0.9520 loss_val: 1.0390 acc_val: 0.7638 time: 0.0480s\n",
      "Epoch: 00229 loss_train: 0.1534 loss_rec: 0.1534 acc_train: 0.9550 loss_val: 1.0524 acc_val: 0.7601 time: 0.0626s\n",
      "Epoch: 00230 loss_train: 0.1527 loss_rec: 0.1527 acc_train: 0.9526 loss_val: 1.0633 acc_val: 0.7638 time: 0.0599s\n",
      "Epoch: 00231 loss_train: 0.1292 loss_rec: 0.1292 acc_train: 0.9587 loss_val: 1.0599 acc_val: 0.7675 time: 0.0523s\n",
      "Epoch: 00232 loss_train: 0.1353 loss_rec: 0.1353 acc_train: 0.9631 loss_val: 1.0396 acc_val: 0.7884 time: 0.0490s\n",
      "Epoch: 00233 loss_train: 0.1611 loss_rec: 0.1611 acc_train: 0.9477 loss_val: 1.0460 acc_val: 0.7884 time: 0.0519s\n",
      "Epoch: 00234 loss_train: 0.1571 loss_rec: 0.1571 acc_train: 0.9483 loss_val: 1.1399 acc_val: 0.7909 time: 0.0545s\n",
      "Epoch: 00235 loss_train: 0.1285 loss_rec: 0.1285 acc_train: 0.9594 loss_val: 1.0640 acc_val: 0.7811 time: 0.0524s\n",
      "Epoch: 00236 loss_train: 0.1642 loss_rec: 0.1642 acc_train: 0.9501 loss_val: 1.1222 acc_val: 0.7651 time: 0.0476s\n",
      "Epoch: 00237 loss_train: 0.1371 loss_rec: 0.1371 acc_train: 0.9538 loss_val: 0.9161 acc_val: 0.7897 time: 0.0529s\n",
      "Epoch: 00238 loss_train: 0.1433 loss_rec: 0.1433 acc_train: 0.9575 loss_val: 0.9691 acc_val: 0.7737 time: 0.0553s\n",
      "Epoch: 00239 loss_train: 0.1382 loss_rec: 0.1382 acc_train: 0.9569 loss_val: 0.9739 acc_val: 0.7823 time: 0.0535s\n",
      "Epoch: 00240 loss_train: 0.1418 loss_rec: 0.1418 acc_train: 0.9594 loss_val: 1.1460 acc_val: 0.7651 time: 0.0519s\n",
      "Epoch: 00241 loss_train: 0.1325 loss_rec: 0.1325 acc_train: 0.9612 loss_val: 1.0600 acc_val: 0.7638 time: 0.0470s\n",
      "Epoch: 00242 loss_train: 0.1441 loss_rec: 0.1441 acc_train: 0.9600 loss_val: 0.9963 acc_val: 0.7847 time: 0.0512s\n",
      "Epoch: 00243 loss_train: 0.1628 loss_rec: 0.1628 acc_train: 0.9489 loss_val: 1.0677 acc_val: 0.7872 time: 0.0498s\n",
      "Epoch: 00244 loss_train: 0.1365 loss_rec: 0.1365 acc_train: 0.9569 loss_val: 1.0145 acc_val: 0.7835 time: 0.0485s\n",
      "Epoch: 00245 loss_train: 0.1335 loss_rec: 0.1335 acc_train: 0.9606 loss_val: 1.0318 acc_val: 0.7823 time: 0.0509s\n",
      "Epoch: 00246 loss_train: 0.1473 loss_rec: 0.1473 acc_train: 0.9575 loss_val: 0.9744 acc_val: 0.7847 time: 0.0432s\n",
      "Epoch: 00247 loss_train: 0.1516 loss_rec: 0.1516 acc_train: 0.9532 loss_val: 1.0593 acc_val: 0.7700 time: 0.0490s\n",
      "Epoch: 00248 loss_train: 0.1510 loss_rec: 0.1510 acc_train: 0.9501 loss_val: 1.0379 acc_val: 0.7897 time: 0.0459s\n",
      "Epoch: 00249 loss_train: 0.1841 loss_rec: 0.1841 acc_train: 0.9477 loss_val: 1.0955 acc_val: 0.7786 time: 0.0569s\n",
      "Epoch: 00250 loss_train: 0.1495 loss_rec: 0.1495 acc_train: 0.9501 loss_val: 0.9979 acc_val: 0.7811 time: 0.0571s\n",
      "Epoch: 00251 loss_train: 0.1598 loss_rec: 0.1598 acc_train: 0.9514 loss_val: 0.9718 acc_val: 0.7884 time: 0.0485s\n",
      "Epoch: 00252 loss_train: 0.1510 loss_rec: 0.1510 acc_train: 0.9538 loss_val: 1.0557 acc_val: 0.7724 time: 0.0526s\n",
      "Epoch: 00253 loss_train: 0.1550 loss_rec: 0.1550 acc_train: 0.9581 loss_val: 1.1085 acc_val: 0.7761 time: 0.0537s\n",
      "Epoch: 00254 loss_train: 0.1714 loss_rec: 0.1714 acc_train: 0.9495 loss_val: 1.0843 acc_val: 0.7626 time: 0.0462s\n",
      "Epoch: 00255 loss_train: 0.1597 loss_rec: 0.1597 acc_train: 0.9587 loss_val: 1.0701 acc_val: 0.7761 time: 0.0483s\n",
      "Epoch: 00256 loss_train: 0.1435 loss_rec: 0.1435 acc_train: 0.9520 loss_val: 0.9353 acc_val: 0.7909 time: 0.0464s\n",
      "Epoch: 00257 loss_train: 0.1427 loss_rec: 0.1427 acc_train: 0.9538 loss_val: 1.0525 acc_val: 0.7688 time: 0.0580s\n",
      "Epoch: 00258 loss_train: 0.1400 loss_rec: 0.1400 acc_train: 0.9569 loss_val: 1.0021 acc_val: 0.7712 time: 0.0530s\n",
      "Epoch: 00259 loss_train: 0.1385 loss_rec: 0.1385 acc_train: 0.9624 loss_val: 0.9348 acc_val: 0.7934 time: 0.0557s\n",
      "Epoch: 00260 loss_train: 0.1400 loss_rec: 0.1400 acc_train: 0.9575 loss_val: 0.9762 acc_val: 0.7934 time: 0.0532s\n",
      "Epoch: 00261 loss_train: 0.1975 loss_rec: 0.1975 acc_train: 0.9569 loss_val: 1.0230 acc_val: 0.7835 time: 0.0522s\n",
      "Epoch: 00262 loss_train: 0.1882 loss_rec: 0.1882 acc_train: 0.9581 loss_val: 1.0490 acc_val: 0.7934 time: 0.0503s\n",
      "Epoch: 00263 loss_train: 0.1864 loss_rec: 0.1864 acc_train: 0.9514 loss_val: 0.9754 acc_val: 0.7700 time: 0.0564s\n",
      "Epoch: 00264 loss_train: 0.1600 loss_rec: 0.1600 acc_train: 0.9520 loss_val: 1.0086 acc_val: 0.7835 time: 0.0511s\n",
      "Epoch: 00265 loss_train: 0.1533 loss_rec: 0.1533 acc_train: 0.9538 loss_val: 1.0539 acc_val: 0.7897 time: 0.0518s\n",
      "Epoch: 00266 loss_train: 0.1493 loss_rec: 0.1493 acc_train: 0.9575 loss_val: 1.0260 acc_val: 0.7897 time: 0.0550s\n",
      "Epoch: 00267 loss_train: 0.1462 loss_rec: 0.1462 acc_train: 0.9587 loss_val: 0.9925 acc_val: 0.7811 time: 0.0511s\n",
      "Epoch: 00268 loss_train: 0.1388 loss_rec: 0.1388 acc_train: 0.9581 loss_val: 0.9878 acc_val: 0.7909 time: 0.0565s\n",
      "Epoch: 00269 loss_train: 0.1291 loss_rec: 0.1291 acc_train: 0.9667 loss_val: 1.0369 acc_val: 0.7724 time: 0.0530s\n",
      "Epoch: 00270 loss_train: 0.1445 loss_rec: 0.1445 acc_train: 0.9550 loss_val: 0.9731 acc_val: 0.7847 time: 0.0523s\n",
      "Epoch: 00271 loss_train: 0.1550 loss_rec: 0.1550 acc_train: 0.9514 loss_val: 0.9658 acc_val: 0.7663 time: 0.0525s\n",
      "Epoch: 00272 loss_train: 0.1428 loss_rec: 0.1428 acc_train: 0.9600 loss_val: 0.9686 acc_val: 0.7872 time: 0.0483s\n",
      "Epoch: 00273 loss_train: 0.1454 loss_rec: 0.1454 acc_train: 0.9563 loss_val: 1.0554 acc_val: 0.7601 time: 0.0466s\n",
      "Epoch: 00274 loss_train: 0.1590 loss_rec: 0.1590 acc_train: 0.9520 loss_val: 1.0063 acc_val: 0.7761 time: 0.0487s\n",
      "Epoch: 00275 loss_train: 0.1377 loss_rec: 0.1377 acc_train: 0.9606 loss_val: 0.8971 acc_val: 0.7774 time: 0.0532s\n",
      "Epoch: 00276 loss_train: 0.1496 loss_rec: 0.1496 acc_train: 0.9514 loss_val: 0.9949 acc_val: 0.7872 time: 0.0565s\n",
      "Epoch: 00277 loss_train: 0.1421 loss_rec: 0.1421 acc_train: 0.9606 loss_val: 1.0298 acc_val: 0.7651 time: 0.0604s\n",
      "Epoch: 00278 loss_train: 0.1187 loss_rec: 0.1187 acc_train: 0.9674 loss_val: 0.9524 acc_val: 0.7724 time: 0.0519s\n",
      "Epoch: 00279 loss_train: 0.1270 loss_rec: 0.1270 acc_train: 0.9649 loss_val: 1.0243 acc_val: 0.7811 time: 0.0551s\n",
      "Epoch: 00280 loss_train: 0.1498 loss_rec: 0.1498 acc_train: 0.9618 loss_val: 1.0003 acc_val: 0.7847 time: 0.0581s\n",
      "Epoch: 00281 loss_train: 0.1315 loss_rec: 0.1315 acc_train: 0.9643 loss_val: 1.0480 acc_val: 0.7503 time: 0.0501s\n",
      "Epoch: 00282 loss_train: 0.1323 loss_rec: 0.1323 acc_train: 0.9581 loss_val: 0.9424 acc_val: 0.7811 time: 0.0523s\n",
      "Epoch: 00283 loss_train: 0.1269 loss_rec: 0.1269 acc_train: 0.9637 loss_val: 1.0214 acc_val: 0.7798 time: 0.0529s\n",
      "Epoch: 00284 loss_train: 0.1235 loss_rec: 0.1235 acc_train: 0.9606 loss_val: 1.0100 acc_val: 0.7774 time: 0.0499s\n",
      "Epoch: 00285 loss_train: 0.1452 loss_rec: 0.1452 acc_train: 0.9507 loss_val: 1.0384 acc_val: 0.7872 time: 0.0469s\n",
      "Epoch: 00286 loss_train: 0.1287 loss_rec: 0.1287 acc_train: 0.9618 loss_val: 1.1096 acc_val: 0.7712 time: 0.0530s\n",
      "Epoch: 00287 loss_train: 0.1335 loss_rec: 0.1335 acc_train: 0.9618 loss_val: 1.0459 acc_val: 0.7700 time: 0.0555s\n",
      "Epoch: 00288 loss_train: 0.1177 loss_rec: 0.1177 acc_train: 0.9680 loss_val: 1.1422 acc_val: 0.7614 time: 0.0536s\n",
      "Epoch: 00289 loss_train: 0.1189 loss_rec: 0.1189 acc_train: 0.9655 loss_val: 1.1170 acc_val: 0.7712 time: 0.0540s\n",
      "Epoch: 00290 loss_train: 0.1397 loss_rec: 0.1397 acc_train: 0.9594 loss_val: 1.0208 acc_val: 0.7897 time: 0.0544s\n",
      "Epoch: 00291 loss_train: 0.1165 loss_rec: 0.1165 acc_train: 0.9624 loss_val: 1.1059 acc_val: 0.7884 time: 0.0544s\n",
      "Epoch: 00292 loss_train: 0.1169 loss_rec: 0.1169 acc_train: 0.9661 loss_val: 1.0129 acc_val: 0.7860 time: 0.0537s\n",
      "Epoch: 00293 loss_train: 0.1686 loss_rec: 0.1686 acc_train: 0.9526 loss_val: 1.0913 acc_val: 0.7712 time: 0.0556s\n",
      "Epoch: 00294 loss_train: 0.1215 loss_rec: 0.1215 acc_train: 0.9618 loss_val: 1.0011 acc_val: 0.7724 time: 0.0444s\n",
      "Epoch: 00295 loss_train: 0.1224 loss_rec: 0.1224 acc_train: 0.9637 loss_val: 1.0280 acc_val: 0.7774 time: 0.0663s\n",
      "Epoch: 00296 loss_train: 0.1273 loss_rec: 0.1273 acc_train: 0.9600 loss_val: 1.0938 acc_val: 0.7761 time: 0.0543s\n",
      "Epoch: 00297 loss_train: 0.1474 loss_rec: 0.1474 acc_train: 0.9538 loss_val: 1.0928 acc_val: 0.7774 time: 0.0550s\n",
      "Epoch: 00298 loss_train: 0.1277 loss_rec: 0.1277 acc_train: 0.9600 loss_val: 1.0820 acc_val: 0.7651 time: 0.0534s\n",
      "Epoch: 00299 loss_train: 0.1190 loss_rec: 0.1190 acc_train: 0.9661 loss_val: 0.9971 acc_val: 0.7823 time: 0.0582s\n",
      "Epoch: 00300 loss_train: 0.1500 loss_rec: 0.1500 acc_train: 0.9544 loss_val: 1.0253 acc_val: 0.7749 time: 0.0554s\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "encoder = GCN_Encoder_s(nfeat=features.shape[1],\n",
    "        nhid=args.n_hidden,\n",
    "        nembed=args.n_hidden,\n",
    "        dropout=args.dropout)\n",
    "classifier = GCN_Classifier_s(nembed=args.n_hidden, \n",
    "        nhid=args.n_hidden, \n",
    "        nclass=labels.max().item() + 1, \n",
    "        dropout=args.dropout)\n",
    "decoder = Decoder_s(nembed=args.n_hidden,\n",
    "        dropout=args.dropout)\n",
    "optimizer_en = optim.Adam(encoder.parameters(),\n",
    "                       lr=args.learning_rate, weight_decay=args.weight_decay)\n",
    "optimizer_cls = optim.Adam(classifier.parameters(),\n",
    "                       lr=args.learning_rate, weight_decay=args.weight_decay)\n",
    "optimizer_de = optim.Adam(decoder.parameters(),\n",
    "                       lr=args.learning_rate, weight_decay=args.weight_decay)\n",
    "def train(epoch):\n",
    "    t = time.time()\n",
    "    encoder.train()\n",
    "    classifier.train()\n",
    "    decoder.train()\n",
    "    optimizer_en.zero_grad()\n",
    "    optimizer_cls.zero_grad()\n",
    "    optimizer_de.zero_grad()\n",
    "\n",
    "    embed = encoder(features, adj_mtx)\n",
    "\n",
    "    if args.setting == 'recon_newG' or args.setting == 'recon' or args.setting == 'newG_cls':\n",
    "        ori_num = labels.shape[0]\n",
    "        embed, labels_new, idx_train_new, adj_up = utils.recon_upsample(embed, labels, train_idx, adj=adj_mtx.detach().to_dense(),portion=args.up_scale, im_class_num=args.im_class_num)\n",
    "        generated_G = decoder(embed)\n",
    "\n",
    "        loss_rec = utils.adj_mse_loss(generated_G[:ori_num, :][:, :ori_num], adj_mtx.detach().to_dense())\n",
    "        \n",
    "        #ipdb.set_trace()\n",
    "\n",
    "\n",
    "        if not args.opt_new_G:\n",
    "            adj_new = copy.deepcopy(generated_G.detach())\n",
    "            threshold = 0.5\n",
    "            adj_new[adj_new<threshold] = 0.0\n",
    "            adj_new[adj_new>=threshold] = 1.0\n",
    "\n",
    "            #ipdb.set_trace()\n",
    "            edge_ac = adj_new[:ori_num, :ori_num].eq(adj_mtx.to_dense()).double().sum()/(ori_num**2)\n",
    "        else:\n",
    "            adj_new = generated_G\n",
    "            edge_ac = F.l1_loss(adj_new[:ori_num, :ori_num], adj_mtx.to_dense(), reduction='mean')\n",
    "\n",
    "\n",
    "        #calculate generation information\n",
    "        exist_edge_prob = adj_new[:ori_num, :ori_num].mean() #edge prob for existing nodes\n",
    "        generated_edge_prob = adj_new[ori_num:, :ori_num].mean() #edge prob for generated nodes\n",
    "        print(\"edge acc: {:.4f}, exist_edge_prob: {:.4f}, generated_edge_prob: {:.4f}\".format(edge_ac.item(), exist_edge_prob.item(), generated_edge_prob.item()))\n",
    "\n",
    "\n",
    "        adj_new = torch.mul(adj_up, adj_new)\n",
    "\n",
    "        exist_edge_prob = adj_new[:ori_num, :ori_num].mean() #edge prob for existing nodes\n",
    "        generated_edge_prob = adj_new[ori_num:, :ori_num].mean() #edge prob for generated nodes\n",
    "        print(\"after filtering, edge acc: {:.4f}, exist_edge_prob: {:.4f}, generated_edge_prob: {:.4f}\".format(edge_ac.item(), exist_edge_prob.item(), generated_edge_prob.item()))\n",
    "\n",
    "\n",
    "        adj_new[:ori_num, :][:, :ori_num] = adj_mtx.detach().to_dense()\n",
    "        #adj_new = adj_new.to_sparse()\n",
    "        #ipdb.set_trace()\n",
    "\n",
    "        if not args.opt_new_G:\n",
    "            adj_new = adj_new.detach()\n",
    "\n",
    "        if args.setting == 'newG_cls':\n",
    "            idx_train_new = train_idx\n",
    "\n",
    "    elif args.setting == 'embed_up':\n",
    "        #perform SMOTE in embedding space\n",
    "        embed, labels_new, idx_train_new = utils.recon_upsample(embed, labels, train_idx, portion=args.up_scale, im_class_num = args.im_class_num)\n",
    "        adj_new = adj_mtx\n",
    "    else:\n",
    "        labels_new = labels\n",
    "        idx_train_new = train_idx\n",
    "        adj_new = adj_mtx\n",
    "\n",
    "    #ipdb.set_trace()\n",
    "    output = classifier(embed, adj_new)\n",
    "\n",
    "\n",
    "\n",
    "    if args.setting == 'reweight':\n",
    "        weight = features.new((labels.max().item() + 1)).fill_(1)\n",
    "        weight[-args.im_class_num:] = 1 + args.up_scale\n",
    "        loss_train = F.cross_entropy(output[idx_train_new], labels_new[idx_train_new], weight=weight)\n",
    "    else:\n",
    "        loss_train = F.cross_entropy(output[idx_train_new], labels_new[idx_train_new])\n",
    "\n",
    "    acc_train = accuracy(output[train_idx], labels_new[train_idx])\n",
    "    if args.setting == 'recon_newG':\n",
    "        loss = loss_train + loss_rec * args.rec_weight\n",
    "    elif args.setting == 'recon':\n",
    "        loss = loss_rec + 0 * loss_train\n",
    "    else:\n",
    "        loss = loss_train\n",
    "        loss_rec = loss_train\n",
    "\n",
    "    loss.backward()\n",
    "    if args.setting == 'newG_cls':\n",
    "        optimizer_en.zero_grad()\n",
    "        optimizer_de.zero_grad()\n",
    "    else:\n",
    "        optimizer_en.step()\n",
    "\n",
    "    optimizer_cls.step()\n",
    "\n",
    "    if args.setting == 'recon_newG' or args.setting == 'recon':\n",
    "        optimizer_de.step()\n",
    "\n",
    "    loss_val = F.cross_entropy(output[val_idx], labels[val_idx])\n",
    "    acc_val = accuracy(output[val_idx], labels[val_idx])\n",
    "\n",
    "    print('Epoch: {:05d}'.format(epoch+1),\n",
    "          'loss_train: {:.4f}'.format(loss_train.item()),\n",
    "          'loss_rec: {:.4f}'.format(loss_rec.item()),\n",
    "          'acc_train: {:.4f}'.format(acc_train.item()),\n",
    "          'loss_val: {:.4f}'.format(loss_val.item()),\n",
    "          'acc_val: {:.4f}'.format(acc_val.item()),\n",
    "          'time: {:.4f}s'.format(time.time() - t))\n",
    "\n",
    "for epoch in range(args.epochs):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train & eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import networkx as nx\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "import pickle\n",
    "\n",
    "\n",
    "def encode_onehot_torch(labels):\n",
    "    num_classes = int(labels.max() + 1)\n",
    "    y = torch.eye(num_classes)\n",
    "    return y[labels]\n",
    "\n",
    "\n",
    "def encode_onehot(labels):\n",
    "    classes = set(labels)\n",
    "    classes_dict = {c: np.identity(len(classes))[i, :] for i, c in\n",
    "                    enumerate(classes)}\n",
    "    labels_onehot = np.array(list(map(classes_dict.get, labels)),\n",
    "                             dtype=np.int32)\n",
    "    return labels_onehot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('arc_selection-master')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "04f122987ad9a59b0c863ec73977cb4833edd644652b774e5b01a9e2fe636c23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
