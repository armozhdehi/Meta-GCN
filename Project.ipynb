{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install higher tensorboard scipy networkx scikit-learn\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from torchvision import datasets,transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "from torch import autograd\n",
    "import higher\n",
    "import itertools\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import networkx as nx\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "import pickle\n",
    "import math\n",
    "import torch\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "import argparse\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "import torch\n",
    "import ipdb\n",
    "from scipy.io import loadmat\n",
    "import networkx as nx\n",
    "import multiprocessing as mp\n",
    "import torch.nn.functional as F\n",
    "from functools import partial\n",
    "import random\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from copy import deepcopy\n",
    "from scipy.spatial.distance import pdist,squareform\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import ipdb\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "import torch\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch.nn.modules.module import Module\n",
    "from torch.nn import init\n",
    "import argparse\n",
    "import scipy.sparse as sp\n",
    "import numpy as np\n",
    "import torch\n",
    "import ipdb\n",
    "from scipy.io import loadmat\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import networkx as nx\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "import pickle\n",
    "import torch.nn.functional as F\n",
    "import itertools as it\n",
    "import matplotlib.pyplot as plt\n",
    "# torch.backends.cudnn.enabled = True\n",
    "# torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GCN layer based on : https://arxiv.org/abs/1609.02907"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphConvolution(Module):\n",
    "    def __init__(self, in_features, out_features, order, bias=True):\n",
    "        super(GraphConvolution, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.order = order\n",
    "        self.weight = torch.nn.ParameterList([])\n",
    "        for i in range(self.order):\n",
    "            self.weight.append(Parameter(torch.FloatTensor(in_features, out_features)))\n",
    "        if bias:\n",
    "            self.bias = Parameter(torch.FloatTensor(out_features))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        for i in range(self.order):\n",
    "            stdv = 1. / math.sqrt(self.weight[i].size(1))\n",
    "            self.weight[i].data.uniform_(-stdv, stdv)\n",
    "        if self.bias is not None:\n",
    "            self.bias.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, input, adj_mtx):\n",
    "        output = []\n",
    "        if self.order == 1 and type(adj_mtx) != list:\n",
    "            adj = [adj_mtx]\n",
    "        for i in range(self.order):\n",
    "            support = torch.mm(input, self.weight[i])\n",
    "            # output.append(support)\n",
    "            output.append(torch.mm(adj_mtx[i], support))\n",
    "        output = sum(output)\n",
    "        if self.bias is not None:\n",
    "            return output + self.bias\n",
    "        else:\n",
    "            return output\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "               + str(self.in_features) + ' -> ' \\\n",
    "               + str(self.out_features) + ')'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_decay = 5e-4\n",
    "epochs = 1000\n",
    "learning_rate_D = 0.01\n",
    "learning_rate_W = 0.01\n",
    "dropout_D = 0.5\n",
    "dropout_W = 0.5\n",
    "gamma = 1\n",
    "no_cuda = False\n",
    "train_ratio=0.6\n",
    "test_ratio=0.2\n",
    "n_classes = 2\n",
    "seed_num = 17\n",
    "torch.manual_seed(seed_num)\n",
    "dataset = \"diabetes\"\n",
    "order = 4\n",
    "n_features = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate the Pima Indian Diabetes (Diabetes) graph through the method used in : https://arxiv.org/abs/2103.00221"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_df = pd.read_csv('./data/diabetes.csv')\n",
    "# print(diabetes_df.head(10))\n",
    "G = nx.Graph()\n",
    "gam = 4\n",
    "for patient_id, row_vals in diabetes_df.iterrows():\n",
    "    G.add_node(str(patient_id), \n",
    "    pregnancies = row_vals[0], \n",
    "    # glucose = row_vals[1], \n",
    "    bloodpressure = row_vals[2], \n",
    "    skinthickness = row_vals[3], \n",
    "    insulin = row_vals[4], \n",
    "    bmi = row_vals[5], \n",
    "    diabetespedigreefunction = row_vals[6], \n",
    "    age = row_vals[7]) \n",
    "    # , outcome = row_vals[8])\n",
    "# Two loops because of the order problem of NetworkX\n",
    "for patient_id, row_vals in diabetes_df.iterrows():\n",
    "    for other_patient_id in range(patient_id + 1, diabetes_df.shape[0]):\n",
    "        if abs(diabetes_df.iloc[[other_patient_id], 1].values[0] - diabetes_df.iloc[[patient_id], 1].values[0]) < gam:\n",
    "            G.add_edge(*(str(patient_id), str(other_patient_id)))\n",
    "diabetes_adj_mtx = nx.to_numpy_matrix(G)\n",
    "# print(diabetes_adj_mtx)\n",
    "# print(G)\n",
    "# pd.DataFrame(diabetes_adj_mtx).to_csv(\"data/diabetes_adj_mtx.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Habermanâ€™s survival (Haberman) graph through the method used in : https://arxiv.org/abs/2103.00221"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "haberman_df = pd.read_csv('./data/haberman.csv')\n",
    "# print(diabetes_df.head(10))\n",
    "G = nx.Graph()\n",
    "gam = 2\n",
    "for patient_id, row_vals in haberman_df.iterrows():\n",
    "    G.add_node(str(patient_id),\n",
    "        age = row_vals[0],\n",
    "        operation_year = row_vals[1],\n",
    "        lymph_nodes = row_vals[2],\n",
    "    )\n",
    "    # survival = row_vals[3])\n",
    "for patient_id, row_vals in haberman_df.iterrows():\n",
    "    for other_patient_id in range(patient_id + 1, haberman_df.shape[0]):\n",
    "        if abs(haberman_df.iloc[[other_patient_id], 2].values[0] - haberman_df.iloc[[patient_id], 2].values[0]) < gam:\n",
    "            G.add_edge(*(str(patient_id), str(other_patient_id)))\n",
    "haberman_adj_mtx = nx.to_numpy_matrix(G)\n",
    "# print(haberman_adj_mtx)\n",
    "# print(G)\n",
    "# pd.DataFrame(diabetes_adj_mtx).to_csv(\"data/haberman_adj_mtx.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(mx, dim):\n",
    "    mx = torch.sigmoid(mx)\n",
    "    return F.normalize(mx, p=1, dim=dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset specific variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dataset == \"diabetes\":\n",
    "    adj_mtx = diabetes_adj_mtx\n",
    "    n_features = 7\n",
    "    n_hidden = [256, 265, 256, 256]\n",
    "elif dataset == \"haberman\":\n",
    "    adj_mtx = haberman_adj_mtx\n",
    "    n_features = 2\n",
    "    n_hidden = [256, 265]\n",
    "else:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wighted_GCN(nn.Module):\n",
    "    def __init__(self, n_feat, n_hid, n_class, dropout, order):\n",
    "        super(Wighted_GCN, self).__init__()\n",
    "        layers = []\n",
    "        if len(n_hid) == 0:\n",
    "            layers.append(GraphConvolution(n_feat, n_class, order=order))\n",
    "        else:\n",
    "            layers.append(GraphConvolution(n_feat, n_hid[0], order=order))\n",
    "            for i in range(len(n_hid) - 1):\n",
    "                layers.append(GraphConvolution(n_hid[i], n_hid[i + 1], order=order))\n",
    "        if n_class > 1:\n",
    "            layers.append(GraphConvolution(n_hid[-1], n_class, order=order))\n",
    "        self.gc = nn.ModuleList(layers)\n",
    "\n",
    "        self.dropout = dropout\n",
    "        self.nclass = n_class\n",
    "\n",
    "    def forward(self, x, adj, samples=-1, func=F.relu):\n",
    "        end_layer = len(self.gc) - 1 if self.nclass > 1 else len(self.gc)\n",
    "        for i in range(end_layer):\n",
    "            x = F.dropout(x, self.dropout, training=self.training)\n",
    "            x = self.gc[i](x, adj)\n",
    "            x = func(x)\n",
    "\n",
    "        if self.nclass > 1:\n",
    "            classifier = self.gc[-1](x, adj)\n",
    "            classifier = F.log_softmax(classifier, dim=1)\n",
    "            return classifier[samples,:], x\n",
    "        else:\n",
    "            return None, x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('arc_selection-master')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "04f122987ad9a59b0c863ec73977cb4833edd644652b774e5b01a9e2fe636c23"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
